# üß† Context Management Modes

> **Optimize context processing for maximum performance and accuracy across different scenarios**

The Context Management system provides intelligent switching between high-performance and full-featured context processing modes, automatically adapting to your current environment and needs.

## üéØ Quick Start

The context management system runs automatically, but you can control and monitor it:

```bash
# Check current context mode
curl http://localhost:5000/api/context/status

# Switch to specific mode
curl -X POST http://localhost:5000/api/context/switch \
  -H "Content-Type: application/json" \
  -d '{"mode": "simple"}'

# Test context preparation performance
curl -X POST http://localhost:5000/api/context/test \
  -H "Content-Type: application/json" \
  -d '{"agent_type": "CodeAgent", "task": "Implement user authentication"}'
```

## üîÑ Context Modes Explained

### FANCY Mode (Full-Featured)
**Best for**: Production workflows requiring maximum accuracy and intelligence

```yaml
Features:
  - ‚úÖ Intelligent file filtering with ML-based relevance scoring
  - ‚úÖ Advanced compression algorithms and context optimization
  - ‚úÖ Predictive caching with agent memory integration
  - ‚úÖ Cross-story context management and dependency tracking
  - ‚úÖ Performance monitoring and adaptive optimization
  - ‚úÖ Background processing and context pre-warming

Performance Profile:
  - Preparation Time: 2-10 seconds
  - Memory Usage: 100-500MB
  - CPU Usage: High
  - Accuracy: Very High (95%+ relevant context)
  - Token Efficiency: Optimal compression
```

**When to use FANCY mode**:
- ‚úÖ Production development workflows
- ‚úÖ Complex projects with large codebases
- ‚úÖ When context accuracy is critical
- ‚úÖ Long-running development sessions
- ‚úÖ Multi-story epic management

### SIMPLE Mode (High-Performance)
**Best for**: Fast operations, testing, and resource-constrained environments

```yaml
Features:
  - ‚ö° Fast pattern-based file matching
  - ‚ö° Token-based truncation with configurable limits
  - ‚ö° Simple LRU caching (10-50 contexts)
  - ‚ö° Minimal CPU and memory overhead
  - ‚ö° Mock interface compatibility
  - ‚ö° CI/CD optimized performance

Performance Profile:
  - Preparation Time: 0.1-1 seconds (10x faster)
  - Memory Usage: 10-50MB (5x less)
  - CPU Usage: Low
  - Accuracy: Good (80%+ relevant context)
  - Token Efficiency: Basic truncation
```

**When to use SIMPLE mode**:
- ‚úÖ Demo scenarios and presentations
- ‚úÖ Mock interface operations
- ‚úÖ High-frequency context preparation
- ‚úÖ Resource-constrained environments
- ‚úÖ CI/CD testing pipelines
- ‚úÖ Quick prototyping sessions

### AUTO Mode (Intelligent Detection)
**Best for**: Dynamic environments where optimal mode varies

```yaml
Auto-Detection Logic:
  - üîç Mock interface active ‚Üí SIMPLE mode
  - üîç CI environment detected ‚Üí SIMPLE mode  
  - üîç Low memory (<2GB) ‚Üí SIMPLE mode
  - üîç Performance mode env var ‚Üí SIMPLE mode
  - üîç Claude Code unavailable ‚Üí SIMPLE mode
  - üîç Full capabilities available ‚Üí FANCY mode

Benefits:
  - Zero configuration required
  - Optimal performance for current environment
  - Automatic adaptation to system resources
  - Seamless switching based on usage patterns
```

**When to use AUTO mode**:
- ‚úÖ Mixed development environments
- ‚úÖ Default configuration for new installations
- ‚úÖ Dynamic resource availability
- ‚úÖ Multi-user shared systems
- ‚úÖ Cloud deployments with variable resources

## ‚öôÔ∏è Configuration Management

### Configuration File Structure

Context management is configured via YAML files:

```yaml
# .orch-state/context_config.yaml

# Core Settings
default_mode: auto              # auto, fancy, or simple
max_tokens: 200000             # Maximum tokens for context
cache_ttl_seconds: 300         # Cache time-to-live

# FANCY Mode Settings
enable_intelligence: true      # Enable ML-based filtering
enable_advanced_caching: true  # Enable predictive caching
enable_monitoring: true        # Enable performance monitoring
enable_cross_story: true      # Enable cross-story management
enable_background_processing: true  # Enable background tasks
max_preparation_time: 30       # Maximum prep time (seconds)

# SIMPLE Mode Settings  
simple_max_files: 10          # Maximum files to process
simple_max_file_size: 50000   # Maximum characters per file
simple_enable_caching: true   # Enable basic caching
simple_cache_size: 50         # Number of contexts to cache

# Auto-Detection Settings
auto_detection_enabled: true   # Enable automatic mode detection
force_simple_in_ci: true      # Force simple mode in CI
force_simple_with_mock: true  # Force simple mode with mock interfaces
min_memory_for_fancy: 2048    # Minimum memory (MB) for fancy mode
min_cpu_cores_for_fancy: 2    # Minimum CPU cores for fancy mode

# Performance Thresholds
max_fancy_preparation_time: 10.0   # Max fancy prep time (seconds)
max_simple_preparation_time: 1.0   # Max simple prep time (seconds)

# Auto-Switching Rules
auto_switch_enabled: true     # Enable automatic mode switching
switch_threshold_failures: 3  # Failures before switching modes
switch_cooldown_seconds: 60   # Cooldown between switches
```

### Environment Variables

Control context management through environment variables:

```bash
# Force specific mode
export AGENT_WORKFLOW_CONTEXT_MODE=simple

# Enable performance mode (forces simple)
export AGENT_WORKFLOW_PERFORMANCE_MODE=true

# Configure resource thresholds
export AGENT_WORKFLOW_MIN_MEMORY=4096
export AGENT_WORKFLOW_MAX_PREP_TIME=5.0

# Debug context management
export AGENT_CONTEXT_DEBUG=true
```

### Web Interface Configuration

Use the web interface for interactive configuration:

```
‚îå‚îÄ Context Management ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                       ‚îÇ
‚îÇ Current Mode: AUTO                üéØ Auto-Detected    ‚îÇ
‚îÇ Active Manager: FancyContextManager                   ‚îÇ
‚îÇ                                                       ‚îÇ
‚îÇ ‚îå‚îÄ Mode Selection ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ ‚îÇ ‚óã AUTO    Intelligent automatic detection       ‚îÇ  ‚îÇ
‚îÇ ‚îÇ ‚óè FANCY   Full-featured processing              ‚îÇ  ‚îÇ  
‚îÇ ‚îÇ ‚óã SIMPLE  High-performance minimal overhead     ‚îÇ  ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                       ‚îÇ
‚îÇ ‚îå‚îÄ Performance Metrics ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ ‚îÇ Preparation Time: 2.3s                         ‚îÇ  ‚îÇ
‚îÇ ‚îÇ Memory Usage: 245MB                             ‚îÇ  ‚îÇ
‚îÇ ‚îÇ Cache Hit Rate: 78%                             ‚îÇ  ‚îÇ
‚îÇ ‚îÇ Files Processed: 23/150                         ‚îÇ  ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                       ‚îÇ
‚îÇ [Switch Mode] [Test Performance] [Configure]         ‚îÇ
‚îÇ                                                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìä Performance Comparison

### Benchmark Results

Performance comparison across different scenarios:

| Scenario | FANCY Mode | SIMPLE Mode | Performance Gain |
|----------|------------|-------------|------------------|
| Small Project (<50 files) | 1.2s | 0.15s | **8x faster** |
| Medium Project (200 files) | 4.8s | 0.35s | **14x faster** |
| Large Project (1000+ files) | 12.3s | 0.8s | **15x faster** |
| Memory Usage (Avg) | 280MB | 35MB | **8x less memory** |
| Context Accuracy | 95% | 82% | 13% accuracy trade-off |

### Resource Utilization

```yaml
FANCY Mode Resource Profile:
  CPU: High initial spike, then moderate
  Memory: Gradual increase with caching
  Disk I/O: Moderate with intelligent filtering
  Network: Minimal (local processing)

SIMPLE Mode Resource Profile:
  CPU: Low constant usage
  Memory: Minimal with bounded cache
  Disk I/O: Low with pattern matching
  Network: None
```

### Context Quality Analysis

```python
# Context quality metrics
{
  "fancy_mode": {
    "relevant_files_ratio": 0.95,
    "token_efficiency": 0.88,
    "dependency_coverage": 0.92,
    "cross_reference_accuracy": 0.89
  },
  "simple_mode": {
    "relevant_files_ratio": 0.82,
    "token_efficiency": 0.65,
    "dependency_coverage": 0.71,
    "cross_reference_accuracy": 0.58
  }
}
```

## üîç Mode Detection Logic

### Automatic Detection Factors

The AUTO mode considers multiple factors to choose the optimal mode:

```python
def detect_optimal_mode() -> ContextMode:
    """Intelligent mode detection algorithm"""
    
    # 1. Interface Detection
    if is_mock_interface_active():
        return ContextMode.SIMPLE
    
    # 2. Environment Detection  
    if is_ci_environment():
        return ContextMode.SIMPLE
        
    # 3. Resource Assessment
    if get_available_memory() < 2048:  # 2GB
        return ContextMode.SIMPLE
        
    if get_cpu_count() < 2:
        return ContextMode.SIMPLE
    
    # 4. Performance Mode Override
    if os.getenv("AGENT_WORKFLOW_PERFORMANCE_MODE"):
        return ContextMode.SIMPLE
        
    # 5. Claude Code Availability
    if not is_claude_code_available():
        return ContextMode.SIMPLE
        
    # Default to full capabilities
    return ContextMode.FANCY
```

### Detection Status Monitoring

Monitor detection factors in real-time:

```json
{
  "detection_status": {
    "current_mode": "auto",
    "detected_mode": "fancy",
    "detection_factors": {
      "mock_interface_active": false,
      "ci_environment": false,
      "low_memory": false,
      "performance_mode_env": false,
      "claude_code_available": true
    },
    "system_resources": {
      "available_memory_mb": 8192,
      "cpu_cores": 8,
      "disk_space_gb": 256
    }
  }
}
```

## üß™ Testing and Optimization

### Performance Testing

Test context preparation performance across modes:

```bash
# Test current mode performance
curl -X POST http://localhost:5000/api/context/test \
  -H "Content-Type: application/json" \
  -d '{
    "agent_type": "CodeAgent",
    "task": "Implement user authentication system",
    "test_iterations": 10
  }'
```

Response includes detailed performance metrics:

```json
{
  "success": true,
  "mode": "fancy",
  "average_preparation_time": 2.34,
  "memory_usage_mb": 245,
  "token_usage": {
    "total_tokens": 45230,
    "core_task_tokens": 12450,
    "compression_ratio": 0.72
  },
  "file_statistics": {
    "total_files_scanned": 147,
    "relevant_files_selected": 23,
    "selection_accuracy": 0.89
  },
  "cache_performance": {
    "cache_hit_rate": 0.78,
    "cache_size_mb": 67
  }
}
```

### A/B Testing Framework

Compare modes side-by-side for your specific use cases:

```python
# Run comparative testing
POST /api/context/compare-modes
{
  "test_scenarios": [
    {
      "name": "user_auth_feature",
      "agent_type": "CodeAgent", 
      "task": "Implement OAuth login flow"
    },
    {
      "name": "database_migration",
      "agent_type": "DataAgent",
      "task": "Design user table migration"
    }
  ],
  "modes_to_test": ["fancy", "simple"],
  "iterations": 5
}
```

### Optimization Recommendations

The system provides automatic optimization suggestions:

```yaml
Optimization Analysis:
  current_mode: fancy
  performance_score: 78/100
  
  recommendations:
    - Consider SIMPLE mode for CI/testing (40% faster)
    - Enable background pre-warming for 15% improvement  
    - Increase cache size for better hit rates
    - Fine-tune file filtering patterns
    
  mode_suitability:
    fancy: "Good for complex tasks, consider optimization"
    simple: "Excellent for testing and demos"
    auto: "Recommended for mixed workloads"
```

## üîÑ Dynamic Mode Switching

### Automatic Switching Triggers

The system can automatically switch modes based on performance:

```yaml
Auto-Switch Scenarios:
  - FANCY mode taking >10s ‚Üí Switch to SIMPLE
  - Memory usage >80% ‚Üí Switch to SIMPLE  
  - 3+ consecutive failures ‚Üí Switch to fallback mode
  - CI environment detected ‚Üí Force SIMPLE
  - Mock interface activated ‚Üí Force SIMPLE

Cooldown Rules:
  - Minimum 60 seconds between switches
  - Maximum 3 switches per hour
  - Manual override always available
```

### Manual Mode Switching

Switch modes manually through the web interface or API:

```bash
# Switch to SIMPLE mode
curl -X POST http://localhost:5000/api/context/switch \
  -H "Content-Type: application/json" \
  -d '{"mode": "simple"}'

# Switch back to AUTO mode
curl -X POST http://localhost:5000/api/context/switch \
  -H "Content-Type: application/json" \
  -d '{"mode": "auto"}'
```

### Hot-Swapping

Mode switches happen without interrupting active operations:

1. **Graceful Transition**: Current context preparations complete
2. **State Preservation**: Cache and configuration maintained
3. **Zero Downtime**: New requests use new mode immediately
4. **Rollback Available**: Automatic rollback on switch failure

## üîß Troubleshooting

### Common Issues

**Mode Detection Not Working**:
```bash
# Check detection status
curl http://localhost:5000/api/context/status

# View detection factors
curl http://localhost:5000/api/context/modes

# Check configuration
cat .orch-state/context_config.yaml
```

**Performance Issues**:
```bash
# Monitor preparation times
curl -X POST http://localhost:5000/api/context/test

# Check resource usage
curl http://localhost:5000/api/context/performance

# Enable debug logging
export AGENT_CONTEXT_DEBUG=true
```

**Configuration Errors**:
```bash
# Validate configuration
python -c "
from lib.context_config import ContextConfig
config = ContextConfig.from_file('.orch-state/context_config.yaml')
validation = config.validate()
print(validation)
"
```

### Error Codes Reference

| Error Code | Description | Solution |
|------------|-------------|----------|
| `MODE_SWITCH_FAILED` | Unable to switch modes | Check configuration and retry |
| `PREPARATION_TIMEOUT` | Context preparation timed out | Switch to SIMPLE mode or increase timeout |
| `RESOURCE_EXHAUSTED` | Insufficient system resources | Use SIMPLE mode or increase resources |
| `CONFIG_INVALID` | Configuration validation failed | Fix configuration file syntax |
| `CACHE_ERROR` | Context cache corruption | Clear cache and restart |

### Debug Mode

Enable comprehensive debugging:

```bash
# Enable debug logging
export AGENT_CONTEXT_DEBUG=true
export CONTEXT_FACTORY_DEBUG=true

# View debug logs
tail -f logs/context-manager.log

# Component-specific debugging
export CONTEXT_MANAGER_TRACE=true
export SIMPLE_CONTEXT_DEBUG=true
```

## üöÄ Advanced Configuration

### Custom Performance Thresholds

Fine-tune mode switching behavior:

```yaml
# Advanced performance configuration
performance_tuning:
  fancy_mode:
    max_preparation_time: 15.0
    memory_limit_mb: 1024
    cpu_usage_threshold: 0.8
    
  simple_mode:
    max_files: 20
    max_file_size: 100000
    cache_size: 100
    
  switching:
    failure_threshold: 2
    cooldown_seconds: 30
    rollback_enabled: true
```

### Integration with Monitoring

Connect context management to external monitoring:

```python
# Custom monitoring integration
from lib.context_manager_factory import get_context_manager_factory

factory = get_context_manager_factory()

# Get performance metrics
metrics = await factory.get_performance_comparison()

# Export to monitoring system
send_to_prometheus(metrics)
send_to_datadog(metrics)
```

### Custom Mode Implementation

Extend the system with custom context modes:

```python
class CustomContextManager(BaseContextManager):
    """Custom context processing implementation"""
    
    async def prepare_context(self, agent_type: str, task: dict) -> ContextResult:
        """Custom context preparation logic"""
        # Implement custom filtering, compression, etc.
        pass
        
    def get_performance_metrics(self) -> Dict[str, Any]:
        """Return custom performance metrics"""
        pass
```

---

## üìö Next Steps

- **[Agent Interface Management](agent-interface-management.md)**: Switch between AI backends
- **[Performance Monitoring](performance-monitoring.md)**: Monitor system performance and optimization
- **[Web Tool Guide](ui-portal-guide.md)**: Access context management through web interface
- **[API Reference](../development/api-reference.md)**: Complete API documentation

The context management system provides intelligent, adaptive context processing that automatically optimizes for your current environment and workload. Use AUTO mode for hands-off optimization, or manually tune modes for specific scenarios to achieve the perfect balance of speed and accuracy.