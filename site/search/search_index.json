{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AI Agent TDD-Scrum Workflow","text":"<p>A sophisticated Human-In-The-Loop (HITL) orchestration framework that coordinates multiple specialized AI agents through a Discord interface, following a research-mode Scrum methodology optimized for solo engineers working with AI assistance.</p>"},{"location":"#overview","title":"Overview","text":"<p>This system implements a sophisticated dual state machine architecture for AI-assisted software development with integrated Test-Driven Development and human oversight. It coordinates multiple TDD cycles in parallel while maintaining proper Scrum methodology, optimized for solo engineers working with AI assistance.</p>"},{"location":"#how-it-works","title":"How It Works","text":"<pre><code>flowchart LR\n    You[\"\ud83d\udc68\u200d\ud83d\udcbb&lt;br/&gt;YOU\"] \n    Chat[\"\ud83d\udcac&lt;br/&gt;Discord&lt;br/&gt;Chat\"]\n    AI[\"\ud83e\udd16&lt;br/&gt;AI Team&lt;br/&gt;Helper\"]\n    Code[\"\ud83d\udcdd&lt;br/&gt;Your&lt;br/&gt;Project\"]\n\n    You --&gt;|\"Tell it what to build\"| Chat\n    Chat --&gt;|\"Coordinates\"| AI\n    AI --&gt;|\"Builds &amp; tests\"| Code\n    Code --&gt;|\"Shows you progress\"| You\n\n    style You fill:#e3f2fd,stroke:#1976d2,stroke-width:3px\n    style Chat fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px\n    style AI fill:#e8f5e8,stroke:#388e3c,stroke-width:2px\n    style Code fill:#fff3e0,stroke:#f57c00,stroke-width:2px</code></pre> <p>The Big Picture: You tell the system what you want to build through simple Discord messages. A team of AI agents collaborates to design, code, test, and improve your project while keeping you in control of every major decision.</p>"},{"location":"#detailed-system-architecture","title":"Detailed System Architecture","text":"<pre><code>graph TB\n    subgraph \"\ud83d\udc64 Solo Engineer\"\n        User[User]\n    end\n\n    subgraph DISCORD [\"\ud83c\udfae Discord Interface\"]\n        Discord[\"/epic /sprint /approve&lt;br/&gt;Slash Commands\"]\n        State[Interactive State&lt;br/&gt;Visualization]\n    end\n\n    subgraph WORKFLOW [\"\ud83e\udd16 TDD-Scrum Workflow System\"]\n        subgraph \"\ud83c\udf9b\ufe0f Control Layer\"\n            SM[Workflow State Machine&lt;br/&gt;IDLE - BACKLOG - SPRINT]\n            HITL[Approval Gates&lt;br/&gt;Strategic Decisions]\n            PM[Persistent Storage&lt;br/&gt;Epics - Stories - Tasks]\n        end\n\n        subgraph \"\ud83c\udfad Ephemeral Agents\"\n            Orch[\ud83c\udfad Orchestrator Agent&lt;br/&gt;Scrum Master&lt;br/&gt;spun up on demand]\n        end\n\n        subgraph \"\ud83d\udd04 TDD Execution Layer\"\n            TDD[TDD State Machine&lt;br/&gt;DESIGN - TEST - CODE - REFACTOR]\n            Design[\ud83c\udfa8 Design Agent&lt;br/&gt;Architecture and Specs]\n            QA[\ud83e\uddea Test Agent&lt;br/&gt;Write Tests First]\n            Code[\ud83d\udcbb Code Agent&lt;br/&gt;Make Tests Pass]\n            Data[\ud83d\udcca Analytics Agent&lt;br/&gt;Metrics and Coverage]\n        end\n    end\n\n    subgraph PROJECT [\"\ud83d\udcbe Your Project 1 to n\"]\n        Tests[\ud83e\uddea Test Suite&lt;br/&gt;RED - GREEN - REFACTOR]\n        Repo[\ud83d\udcc1 Git Repository&lt;br/&gt;Code &amp; Documentation]\n    end\n\n    User --&gt;|\"Commands\"| Discord\n    Discord &lt;--&gt;|\"Validates\"| SM\n    Discord --&gt;|\"Updates\"| State\n    State --&gt;|\"Progress\"| User\n\n    SM --&gt;|\"Spins up\"| Orch\n    Orch --&gt;|\"Decisions\"| SM\n    SM &lt;--&gt;|\"Enforces\"| HITL\n    SM &lt;--&gt;|\"Reads/Writes\"| PM\n\n    Orch --&gt;|\"Plans Sprint\"| PM\n    PM --&gt;|\"Assigns Story\"| TDD\n    TDD --&gt;|\"1 Design\"| Design\n    Design --&gt;|\"Specs\"| TDD\n    TDD --&gt;|\"2 Test\"| QA\n    QA --&gt;|\"Tests\"| Tests\n    TDD --&gt;|\"3 Code\"| Code\n    Code &lt;--&gt;|\"TDD Cycle\"| Tests\n    TDD --&gt;|\"4 Analyze\"| Data\n    Data --&gt;|\"Metrics\"| TDD\n\n    TDD --&gt;|\"Story Complete\"| SM\n    HITL &lt;--&gt;|\"Approvals\"| Discord\n\n    Code --&gt;|\"Commits\"| Repo\n    Tests --&gt;|\"Validates\"| Repo\n\n    style User fill:#e1f5fe,stroke:#0277bd,stroke-width:3px\n    style DISCORD fill:#f8f4ff,stroke:#7b1fa2,stroke-width:3px\n    style WORKFLOW fill:#f0f8f0,stroke:#388e3c,stroke-width:3px\n    style PROJECT fill:#fff8e1,stroke:#f57c00,stroke-width:3px\n    style Discord fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px\n    style State fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px\n    style SM fill:#ff6b6b,stroke:#c92a2a,stroke-width:3px\n    style PM fill:#fff3e0,stroke:#f57c00,stroke-width:2px\n    style HITL fill:#fff3e0,stroke:#f57c00,stroke-width:2px\n    style Orch fill:#ffd43b,stroke:#fab005,stroke-width:3px\n    style TDD fill:#4dabf7,stroke:#1971c2,stroke-width:3px\n    style Design fill:#f1f8e9,stroke:#388e3c,stroke-width:2px\n    style QA fill:#ffebee,stroke:#d32f2f,stroke-width:3px\n    style Code fill:#e8f5e8,stroke:#388e3c,stroke-width:2px\n    style Data fill:#fce4ec,stroke:#c2185b,stroke-width:2px\n    style Tests fill:#ffebee,stroke:#d32f2f,stroke-width:3px\n    style Repo fill:#e3f2fd,stroke:#1976d2,stroke-width:2px</code></pre>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#core-architecture","title":"Core Architecture","text":"<ul> <li>Dual State Machine Architecture: Primary workflow coordination with secondary TDD state machines</li> <li>Parallel TDD Processing: Multiple stories developed simultaneously with proper RED-GREEN-REFACTOR cycles</li> <li>Ephemeral Agent System: On-demand agent creation and coordination for optimal resource utilization</li> <li>Context Management System: Intelligent agent communication with optimized context sharing and memory management</li> </ul>"},{"location":"#multi-project-orchestration","title":"Multi-Project Orchestration","text":"<ul> <li>Global Resource Management: Intelligent allocation of CPU, memory, and agents across projects</li> <li>Cross-Project Intelligence: Pattern recognition and knowledge sharing between projects</li> <li>Project Prioritization: Priority-based scheduling and resource allocation</li> <li>Security Isolation: Project-level security boundaries and access control</li> </ul>"},{"location":"#human-in-the-loop-interface","title":"Human-In-The-Loop Interface","text":"<ul> <li>Discord Integration: Complete HITL interface with TDD-aware slash commands and interactive UI</li> <li>Real-time Monitoring: Live visibility into all TDD cycles with WebSocket-based updates</li> <li>Human Oversight: Strategic approval gates with automated TDD execution and error escalation</li> <li>Interactive State Visualization: Real-time state diagrams and progress tracking</li> </ul>"},{"location":"#quality-testing","title":"Quality &amp; Testing","text":"<ul> <li>TDD Methodology Enforcement: Strict RED-GREEN-REFACTOR cycle implementation</li> <li>Comprehensive Testing: Unit, integration, and E2E test coverage with TDD methodology enforcement</li> <li>Real-time State Visualizer: NO-AGENT validation mode for testing workflows</li> <li>Performance Analytics: TDD cycle time tracking and optimization insights</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Get up and running in minutes:</p> <pre><code># Clone and install\ngit clone https://github.com/jmontp/agent-workflow.git\ncd agent-workflow\nmake install\n\n# Configure\nexport DISCORD_BOT_TOKEN=\"your_token_here\"\n\n# Run\nmake run\n</code></pre> <p>\u2192 Detailed Installation Guide</p>"},{"location":"#dual-state-machine-workflow","title":"Dual State Machine Workflow","text":"<p>The system operates two coordinated state machines for complete TDD-Scrum integration:</p> <pre><code>stateDiagram-v2\n    [*] --&gt; IDLE\n    IDLE --&gt; BACKLOG_READY : /epic\n    BACKLOG_READY --&gt; SPRINT_PLANNED : /sprint plan\n    SPRINT_PLANNED --&gt; SPRINT_ACTIVE : /sprint start\n    SPRINT_ACTIVE --&gt; SPRINT_REVIEW : tasks complete\n    SPRINT_REVIEW --&gt; IDLE : /feedback\n    SPRINT_ACTIVE --&gt; SPRINT_PAUSED : /sprint pause\n    SPRINT_PAUSED --&gt; SPRINT_ACTIVE : /sprint resume\n    SPRINT_ACTIVE --&gt; BLOCKED : CI fails 3\u00d7\n    BLOCKED --&gt; SPRINT_ACTIVE : /suggest_fix</code></pre>"},{"location":"#tdd-state-machine-per-story","title":"TDD State Machine (Per Story)","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; DESIGN\n    DESIGN --&gt; TEST_RED : specs complete\n    TEST_RED --&gt; CODE_GREEN : tests failing\n    CODE_GREEN --&gt; REFACTOR : tests passing\n    REFACTOR --&gt; COMMIT : quality gates met\n    COMMIT --&gt; [*] : story complete\n\n    REFACTOR --&gt; CODE_GREEN : tests broken\n    CODE_GREEN --&gt; TEST_RED : need more tests\n    TEST_RED --&gt; DESIGN : requirements unclear</code></pre> <p>Key TDD Commands: - <code>/tdd overview</code> - Monitor all active TDD cycles - <code>/tdd status AUTH-1</code> - Check specific story progress - <code>/tdd review_cycle AUTH-1</code> - Request human review - <code>/tdd metrics</code> - View TDD performance data</p> <p>\u2192 Complete State Machine Reference | \u2192 TDD Workflow Guide</p>"},{"location":"#ephemeral-ai-agent-system","title":"Ephemeral AI Agent System","text":"<p>Specialized agents are created on-demand for optimal resource utilization:</p>"},{"location":"#orchestrator-agent-temporary","title":"Orchestrator Agent (Temporary)","text":"<ul> <li>Sprint coordination and multi-task management</li> <li>Spun up during SPRINT_ACTIVE state</li> <li>Manages parallel TDD cycle execution</li> <li>Handles cross-story dependencies and coordination</li> </ul>"},{"location":"#design-agents-per-story","title":"Design Agents (Per Story)","text":"<ul> <li>Technical specifications for individual stories</li> <li>Created during TDD DESIGN phase</li> <li>Architecture decisions and interface definitions</li> <li>Destroyed after design phase completion</li> </ul>"},{"location":"#qa-agents-per-tdd-cycle","title":"QA Agents (Per TDD Cycle)","text":"<ul> <li>Test suite creation following TDD methodology</li> <li>Active during TEST_RED phase</li> <li>Comprehensive test coverage for story requirements</li> <li>Ensures proper failing tests before implementation</li> </ul>"},{"location":"#code-agents-per-tdd-cycle","title":"Code Agents (Per TDD Cycle)","text":"<ul> <li>Implementation during CODE_GREEN and REFACTOR phases</li> <li>Makes tests pass with minimal implementation</li> <li>Applies refactoring while maintaining green tests</li> <li>Handles version control and final commits</li> </ul>"},{"location":"#analytics-agent-persistent","title":"Analytics Agent (Persistent)","text":"<ul> <li>Cross-story metrics and performance analysis</li> <li>TDD cycle time tracking and optimization</li> <li>Sprint progress reporting and forecasting</li> <li>Continuous process improvement insights</li> </ul> <p>\u2192 Agent Capabilities Reference</p>"},{"location":"#essential-commands","title":"Essential Commands","text":"<p>Master these key slash commands for dual state machine control:</p>"},{"location":"#workflow-commands","title":"Workflow Commands","text":"Command Purpose Example <code>/epic</code> Define high-level initiatives <code>/epic \"Build authentication system\"</code> <code>/sprint plan</code> Plan sprint with stories <code>/sprint plan AUTH-1 AUTH-2</code> <code>/sprint start</code> Begin sprint execution (creates TDD cycles) <code>/sprint start</code> <code>/approve</code> Approve pending tasks <code>/approve AUTH-1 AUTH-2</code> <code>/state</code> Interactive state inspection <code>/state</code>"},{"location":"#tdd-commands","title":"TDD Commands","text":"Command Purpose Example <code>/tdd overview</code> Monitor all TDD cycles <code>/tdd overview</code> <code>/tdd status</code> Check specific story progress <code>/tdd status AUTH-1</code> <code>/tdd review_cycle</code> Request human review <code>/tdd review_cycle AUTH-1</code> <code>/tdd metrics</code> View TDD performance data <code>/tdd metrics</code> <code>/tdd pause/resume</code> Control TDD cycle execution <code>/tdd pause AUTH-1</code> <p>\u2192 Complete Command Reference</p>"},{"location":"#architecture","title":"Architecture","text":"<p>The system uses a clean layered architecture:</p> <ul> <li>Scripts Layer: Executable orchestrator entry points</li> <li>Library Layer: Core business logic and agents</li> <li>Interface Layer: Discord bot and external integrations</li> <li>Data Layer: State persistence and configuration</li> </ul> <p>\u2192 Detailed Architecture Documentation</p>"},{"location":"#testing-quality","title":"Testing &amp; Quality","text":"<p>Comprehensive testing strategy ensures reliability:</p> <ul> <li>Unit Tests: State machine validation and component testing</li> <li>Integration Tests: Orchestrator workflows and agent coordination  </li> <li>E2E Tests: Complete user scenarios and error handling</li> <li>Coverage Target: &gt;90% code coverage with automated reporting</li> </ul> <p>\u2192 Testing Strategy &amp; Implementation</p>"},{"location":"#contributing","title":"Contributing","text":"<p>We welcome contributions! The system is designed for extensibility:</p> <ol> <li>Fork the repository</li> <li>Create a feature branch</li> <li>Implement with tests</li> <li>Submit a pull request</li> </ol> <p>\u2192 Contributing Guidelines</p>"},{"location":"#documentation-sections","title":"Documentation Sections","text":"Section Description Getting Started Installation, setup, and TDD workflow examples User Guide Commands, workflows, and daily usage TDD Workflow Complete TDD cycle management and monitoring Multi-Project Orchestration Managing multiple projects simultaneously State Machines Dual state machine architecture and transitions Architecture Dual state machine system design and coordination Context Management Intelligent agent communication and context optimization Parallel TDD Architecture Multi-story TDD processing with conflict resolution Concepts Core principles and ephemeral agent patterns Advanced Detailed technical implementation Security Implementation Multi-project security and isolation Testing Strategy Comprehensive testing approach and TDD validation Deployment Production setup and configuration <p>Getting Help</p> <ul> <li>Check the Command Reference for syntax</li> <li>Use <code>/state</code> in Discord to see available commands</li> <li>Review Common Workflows for examples</li> <li>See Troubleshooting for issues</li> </ul>"},{"location":"STYLE_GUIDE/","title":"Documentation Style Guide","text":"<p>This style guide ensures consistent, professional, and visually appealing documentation across the AI Agent TDD-Scrum Workflow system while maintaining maximum information density.</p>"},{"location":"STYLE_GUIDE/#visual-hierarchy-principles","title":"Visual Hierarchy Principles","text":""},{"location":"STYLE_GUIDE/#1-heading-structure","title":"1. Heading Structure","text":"<p>Use consistent heading levels to create clear information hierarchy:</p> <pre><code># Page Title (H1) - Only one per page\n## Major Section (H2) - Primary content divisions\n### Subsection (H3) - Secondary divisions\n#### Detail Section (H4) - Specific topics\n##### Minor Detail (H5) - Rarely used\n</code></pre> <p>Best Practices: - Skip heading levels sparingly (H1 \u2192 H3 is acceptable if logical) - Use descriptive, action-oriented headings - Keep headings concise but informative - Add emoji strategically for visual scanning (\ud83c\udfaf for objectives, \ud83d\udd27 for technical details, \u26a0\ufe0f for warnings)</p>"},{"location":"STYLE_GUIDE/#2-content-organization-patterns","title":"2. Content Organization Patterns","text":""},{"location":"STYLE_GUIDE/#command-reference-pattern","title":"Command Reference Pattern","text":"<pre><code>**`/command syntax`**\nBrief description in sentence case.\n\n**Example:**\n```bash\n/example usage\n</code></pre> <p>Use case: When to use this command. <pre><code>#### Feature Overview Pattern\n```markdown\n### \ud83c\udfaf Feature Name\nBrief introduction paragraph explaining the feature's purpose and value.\n\n#### How It Works\nTechnical explanation with visual aids.\n\n#### Key Benefits\n- Benefit 1 with specific value\n- Benefit 2 with measurable impact\n- Benefit 3 with user advantage\n\n#### Quick Start\n```bash\n# Minimal example\ncommand --option value\n</code></pre></p> <p>\u2192 Detailed Guide <pre><code>#### Process Flow Pattern\n```markdown\n### Step-by-Step Process\n\n#### Phase 1: Setup\n**What happens automatically:**\n- System behavior 1\n- System behavior 2\n\n**Human interaction:**\n```bash\n/command example\n# Expected output or behavior\n</code></pre></p> <p>Artifacts created: - File 1: Purpose and location - File 2: Purpose and location <pre><code>## Visual Elements and Formatting\n\n### 1. Emphasis and Highlighting\n\n#### Text Emphasis\n- **Bold** for commands, file names, important concepts\n- *Italic* for emphasis, first use of technical terms\n- `Inline code` for code snippets, variables, file paths\n- **`Combined bold + code`** for command names in text\n\n#### Callout Boxes\nUse MkDocs admonitions for important information:\n\n```markdown\n!!! tip \"Pro Tip\"\n    Use this pattern for helpful hints and best practices.\n\n!!! warning \"Important\"\n    Critical information that prevents errors or problems.\n\n!!! danger \"Security Alert\"\n    Security-related warnings and requirements.\n\n!!! info \"Technical Detail\"\n    Additional context for advanced users.\n\n!!! success \"Best Practice\"\n    Recommended approaches and patterns.\n\n!!! example \"Real-World Example\"\n    Practical examples and use cases.\n</code></pre></p>"},{"location":"STYLE_GUIDE/#2-code-and-commands","title":"2. Code and Commands","text":""},{"location":"STYLE_GUIDE/#code-block-standards","title":"Code Block Standards","text":"<pre><code>```bash\n# Use bash for shell commands with helpful comments\n/command --option value  # What this does\n</code></pre> <pre><code># Use proper language highlighting\ndef example_function():\n    \"\"\"Clear docstring.\"\"\"\n    return \"formatted_code\"\n</code></pre> <p><pre><code># Configuration examples with comments\nkey: value  # Purpose of this setting\n</code></pre> <pre><code>#### Command Documentation Format\n```markdown\n**`/command &lt;required&gt; [optional]`**\nClear description of what the command does.\n\n**Parameters:**\n- `required`: Description and constraints\n- `optional`: Description and default value\n\n**Example:**\n```bash\n/command auth-system --priority high\n</code></pre></p> <p>Output: <pre><code>Expected response format\n</code></pre></p> <p>Use Cases: - When to use this command - Common scenarios and workflows <pre><code>### 3. Visual Aids and Diagrams\n\n#### Mermaid Diagram Standards\n```markdown\n```mermaid\ngraph TB\n    A[Clear Node Names] --&gt; B[Descriptive Labels]\n    B --&gt; C[Consistent Styling]\n\n    style A fill:#e3f2fd,stroke:#1976d2,stroke-width:2px\n    style B fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px\n    style C fill:#e8f5e8,stroke:#388e3c,stroke-width:2px\n</code></pre> <pre><code>**Diagram Best Practices:**\n- Use consistent color schemes for similar concepts\n- Keep node labels concise but descriptive\n- Add styling for visual distinction\n- Include legend when helpful\n- Ensure diagrams scale well on mobile\n\n#### Table Formatting\n```markdown\n| Command | Purpose | Example |\n|---------|---------|---------|\n| `/epic` | Define initiatives | `/epic \"Build auth system\"` |\n| `/sprint` | Manage sprints | `/sprint start` |\n\n**Table Guidelines:**\n- Keep columns balanced in width\n- Use consistent formatting within columns\n- Add examples for clarity\n- Break large tables into focused sections\n</code></pre></p>"},{"location":"STYLE_GUIDE/#content-structure-patterns","title":"Content Structure Patterns","text":""},{"location":"STYLE_GUIDE/#1-landing-page-structure","title":"1. Landing Page Structure","text":"<pre><code># Page Title\nCompelling one-sentence description of value proposition.\n\n## Overview\nBrief explanation of what this covers and why it matters.\n\n## Quick Start\nImmediate actionable content:\n```bash\n# Minimal working example\ncommand to get started\n</code></pre>"},{"location":"STYLE_GUIDE/#key-concepts","title":"Key Concepts","text":""},{"location":"STYLE_GUIDE/#concept-1","title":"Concept 1","text":"<p>Brief explanation with example.</p>"},{"location":"STYLE_GUIDE/#concept-2","title":"Concept 2","text":"<p>Brief explanation with example.</p>"},{"location":"STYLE_GUIDE/#detailed-sections","title":"Detailed Sections","text":"<p>[Link structure for deeper content]</p>"},{"location":"STYLE_GUIDE/#related-resources","title":"Related Resources","text":"<ul> <li>Link 1: What you'll find there</li> <li>Link 2: What you'll find there <pre><code>### 2. Reference Page Structure\n```markdown\n# Reference Title\nBrief description of scope and audience.\n\n## Quick Reference\nEssential information in scannable format.\n\n## Detailed Reference\n### Category 1\nDetailed information organized logically.\n\n### Category 2\nDetailed information organized logically.\n\n## Examples\nReal-world usage scenarios.\n\n## Troubleshooting\nCommon issues and solutions.\n</code></pre></li> </ul>"},{"location":"STYLE_GUIDE/#3-tutorial-page-structure","title":"3. Tutorial Page Structure","text":"<pre><code># Tutorial Title\nWhat you'll accomplish and prerequisites.\n\n## Prerequisites\n- Requirement 1\n- Requirement 2\n\n## Step 1: Setup\nClear instructions with expected outcomes.\n\n## Step 2: Implementation\nDetailed steps with verification points.\n\n## Step 3: Validation\nHow to confirm success.\n\n## Next Steps\nWhere to go from here.\n\n## Troubleshooting\nCommon issues specific to this tutorial.\n</code></pre>"},{"location":"STYLE_GUIDE/#cross-references-and-navigation","title":"Cross-References and Navigation","text":""},{"location":"STYLE_GUIDE/#1-link-patterns","title":"1. Link Patterns","text":"<pre><code># Internal Links\n[**\u2192 Detailed Guide**](relative/path.md)\n[**Complete Reference**](../reference/commands.md)\n\n# External Links\n[External Resource](https://example.com) (opens in new tab)\n\n# Section Links\n[Jump to Configuration](#configuration)\n</code></pre>"},{"location":"STYLE_GUIDE/#2-navigation-aids","title":"2. Navigation Aids","text":"<pre><code>## Quick Navigation\n| Section | Description |\n|---------|-------------|\n| [Getting Started](#getting-started) | Setup and first steps |\n| [Advanced Usage](#advanced-usage) | Power user features |\n| [Troubleshooting](#troubleshooting) | Common issues |\n\n---\n\n!!! tip \"Navigation Helper\"\n    Use the table of contents in the right sidebar to jump between sections.\n    Press `s` to open the search dialog.\n</code></pre>"},{"location":"STYLE_GUIDE/#icon-and-emoji-usage","title":"Icon and Emoji Usage","text":""},{"location":"STYLE_GUIDE/#1-strategic-icon-usage","title":"1. Strategic Icon Usage","text":"<p>Use icons to enhance scanning and navigation, not for decoration:</p> <pre><code>### \ud83c\udfaf Objectives (goals and targets)\n### \ud83d\udd27 Technical Details (implementation)\n### \ud83d\ude80 Quick Start (getting started)\n### \ud83d\udcca Metrics (data and analytics)\n### \u26a0\ufe0f Important (warnings and cautions)\n### \ud83d\udca1 Tips (helpful hints)\n### \ud83d\udd0d Examples (demonstrations)\n### \ud83c\udfd7\ufe0f Architecture (system design)\n### \ud83d\udd12 Security (security-related content)\n### \ud83d\udd04 Process (workflows and procedures)\n</code></pre>"},{"location":"STYLE_GUIDE/#2-functional-icons","title":"2. Functional Icons","text":"<pre><code>**Status Indicators:**\n- \u2705 Completed/Working\n- \u23f3 In Progress\n- \u274c Failed/Broken\n- \ud83d\udd04 Processing\n- \u23f8\ufe0f Paused\n\n**Action Indicators:**\n- \u25b6\ufe0f Start/Play\n- \u23f8\ufe0f Pause\n- \u23f9\ufe0f Stop\n- \ud83d\udd04 Restart/Refresh\n- \u26a1 Quick Action\n</code></pre>"},{"location":"STYLE_GUIDE/#accessibility-and-mobile-considerations","title":"Accessibility and Mobile Considerations","text":""},{"location":"STYLE_GUIDE/#1-mobile-friendly-formatting","title":"1. Mobile-Friendly Formatting","text":"<ul> <li>Keep tables narrow or use responsive design</li> <li>Break long code blocks into smaller sections</li> <li>Use collapsible sections for lengthy content</li> <li>Ensure diagrams scale appropriately</li> </ul>"},{"location":"STYLE_GUIDE/#2-accessibility-standards","title":"2. Accessibility Standards","text":"<ul> <li>Use descriptive link text</li> <li>Provide alt text for images</li> <li>Ensure sufficient color contrast</li> <li>Use semantic HTML structure</li> <li>Test with screen readers</li> </ul>"},{"location":"STYLE_GUIDE/#quality-checklist","title":"Quality Checklist","text":"<p>Before publishing any documentation page, verify:</p>"},{"location":"STYLE_GUIDE/#content-quality","title":"Content Quality","text":"<ul> <li> Clear, concise page title</li> <li> One-sentence value proposition</li> <li> Logical information hierarchy</li> <li> Working code examples</li> <li> Up-to-date information</li> <li> Proper spelling and grammar</li> </ul>"},{"location":"STYLE_GUIDE/#visual-quality","title":"Visual Quality","text":"<ul> <li> Consistent heading structure</li> <li> Appropriate use of emphasis</li> <li> Well-formatted code blocks</li> <li> Clear diagrams with consistent styling</li> <li> Strategic use of icons/emojis</li> <li> Proper table formatting</li> </ul>"},{"location":"STYLE_GUIDE/#user-experience","title":"User Experience","text":"<ul> <li> Clear navigation paths</li> <li> Quick reference sections</li> <li> Real-world examples</li> <li> Troubleshooting guidance</li> <li> Cross-references to related content</li> <li> Mobile-friendly formatting</li> </ul>"},{"location":"STYLE_GUIDE/#technical-quality","title":"Technical Quality","text":"<ul> <li> Valid Markdown syntax</li> <li> Working internal links</li> <li> Proper file naming conventions</li> <li> Consistent file structure</li> <li> MkDocs compatibility</li> </ul>"},{"location":"STYLE_GUIDE/#templates-and-patterns","title":"Templates and Patterns","text":"<p>This style guide should be used with the following templates: - Command Reference Template - Feature Overview Template - Tutorial Template - Architecture Documentation Template - Troubleshooting Template</p> <p>Each template implements these style guidelines for specific content types, ensuring consistency across all documentation.</p>"},{"location":"advanced/architecture-detailed/","title":"Architecture Overview","text":"<p>The AI Agent TDD-Scrum Workflow system follows a clean, layered architecture designed for scalability, maintainability, and extensibility.</p>"},{"location":"advanced/architecture-detailed/#two-repository-model","title":"Two-Repository Model","text":"<p>The system operates on a clear separation between orchestration and project concerns:</p>"},{"location":"advanced/architecture-detailed/#orchestration-repository-this-repo","title":"Orchestration Repository (this repo)","text":"<ul> <li>Purpose: Central framework for AI agent coordination</li> <li>Contents: Agent definitions, workflow engine, Discord bot, security policies</li> <li>Scope: Global across all managed projects</li> <li>Lifecycle: Long-lived, evolves with framework capabilities</li> </ul>"},{"location":"advanced/architecture-detailed/#project-repositories-1-to-n","title":"Project Repositories (1 to n)","text":"<ul> <li>Purpose: Individual codebases being developed with AI assistance</li> <li>Contents: Project code + embedded workflow data in <code>.orch-state/</code></li> <li>Scope: Project-specific data and state</li> <li>Lifecycle: Tied to project development lifecycle</li> </ul> <p>This separation ensures: - Data Ownership: Project data stays with the project code - Version Control: Project management data versioned with code changes - Portability: Projects can move between orchestration instances - Security: Clear boundaries between global and project-specific access</p>"},{"location":"advanced/architecture-detailed/#system-architecture","title":"System Architecture","text":"<p>The system implements a dual state machine architecture that coordinates workflow management with Test-Driven Development cycles:</p> <pre><code>graph TB\n    subgraph \"User Interface Layer\"\n        Discord[Discord Bot Interface]\n        CLI[Command Line Interface]\n    end\n\n    subgraph \"Application Layer\"\n        Orch[Orchestrator]\n        WSM[Workflow State Machine]\n        TSM[TDD State Machine]\n        Commands[Command Handlers]\n        Coord[State Coordination]\n    end\n\n    subgraph \"Domain Layer\"\n        Agents[Enhanced AI Agent Library]\n        Tasks[Task Management]\n        Projects[Project Management]\n        TDDCycles[TDD Cycle Management]\n    end\n\n    subgraph \"Infrastructure Layer\"\n        State[State Persistence]\n        TDDState[TDD State Storage]\n        Config[Configuration]\n        Logging[Logging &amp; Monitoring]\n    end\n\n    Discord --&gt; Orch\n    CLI --&gt; Orch\n    Orch --&gt; WSM\n    Orch --&gt; TSM\n    Orch --&gt; Commands\n    WSM --&gt; Coord\n    TSM --&gt; Coord\n    Commands --&gt; Agents\n    Commands --&gt; Tasks\n    Commands --&gt; Projects\n    Commands --&gt; TDDCycles\n    Agents --&gt; State\n    Agents --&gt; TDDState\n    Projects --&gt; State\n    TDDCycles --&gt; TDDState\n    Orch --&gt; Config\n    Orch --&gt; Logging</code></pre>"},{"location":"advanced/architecture-detailed/#core-principles","title":"Core Principles","text":""},{"location":"advanced/architecture-detailed/#1-separation-of-concerns","title":"1. Separation of Concerns","text":"<p>Each layer has distinct responsibilities: - Interface Layer: User interaction and external communication - Application Layer: Workflow orchestration and business logic - Domain Layer: Core business entities and AI agent coordination - Infrastructure Layer: Data persistence, configuration, and cross-cutting concerns</p>"},{"location":"advanced/architecture-detailed/#2-dual-state-machine-architecture","title":"2. Dual State Machine Architecture","text":"<p>The system enforces dual state machines for comprehensive workflow management:</p> <p>Workflow State Machine: - Manages project lifecycle (IDLE \u2192 BACKLOG_READY \u2192 SPRINT_PLANNED \u2192 SPRINT_ACTIVE \u2192 SPRINT_REVIEW) - Controls high-level workflow transitions - Coordinates multi-project orchestration</p> <p>TDD State Machine: - Manages story-level development cycles (DESIGN \u2192 TEST_RED \u2192 CODE_GREEN \u2192 REFACTOR \u2192 COMMIT) - Enforces Test-Driven Development best practices - Coordinates agent handoffs between TDD phases - Preserves test artifacts through the development cycle</p> <p>State Coordination: - Dual state machines operate in parallel - TDD cycles activate automatically when sprints start - Workflow states gate TDD progression - Cross-state validation ensures consistency</p>"},{"location":"advanced/architecture-detailed/#3-event-driven-architecture","title":"3. Event-Driven Architecture","text":"<p>Components communicate through well-defined events: - Command execution triggers state transitions - Agent completion events update project status - Human approval events unblock workflows</p>"},{"location":"advanced/architecture-detailed/#4-plugin-architecture","title":"4. Plugin Architecture","text":"<p>Agents are designed as pluggable components: - Common base interface for all agents - Easy to add new specialized agents - Configurable agent behavior per project</p>"},{"location":"advanced/architecture-detailed/#directory-structure","title":"Directory Structure","text":"<pre><code>agent-workflow/\n\u251c\u2500\u2500 docs_src/           # MkDocs documentation source\n\u251c\u2500\u2500 docs/              # Original documentation files\n\u251c\u2500\u2500 scripts/           # Executable entry points\n\u2502   \u2514\u2500\u2500 orchestrator.py\n\u251c\u2500\u2500 lib/               # Core library code\n\u2502   \u251c\u2500\u2500 agents/        # Enhanced AI agent implementations\n\u2502   \u251c\u2500\u2500 state_machine.py      # Workflow state machine\n\u2502   \u251c\u2500\u2500 tdd_state_machine.py  # TDD state machine\n\u2502   \u251c\u2500\u2500 tdd_models.py         # TDD data models\n\u2502   \u2514\u2500\u2500 discord_bot.py\n\u251c\u2500\u2500 tests/             # Test suite\n\u2502   \u251c\u2500\u2500 unit/         # Unit tests\n\u2502   \u2502   \u251c\u2500\u2500 test_tdd_models.py\n\u2502   \u2502   \u2514\u2500\u2500 test_tdd_state_machine.py\n\u2502   \u251c\u2500\u2500 integration/  # Integration tests\n\u2502   \u2514\u2500\u2500 conftest.py   # Test configuration\n\u251c\u2500\u2500 requirements.txt   # Dependencies\n\u251c\u2500\u2500 mkdocs.yml        # Documentation configuration\n\u251c\u2500\u2500 Makefile          # Build automation\n\u2514\u2500\u2500 README.md         # Project overview\n</code></pre>"},{"location":"advanced/architecture-detailed/#component-interaction","title":"Component Interaction","text":""},{"location":"advanced/architecture-detailed/#1-dual-state-machine-command-flow","title":"1. Dual State Machine Command Flow","text":"<pre><code>sequenceDiagram\n    participant User\n    participant Discord\n    participant Orchestrator\n    participant WSM as Workflow SM\n    participant TSM as TDD SM\n    participant Agent\n\n    User-&gt;&gt;Discord: /epic \"Build auth system\"\n    Discord-&gt;&gt;Orchestrator: handle_command()\n    Orchestrator-&gt;&gt;WSM: validate_command()\n    WSM--&gt;&gt;Orchestrator: validation_result\n    Orchestrator-&gt;&gt;Agent: dispatch_task()\n    Agent--&gt;&gt;Orchestrator: task_result\n    Orchestrator-&gt;&gt;WSM: transition_state()\n\n    Note over Orchestrator,TSM: Sprint activation triggers TDD\n    Orchestrator-&gt;&gt;TSM: create_tdd_cycle(story)\n    TSM-&gt;&gt;Agent: design_phase()\n    Agent-&gt;&gt;TSM: design_complete\n    TSM-&gt;&gt;Agent: test_red_phase()\n    Agent-&gt;&gt;TSM: tests_committed\n    TSM-&gt;&gt;Agent: code_green_phase()\n\n    Orchestrator--&gt;&gt;Discord: command_response\n    Discord--&gt;&gt;User: Success message</code></pre>"},{"location":"advanced/architecture-detailed/#2-dual-state-management","title":"2. Dual State Management","text":"<ul> <li>Workflow State: Project-level state in <code>.orch-state/status.json</code></li> <li>TDD State: Story-level state in <code>.orch-state/tdd/</code></li> <li>State Coordination: Orchestrator coordinates both state machines</li> <li>State Recovery: Both systems recover state on restart</li> <li>Multi-Project: Independent dual state machines per project</li> <li>Test Preservation: TDD state preserves test artifacts through cycles</li> </ul>"},{"location":"advanced/architecture-detailed/#3-enhanced-agent-coordination","title":"3. Enhanced Agent Coordination","text":"<ul> <li>Dual Task Queues: Workflow tasks and TDD tasks managed separately</li> <li>Phase-Specific Agents: Agents specialized for TDD phases (Design, QA, Code)</li> <li>TDD Agent Handoffs: Coordinated transitions between TDD phases</li> <li>Test Preservation: QA Agent preserves tests through code and refactor phases</li> <li>Retry Logic: TDD-aware retry with phase-specific backoff</li> <li>Human Escalation: HITL approval for both workflow and TDD decisions</li> <li>Parallel TDD Cycles: Multiple stories can run TDD cycles simultaneously</li> </ul>"},{"location":"advanced/architecture-detailed/#design-patterns","title":"Design Patterns","text":""},{"location":"advanced/architecture-detailed/#1-command-pattern","title":"1. Command Pattern","text":"<p>Each user command is encapsulated as a command object: - Enables undo/redo functionality - Facilitates command logging and auditing - Allows command queuing and batch processing</p>"},{"location":"advanced/architecture-detailed/#2-state-pattern","title":"2. State Pattern","text":"<p>Workflow states encapsulate behavior: - Each state defines allowed commands - State transitions are explicit and validated - Easy to add new states and transitions</p>"},{"location":"advanced/architecture-detailed/#3-strategy-pattern","title":"3. Strategy Pattern","text":"<p>Agent implementations use strategy pattern: - Agents can be swapped at runtime - Different strategies for different project types - Easy A/B testing of agent behaviors</p>"},{"location":"advanced/architecture-detailed/#4-observer-pattern","title":"4. Observer Pattern","text":"<p>Event-driven communication between components: - Loose coupling between layers - Easy to add new event handlers - Supports monitoring and debugging</p>"},{"location":"advanced/architecture-detailed/#scalability-considerations","title":"Scalability Considerations","text":""},{"location":"advanced/architecture-detailed/#1-horizontal-scaling","title":"1. Horizontal Scaling","text":"<ul> <li>Multiple orchestrator instances can run simultaneously</li> <li>Discord bot can be load-balanced</li> <li>Agent execution can be distributed</li> </ul>"},{"location":"advanced/architecture-detailed/#2-performance-optimization","title":"2. Performance Optimization","text":"<ul> <li>Async/await throughout for I/O operations</li> <li>Caching of frequently accessed data</li> <li>Batch processing of similar tasks</li> </ul>"},{"location":"advanced/architecture-detailed/#3-resource-management","title":"3. Resource Management","text":"<ul> <li>Connection pooling for external services</li> <li>Rate limiting for API calls</li> <li>Memory-efficient state storage</li> </ul>"},{"location":"advanced/architecture-detailed/#security-architecture","title":"Security Architecture","text":"<p>The system implements comprehensive security through multiple layers of protection. See Security Implementation for detailed information.</p>"},{"location":"advanced/architecture-detailed/#1-agent-security-model","title":"1. Agent Security Model","text":"<ul> <li>Command Access Control: Each agent type has restricted tool access</li> <li>Principle of Least Privilege: Agents can only access necessary tools</li> <li>Automatic Enforcement: Security boundaries applied via Claude Code CLI flags</li> </ul>"},{"location":"advanced/architecture-detailed/#2-authentication-authorization","title":"2. Authentication &amp; Authorization","text":"<ul> <li>Discord bot token authentication</li> <li>Role-based access control in Discord</li> <li>Project-level permission isolation</li> <li>Agent-specific security profiles</li> </ul>"},{"location":"advanced/architecture-detailed/#3-data-protection","title":"3. Data Protection","text":"<ul> <li>No sensitive data stored in state files</li> <li>Environment variables for secrets</li> <li>Audit logging of all commands and agent tool usage</li> <li>State file access controls</li> </ul>"},{"location":"advanced/architecture-detailed/#tdd-architecture-components","title":"TDD Architecture Components","text":""},{"location":"advanced/architecture-detailed/#tdd-state-machine","title":"TDD State Machine","text":"<p>The TDD State Machine manages the Test-Driven Development cycle for individual stories:</p> <pre><code>stateDiagram-v2\n    [*] --&gt; DESIGN\n    DESIGN --&gt; DESIGN : /tdd design\n    DESIGN --&gt; TEST_RED : /tdd test\n    TEST_RED --&gt; TEST_RED : /tdd test\n    TEST_RED --&gt; CODE_GREEN : /tdd commit-tests\n    CODE_GREEN --&gt; CODE_GREEN : /tdd code\n    CODE_GREEN --&gt; REFACTOR : /tdd commit-code\n    CODE_GREEN --&gt; COMMIT : /tdd commit\n    REFACTOR --&gt; REFACTOR : /tdd refactor\n    REFACTOR --&gt; COMMIT : /tdd commit-refactor\n    COMMIT --&gt; DESIGN : /tdd next (new task)\n    COMMIT --&gt; [*] : cycle complete\n\n    note right of DESIGN : Create specs &amp; acceptance criteria\n    note right of TEST_RED : Write failing tests (preserved in repo)\n    note right of CODE_GREEN : Implement minimal code (tests committed)\n    note right of REFACTOR : Improve code quality (code committed)\n    note right of COMMIT : Save progress (refactoring committed)</code></pre>"},{"location":"advanced/architecture-detailed/#tdd-data-models","title":"TDD Data Models","text":"<p>Comprehensive data models support the TDD workflow:</p> <ul> <li>TDDCycle: Links to story, manages tasks and overall progress</li> <li>TDDTask: Individual task within cycle, tracks test files and results</li> <li>TestFile: Manages test file lifecycle and CI integration</li> <li>TestResult: Captures test execution outcomes and metrics</li> </ul>"},{"location":"advanced/architecture-detailed/#test-preservation-workflow","title":"Test Preservation Workflow","text":"<p>The system preserves test artifacts through the entire development cycle:</p> <ol> <li>TEST_RED Phase: Tests created in <code>tests/tdd/{story_id}/</code></li> <li>CODE_GREEN Phase: Tests committed to repository</li> <li>REFACTOR Phase: Tests remain unchanged, validate refactoring</li> <li>COMMIT Phase: Tests promoted to permanent test locations</li> <li>Integration: Tests integrated into CI/CD pipeline</li> </ol>"},{"location":"advanced/architecture-detailed/#enhanced-agent-capabilities","title":"Enhanced Agent Capabilities","text":"<p>Design Agent (TDD-Enhanced): - Creates technical specifications for TDD cycles - Defines acceptance criteria and test strategies - Generates design artifacts for test creation</p> <p>QA Agent (TDD-Enhanced): - Writes comprehensive failing tests (RED phase) - Manages test file lifecycle and preservation - Validates test coverage and quality - Ensures tests remain green through refactoring</p> <p>Code Agent (TDD-Enhanced): - Implements minimal code to make tests pass (GREEN phase) - Refactors code while preserving test success - Commits code with proper test integration - Maintains TDD discipline throughout development</p>"},{"location":"advanced/architecture-detailed/#extensibility-points","title":"Extensibility Points","text":""},{"location":"advanced/architecture-detailed/#1-custom-agents","title":"1. Custom Agents","text":"<pre><code>class CustomAgent(BaseAgent):\n    def __init__(self):\n        super().__init__(\n            name=\"CustomAgent\",\n            capabilities=[\"custom_capability\"]\n        )\n\n    async def run(self, task, dry_run=False):\n        # Custom implementation\n        pass\n</code></pre>"},{"location":"advanced/architecture-detailed/#2-custom-commands","title":"2. Custom Commands","text":"<p>Add new slash commands by extending the Discord bot: <pre><code>@app_commands.command(name=\"custom\", description=\"Custom command\")\nasync def custom_command(self, interaction, param: str):\n    # Custom command implementation\n    pass\n</code></pre></p>"},{"location":"advanced/architecture-detailed/#3-custom-workflow-states","title":"3. Custom Workflow States","text":"<p>Extend the workflow state machine with new states: <pre><code>class CustomWorkflowState(Enum):\n    CUSTOM_STATE = \"CUSTOM_STATE\"\n</code></pre></p>"},{"location":"advanced/architecture-detailed/#4-custom-tdd-states","title":"4. Custom TDD States","text":"<p>Extend the TDD state machine with new phases: <pre><code>class CustomTDDState(Enum):\n    SECURITY_REVIEW = \"SECURITY_REVIEW\"\n    PERFORMANCE_TEST = \"PERFORMANCE_TEST\"\n</code></pre></p>"},{"location":"advanced/architecture-detailed/#5-tdd-cycle-customization","title":"5. TDD Cycle Customization","text":"<p>Customize TDD cycles for specific story types: <pre><code>class CustomTDDCycle(TDDCycle):\n    def __init__(self, story_type: str):\n        super().__init__()\n        if story_type == \"api\":\n            self.add_integration_tests = True\n        elif story_type == \"ui\":\n            self.add_e2e_tests = True\n</code></pre></p>"},{"location":"advanced/architecture-detailed/#monitoring-observability","title":"Monitoring &amp; Observability","text":""},{"location":"advanced/architecture-detailed/#1-logging-strategy","title":"1. Logging Strategy","text":"<ul> <li>Structured logging with JSON format</li> <li>Different log levels per component</li> <li>Centralized log aggregation ready</li> </ul>"},{"location":"advanced/architecture-detailed/#2-metrics-collection","title":"2. Metrics Collection","text":"<ul> <li>Command execution metrics</li> <li>Agent performance metrics</li> <li>State transition tracking</li> </ul>"},{"location":"advanced/architecture-detailed/#3-health-checks","title":"3. Health Checks","text":"<ul> <li>Discord bot connectivity</li> <li>Agent responsiveness</li> <li>State persistence availability</li> </ul> <p>Architecture Evolution</p> <p>This architecture is designed to evolve with the system's needs. New patterns and components can be added while maintaining backward compatibility.</p>"},{"location":"advanced/code/","title":"C4 Code Diagram - AI Agent TDD-Scrum Workflow","text":""},{"location":"advanced/code/#dual-state-machine-class-structure","title":"Dual State Machine Class Structure","text":"<p>The system implements dual state machines that work in coordination to manage both workflow progression and Test-Driven Development cycles.</p>"},{"location":"advanced/code/#workflow-state-machine","title":"Workflow State Machine","text":"<pre><code>classDiagram\n    class WorkflowStateMachine {\n        +current_state: WorkflowState\n        +validate_command(command: Command) bool\n        +transition(command: Command) WorkflowState\n        +get_allowed_commands() List[Command]\n        +get_state_diagram() str\n        +coordinate_with_tdd(tdd_sm: TDDStateMachine) void\n    }\n\n    class WorkflowState {\n        &lt;&lt;enumeration&gt;&gt;\n        IDLE\n        BACKLOG_READY\n        SPRINT_PLANNED\n        SPRINT_ACTIVE\n        SPRINT_PAUSED\n        SPRINT_REVIEW\n        BLOCKED\n    }\n\n    class Command {\n        +name: str\n        +args: Dict\n        +validate() bool\n        +execute() Result\n    }\n\n    WorkflowStateMachine --&gt; WorkflowState\n    WorkflowStateMachine --&gt; Command</code></pre>"},{"location":"advanced/code/#tdd-state-machine","title":"TDD State Machine","text":"<pre><code>classDiagram\n    class TDDStateMachine {\n        +current_state: TDDState\n        +active_cycle: TDDCycle\n        +validate_command(command: str, cycle: TDDCycle) TDDCommandResult\n        +transition(command: str, cycle: TDDCycle) TDDCommandResult\n        +get_allowed_commands(cycle: TDDCycle) List[str]\n        +get_next_suggested_command(cycle: TDDCycle) str\n        +get_state_info(cycle: TDDCycle) Dict\n        +set_active_cycle(cycle: TDDCycle) void\n        +can_auto_progress(cycle: TDDCycle) bool\n    }\n\n    class TDDState {\n        &lt;&lt;enumeration&gt;&gt;\n        DESIGN\n        TEST_RED\n        CODE_GREEN\n        REFACTOR\n        COMMIT\n    }\n\n    class TDDCommandResult {\n        +success: bool\n        +new_state: TDDState\n        +error_message: str\n        +hint: str\n        +data: Dict\n    }\n\n    TDDStateMachine --&gt; TDDState\n    TDDStateMachine --&gt; TDDCommandResult</code></pre>"},{"location":"advanced/code/#tdd-data-models","title":"TDD Data Models","text":"<pre><code>classDiagram\n    class TDDCycle {\n        +id: str\n        +story_id: str\n        +current_state: TDDState\n        +current_task_id: str\n        +tasks: List[TDDTask]\n        +started_at: str\n        +completed_at: str\n        +total_test_runs: int\n        +total_refactors: int\n        +total_commits: int\n        +ci_status: CIStatus\n        +overall_test_coverage: float\n        +is_complete() bool\n        +get_current_task() TDDTask\n        +add_task(task: TDDTask) void\n        +start_task(task_id: str) bool\n        +complete_current_task() bool\n    }\n\n    class TDDTask {\n        +id: str\n        +cycle_id: str\n        +description: str\n        +acceptance_criteria: List[str]\n        +current_state: TDDState\n        +test_files: List[str]\n        +test_file_objects: List[TestFile]\n        +source_files: List[str]\n        +test_results: List[TestResult]\n        +design_notes: str\n        +implementation_notes: str\n        +refactor_notes: str\n        +has_passing_tests() bool\n        +has_failing_tests() bool\n        +can_commit_tests() bool\n        +can_commit_code() bool\n    }\n\n    class TestFile {\n        +id: str\n        +file_path: str\n        +relative_path: str\n        +story_id: str\n        +task_id: str\n        +status: TestFileStatus\n        +ci_status: CIStatus\n        +test_count: int\n        +passing_tests: int\n        +failing_tests: int\n        +coverage_percentage: float\n        +exists() bool\n        +is_committed() bool\n        +is_passing() bool\n        +get_permanent_location() str\n    }\n\n    class TestResult {\n        +id: str\n        +test_file: str\n        +test_name: str\n        +status: TestStatus\n        +output: str\n        +error_message: str\n        +execution_time: float\n        +timestamp: str\n    }\n\n    TDDCycle --&gt; TDDTask\n    TDDTask --&gt; TestFile\n    TDDTask --&gt; TestResult\n    TestFile --&gt; TestResult</code></pre>"},{"location":"advanced/code/#enhanced-agent-class-hierarchy","title":"Enhanced Agent Class Hierarchy","text":"<pre><code>classDiagram\n    class BaseAgent {\n        &lt;&lt;abstract&gt;&gt;\n        +name: str\n        +capabilities: List[str]\n        +tdd_capabilities: List[str]\n        +run(task: Task, dry: bool) Result\n        +run_tdd_phase(tdd_task: TDDTask, phase: TDDState) Result\n        +validate_task(task: Task) bool\n        +validate_tdd_task(tdd_task: TDDTask) bool\n        +get_status() AgentStatus\n        +get_tdd_context(cycle: TDDCycle) Dict\n    }\n\n    class DesignAgent {\n        +run(task: Task, dry: bool) Result\n        +run_tdd_phase(tdd_task: TDDTask, phase: TDDState) Result\n        +create_architecture(requirements: str) str\n        +create_tdd_specifications(story: Story) str\n        +define_acceptance_criteria(story: Story) List[str]\n        +create_test_strategy(story: Story) str\n        +review_design(design: str) str\n    }\n\n    class CodeAgent {\n        +run(task: Task, dry: bool) Result\n        +run_tdd_phase(tdd_task: TDDTask, phase: TDDState) Result\n        +implement_feature(spec: str) str\n        +implement_minimal_code(test_files: List[TestFile]) str\n        +refactor_code(target: str, preserve_tests: bool) str\n        +commit_tdd_phase(phase: TDDState, files: List[str]) str\n        +fix_bug(issue: str) str\n    }\n\n    class QAAgent {\n        +run(task: Task, dry: bool) Result\n        +run_tdd_phase(tdd_task: TDDTask, phase: TDDState) Result\n        +write_failing_tests(spec: str, story_id: str) List[TestFile]\n        +validate_test_failure(test_files: List[TestFile]) bool\n        +preserve_tests_during_code(test_files: List[TestFile]) bool\n        +validate_tests_still_pass(test_files: List[TestFile]) bool\n        +promote_tests_to_permanent(test_files: List[TestFile]) bool\n        +run_tests(code: str) TestResult\n        +calculate_coverage(test_files: List[TestFile]) float\n    }\n\n    class DataAgent {\n        +run(task: Task, dry: bool) Result\n        +analyze_data(dataset: str) str\n        +create_pipeline(spec: str) str\n        +analyze_tdd_metrics(cycle: TDDCycle) Dict\n    }\n\n    BaseAgent &lt;|-- DesignAgent\n    BaseAgent &lt;|-- CodeAgent\n    BaseAgent &lt;|-- QAAgent\n    BaseAgent &lt;|-- DataAgent</code></pre>"},{"location":"advanced/code/#tdd-phase-management-classes","title":"TDD Phase Management Classes","text":"<pre><code>classDiagram\n    class TDDPhaseManager {\n        +current_phase: TDDState\n        +active_cycles: Dict[str, TDDCycle]\n        +coordinate_agent_handoff(from_agent: BaseAgent, to_agent: BaseAgent) bool\n        +validate_phase_completion(cycle: TDDCycle, phase: TDDState) bool\n        +trigger_phase_transition(cycle: TDDCycle, new_phase: TDDState) bool\n        +handle_phase_failure(cycle: TDDCycle, error: Exception) void\n    }\n\n    class TestPreservationManager {\n        +preserve_test_files(test_files: List[TestFile]) bool\n        +validate_test_integrity(test_files: List[TestFile]) bool\n        +commit_test_phase(cycle: TDDCycle, phase: TDDState) bool\n        +promote_tests_to_permanent(cycle: TDDCycle) bool\n        +rollback_test_changes(cycle: TDDCycle, to_phase: TDDState) bool\n    }\n\n    class TDDCycleCoordinator {\n        +create_cycle_for_story(story: Story) TDDCycle\n        +start_cycle(cycle_id: str) bool\n        +pause_cycle(cycle_id: str) bool\n        +resume_cycle(cycle_id: str) bool\n        +complete_cycle(cycle_id: str) bool\n        +get_cycle_progress(cycle_id: str) Dict\n        +coordinate_multiple_cycles(story_ids: List[str]) bool\n    }\n\n    TDDPhaseManager --&gt; TDDCycle\n    TestPreservationManager --&gt; TestFile\n    TDDCycleCoordinator --&gt; TDDCycle</code></pre>"},{"location":"advanced/code/#enhanced-orchestrator-core-classes","title":"Enhanced Orchestrator Core Classes","text":"<pre><code>classDiagram\n    class Orchestrator {\n        +projects: Dict[str, Project]\n        +agents: Dict[str, BaseAgent]\n        +workflow_state_machine: WorkflowStateMachine\n        +tdd_state_machine: TDDStateMachine\n        +state_coordinator: StateCoordinator\n        +tdd_coordinator: TDDCycleCoordinator\n        +handle_command(command: Command) Result\n        +handle_tdd_command(command: str, story_id: str) Result\n        +dispatch_task(task: Task) Result\n        +dispatch_tdd_task(tdd_task: TDDTask, phase: TDDState) Result\n        +escalate_to_human(task: Task) ApprovalRequest\n        +coordinate_dual_states() void\n    }\n\n    class Project {\n        +name: str\n        +path: Path\n        +workflow_state: ProjectState\n        +tdd_state: TDDProjectState\n        +orchestration_mode: OrchestrationMode\n        +load_workflow_state() ProjectState\n        +save_workflow_state(state: ProjectState) void\n        +load_tdd_state() TDDProjectState\n        +save_tdd_state(state: TDDProjectState) void\n    }\n\n    class ProjectState {\n        +current_state: WorkflowState\n        +active_tasks: List[Task]\n        +pending_approvals: List[ApprovalRequest]\n        +sprint_backlog: List[Story]\n        +product_backlog: List[Story]\n    }\n\n    class TDDProjectState {\n        +active_cycles: Dict[str, TDDCycle]\n        +completed_cycles: List[TDDCycle]\n        +test_coverage_metrics: Dict\n        +tdd_performance_metrics: Dict\n        +get_active_cycle_for_story(story_id: str) TDDCycle\n        +create_cycle_for_story(story: Story) TDDCycle\n    }\n\n    class StateCoordinator {\n        +coordinate_workflow_and_tdd() bool\n        +validate_state_consistency() bool\n        +handle_state_conflicts() void\n        +sync_sprint_with_tdd_cycles() bool\n    }\n\n    class Task {\n        +id: str\n        +agent_type: str\n        +command: str\n        +status: TaskStatus\n        +retry_count: int\n        +created_at: datetime\n        +tdd_context: Dict\n    }\n\n    Orchestrator --&gt; Project\n    Orchestrator --&gt; StateCoordinator\n    Orchestrator --&gt; TDDCycleCoordinator\n    Project --&gt; ProjectState\n    Project --&gt; TDDProjectState\n    ProjectState --&gt; Task\n    TDDProjectState --&gt; TDDCycle\n    Orchestrator --&gt; WorkflowStateMachine\n    Orchestrator --&gt; TDDStateMachine\n    Orchestrator --&gt; BaseAgent</code></pre>"},{"location":"advanced/code/#discord-bot-classes","title":"Discord Bot Classes","text":"<pre><code>classDiagram\n    class DiscordBot {\n        +orchestrator: Orchestrator\n        +client: discord.Client\n        +handle_slash_command(interaction: Interaction) void\n        +send_notification(message: str, channel: str) void\n        +create_interactive_view(state: State) discord.View\n    }\n\n    class CommandHandler {\n        +parse_command(interaction: Interaction) Command\n        +validate_command(command: Command) bool\n        +execute_command(command: Command) Result\n    }\n\n    class StateView {\n        +state: State\n        +create_buttons() List[discord.Button]\n        +create_embed() discord.Embed\n        +handle_button_click(interaction: Interaction) void\n    }\n\n    class NotificationManager {\n        +send_approval_request(request: ApprovalRequest) void\n        +send_status_update(project: str, status: str) void\n        +send_error_notification(error: Exception) void\n    }\n\n    DiscordBot --&gt; CommandHandler\n    DiscordBot --&gt; StateView\n    DiscordBot --&gt; NotificationManager\n    DiscordBot --&gt; Orchestrator</code></pre>"},{"location":"advanced/component/","title":"C4 Component Diagram - AI Agent TDD-Scrum Workflow","text":""},{"location":"advanced/component/#component-architecture","title":"Component Architecture","text":"<p>The system implements a dual state machine architecture with TDD-enhanced agents that coordinate workflow management and Test-Driven Development cycles.</p>"},{"location":"advanced/component/#discord-bot-components","title":"Discord Bot Components","text":"<pre><code>C4Component\n    title Discord Bot Components\n\n    Container_Boundary(discord_bot, \"Discord Bot\") {\n        Component(command_parser, \"Command Parser\", \"Parse and validate slash commands\")\n        Component(state_visualizer, \"State Visualizer\", \"Generate interactive state diagrams\")\n        Component(notification_manager, \"Notification Manager\", \"Send alerts and status updates\")\n        Component(button_handler, \"Button Handler\", \"Handle interactive UI elements\")\n    }\n\n    Container(orchestrator, \"Orchestrator\", \"Core coordination logic\")\n    System_Ext(discord_api, \"Discord API\")\n\n    Rel(discord_api, command_parser, \"Slash command events\")\n    Rel(command_parser, orchestrator, \"Validated commands\")\n    Rel(orchestrator, state_visualizer, \"State data\")\n    Rel(state_visualizer, discord_api, \"Interactive messages\")\n    Rel(orchestrator, notification_manager, \"Status updates\")\n    Rel(notification_manager, discord_api, \"Notifications\")\n    Rel(button_handler, orchestrator, \"User interactions\")</code></pre>"},{"location":"advanced/component/#orchestrator-components","title":"Orchestrator Components","text":"<pre><code>C4Component\n    title Orchestrator Components (Dual State Machine Architecture)\n\n    Container_Boundary(orchestrator, \"Orchestrator\") {\n        Component(workflow_sm, \"Workflow State Machine\", \"Enforce workflow command transitions\")\n        Component(tdd_sm, \"TDD State Machine\", \"Enforce TDD command transitions\")\n        Component(state_coordinator, \"State Coordinator\", \"Coordinate dual state machines\")\n        Component(project_manager, \"Project Manager\", \"Multi-project coordination\")\n        Component(task_dispatcher, \"Task Dispatcher\", \"Agent task coordination\")\n        Component(tdd_coordinator, \"TDD Coordinator\", \"Manage TDD cycles and tasks\")\n        Component(approval_gate, \"Approval Gate\", \"HITL workflow management\")\n        Component(retry_logic, \"Retry Logic\", \"3-attempt failure handling\")\n    }\n\n    Container(agent_lib, \"Enhanced Agent Library\")\n    Container(state_store, \"State Store\")\n    Container(tdd_store, \"TDD State Store\")\n    Container(discord_bot, \"Discord Bot\")\n\n    Rel(discord_bot, workflow_sm, \"Workflow command validation\")\n    Rel(discord_bot, tdd_sm, \"TDD command validation\")\n    Rel(workflow_sm, state_coordinator, \"Workflow state changes\")\n    Rel(tdd_sm, state_coordinator, \"TDD state changes\")\n    Rel(state_coordinator, project_manager, \"Coordinated state transitions\")\n    Rel(project_manager, task_dispatcher, \"Workflow task assignment\")\n    Rel(project_manager, tdd_coordinator, \"TDD cycle management\")\n    Rel(task_dispatcher, agent_lib, \"Agent execution\")\n    Rel(tdd_coordinator, agent_lib, \"TDD phase execution\")\n    Rel(approval_gate, discord_bot, \"Approval requests\")\n    Rel(retry_logic, approval_gate, \"Escalation after 3 failures\")\n    Rel(project_manager, state_store, \"Persist workflow state\")\n    Rel(tdd_coordinator, tdd_store, \"Persist TDD state\")</code></pre>"},{"location":"advanced/component/#enhanced-agent-library-components","title":"Enhanced Agent Library Components","text":"<pre><code>C4Component\n    title Enhanced Agent Library Components (TDD-Capable)\n\n    Container_Boundary(agent_lib, \"Enhanced Agent Library\") {\n        Component(base_agent, \"Base Agent\", \"Common agent interface\")\n        Component(design_agent_tdd, \"Design Agent (TDD)\", \"TDD specifications &amp; design\")\n        Component(code_agent_tdd, \"Code Agent (TDD)\", \"TDD implementation &amp; refactoring\")\n        Component(qa_agent_tdd, \"QA Agent (TDD)\", \"Test creation &amp; preservation\")\n        Component(data_agent, \"Data Agent\", \"Data processing\")\n        Component(tdd_phase_manager, \"TDD Phase Manager\", \"Coordinate TDD agent handoffs\")\n        Component(test_preservation, \"Test Preservation\", \"Manage test file lifecycle\")\n        Component(anthropic_client, \"Anthropic Client\", \"AI model integration\")\n        Component(github_client, \"GitHub Client\", \"Repository operations\")\n    }\n\n    System_Ext(anthropic_api, \"Anthropic API\")\n    System_Ext(github_api, \"GitHub API\")\n\n    Rel(base_agent, design_agent_tdd, \"Inheritance\")\n    Rel(base_agent, code_agent_tdd, \"Inheritance\")\n    Rel(base_agent, qa_agent_tdd, \"Inheritance\")\n    Rel(base_agent, data_agent, \"Inheritance\")\n    Rel(tdd_phase_manager, design_agent_tdd, \"Design phase coordination\")\n    Rel(tdd_phase_manager, qa_agent_tdd, \"Test phase coordination\")\n    Rel(tdd_phase_manager, code_agent_tdd, \"Code phase coordination\")\n    Rel(qa_agent_tdd, test_preservation, \"Test file management\")\n    Rel(code_agent_tdd, test_preservation, \"Test validation\")\n    Rel(design_agent_tdd, anthropic_client, \"AI requests\")\n    Rel(code_agent_tdd, anthropic_client, \"AI requests\")\n    Rel(qa_agent_tdd, anthropic_client, \"AI requests\")\n    Rel(code_agent_tdd, github_client, \"Code commits\")\n    Rel(qa_agent_tdd, github_client, \"Test commits\")\n    Rel(anthropic_client, anthropic_api, \"API calls\")\n    Rel(github_client, github_api, \"Repository operations\")</code></pre>"},{"location":"advanced/component/#tdd-state-management-components","title":"TDD State Management Components","text":"<pre><code>C4Component\n    title TDD State Management Components\n\n    Container_Boundary(tdd_system, \"TDD Management System\") {\n        Component(tdd_state_machine, \"TDD State Machine\", \"Enforce TDD transitions\")\n        Component(tdd_cycle_manager, \"TDD Cycle Manager\", \"Manage TDD cycles per story\")\n        Component(tdd_task_manager, \"TDD Task Manager\", \"Handle TDD tasks within cycles\")\n        Component(test_file_manager, \"Test File Manager\", \"Manage test file lifecycle\")\n        Component(test_result_tracker, \"Test Result Tracker\", \"Track test execution results\")\n        Component(ci_integration, \"CI Integration\", \"Interface with CI/CD pipelines\")\n    }\n\n    Container(tdd_storage, \"TDD Storage\")\n    Container(test_artifacts, \"Test Artifacts\")\n\n    Rel(tdd_state_machine, tdd_cycle_manager, \"State transitions\")\n    Rel(tdd_cycle_manager, tdd_task_manager, \"Task lifecycle\")\n    Rel(tdd_task_manager, test_file_manager, \"Test file operations\")\n    Rel(test_file_manager, test_result_tracker, \"Test execution\")\n    Rel(test_result_tracker, ci_integration, \"CI validation\")\n    Rel(tdd_cycle_manager, tdd_storage, \"Persist TDD state\")\n    Rel(test_file_manager, test_artifacts, \"Store test files\")</code></pre>"},{"location":"advanced/component/#test-preservation-workflow-components","title":"Test Preservation Workflow Components","text":"<pre><code>C4Component\n    title Test Preservation Workflow Components\n\n    Container_Boundary(test_preservation, \"Test Preservation System\") {\n        Component(test_creator, \"Test Creator\", \"Create failing tests (RED phase)\")\n        Component(test_committer, \"Test Committer\", \"Commit tests to repository\")\n        Component(test_validator, \"Test Validator\", \"Validate tests during code phases\")\n        Component(test_promoter, \"Test Promoter\", \"Promote tests to permanent location\")\n        Component(coverage_tracker, \"Coverage Tracker\", \"Track test coverage metrics\")\n    }\n\n    Container(tdd_test_dir, \"TDD Test Directory\")\n    Container(permanent_tests, \"Permanent Test Location\")\n    Container(coverage_reports, \"Coverage Reports\")\n\n    Rel(test_creator, tdd_test_dir, \"Create test files\")\n    Rel(test_committer, tdd_test_dir, \"Commit failing tests\")\n    Rel(test_validator, tdd_test_dir, \"Validate during development\")\n    Rel(test_promoter, permanent_tests, \"Integrate into test suite\")\n    Rel(coverage_tracker, coverage_reports, \"Generate coverage data\")\n    Rel(test_promoter, tdd_test_dir, \"Source test files\")</code></pre>"},{"location":"advanced/container/","title":"C4 Container Diagram - AI Agent TDD-Scrum Workflow","text":""},{"location":"advanced/container/#container-architecture","title":"Container Architecture","text":"<p>The system implements a dual state machine architecture that coordinates workflow management with Test-Driven Development cycles through specialized containers.</p> <pre><code>C4Container\n    title Container Diagram - AI Agent Workflow System (Dual State Machine)\n\n    Person(user, \"Product Owner\", \"Solo developer\")\n\n    System_Boundary(system, \"AI Agent Workflow System\") {\n        Container(discord_bot, \"Discord Bot\", \"Python, discord.py\", \"Command interface, dual state visualization, notifications\")\n        Container(orchestrator, \"Orchestrator\", \"Python, asyncio\", \"Central coordination, dual state machines, project management\")\n        Container(workflow_sm, \"Workflow State Machine\", \"Python\", \"Project lifecycle state management\")\n        Container(tdd_sm, \"TDD State Machine\", \"Python\", \"Story-level TDD cycle management\")\n        Container(agent_lib, \"Enhanced Agent Library\", \"Python, anthropic\", \"TDD-capable AI agents (Design, Code, Data, QA)\")\n        Container(state_store, \"Workflow State Store\", \"JSON files\", \"Project state, task queues, approval gates\")\n        Container(tdd_store, \"TDD State Store\", \"JSON files\", \"TDD cycles, tasks, test results, coverage\")\n        Container(test_artifacts, \"Test Artifacts\", \"File system\", \"Test files, test results, coverage reports\")\n        Container(config, \"Configuration\", \"YAML\", \"Project definitions, orchestration modes, TDD settings\")\n    }\n\n    System_Ext(discord_api, \"Discord API\", \"Real-time messaging platform\")\n    System_Ext(github_api, \"GitHub API\", \"Repository and CI/CD integration\")\n    System_Ext(anthropic_api, \"Anthropic API\", \"Claude AI models\")\n    System_Ext(ci_system, \"CI/CD System\", \"Test execution and validation\")\n\n    Rel(user, discord_api, \"Slash commands, TDD interactions\")\n    Rel(discord_api, discord_bot, \"Webhook events, API calls\")\n    Rel(discord_bot, orchestrator, \"Command dispatch, state queries\")\n    Rel(orchestrator, workflow_sm, \"Workflow state management\")\n    Rel(orchestrator, tdd_sm, \"TDD state management\")\n    Rel(orchestrator, agent_lib, \"Task execution requests\")\n    Rel(workflow_sm, state_store, \"Read/write workflow state\")\n    Rel(tdd_sm, tdd_store, \"Read/write TDD state\")\n    Rel(agent_lib, test_artifacts, \"Test file operations\")\n    Rel(orchestrator, config, \"Load project definitions\")\n    Rel(agent_lib, anthropic_api, \"AI model requests\")\n    Rel(agent_lib, github_api, \"Code commits, test commits\")\n    Rel(test_artifacts, ci_system, \"Test execution\")</code></pre>"},{"location":"advanced/container/#container-responsibilities","title":"Container Responsibilities","text":""},{"location":"advanced/container/#discord-bot","title":"Discord Bot","text":"<ul> <li>Parse and validate workflow and TDD slash commands</li> <li>Implement dual state visualization (workflow + TDD)</li> <li>Send notifications for both workflow and TDD events</li> <li>Handle user interactions and approval buttons</li> <li>Display TDD cycle progress and test results</li> </ul>"},{"location":"advanced/container/#orchestrator","title":"Orchestrator","text":"<ul> <li>Coordinate dual state machines (workflow + TDD)</li> <li>Enforce state machine transitions for both systems</li> <li>Coordinate multi-agent workflows with TDD integration</li> <li>Implement HITL approval gates for workflow and TDD decisions</li> <li>Manage project lifecycle with TDD cycle coordination</li> </ul>"},{"location":"advanced/container/#workflow-state-machine","title":"Workflow State Machine","text":"<ul> <li>Manage project-level states (IDLE \u2192 BACKLOG_READY \u2192 SPRINT_PLANNED \u2192 SPRINT_ACTIVE \u2192 SPRINT_REVIEW)</li> <li>Validate workflow command sequences</li> <li>Trigger TDD cycle creation during sprint activation</li> <li>Coordinate with TDD state machine for sprint completion</li> </ul>"},{"location":"advanced/container/#tdd-state-machine","title":"TDD State Machine","text":"<ul> <li>Manage story-level TDD cycles (DESIGN \u2192 TEST_RED \u2192 CODE_GREEN \u2192 REFACTOR \u2192 COMMIT)</li> <li>Enforce TDD command sequences and best practices</li> <li>Coordinate agent handoffs between TDD phases</li> <li>Validate TDD transition conditions (test status, code quality)</li> </ul>"},{"location":"advanced/container/#enhanced-agent-library","title":"Enhanced Agent Library","text":"<ul> <li>TDD-capable agent implementations with phase specialization</li> <li>Design Agent: Creates TDD specifications and acceptance criteria</li> <li>QA Agent: Manages test creation, preservation, and validation</li> <li>Code Agent: Implements TDD discipline (minimal code, refactoring)</li> <li>Anthropic API integration with TDD context</li> <li>GitHub operations including test commits and CI integration</li> </ul>"},{"location":"advanced/container/#workflow-state-store","title":"Workflow State Store","text":"<ul> <li>Persist workflow state across restarts</li> <li>Track task queues and approvals</li> <li>Maintain project status and sprint progress</li> <li>Coordinate with TDD state for completion tracking</li> </ul>"},{"location":"advanced/container/#tdd-state-store","title":"TDD State Store","text":"<ul> <li>Persist TDD cycle state and progress</li> <li>Track test results and coverage metrics</li> <li>Maintain test file lifecycle information</li> <li>Store TDD task progress and agent handoff data</li> </ul>"},{"location":"advanced/container/#test-artifacts","title":"Test Artifacts","text":"<ul> <li>Store test files in TDD directory structure</li> <li>Maintain test results and execution history</li> <li>Preserve test coverage reports and metrics</li> <li>Support test file promotion to permanent locations</li> </ul>"},{"location":"advanced/container/#configuration","title":"Configuration","text":"<ul> <li>Define project orchestration modes (including TDD settings)</li> <li>Configure agent behaviors for TDD phases</li> <li>Set approval thresholds for both workflow and TDD decisions</li> <li>Define TDD quality gates and coverage requirements</li> </ul>"},{"location":"advanced/context/","title":"C4 Context Diagram - AI Agent TDD-Scrum Workflow","text":""},{"location":"advanced/context/#system-context","title":"System Context","text":"<p>The system context shows how the dual state machine architecture integrates with external systems to support both workflow management and Test-Driven Development cycles.</p> <pre><code>C4Context\n    title System Context - AI Agent TDD-Scrum Workflow (Dual State Machine)\n\n    Person(user, \"Product Owner/Engineer\", \"Solo developer using AI agents for TDD-enhanced software development\")\n\n    System_Boundary(system, \"AI Agent Workflow System\") {\n        System(orchestrator, \"Agent Orchestrator\", \"Coordinates AI agents through dual state machines (Workflow + TDD)\")\n    }\n\n    System_Ext(discord, \"Discord\", \"Primary interface for workflow and TDD command interaction\")\n    System_Ext(github, \"GitHub\", \"Source code repository, test preservation, and CI/CD\")\n    System_Ext(anthropic, \"Anthropic API\", \"AI agent capabilities for TDD phases\")\n    System_Ext(ci_system, \"CI/CD System\", \"Test execution, coverage reporting, and quality gates\")\n\n    Rel(user, discord, \"Issues workflow/TDD commands, approves tasks\")\n    Rel(discord, orchestrator, \"Dual command execution, TDD notifications\")\n    Rel(orchestrator, github, \"Code changes, test commits, PR management\")\n    Rel(orchestrator, anthropic, \"Agent task execution with TDD context\")\n    Rel(orchestrator, ci_system, \"Test execution, coverage validation\")\n    Rel(github, user, \"Code review, TDD cycle feedback\")\n    Rel(ci_system, user, \"Test results, coverage reports\")\n    Rel(github, ci_system, \"Test file integration, CI triggers\")</code></pre>"},{"location":"advanced/context/#key-interactions","title":"Key Interactions","text":"<ol> <li>User \u2192 Discord: Issues workflow and TDD slash commands (<code>/epic</code>, <code>/sprint</code>, <code>/tdd test</code>, <code>/tdd code</code>, <code>/approve</code>)</li> <li>Discord \u2192 Orchestrator: Dual command parsing and state transitions (workflow + TDD)</li> <li>Orchestrator \u2192 Agents: Task dispatch with TDD phase coordination</li> <li>Agents \u2192 GitHub: Code implementation, test preservation, and PR creation</li> <li>Agents \u2192 CI System: Test execution, coverage validation, and quality gates</li> <li>GitHub \u2192 User: CI results, TDD cycle progress, and code review</li> <li>CI System \u2192 User: Test results, coverage reports, and TDD metrics</li> <li>User Approval Loop: HITL gates for strategic workflow and TDD decisions</li> <li>Test Preservation Flow: TDD test files committed and preserved through development cycle</li> <li>Dual State Coordination: Workflow and TDD state machines synchronized for sprint completion</li> </ol>"},{"location":"advanced/data-flow/","title":"Data Flow Architecture","text":"<p>This document describes how data flows between the orchestration repository and project repositories in the two-repository model, including the Test-Driven Development workflow and test preservation patterns.</p>"},{"location":"advanced/data-flow/#overview","title":"Overview","text":"<p>The AI Agent TDD-Scrum workflow system operates on a clear separation between: - Orchestration Repository: Central framework, coordination, and dual state machine management - Project Repositories: Individual codebases with embedded project management data and TDD state</p> <p>The system implements dual data flows: - Workflow Data Flow: Project-level state and management data - TDD Data Flow: Story-level TDD cycles, test files, and test preservation</p>"},{"location":"advanced/data-flow/#data-flow-patterns","title":"Data Flow Patterns","text":""},{"location":"advanced/data-flow/#4-tdd-cycle-initialization-flow","title":"4. TDD Cycle Initialization Flow","text":"<pre><code>sequenceDiagram\n    participant O as Orchestrator\n    participant TSM as TDD SM\n    participant DA as Design Agent\n    participant P as Project Repo\n    participant TDD as TDD Storage\n\n    Note over O,P: Sprint starts, TDD cycles created\n    O-&gt;&gt;TSM: Create TDD cycle for story AUTH-1\n    TSM-&gt;&gt;TDD: Initialize cycle data\n    TDD-&gt;&gt;TDD: Create cycle-{id}.json\n    TSM-&gt;&gt;P: Create TDD test directory\n    P-&gt;&gt;P: mkdir tests/tdd/AUTH-1/\n\n    Note over TSM,DA: DESIGN phase begins\n    TSM-&gt;&gt;DA: Start design phase\n    DA-&gt;&gt;P: Read story requirements\n    P-&gt;&gt;DA: Return story data\n    DA-&gt;&gt;DA: Create technical specifications\n    DA-&gt;&gt;TDD: Store design artifacts\n    TDD-&gt;&gt;TDD: Update cycle with design notes\n    DA-&gt;&gt;TSM: Design phase complete\n    TSM-&gt;&gt;TSM: Transition to TEST_RED</code></pre>"},{"location":"advanced/data-flow/#5-test-preservation-workflow","title":"5. Test Preservation Workflow","text":"<pre><code>sequenceDiagram\n    participant QA as QA Agent\n    participant CA as Code Agent\n    participant P as Project Repo\n    participant TDD as TDD Storage\n    participant CI as CI System\n\n    Note over QA,P: TEST_RED phase - create failing tests\n    QA-&gt;&gt;P: Create test files in tests/tdd/AUTH-1/\n    P-&gt;&gt;P: Write test_login.py (failing)\n    QA-&gt;&gt;P: Run tests to confirm failures\n    P-&gt;&gt;QA: Test results (RED)\n    QA-&gt;&gt;TDD: Store test results\n    QA-&gt;&gt;P: Git commit failing tests\n    P-&gt;&gt;P: Commit tests to repository\n\n    Note over CA,P: CODE_GREEN phase - implement minimal code\n    CA-&gt;&gt;P: Read committed test files\n    P-&gt;&gt;CA: Return test requirements\n    CA-&gt;&gt;P: Implement minimal code in src/\n    CA-&gt;&gt;P: Run tests to verify GREEN\n    P-&gt;&gt;CA: Test results (GREEN)\n    CA-&gt;&gt;TDD: Store passing test results\n    CA-&gt;&gt;P: Git commit implementation\n\n    Note over CA,CI: REFACTOR phase - improve while preserving tests\n    CA-&gt;&gt;P: Refactor code quality\n    CA-&gt;&gt;P: Run tests to ensure still GREEN\n    P-&gt;&gt;CA: Test results (GREEN)\n    CA-&gt;&gt;P: Git commit refactored code\n    P-&gt;&gt;CI: Trigger CI pipeline\n    CI-&gt;&gt;P: Run full test suite\n    CI-&gt;&gt;TDD: Store CI results</code></pre>"},{"location":"advanced/data-flow/#6-test-file-lifecycle-management","title":"6. Test File Lifecycle Management","text":"<pre><code>sequenceDiagram\n    participant TSM as TDD SM\n    participant TFM as Test File Manager\n    participant P as Project Repo\n    participant TDD as TDD Storage\n\n    Note over TSM,P: Test file creation in TDD directory\n    TSM-&gt;&gt;TFM: Create test file for story\n    TFM-&gt;&gt;P: tests/tdd/AUTH-1/test_login.py\n    TFM-&gt;&gt;TDD: Track file in TestFile object\n    TDD-&gt;&gt;TDD: Store file metadata\n\n    Note over TFM,P: Test file preservation through phases\n    TFM-&gt;&gt;P: Git commit (TEST_RED \u2192 CODE_GREEN)\n    TFM-&gt;&gt;TDD: Update file status to COMMITTED\n    TFM-&gt;&gt;P: Validate tests remain (CODE_GREEN \u2192 REFACTOR)\n    TFM-&gt;&gt;TDD: Update file status to PASSING\n\n    Note over TFM,P: Test file promotion to permanent location\n    TFM-&gt;&gt;P: Copy to tests/unit/test_login.py\n    TFM-&gt;&gt;TDD: Update file status to INTEGRATED\n    TFM-&gt;&gt;P: Update CI configuration\n    TFM-&gt;&gt;P: Git commit final test integration</code></pre>"},{"location":"advanced/data-flow/#1-project-registration-flow","title":"1. Project Registration Flow","text":"<pre><code>sequenceDiagram\n    participant U as User\n    participant D as Discord Bot\n    participant O as Orchestrator\n    participant P as Project Repo\n    participant G as Git\n\n    U-&gt;&gt;D: /project register &lt;path&gt;\n    D-&gt;&gt;D: Validate path exists\n    D-&gt;&gt;D: Check if git repository\n    D-&gt;&gt;D: Verify no existing channel\n    D-&gt;&gt;P: Initialize .orch-state/\n    P-&gt;&gt;P: Create directory structure\n    P-&gt;&gt;P: Create template files\n    D-&gt;&gt;D: Create Discord channel\n    D-&gt;&gt;O: Register project\n    O-&gt;&gt;O: Add to project registry\n    D-&gt;&gt;U: Registration complete</code></pre>"},{"location":"advanced/data-flow/#2-command-execution-flow","title":"2. Command Execution Flow","text":"<pre><code>sequenceDiagram\n    participant U as User\n    participant D as Discord Bot\n    participant O as Orchestrator\n    participant SM as State Machine\n    participant A as Agent\n    participant P as Project Repo\n\n    U-&gt;&gt;D: /epic \"New feature\"\n    D-&gt;&gt;O: Route command to project\n    O-&gt;&gt;SM: Validate against state\n    SM-&gt;&gt;O: Command allowed\n    O-&gt;&gt;A: Create epic task\n    A-&gt;&gt;P: Read current backlog.json\n    P-&gt;&gt;A: Return project data\n    A-&gt;&gt;A: Create epic object\n    A-&gt;&gt;P: Write updated backlog.json\n    A-&gt;&gt;O: Task complete\n    O-&gt;&gt;D: Success response\n    D-&gt;&gt;U: Epic created notification</code></pre>"},{"location":"advanced/data-flow/#3-sprint-management-with-tdd-integration-flow","title":"3. Sprint Management with TDD Integration Flow","text":"<pre><code>sequenceDiagram\n    participant U as User\n    participant D as Discord Bot\n    participant O as Orchestrator\n    participant WSM as Workflow SM\n    participant TSM as TDD SM\n    participant P as Project Repo\n\n    U-&gt;&gt;D: /sprint plan\n    D-&gt;&gt;O: Route to project\n    O-&gt;&gt;WSM: Validate sprint planning\n    WSM-&gt;&gt;O: Planning allowed\n    O-&gt;&gt;P: Read backlog.json\n    P-&gt;&gt;O: Return stories\n    O-&gt;&gt;P: Create sprint in sprints/\n    P-&gt;&gt;P: Write sprint-xxx.json\n    O-&gt;&gt;P: Update story assignments\n    P-&gt;&gt;P: Update backlog.json\n\n    Note over O,TSM: Sprint start triggers TDD cycles\n    U-&gt;&gt;D: /sprint start\n    D-&gt;&gt;O: Start sprint\n    O-&gt;&gt;WSM: Transition to SPRINT_ACTIVE\n    loop For each story in sprint\n        O-&gt;&gt;TSM: Create TDD cycle\n        TSM-&gt;&gt;P: Create TDD state in .orch-state/tdd/\n        P-&gt;&gt;P: Initialize story TDD directory\n    end\n\n    O-&gt;&gt;D: Sprint and TDD cycles active\n    D-&gt;&gt;U: Show sprint and TDD status</code></pre>"},{"location":"advanced/data-flow/#data-storage-patterns","title":"Data Storage Patterns","text":""},{"location":"advanced/data-flow/#orchestration-repository","title":"Orchestration Repository","text":"<pre><code>agent-workflow/\n\u251c\u2500\u2500 lib/\n\u2502   \u251c\u2500\u2500 agents/              # Agent definitions (global)\n\u2502   \u251c\u2500\u2500 state_machine.py     # Workflow states (global)\n\u2502   \u251c\u2500\u2500 discord_bot.py       # Interface (global)\n\u2502   \u2514\u2500\u2500 agent_tool_config.py # Security policies (global)\n\u251c\u2500\u2500 scripts/\n\u2502   \u2514\u2500\u2500 orchestrator.py      # Coordination engine (global)\n\u2514\u2500\u2500 docs_src/               # Framework documentation (global)\n</code></pre>"},{"location":"advanced/data-flow/#project-repository","title":"Project Repository","text":"<pre><code>project-repo/\n\u251c\u2500\u2500 src/                    # Project code (project-specific)\n\u251c\u2500\u2500 tests/                  # Project tests (project-specific)\n\u2502   \u251c\u2500\u2500 unit/              # Permanent unit tests\n\u2502   \u251c\u2500\u2500 integration/       # Permanent integration tests\n\u2502   \u2514\u2500\u2500 tdd/               # TDD working directory\n\u2502       \u2514\u2500\u2500 {story-id}/    # Per-story TDD tests\n\u251c\u2500\u2500 .orch-state/           # Workflow data (project-specific)\n\u2502   \u251c\u2500\u2500 backlog.json       # Project management data\n\u2502   \u251c\u2500\u2500 sprints/           # Sprint history\n\u2502   \u251c\u2500\u2500 tdd/               # TDD state storage\n\u2502   \u2502   \u251c\u2500\u2500 cycles/        # TDD cycle data\n\u2502   \u2502   \u2514\u2500\u2500 test-results/  # Test execution results\n\u2502   \u251c\u2500\u2500 architecture.md    # Project architecture decisions\n\u2502   \u251c\u2500\u2500 best-practices.md  # Project conventions\n\u2502   \u2514\u2500\u2500 status.json        # Current workflow state\n\u2514\u2500\u2500 .git/                  # Version control (project-specific)\n</code></pre>"},{"location":"advanced/data-flow/#readwrite-access-patterns","title":"Read/Write Access Patterns","text":""},{"location":"advanced/data-flow/#read-operations","title":"Read Operations","text":"<ul> <li>Orchestrator \u2192 Project: Reads workflow state, backlog, and configuration</li> <li>TDD State Machine \u2192 Project: Reads TDD cycles, test results, and coverage</li> <li>Discord Bot \u2192 Project: Displays current workflow and TDD status</li> <li>Agents \u2192 Project: Access context for both workflow and TDD decision making</li> <li>Test File Manager \u2192 Project: Reads test files and execution results</li> </ul>"},{"location":"advanced/data-flow/#write-operations","title":"Write Operations","text":"<ul> <li>Orchestrator \u2192 Project: Updates workflow state and project data</li> <li>TDD State Machine \u2192 Project: Updates TDD cycle state and test data</li> <li>Agents \u2192 Project: Persist workflow task results and TDD artifacts</li> <li>Discord Commands \u2192 Project: Modify backlogs, sprints, and TDD cycles</li> <li>Test Preservation \u2192 Project: Commit and promote test files</li> </ul>"},{"location":"advanced/data-flow/#security-boundaries","title":"Security Boundaries","text":"<ul> <li>No Cross-Project Access: Agents cannot read other project data or TDD cycles</li> <li>Limited Write Scope: Only <code>.orch-state/</code> and <code>tests/tdd/</code> directories writable</li> <li>TDD Isolation: TDD cycles isolated per story to prevent test contamination</li> <li>Git Permissions: Standard repository access controls apply to both workflow and test data</li> </ul>"},{"location":"advanced/data-flow/#state-synchronization","title":"State Synchronization","text":""},{"location":"advanced/data-flow/#dual-state-machine-coordination","title":"Dual State Machine Coordination","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; IDLE\n\n    state \"Workflow States\" as WF {\n        IDLE --&gt; BACKLOG_READY: /epic\n        BACKLOG_READY --&gt; SPRINT_PLANNED: /sprint plan\n        SPRINT_PLANNED --&gt; SPRINT_ACTIVE: /sprint start\n        SPRINT_ACTIVE --&gt; SPRINT_REVIEW: /sprint status\n        SPRINT_REVIEW --&gt; IDLE: /feedback\n    }\n\n    state \"TDD States (Per Story)\" as TDD {\n        [*] --&gt; DESIGN\n        DESIGN --&gt; TEST_RED: /tdd test\n        TEST_RED --&gt; CODE_GREEN: /tdd commit-tests\n        CODE_GREEN --&gt; REFACTOR: /tdd commit-code\n        REFACTOR --&gt; COMMIT: /tdd commit-refactor\n        COMMIT --&gt; [*]\n    }\n\n    SPRINT_ACTIVE --&gt; TDD: Story TDD cycles\n    TDD --&gt; SPRINT_REVIEW: All stories complete\n\n    note right of WF\n        Workflow state stored in\n        .orch-state/status.json\n    end note\n\n    note right of TDD\n        TDD state stored in\n        .orch-state/tdd/cycles/\n    end note</code></pre>"},{"location":"advanced/data-flow/#multi-project-coordination","title":"Multi-Project Coordination","text":"<ul> <li>Independent Dual States: Each project has own workflow and TDD state machines</li> <li>Parallel Execution: Multiple projects and TDD cycles can be active simultaneously</li> <li>Resource Sharing: Agents allocated per project and TDD phase needs</li> <li>Conflict Prevention: Discord channels provide isolation for both workflow and TDD commands</li> <li>TDD Isolation: TDD cycles per story prevent cross-story test contamination</li> </ul>"},{"location":"advanced/data-flow/#data-consistency","title":"Data Consistency","text":""},{"location":"advanced/data-flow/#eventual-consistency-model","title":"Eventual Consistency Model","text":"<ul> <li>Local Consistency: Each project maintains internal consistency for both workflow and TDD data</li> <li>Dual State Consistency: Workflow and TDD state machines maintain synchronized state</li> <li>Global Coordination: Orchestrator ensures cross-project resource allocation and TDD cycle coordination</li> <li>Conflict Resolution: Manual intervention for complex workflow and TDD scenarios</li> </ul>"},{"location":"advanced/data-flow/#transaction-boundaries","title":"Transaction Boundaries","text":"<ul> <li>Single Project: ACID properties maintained within project for both workflow and TDD data</li> <li>Cross Project: No transactions spanning projects or TDD cycles</li> <li>TDD Atomicity: TDD phase transitions are atomic within a story</li> <li>Rollback Strategy: Git provides rollback capabilities for both code and test artifacts</li> </ul>"},{"location":"advanced/data-flow/#backup-and-recovery","title":"Backup and Recovery","text":"<ul> <li>Git History: Complete audit trail of all workflow and TDD changes</li> <li>State Recovery: Projects can be restored from any git commit including TDD state</li> <li>Test Preservation: TDD test artifacts preserved through git history</li> <li>Disaster Recovery: Projects portable between orchestration instances with full TDD history</li> </ul>"},{"location":"advanced/data-flow/#performance-considerations","title":"Performance Considerations","text":""},{"location":"advanced/data-flow/#read-performance","title":"Read Performance","text":"<ul> <li>Local Access: Project and TDD data accessed directly from filesystem</li> <li>Caching Strategy: Orchestrator caches frequently accessed workflow and TDD state</li> <li>Lazy Loading: Project and TDD data loaded on-demand</li> <li>TDD State Optimization: TDD cycles loaded only when stories are active</li> </ul>"},{"location":"advanced/data-flow/#write-performance","title":"Write Performance","text":"<ul> <li>Batched Writes: Multiple workflow and TDD changes combined into single commits</li> <li>Asynchronous Operations: Non-blocking writes to project repositories and TDD storage</li> <li>Conflict Avoidance: Structured data minimizes merge conflicts for both workflow and TDD data</li> <li>Test File Efficiency: Test files written incrementally during TDD phases</li> </ul>"},{"location":"advanced/data-flow/#scalability","title":"Scalability","text":"<ul> <li>Horizontal Scaling: Add projects and TDD cycles without affecting others</li> <li>Resource Isolation: Per-project and per-story resource allocation</li> <li>Network Efficiency: Local filesystem access minimizes I/O for both workflow and test data</li> <li>TDD Parallelization: Multiple TDD cycles can run simultaneously across stories</li> </ul>"},{"location":"advanced/data-flow/#monitoring-and-observability","title":"Monitoring and Observability","text":""},{"location":"advanced/data-flow/#data-flow-metrics","title":"Data Flow Metrics","text":"<ul> <li>Command Latency: Time from Discord to project and TDD updates</li> <li>State Transition Frequency: Workflow and TDD progression rates</li> <li>Error Rates: Failed operations per project and TDD cycle</li> <li>TDD Cycle Metrics: Time spent in each TDD phase, test coverage progression</li> <li>Test Preservation Success: Rate of successful test file lifecycle management</li> </ul>"},{"location":"advanced/data-flow/#audit-trail","title":"Audit Trail","text":"<ul> <li>Git History: All workflow and TDD changes tracked in version control</li> <li>Discord Logs: Command execution history for both workflow and TDD commands</li> <li>Agent Logs: Detailed task execution traces including TDD phase transitions</li> <li>TDD Logs: Test creation, execution, and preservation activities</li> <li>Test Result History: Complete test execution timeline and results</li> </ul>"},{"location":"advanced/data-flow/#health-checks","title":"Health Checks","text":"<ul> <li>Project Repository: Git status and filesystem health for both workflow and test data</li> <li>Data Integrity: JSON schema validation for workflow and TDD state</li> <li>State Consistency: Dual state machine validation and synchronization</li> <li>Test File Integrity: Verification of test file preservation and promotion</li> <li>TDD Cycle Health: Detection of stuck TDD cycles and automated recovery</li> </ul>"},{"location":"advanced/orchestration-repo/","title":"Orchestration Repository Architecture","text":"<p>The orchestration repository (this repository) contains the AI agent framework, dual state machine architecture, and multi-project coordination logic. It serves as the centralized system that manages multiple project repositories with integrated Test-Driven Development workflows.</p>"},{"location":"advanced/orchestration-repo/#responsibilities","title":"Responsibilities","text":""},{"location":"advanced/orchestration-repo/#core-framework","title":"Core Framework","text":"<ul> <li>Enhanced Agent Definitions: TDD-capable AI agent types (CodeAgent, DesignAgent, QAAgent, DataAgent)</li> <li>Dual State Machines: Workflow and TDD state management with validation</li> <li>Discord Bot: Human-In-The-Loop interface for workflow and TDD commands</li> <li>Enhanced Security System: Agent tool access control with TDD phase restrictions</li> <li>Orchestrator: Central coordination engine with dual state machine support</li> <li>TDD Framework: Complete TDD cycle management and test preservation system</li> </ul>"},{"location":"advanced/orchestration-repo/#multi-project-management","title":"Multi-Project Management","text":"<ul> <li>Project Registry: Configuration and discovery of project repositories with TDD support</li> <li>Channel Management: Automatic Discord channel creation per project with TDD command support</li> <li>Dual State Coordination: Cross-project workflow and TDD cycle management</li> <li>Resource Allocation: Agent assignment and task distribution across workflow and TDD phases</li> <li>TDD Orchestration: Parallel TDD cycle management across multiple stories and projects</li> </ul>"},{"location":"advanced/orchestration-repo/#global-configuration","title":"Global Configuration","text":"<ul> <li>Enhanced Agent Security Profiles: Tool access restrictions per agent type with TDD phase controls</li> <li>Workflow Templates: Reusable workflow definitions with TDD integration</li> <li>TDD Templates: Reusable TDD cycle configurations and quality gates</li> <li>Discord Bot Configuration: Global bot settings for workflow and TDD commands</li> <li>Logging and Monitoring: Centralized logging across all projects including TDD activities</li> </ul>"},{"location":"advanced/orchestration-repo/#architecture-components","title":"Architecture Components","text":"<pre><code>graph TB\n    subgraph \"Orchestration Repository (Enhanced)\"\n        O[Orchestrator]\n        DB[Discord Bot]\n        WSM[Workflow SM]\n        TSM[TDD SM]\n        SC[State Coordinator]\n        A[Enhanced Agents]\n        S[Security System]\n        TDD[TDD Framework]\n\n        O --&gt; DB\n        O --&gt; WSM\n        O --&gt; TSM\n        O --&gt; SC\n        O --&gt; A\n        O --&gt; TDD\n        A --&gt; S\n        WSM --&gt; SC\n        TSM --&gt; SC\n        TDD --&gt; TSM\n    end\n\n    subgraph \"Project Repository 1\"\n        P1[Project Code]\n        D1[.orch-state/]\n        T1[tests/tdd/]\n    end\n\n    subgraph \"Project Repository 2\"\n        P2[Project Code]\n        D2[.orch-state/]\n        T2[tests/tdd/]\n    end\n\n    O --&gt; D1\n    O --&gt; D2\n    DB --&gt; D1\n    DB --&gt; D2\n    TDD --&gt; T1\n    TDD --&gt; T2</code></pre>"},{"location":"advanced/orchestration-repo/#data-flow","title":"Data Flow","text":""},{"location":"advanced/orchestration-repo/#project-registration","title":"Project Registration","text":"<ol> <li>User runs <code>/project register &lt;path&gt;</code> in Discord</li> <li>Discord Bot validates project path and git repository</li> <li>Orchestrator creates project instance with storage</li> <li>Discord channel created with naming convention <code>{hostname}-{projectname}</code></li> <li>Project structure initialized in target repository</li> </ol>"},{"location":"advanced/orchestration-repo/#enhanced-command-execution-with-tdd-support","title":"Enhanced Command Execution (with TDD Support)","text":"<ol> <li>User issues workflow or TDD command in project-specific Discord channel</li> <li>Discord Bot routes command to Orchestrator with project and TDD context</li> <li>Orchestrator validates command against appropriate state machine (workflow or TDD)</li> <li>State Coordinator ensures dual state machine consistency</li> <li>Appropriate agent executes command with enhanced security restrictions</li> <li>Results stored in project repository's <code>.orch-state/</code> directory (workflow or TDD)</li> <li>TDD-specific results also stored in <code>tests/tdd/</code> directory structure</li> </ol>"},{"location":"advanced/orchestration-repo/#enhanced-state-management-dual-state-architecture","title":"Enhanced State Management (Dual State Architecture)","text":"<ul> <li>Global State: Orchestrator maintains registry of all projects with dual state tracking</li> <li>Project Workflow State: Each project has independent workflow state machine</li> <li>Project TDD State: Each project has independent TDD state machines per story</li> <li>Dual Persistence: </li> <li>Workflow state persisted in <code>.orch-state/status.json</code></li> <li>TDD state persisted in <code>.orch-state/tdd/</code> directory</li> <li>State Coordination: State Coordinator ensures workflow and TDD state consistency</li> <li>Synchronization: Discord Bot keeps channel mappings current for both workflow and TDD</li> </ul>"},{"location":"advanced/orchestration-repo/#security-architecture","title":"Security Architecture","text":""},{"location":"advanced/orchestration-repo/#enhanced-agent-isolation-with-tdd-controls","title":"Enhanced Agent Isolation (with TDD Controls)","text":"<ul> <li>Each project has isolated agent instances with TDD capabilities</li> <li>Agents cannot access data from other projects or TDD cycles</li> <li>Story-level TDD isolation prevents cross-story contamination</li> <li>Tool access restricted based on agent type, project context, and TDD phase</li> <li>TDD phase-specific restrictions ensure proper test preservation</li> </ul>"},{"location":"advanced/orchestration-repo/#enhanced-repository-boundaries-with-tdd-support","title":"Enhanced Repository Boundaries (with TDD Support)","text":"<ul> <li>Orchestration repo has read-only access to project repos</li> <li>Write access limited to <code>.orch-state/</code> and <code>tests/tdd/</code> directories only</li> <li>No cross-project or cross-story TDD data access without explicit permission</li> <li>Test file preservation workflow enforces proper access controls</li> </ul>"},{"location":"advanced/orchestration-repo/#enhanced-discord-security-with-tdd-commands","title":"Enhanced Discord Security (with TDD Commands)","text":"<ul> <li>Project-specific channels provide access control for workflow and TDD commands</li> <li>Commands validated against project membership and TDD cycle permissions</li> <li>Audit trail maintained in project repositories for both workflow and TDD activities</li> <li>TDD command permissions integrated with Discord role-based access control</li> </ul>"},{"location":"advanced/orchestration-repo/#deployment-model","title":"Deployment Model","text":""},{"location":"advanced/orchestration-repo/#single-instance","title":"Single Instance","text":"<ul> <li>One orchestration instance manages multiple projects</li> <li>Scales horizontally by project distribution</li> <li>Discord Bot provides unified interface</li> </ul>"},{"location":"advanced/orchestration-repo/#enhanced-configuration-with-tdd-support","title":"Enhanced Configuration (with TDD Support)","text":"<ul> <li>Projects registered via Discord commands with TDD capabilities enabled</li> <li>TDD templates and quality gates configured automatically</li> <li>No manual configuration files required for workflow or TDD setup</li> <li>Self-discovering and self-healing for both workflow and TDD state</li> </ul>"},{"location":"advanced/orchestration-repo/#enhanced-monitoring-with-tdd-metrics","title":"Enhanced Monitoring (with TDD Metrics)","text":"<ul> <li>Centralized logging from all projects including TDD activities</li> <li>Health checks per project covering workflow and TDD state</li> <li>Performance metrics aggregated across projects including TDD cycle times</li> <li>TDD-specific metrics: cycle completion rates, test coverage trends, quality gate pass rates</li> <li>Real-time TDD cycle monitoring and stuck cycle detection</li> </ul>"},{"location":"advanced/project-repo/","title":"Project Repository Architecture","text":"<p>Project repositories contain the actual code being developed with AI assistance using Test-Driven Development workflows. Each project repository maintains its own project management data, workflow state, and TDD state while being coordinated by the orchestration system's dual state machine architecture.</p>"},{"location":"advanced/project-repo/#repository-structure","title":"Repository Structure","text":"<pre><code>project-repository/\n\u251c\u2500\u2500 src/                     # Project source code\n\u251c\u2500\u2500 tests/                   # Project tests\n\u2502   \u251c\u2500\u2500 unit/                # Permanent unit tests\n\u2502   \u251c\u2500\u2500 integration/         # Permanent integration tests\n\u2502   \u2514\u2500\u2500 tdd/                 # TDD working directory\n\u2502       \u251c\u2500\u2500 AUTH-1/          # Story-specific TDD tests\n\u2502       \u2502   \u251c\u2500\u2500 test_login.py\n\u2502       \u2502   \u2514\u2500\u2500 test_auth.py\n\u2502       \u2514\u2500\u2500 AUTH-2/          # Another story's TDD tests\n\u251c\u2500\u2500 .git/                    # Git repository\n\u251c\u2500\u2500 .orch-state/            # AI workflow state (managed by orchestration)\n\u2502   \u251c\u2500\u2500 backlog.json        # Epics, stories, and priorities\n\u2502   \u251c\u2500\u2500 sprints/            # Sprint data and retrospectives\n\u2502   \u2502   \u251c\u2500\u2500 sprint-abc123.json\n\u2502   \u2502   \u2514\u2500\u2500 sprint-def456.json\n\u2502   \u251c\u2500\u2500 tdd/                # TDD state storage\n\u2502   \u2502   \u251c\u2500\u2500 cycles/         # TDD cycle data per story\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 AUTH-1-cycle.json\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 AUTH-2-cycle.json\n\u2502   \u2502   \u2514\u2500\u2500 test-results/   # Test execution results\n\u2502   \u2502       \u251c\u2500\u2500 AUTH-1-results.json\n\u2502   \u2502       \u2514\u2500\u2500 coverage-reports/\n\u2502   \u251c\u2500\u2500 architecture.md     # Project-specific architecture decisions\n\u2502   \u251c\u2500\u2500 best-practices.md   # Project conventions and patterns\n\u2502   \u2514\u2500\u2500 status.json         # Current workflow state\n\u2514\u2500\u2500 README.md               # Project documentation\n</code></pre>"},{"location":"advanced/project-repo/#orch-state-directory","title":"<code>.orch-state/</code> Directory","text":""},{"location":"advanced/project-repo/#purpose","title":"Purpose","text":"<p>The <code>.orch-state/</code> directory stores all AI workflow-related data and TDD state within the project repository, ensuring that project management information and TDD cycle data are version-controlled alongside the code. This includes both high-level workflow state and detailed TDD cycle progression.</p>"},{"location":"advanced/project-repo/#enhanced-contents-with-tdd-support","title":"Enhanced Contents (with TDD Support)","text":""},{"location":"advanced/project-repo/#new-tdd-specific-storage","title":"New TDD-Specific Storage","text":"<p><code>.orch-state/tdd/</code> Directory Structure: - <code>cycles/</code>: TDD cycle data per story - <code>test-results/</code>: Test execution results and metrics - <code>coverage-reports/</code>: Test coverage data and trends - <code>metrics/</code>: TDD performance and quality metrics</p> <p><code>tests/tdd/</code> Directory Structure: - <code>{story-id}/</code>: Story-specific test files during TDD development - Test files preserved through TDD phases - Eventually promoted to permanent test locations</p>"},{"location":"advanced/project-repo/#traditional-contents-enhanced","title":"Traditional Contents (Enhanced)","text":""},{"location":"advanced/project-repo/#backlogjson","title":"<code>backlog.json</code>","text":"<p>Contains all project management data: <pre><code>{\n  \"epics\": [\n    {\n      \"id\": \"epic-001\",\n      \"title\": \"User Authentication System\",\n      \"description\": \"Complete user auth with login, registration, and session management\",\n      \"created_at\": \"2024-01-15T10:30:00Z\",\n      \"status\": \"active\"\n    }\n  ],\n  \"stories\": [\n    {\n      \"id\": \"story-001\",\n      \"epic_id\": \"epic-001\",\n      \"title\": \"User login functionality\",\n      \"description\": \"As a user, I want to log in with email/password\",\n      \"acceptance_criteria\": [\"Login form validation\", \"Error handling\", \"Session creation\"],\n      \"priority\": 1,\n      \"status\": \"backlog\",\n      \"sprint_id\": null,\n      \"created_at\": \"2024-01-15T10:35:00Z\"\n    }\n  ],\n  \"sprints\": [\n    {\n      \"id\": \"sprint-001\",\n      \"goal\": \"Implement basic user authentication\",\n      \"start_date\": \"2024-01-16\",\n      \"end_date\": \"2024-01-30\",\n      \"story_ids\": [\"story-001\", \"story-002\"],\n      \"status\": \"active\",\n      \"created_at\": \"2024-01-16T09:00:00Z\"\n    }\n  ]\n}\n</code></pre></p>"},{"location":"advanced/project-repo/#sprints-directory","title":"<code>sprints/</code> Directory","text":"<p>Individual sprint files with detailed information: <pre><code>{\n  \"id\": \"sprint-001\",\n  \"goal\": \"Implement basic user authentication\",\n  \"start_date\": \"2024-01-16\",\n  \"end_date\": \"2024-01-30\",\n  \"story_ids\": [\"story-001\", \"story-002\"],\n  \"status\": \"completed\",\n  \"retrospective\": {\n    \"what_went_well\": [\n      \"Good test coverage achieved\",\n      \"Clear user stories helped focus development\"\n    ],\n    \"what_could_improve\": [\n      \"Better estimation needed\",\n      \"More frequent code reviews\"\n    ],\n    \"action_items\": [\n      \"Implement automated testing pipeline\",\n      \"Schedule daily standup meetings\"\n    ]\n  }\n}\n</code></pre></p>"},{"location":"advanced/project-repo/#architecturemd","title":"<code>architecture.md</code>","text":"<p>Project-specific architectural decisions and design documentation: <pre><code># Project Architecture\n\n## Overview\nThis project implements a modern web application with React frontend and Node.js backend.\n\n## Components\n- Frontend: React 18 with TypeScript\n- Backend: Node.js with Express\n- Database: PostgreSQL with Prisma ORM\n- Authentication: JWT with refresh tokens\n\n## Design Decisions\n- **Microservices**: Monolithic architecture chosen for simplicity\n- **State Management**: Redux Toolkit for complex state scenarios\n- **Testing**: Jest + React Testing Library for unit tests\n\n## Dependencies\n- External APIs: Stripe for payments, SendGrid for emails\n- Third-party libraries: Material-UI for components\n\n## Future Considerations\n- Migration to microservices when scaling becomes necessary\n- Implementation of GraphQL for more efficient data fetching\n</code></pre></p>"},{"location":"advanced/project-repo/#best-practicesmd","title":"<code>best-practices.md</code>","text":"<p>Project-specific coding standards and AI agent guidelines: <pre><code># Project Best Practices\n\n## Code Standards\n- Use TypeScript for all new code\n- Follow ESLint and Prettier configurations\n- Minimum 80% test coverage required\n\n## Testing Strategy\n- Unit tests for all business logic\n- Integration tests for API endpoints\n- E2E tests for critical user workflows\n\n## Git Workflow\n- Feature branches from main\n- Pull request required for all changes\n- Squash and merge strategy\n\n## AI Agent Guidelines\n- CodeAgent should follow existing patterns in src/utils/\n- Use established error handling patterns\n- Maintain consistency with existing component structure\n\n## Review Process\n- Automated tests must pass\n- Code review by at least one team member\n- Security review for authentication changes\n</code></pre></p>"},{"location":"advanced/project-repo/#statusjson","title":"<code>status.json</code>","text":"<p>Current workflow state and metadata with TDD integration: <pre><code>{\n  \"current_state\": \"SPRINT_ACTIVE\",\n  \"orchestration_mode\": \"blocking\",\n  \"last_updated\": \"2024-01-20T14:30:00Z\",\n  \"active_tasks\": [\n    {\n      \"id\": \"task-001\",\n      \"agent_type\": \"CodeAgent\",\n      \"command\": \"Implement user login form\",\n      \"status\": \"in_progress\",\n      \"tdd_context\": {\n        \"story_id\": \"AUTH-1\",\n        \"current_tdd_state\": \"CODE_GREEN\",\n        \"cycle_id\": \"cycle-abc123\"\n      }\n    }\n  ],\n  \"pending_approvals\": [\"story-003\", \"story-004\"],\n  \"active_tdd_cycles\": {\n    \"AUTH-1\": \"CODE_GREEN\",\n    \"AUTH-2\": \"TEST_RED\",\n    \"AUTH-3\": \"DESIGN\"\n  },\n  \"tdd_summary\": {\n    \"total_cycles\": 3,\n    \"completed_cycles\": 0,\n    \"average_cycle_time\": \"0h 00m\",\n    \"overall_test_coverage\": 0.0\n  }\n}\n</code></pre></p>"},{"location":"advanced/project-repo/#tdd-cycle-data-orch-statetddcyclesauth-1-cyclejson","title":"TDD Cycle Data (<code>.orch-state/tdd/cycles/AUTH-1-cycle.json</code>)","text":"<p>Detailed TDD cycle state and progress: <pre><code>{\n  \"id\": \"cycle-abc123\",\n  \"story_id\": \"AUTH-1\",\n  \"current_state\": \"CODE_GREEN\",\n  \"current_task_id\": \"task-def456\",\n  \"tasks\": [\n    {\n      \"id\": \"task-def456\",\n      \"description\": \"Implement user login validation\",\n      \"current_state\": \"CODE_GREEN\",\n      \"test_files\": [\"tests/tdd/AUTH-1/test_login.py\"],\n      \"test_file_objects\": [\n        {\n          \"id\": \"testfile-ghi789\",\n          \"file_path\": \"/project/tests/tdd/AUTH-1/test_login.py\",\n          \"relative_path\": \"tests/tdd/AUTH-1/test_login.py\",\n          \"status\": \"committed\",\n          \"test_count\": 5,\n          \"passing_tests\": 5,\n          \"failing_tests\": 0,\n          \"coverage_percentage\": 92.5\n        }\n      ],\n      \"design_notes\": \"Login form with email/password validation\",\n      \"implementation_notes\": \"Minimal implementation to pass tests\"\n    }\n  ],\n  \"started_at\": \"2024-01-20T10:00:00Z\",\n  \"total_test_runs\": 12,\n  \"total_commits\": 3,\n  \"ci_status\": \"passed\",\n  \"overall_test_coverage\": 92.5\n}\n</code></pre></p>"},{"location":"advanced/project-repo/#test-results-data-orch-statetddtest-resultsauth-1-resultsjson","title":"Test Results Data (<code>.orch-state/tdd/test-results/AUTH-1-results.json</code>)","text":"<p>Test execution history and metrics: <pre><code>{\n  \"story_id\": \"AUTH-1\",\n  \"cycle_id\": \"cycle-abc123\",\n  \"latest_results\": [\n    {\n      \"id\": \"result-jkl012\",\n      \"test_file\": \"tests/tdd/AUTH-1/test_login.py\",\n      \"test_name\": \"test_valid_login\",\n      \"status\": \"green\",\n      \"execution_time\": 0.045,\n      \"timestamp\": \"2024-01-20T14:25:00Z\"\n    }\n  ],\n  \"test_run_history\": [\n    {\n      \"timestamp\": \"2024-01-20T14:25:00Z\",\n      \"total_tests\": 5,\n      \"passing\": 5,\n      \"failing\": 0,\n      \"coverage\": 92.5,\n      \"phase\": \"CODE_GREEN\"\n    }\n  ],\n  \"coverage_trend\": {\n    \"baseline\": 0.0,\n    \"current\": 92.5,\n    \"target\": 90.0,\n    \"trend\": \"increasing\"\n  }\n}\n</code></pre></p>"},{"location":"advanced/project-repo/#version-control-integration","title":"Version Control Integration","text":""},{"location":"advanced/project-repo/#enhanced-git-integration-with-tdd-support","title":"Enhanced Git Integration (with TDD Support)","text":"<ul> <li>All <code>.orch-state/</code> files are version controlled (workflow + TDD data)</li> <li>TDD cycle changes tracked alongside code modifications</li> <li>Test file preservation through git commits during TDD phases</li> <li>Sprint data and TDD metrics preserved in project history</li> <li>Architecture decisions and TDD insights documented over time</li> <li>Complete TDD audit trail from design through commit phases</li> </ul>"},{"location":"advanced/project-repo/#enhanced-branching-strategy-with-tdd-support","title":"Enhanced Branching Strategy (with TDD Support)","text":"<ul> <li><code>.orch-state/</code> changes typically made on main branch (workflow + TDD data)</li> <li>Sprint planning updates committed as project milestones with TDD cycle initialization</li> <li>Feature branches may update story status and TDD cycle progress</li> <li>TDD test files committed during RED phase to preserve failing tests</li> <li>Code implementation committed during GREEN phase with passing tests</li> <li>Refactored code committed during REFACTOR phase with continued test success</li> </ul>"},{"location":"advanced/project-repo/#enhanced-conflict-resolution-with-tdd-support","title":"Enhanced Conflict Resolution (with TDD Support)","text":"<ul> <li>Merge conflicts in <code>.orch-state/</code> resolved like any code (workflow + TDD data)</li> <li>Orchestrator detects and reports dual state inconsistencies</li> <li>TDD cycle conflicts resolved with test preservation priority</li> <li>Manual intervention required for complex workflow and TDD conflicts</li> <li>Test file conflicts resolved with latest working test version</li> </ul>"},{"location":"advanced/project-repo/#data-ownership","title":"Data Ownership","text":""},{"location":"advanced/project-repo/#enhanced-project-data-with-tdd-support","title":"Enhanced Project Data (with TDD Support)","text":"<ul> <li>Belongs to Project: Stories, epics, sprints, architecture decisions, TDD cycles, test results</li> <li>Versioned with Code: All management and TDD data tracked in git</li> <li>Project-Specific: No shared data between projects or TDD cycles</li> <li>Story-Level TDD Isolation: TDD cycles and test files isolated per story</li> </ul>"},{"location":"advanced/project-repo/#orchestration-data","title":"Orchestration Data","text":"<ul> <li>Belongs to Orchestrator: Agent definitions, security policies</li> <li>Global Configuration: Shared across all projects</li> <li>Runtime State: Project registration and channel mappings</li> </ul>"},{"location":"advanced/project-repo/#benefits-of-repository-co-location","title":"Benefits of Repository Co-location","text":""},{"location":"advanced/project-repo/#consistency","title":"Consistency","text":"<ul> <li>Project management data evolves with code</li> <li>Architecture decisions documented alongside implementation</li> <li>Sprint retrospectives linked to specific code versions</li> </ul>"},{"location":"advanced/project-repo/#auditability","title":"Auditability","text":"<ul> <li>Complete history of project decisions</li> <li>Correlation between features and planning data</li> <li>Compliance and tracking for regulated environments</li> </ul>"},{"location":"advanced/project-repo/#portability","title":"Portability","text":"<ul> <li>Projects can be moved between orchestration instances</li> <li>Self-contained project data travels with repository</li> <li>No external dependencies for project management data</li> </ul>"},{"location":"advanced/project-repo/#access-patterns","title":"Access Patterns","text":""},{"location":"advanced/project-repo/#enhanced-read-access-with-tdd-support","title":"Enhanced Read Access (with TDD Support)","text":"<ul> <li>Orchestrator reads project workflow and TDD state</li> <li>Discord Bot displays current workflow and TDD status with progress</li> <li>Agents access project and TDD context for decision making</li> <li>TDD agents read test files and execution results for phase coordination</li> </ul>"},{"location":"advanced/project-repo/#enhanced-write-access-with-tdd-support","title":"Enhanced Write Access (with TDD Support)","text":"<ul> <li>Only orchestrator writes to <code>.orch-state/</code> (workflow + TDD data)</li> <li>TDD agents write to <code>tests/tdd/</code> directory during appropriate phases</li> <li>Changes made through Discord workflow and TDD commands</li> <li>Agent results persisted automatically in appropriate storage locations</li> <li>Test files preserved through TDD phase transitions</li> </ul>"},{"location":"advanced/project-repo/#enhanced-security-with-tdd-support","title":"Enhanced Security (with TDD Support)","text":"<ul> <li>Repository access controls apply to workflow and TDD data</li> <li>No cross-project or cross-story TDD data leakage</li> <li>TDD phase-specific access controls for test file modifications</li> <li>Standard git permissions model used for both code and test artifacts</li> <li>Story-level TDD isolation enforced through directory structure and access controls</li> </ul>"},{"location":"advanced/security-implementation/","title":"Security Architecture","text":""},{"location":"advanced/security-implementation/#overview","title":"Overview","text":"<p>The AI Agent TDD-Scrum Workflow system implements comprehensive security measures to ensure safe operation of AI agents with appropriate access controls and data protection. This includes enhanced security boundaries for Test-Driven Development workflows, test file access controls, and TDD-specific agent restrictions.</p>"},{"location":"advanced/security-implementation/#agent-security-model","title":"Agent Security Model","text":""},{"location":"advanced/security-implementation/#command-access-control","title":"Command Access Control","text":"<p>Each agent type operates under the Principle of Least Privilege, with access restricted to only the tools necessary for their specific function.</p> <pre><code>graph LR\n    subgraph \"Agent Security Layers\"\n        Claude[Claude Code CLI]\n        Config[Agent Tool Config]\n        Validation[Access Validation]\n    end\n\n    subgraph \"Agent Types\"\n        Orchestrator[Orchestrator&lt;br/&gt;Full Access]\n        Code[Code Agent&lt;br/&gt;Edit + Commit]\n        Design[Design Agent&lt;br/&gt;Read Only]\n        QA[QA Agent&lt;br/&gt;Test Only]\n        Data[Data Agent&lt;br/&gt;Analysis Only]\n    end\n\n    Claude --&gt; Config\n    Config --&gt; Validation\n    Validation --&gt; Orchestrator\n    Validation --&gt; Code\n    Validation --&gt; Design\n    Validation --&gt; QA\n    Validation --&gt; Data</code></pre>"},{"location":"advanced/security-implementation/#enhanced-agent-access-matrix-with-tdd-capabilities","title":"Enhanced Agent Access Matrix (with TDD Capabilities)","text":"Tool Category Orchestrator Code Agent (TDD) Design Agent (TDD) QA Agent (TDD) Data Agent File Operations Read files \u2705 \u2705 \u2705 \u2705 \u2705 Write new files \u2705 \u2705 \u2705 \u2705 \u2705 Edit existing code \u2705 \u2705 \u274c \u274c \u274c Delete files \u2705 \u274c \u274c \u274c \u274c TDD-Specific File Operations Create test files \u2705 \u2705 \u274c \u2705 \u274c Edit test files \u2705 \u2705 (during CODE_GREEN) \u274c \u2705 (during TEST_RED) \u274c Preserve test files \u2705 \u2705 \u274c \u2705 \u274c Promote test files \u2705 \u2705 \u274c \u2705 \u274c Delete test files \u2705 \u274c \u274c \u274c \u274c Version Control Git status/diff \u2705 \u2705 \u2705 \u2705 \u274c Git add/commit \u2705 \u2705 \u274c \u2705 (tests only) \u274c Git push \u2705 \u274c \u274c \u274c \u274c TDD-Specific Version Control Commit failing tests \u2705 \u274c \u274c \u2705 \u274c Commit code with tests \u2705 \u2705 \u274c \u274c \u274c Commit refactored code \u2705 \u2705 \u274c \u274c \u274c Testing &amp; Analysis Run tests \u2705 \u2705 \u274c \u2705 \u274c Code quality tools \u2705 \u2705 \u274c \u2705 \u274c TDD-Specific Testing Create failing tests \u2705 \u274c \u274c \u2705 \u274c Validate test failures \u2705 \u2705 \u274c \u2705 \u274c Test coverage analysis \u2705 \u2705 \u274c \u2705 \u2705 System Operations Package management \u2705 \u2705 (limited) \u274c \u274c \u274c Process management \u2705 \u274c \u274c \u274c \u274c Network access \u2705 \u274c \u2705 (research) \u274c \u274c"},{"location":"advanced/security-implementation/#security-implementation","title":"Security Implementation","text":""},{"location":"advanced/security-implementation/#1-tool-restriction-enforcement","title":"1. Tool Restriction Enforcement","text":"<p>The system leverages Claude Code's built-in security flags:</p> <pre><code>claude --allowedTools \"Read Write Glob\" --disallowedTools \"Bash(rm) Edit\"\n</code></pre> <p>Architecture Components:</p> <ul> <li><code>agent_tool_config.py</code>: Centralized security configuration</li> <li>Enhanced Claude Client: Automatic tool restriction application</li> <li>Agent Integration: Transparent security enforcement</li> </ul>"},{"location":"advanced/security-implementation/#2-command-categories","title":"2. Command Categories","text":""},{"location":"advanced/security-implementation/#restricted-commands-blocked-for-most-agents","title":"Restricted Commands (Blocked for Most Agents)","text":"<ul> <li><code>sudo</code>, <code>su</code> - Privilege escalation</li> <li><code>chmod</code>, <code>chown</code> - Permission changes</li> <li><code>kill</code>, <code>killall</code> - Process termination</li> <li><code>curl</code>, <code>wget</code> - Network downloads</li> <li><code>ssh</code>, <code>scp</code> - Remote access</li> <li><code>docker run</code> - Container operations</li> </ul>"},{"location":"advanced/security-implementation/#elevated-commands-orchestrator-only","title":"Elevated Commands (Orchestrator Only)","text":"<ul> <li><code>rm</code>, <code>rmdir</code> - File deletion</li> <li><code>git push</code> - Publishing changes</li> </ul>"},{"location":"advanced/security-implementation/#code-management-commands-orchestrator-code-agent","title":"Code Management Commands (Orchestrator + Code Agent)","text":"<ul> <li><code>git commit</code> - Version control commits</li> <li><code>git add</code> - Stage changes</li> <li><code>git reset</code> - Reset changes</li> </ul>"},{"location":"advanced/security-implementation/#3-security-validation","title":"3. Security Validation","text":"<pre><code>from lib.agent_tool_config import validate_agent_access, AgentType\n\n# Runtime validation\ncan_commit = validate_agent_access(AgentType.CODE, \"Bash(git commit)\")  # \u2705 True\ncan_delete = validate_agent_access(AgentType.CODE, \"Bash(rm)\")          # \u274c False\n</code></pre>"},{"location":"advanced/security-implementation/#data-protection","title":"Data Protection","text":""},{"location":"advanced/security-implementation/#1-enhanced-state-management-security","title":"1. Enhanced State Management Security","text":"<ul> <li>No Sensitive Data: State files contain only workflow and TDD metadata</li> <li>Dual State Storage: </li> <li>Workflow state persisted in <code>.orch-state/status.json</code></li> <li>TDD state persisted in <code>.orch-state/tdd/</code></li> <li>Project Isolation: Independent workflow and TDD state per project</li> <li>Story-Level TDD Isolation: TDD cycles isolated per story to prevent cross-contamination</li> <li>Access Control: File system permissions protect both workflow and TDD state</li> <li>Test File Protection: Test files in <code>tests/tdd/</code> protected from unauthorized modification</li> </ul>"},{"location":"advanced/security-implementation/#2-environment-security","title":"2. Environment Security","text":"<pre><code># Required environment variables\nexport DISCORD_BOT_TOKEN=\"your_token_here\"\n\n# Optional: Restrict Claude Code directory access\nclaude --add-dir ./project-dir\n</code></pre>"},{"location":"advanced/security-implementation/#3-secret-management","title":"3. Secret Management","text":"<ul> <li>Environment Variables: All secrets stored as env vars</li> <li>No Hardcoded Secrets: Code contains no embedded credentials</li> <li>Token Rotation: Support for rotating API tokens</li> <li>Audit Logging: All credential usage logged</li> </ul>"},{"location":"advanced/security-implementation/#authentication-authorization","title":"Authentication &amp; Authorization","text":""},{"location":"advanced/security-implementation/#1-discord-bot-security","title":"1. Discord Bot Security","text":"<pre><code># Role-based access control\n@app_commands.command()\n@requires_role(\"developer\")\nasync def sensitive_command(self, interaction):\n    # Only users with 'developer' role can execute\n    pass\n</code></pre>"},{"location":"advanced/security-implementation/#2-project-level-permissions","title":"2. Project-Level Permissions","text":"<ul> <li>Channel Isolation: Each project has dedicated Discord channel</li> <li>User Permissions: Discord role-based access control</li> <li>Command Restrictions: Sensitive commands require elevated roles</li> </ul>"},{"location":"advanced/security-implementation/#input-validation-sanitization","title":"Input Validation &amp; Sanitization","text":""},{"location":"advanced/security-implementation/#1-enhanced-command-validation","title":"1. Enhanced Command Validation","text":"<pre><code>def validate_epic_command(description: str) -&gt; bool:\n    \"\"\"Validate epic description input\"\"\"\n    if len(description) &gt; 500:\n        raise ValueError(\"Epic description too long\")\n\n    # Prevent command injection\n    dangerous_chars = [';', '&amp;&amp;', '||', '`', '$']\n    if any(char in description for char in dangerous_chars):\n        raise ValueError(\"Invalid characters in description\")\n\n    return True\n\ndef validate_tdd_command(command: str, story_id: str, cycle: TDDCycle) -&gt; bool:\n    \"\"\"Validate TDD command input with cycle context\"\"\"\n    # Validate story ID format\n    if not re.match(r'^[A-Z0-9-]+$', story_id):\n        raise ValueError(\"Invalid story ID format\")\n\n    # Validate TDD command format\n    valid_tdd_commands = ['/tdd test', '/tdd code', '/tdd refactor', '/tdd commit']\n    if command not in valid_tdd_commands:\n        raise ValueError(f\"Invalid TDD command: {command}\")\n\n    # Validate against TDD state machine\n    if not cycle or not cycle.current_state:\n        raise ValueError(\"Invalid TDD cycle state\")\n\n    return True\n</code></pre>"},{"location":"advanced/security-implementation/#2-dual-state-machine-validation","title":"2. Dual State Machine Validation","text":"<ul> <li>Workflow Command Sequencing: Only valid workflow commands allowed per state</li> <li>TDD Command Sequencing: TDD commands validated against TDD state and conditions</li> <li>Cross-State Validation: Workflow and TDD states validated for consistency</li> <li>Parameter Validation: All inputs validated before processing (workflow + TDD)</li> <li>Error Handling: Graceful failure with helpful error messages for both systems</li> <li>Test File Validation: Test file paths and contents validated for security</li> </ul>"},{"location":"advanced/security-implementation/#audit-monitoring","title":"Audit &amp; Monitoring","text":""},{"location":"advanced/security-implementation/#1-security-logging","title":"1. Security Logging","text":"<pre><code># Security-relevant events logged\nlogger.security(\"Agent access granted\", extra={\n    \"agent_type\": \"CodeAgent\",\n    \"tool\": \"git commit\",\n    \"user\": interaction.user.id,\n    \"project\": project_name\n})\n</code></pre>"},{"location":"advanced/security-implementation/#2-access-monitoring","title":"2. Access Monitoring","text":"<ul> <li>Tool Usage Tracking: All agent tool usage logged</li> <li>Failed Access Attempts: Blocked commands logged</li> <li>User Activity: Discord command usage tracked</li> <li>Anomaly Detection: Unusual usage patterns flagged</li> </ul>"},{"location":"advanced/security-implementation/#threat-model-mitigations","title":"Threat Model &amp; Mitigations","text":""},{"location":"advanced/security-implementation/#1-enhanced-threat-model-with-tdd-considerations","title":"1. Enhanced Threat Model (with TDD Considerations)","text":"Threat Impact Likelihood Mitigation Malicious Agent Commands High Medium Enhanced tool access restrictions + TDD phase controls TDD Test Tampering High Medium Test file access controls + preservation workflow Privilege Escalation High Low Command filtering + TDD phase validation Code Injection via Tests Medium Medium Test content validation + sandboxed execution Cross-Story Test Contamination Medium Medium Story-level TDD isolation Test File Exfiltration Medium Low Network restrictions + test file access controls Unauthorized TDD State Access Medium Low TDD state access controls + Discord role permissions TDD Cycle Disruption Low Medium TDD state validation + recovery mechanisms"},{"location":"advanced/security-implementation/#2-security-controls","title":"2. Security Controls","text":""},{"location":"advanced/security-implementation/#preventive-controls","title":"Preventive Controls","text":"<ul> <li>Enhanced agent tool restrictions (including TDD-specific controls)</li> <li>Input validation (workflow + TDD commands)</li> <li>Role-based access control (including TDD command permissions)</li> <li>Environment isolation (including TDD workspace isolation)</li> <li>TDD-Specific Controls:</li> <li>Test file access restrictions per TDD phase</li> <li>Story-level TDD cycle isolation</li> <li>Test preservation workflow validation</li> <li>TDD state transition controls</li> </ul>"},{"location":"advanced/security-implementation/#detective-controls","title":"Detective Controls","text":"<ul> <li>Comprehensive audit logging (workflow + TDD activities)</li> <li>Access monitoring (including test file access)</li> <li>Anomaly detection (including TDD cycle anomalies)</li> <li>Failed attempt tracking (workflow + TDD command failures)</li> <li>TDD-Specific Detection:</li> <li>Test file modification monitoring</li> <li>TDD phase transition tracking</li> <li>Test preservation validation logging</li> <li>Cross-story contamination detection</li> </ul>"},{"location":"advanced/security-implementation/#corrective-controls","title":"Corrective Controls","text":"<ul> <li>Automatic command blocking (workflow + TDD commands)</li> <li>Error recovery procedures (including TDD cycle recovery)</li> <li>State rollback capabilities (dual state machine rollback)</li> <li>Alert escalation (workflow + TDD security events)</li> <li>TDD-Specific Corrections:</li> <li>Test file restoration from git history</li> <li>TDD cycle state recovery</li> <li>Test preservation workflow repair</li> <li>Cross-story isolation enforcement</li> </ul>"},{"location":"advanced/security-implementation/#security-testing","title":"Security Testing","text":""},{"location":"advanced/security-implementation/#1-enhanced-automated-security-tests","title":"1. Enhanced Automated Security Tests","text":"<pre><code># Example security test for TDD workflow\ndef test_code_agent_cannot_delete_files(self):\n    \"\"\"Verify code agent cannot use rm command\"\"\"\n    access_granted = validate_agent_access(AgentType.CODE, \"Bash(rm)\")\n    self.assertFalse(access_granted)\n\ndef test_qa_agent_cannot_edit_code_during_test_red(self):\n    \"\"\"Verify QA agent cannot edit source code during TEST_RED phase\"\"\"\n    cycle = create_test_tdd_cycle(state=TDDState.TEST_RED)\n    access_granted = validate_tdd_phase_access(\n        AgentType.QA, \"Edit(src/main.py)\", cycle\n    )\n    self.assertFalse(access_granted)\n\ndef test_code_agent_cannot_modify_tests_during_refactor(self):\n    \"\"\"Verify code agent cannot modify test files during REFACTOR phase\"\"\"\n    cycle = create_test_tdd_cycle(state=TDDState.REFACTOR)\n    access_granted = validate_tdd_phase_access(\n        AgentType.CODE, \"Edit(tests/tdd/story-1/test_feature.py)\", cycle\n    )\n    self.assertFalse(access_granted)\n\ndef test_cross_story_tdd_isolation(self):\n    \"\"\"Verify agents cannot access other story's TDD cycles\"\"\"\n    story1_cycle = create_test_tdd_cycle(story_id=\"STORY-1\")\n    story2_cycle = create_test_tdd_cycle(story_id=\"STORY-2\")\n\n    access_granted = validate_cross_story_access(\n        AgentType.QA, story1_cycle, story2_cycle\n    )\n    self.assertFalse(access_granted)\n</code></pre>"},{"location":"advanced/security-implementation/#2-enhanced-security-test-categories","title":"2. Enhanced Security Test Categories","text":"<ul> <li>Access Control Tests: Verify agent restrictions work (including TDD phase restrictions)</li> <li>Input Validation Tests: Test command injection prevention (workflow + TDD commands)</li> <li>Authentication Tests: Verify Discord role enforcement (including TDD command permissions)</li> <li>State Security Tests: Ensure state tampering protection (dual state machine)</li> <li>TDD-Specific Security Tests:</li> <li>TDD phase access control validation</li> <li>Test file modification restrictions</li> <li>Story-level TDD isolation verification</li> <li>Test preservation workflow security</li> <li>Cross-phase contamination prevention</li> </ul>"},{"location":"advanced/security-implementation/#security-configuration","title":"Security Configuration","text":""},{"location":"advanced/security-implementation/#1-enhanced-agent-security-profiles-with-tdd-support","title":"1. Enhanced Agent Security Profiles (with TDD Support)","text":"<p>Create custom security profiles by modifying <code>AGENT_TOOL_CONFIG</code> with TDD phase awareness:</p> <pre><code>TDD_ENHANCED_AGENT_CONFIG = {\n    AgentType.QA_TDD: {\n        \"allowed_tools\": {\n            TDDState.TEST_RED: [\n                \"Read\", \"Write\", \"Bash(pytest)\",\n                \"TestFileCreate\", \"TestFileEdit\"\n            ],\n            TDDState.CODE_GREEN: [\n                \"Read\", \"Bash(pytest)\",\n                \"TestFileValidate\"\n            ],\n            TDDState.REFACTOR: [\n                \"Read\", \"Bash(pytest)\",\n                \"TestFileValidate\"\n            ]\n        },\n        \"disallowed_tools\": {\n            \"*\": [\n                \"Edit(src/*)\", \"Bash(rm)\", \"TestFileDelete\"\n            ],\n            TDDState.CODE_GREEN: [\n                \"TestFileEdit\", \"TestFileCreate\"\n            ]\n        },\n        \"tdd_restrictions\": {\n            \"story_isolation\": True,\n            \"test_preservation\": True,\n            \"cross_phase_validation\": True\n        }\n    },\n    AgentType.CODE_TDD: {\n        \"allowed_tools\": {\n            TDDState.CODE_GREEN: [\n                \"Read\", \"Edit(src/*)\", \"Write(src/*)\",\n                \"Bash(pytest)\", \"TestFileValidate\"\n            ],\n            TDDState.REFACTOR: [\n                \"Read\", \"Edit(src/*)\", \"Refactor\",\n                \"Bash(pytest)\", \"TestFileValidate\"\n            ]\n        },\n        \"disallowed_tools\": {\n            \"*\": [\n                \"TestFileEdit\", \"TestFileCreate\", \"Bash(rm)\"\n            ],\n            TDDState.TEST_RED: [\n                \"Edit(src/*)\", \"Write(src/*)\"\n            ]\n        }\n    }\n}\n</code></pre>"},{"location":"advanced/security-implementation/#2-enhanced-environment-security-settings-with-tdd-support","title":"2. Enhanced Environment Security Settings (with TDD Support)","text":"<pre><code># Restrict Claude Code to specific directories\nexport CLAUDE_ALLOWED_DIRS=\"/workspace/safe-dir\"\n\n# Enable additional security logging\nexport SECURITY_LOG_LEVEL=\"DEBUG\"\n\n# Require explicit permission for network access\nexport REQUIRE_NETWORK_APPROVAL=\"true\"\n\n# TDD-specific security settings\nexport TDD_ISOLATION_ENABLED=\"true\"\nexport TDD_TEST_FILE_VALIDATION=\"strict\"\nexport TDD_CROSS_STORY_ACCESS=\"deny\"\nexport TDD_PHASE_ENFORCEMENT=\"strict\"\n\n# Test file security settings\nexport TEST_FILE_BACKUP_ENABLED=\"true\"\nexport TEST_PRESERVATION_VALIDATION=\"enabled\"\nexport TEST_FILE_PROMOTION_APPROVAL=\"required\"\n</code></pre>"},{"location":"advanced/security-implementation/#best-practices","title":"Best Practices","text":""},{"location":"advanced/security-implementation/#1-development-security","title":"1. Development Security","text":"<ul> <li>Code Review: All security-related changes require review</li> <li>Principle of Least Privilege: Grant minimal necessary permissions</li> <li>Defense in Depth: Multiple security layers</li> <li>Fail Secure: Default to deny for unknown operations</li> </ul>"},{"location":"advanced/security-implementation/#2-operational-security","title":"2. Operational Security","text":"<ul> <li>Regular Audits: Periodic review of agent permissions</li> <li>Security Updates: Keep dependencies updated</li> <li>Incident Response: Clear procedures for security events</li> <li>Backup &amp; Recovery: Secure backup of critical data</li> </ul>"},{"location":"advanced/security-implementation/#3-monitoring-alerting","title":"3. Monitoring &amp; Alerting","text":"<pre><code># Security alert example\nif failed_access_attempts &gt; 5:\n    alert_security_team(\n        \"Multiple failed access attempts\",\n        agent_type=agent.name,\n        user=user_id,\n        timestamp=datetime.now()\n    )\n</code></pre>"},{"location":"advanced/security-implementation/#compliance-considerations","title":"Compliance Considerations","text":""},{"location":"advanced/security-implementation/#1-data-privacy","title":"1. Data Privacy","text":"<ul> <li>No PII Storage: System avoids storing personal information</li> <li>Data Minimization: Only necessary data collected</li> <li>Retention Policies: Automatic log rotation and cleanup</li> </ul>"},{"location":"advanced/security-implementation/#2-access-controls","title":"2. Access Controls","text":"<ul> <li>Role Separation: Clear separation of duties</li> <li>Audit Trail: Complete audit trail of all actions</li> <li>Access Reviews: Regular review of user permissions</li> </ul> <p>Security Updates</p> <p>Security configurations should be reviewed regularly and updated as new threats emerge. Monitor security advisories for all dependencies.</p> <p>Incident Response</p> <p>In case of suspected security incident, immediately disable affected agents and review audit logs. Contact security team for investigation procedures.</p>"},{"location":"advanced/testing/","title":"Testing Plan - AI Agent TDD-Scrum Workflow","text":""},{"location":"advanced/testing/#testing-strategy","title":"Testing Strategy","text":"<p>The testing strategy covers both the framework itself and the Test-Driven Development functionality that the system orchestrates. This includes testing the dual state machine architecture, TDD cycle management, and test preservation workflows.</p>"},{"location":"advanced/testing/#test-pyramid","title":"Test Pyramid","text":"<ol> <li>Unit Tests (70%) - Individual component testing</li> <li>Integration Tests (20%) - Component interaction testing  </li> <li>End-to-End Tests (10%) - Full workflow testing</li> </ol>"},{"location":"advanced/testing/#test-categories","title":"Test Categories","text":""},{"location":"advanced/testing/#1-dual-state-machine-tests","title":"1. Dual State Machine Tests","text":"<p>Workflow State Machine: - File: <code>tests/unit/test_state_machine.py</code> - Coverage: All workflow state transitions and command validations - Approach: Table-driven tests with (current_state, command) \u2192 expected_result</p> <pre><code>workflow_test_cases = [\n    (\"IDLE\", \"/epic\", \"BACKLOG_READY\", True),\n    (\"IDLE\", \"/sprint start\", \"IDLE\", False),  # Invalid transition\n    (\"SPRINT_ACTIVE\", \"/sprint pause\", \"SPRINT_PAUSED\", True),\n    # ... comprehensive matrix\n]\n</code></pre> <p>TDD State Machine: - File: <code>tests/unit/test_tdd_state_machine.py</code> \u2705 - Coverage: All TDD state transitions and command validations - Approach: Table-driven tests with TDD context validation</p> <pre><code>tdd_test_cases = [\n    (\"DESIGN\", \"/tdd test\", \"TEST_RED\", True, {}),\n    (\"TEST_RED\", \"/tdd commit-tests\", \"CODE_GREEN\", True, {\"has_failing_tests\": True}),\n    (\"CODE_GREEN\", \"/tdd commit-code\", \"REFACTOR\", True, {\"has_passing_tests\": True}),\n    (\"DESIGN\", \"/tdd code\", \"DESIGN\", False, {}),  # Invalid - need tests first\n    # ... comprehensive TDD matrix\n]\n</code></pre> <p>State Coordination: - File: <code>tests/unit/test_state_coordination.py</code> - Coverage: Dual state machine coordination and synchronization - Approach: Integration tests for workflow and TDD state interactions</p>"},{"location":"advanced/testing/#2-enhanced-agent-library-tests","title":"2. Enhanced Agent Library Tests","text":"<ul> <li>Files: </li> <li><code>tests/unit/test_base_agent.py</code></li> <li><code>tests/unit/test_design_agent.py</code></li> <li><code>tests/unit/test_code_agent.py</code></li> <li><code>tests/unit/test_qa_agent.py</code></li> <li><code>tests/unit/test_data_agent.py</code></li> <li><code>tests/unit/test_agent_tool_config.py</code> \u2705</li> <li><code>tests/unit/test_tdd_phase_manager.py</code></li> <li><code>tests/unit/test_test_preservation.py</code></li> <li>Coverage: </li> <li>Agent initialization and configuration</li> <li>Task execution with dry-run mode</li> <li>TDD Phase Execution: TDD-specific agent capabilities</li> <li>Test Preservation: Test file lifecycle management</li> <li>Error handling and retry logic for both workflow and TDD tasks</li> <li>Agent Security: Tool access control and command restrictions</li> <li>Claude Code integration (mocked)</li> <li>TDD Agent Coordination: Handoffs between TDD phases</li> </ul>"},{"location":"advanced/testing/#3-discord-bot-tests","title":"3. Discord Bot Tests","text":"<ul> <li>Files:</li> <li><code>tests/unit/test_discord_bot.py</code></li> <li><code>tests/unit/test_command_parser.py</code></li> <li><code>tests/unit/test_state_visualizer.py</code></li> <li>Coverage:</li> <li>Slash command parsing and validation</li> <li>Interactive state visualization</li> <li>Button handling and user interactions</li> <li>Channel management (create project channels)</li> <li>Error message formatting</li> </ul>"},{"location":"advanced/testing/#4-orchestrator-tests","title":"4. Orchestrator Tests","text":"<ul> <li>Files:</li> <li><code>tests/unit/test_orchestrator.py</code></li> <li><code>tests/unit/test_project_manager.py</code></li> <li><code>tests/unit/test_approval_gate.py</code></li> <li>Coverage:</li> <li>Multi-project coordination</li> <li>HITL approval workflow</li> <li>Task dispatch and retry logic</li> <li>State persistence and recovery</li> </ul>"},{"location":"advanced/testing/#5-integration-tests","title":"5. Integration Tests","text":"<ul> <li>Files:</li> <li><code>tests/integration/test_discord_orchestrator.py</code></li> <li><code>tests/integration/test_agent_coordination.py</code></li> <li><code>tests/integration/test_state_persistence.py</code></li> <li><code>tests/integration/test_tdd_workflow_integration.py</code></li> <li><code>tests/integration/test_dual_state_coordination.py</code></li> <li><code>tests/integration/test_test_preservation_integration.py</code></li> <li>Coverage:</li> <li>Discord \u2192 Orchestrator \u2192 Agent workflows (including TDD commands)</li> <li>Dual state machine integration with Discord UI</li> <li>Multi-agent task coordination with TDD phase handoffs</li> <li>Project state persistence across restarts (workflow + TDD)</li> <li>TDD Workflow Integration: Complete TDD cycle execution</li> <li>Test Preservation Integration: Test file lifecycle across phases</li> <li>State Coordination: Workflow and TDD state synchronization</li> </ul>"},{"location":"advanced/testing/#6-end-to-end-tests","title":"6. End-to-End Tests","text":"<ul> <li>Files:</li> <li><code>tests/e2e/test_complete_workflow.py</code></li> <li><code>tests/e2e/test_approval_scenarios.py</code></li> <li><code>test_tdd_e2e.py</code> \u2705</li> <li><code>tests/e2e/test_dual_state_e2e.py</code></li> <li>Coverage:</li> <li>Complete epic \u2192 sprint \u2192 TDD cycles \u2192 implementation workflow</li> <li>HITL approval gates and escalation for both workflow and TDD decisions</li> <li>Multi-project orchestration scenarios with parallel TDD cycles</li> <li>Error recovery and retry scenarios in TDD workflows</li> <li>Complete TDD Cycles: DESIGN \u2192 TEST_RED \u2192 CODE_GREEN \u2192 REFACTOR \u2192 COMMIT</li> <li>Test Preservation E2E: Full test file lifecycle from creation to integration</li> </ul>"},{"location":"advanced/testing/#7-tdd-specific-test-categories","title":"7. TDD-Specific Test Categories","text":"<p>TDD Models Testing: - File: <code>tests/unit/test_tdd_models.py</code> \u2705 - Coverage: TDDCycle, TDDTask, TestFile, TestResult data models - Approach: Unit tests for all model methods and state transitions</p> <p>Test File Lifecycle Testing: - Files:    - <code>tests/unit/test_test_file_lifecycle.py</code>   - <code>tests/integration/test_test_preservation_workflow.py</code> - Coverage: Test file creation, preservation, promotion, and integration - Approach: Mock filesystem operations and git commands</p> <p>TDD Metrics and Analytics Testing: - Files:   - <code>tests/unit/test_tdd_metrics.py</code>   - <code>tests/integration/test_tdd_analytics.py</code> - Coverage: TDD cycle time metrics, test coverage tracking, quality gates - Approach: Time-series data validation and metric calculation testing</p>"},{"location":"advanced/testing/#test-implementation-structure","title":"Test Implementation Structure","text":""},{"location":"advanced/testing/#mock-strategy","title":"Mock Strategy","text":"<ul> <li>Discord API: Mock discord.py interactions (including TDD command handling)</li> <li>Anthropic API: Mock AI model responses with realistic outputs for TDD phases</li> <li>GitHub API: Mock repository operations, CI results, and test file commits</li> <li>File System: Use temporary directories for state persistence (workflow + TDD)</li> <li>Test Execution: Mock test runners and coverage tools</li> <li>CI/CD Systems: Mock CI pipeline integration and test result reporting</li> </ul>"},{"location":"advanced/testing/#test-data","title":"Test Data","text":"<ul> <li>Fixtures: <code>tests/fixtures/</code></li> <li>Sample project configurations (including TDD settings)</li> <li>Mock Discord interactions (workflow + TDD commands)</li> <li>Predefined AI responses for TDD phases</li> <li>Test state machine configurations (dual state machines)</li> <li>TDD Fixtures:<ul> <li>Sample TDD cycles and tasks</li> <li>Mock test files and test results</li> <li>Test coverage data samples</li> <li>TDD metrics test data</li> </ul> </li> </ul>"},{"location":"advanced/testing/#performance-tests","title":"Performance Tests","text":"<ul> <li>Load Testing: Multiple concurrent projects</li> <li>Stress Testing: High-frequency command processing  </li> <li>Memory Testing: Long-running orchestrator instances</li> </ul>"},{"location":"advanced/testing/#test-execution","title":"Test Execution","text":""},{"location":"advanced/testing/#continuous-testing","title":"Continuous Testing","text":"<pre><code># Unit tests (fast feedback)\npytest tests/unit/ -v\n\n# TDD-specific unit tests\npytest tests/unit/test_tdd_*.py -v\n\n# Integration tests (moderate speed)\npytest tests/integration/ -v\n\n# TDD integration tests\npytest tests/integration/*tdd*.py -v\n\n# Full test suite (comprehensive)\npytest tests/ -v --cov=lib --cov=scripts\n\n# TDD E2E tests\npytest test_tdd_e2e.py -v\n\n# Performance tests (separate run)\npytest tests/performance/ -v\n</code></pre>"},{"location":"advanced/testing/#test-coverage-targets","title":"Test Coverage Targets","text":"<ul> <li>Unit Tests: \u226595% line coverage (including TDD modules)</li> <li>Integration Tests: \u226590% feature coverage (including TDD workflows)</li> <li>E2E Tests: 100% critical path coverage (including complete TDD cycles)</li> <li>TDD Functionality: \u226598% coverage for TDD state machine and data models</li> <li>Test Preservation: 100% coverage for test file lifecycle management</li> </ul>"},{"location":"advanced/testing/#test-environment-setup","title":"Test Environment Setup","text":"<pre><code># Test dependencies\npip install pytest pytest-cov pytest-asyncio pytest-mock\n\n# Discord testing with mock bot\nexport DISCORD_BOT_TOKEN=\"test_token\"\nexport ANTHROPIC_API_KEY=\"test_key\"\n\n# Test database setup\nmkdir -p tests/tmp\n</code></pre>"},{"location":"advanced/testing/#quality-gates","title":"Quality Gates","text":""},{"location":"advanced/testing/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<ul> <li>Run unit tests</li> <li>Check code coverage</li> <li>Lint code style</li> <li>Validate type hints</li> </ul>"},{"location":"advanced/testing/#cicd-pipeline","title":"CI/CD Pipeline","text":"<ol> <li>Fast Tests: Unit tests on every commit</li> <li>Integration Tests: On pull request</li> <li>E2E Tests: On main branch merge</li> <li>Performance Tests: Nightly runs</li> </ol>"},{"location":"advanced/testing/#test-driven-development-process","title":"Test-Driven Development Process","text":"<ol> <li>Write failing test for new feature</li> <li>Implement minimal code to pass test  </li> <li>Refactor while maintaining test coverage</li> <li>Add integration tests for feature interactions</li> <li>Add E2E test for user-facing workflows</li> </ol>"},{"location":"advanced/testing/#test-scenarios-priority","title":"Test Scenarios Priority","text":""},{"location":"advanced/testing/#high-priority-must-test","title":"High Priority (Must Test)","text":"<ul> <li>Dual State Machine: Workflow and TDD command validation</li> <li>TDD State Transitions: All TDD phase transitions and conditions</li> <li>Test Preservation: Test file lifecycle and preservation workflow</li> <li>HITL approval workflows (workflow + TDD decisions)</li> <li>Enhanced Agent Execution: TDD-capable agent task execution</li> <li>Agent security and tool restrictions \u2705</li> <li>Discord command parsing (workflow + TDD commands)</li> <li>Dual State Persistence: Workflow and TDD state persistence</li> <li>Agent TDD Coordination: Handoffs between TDD phases</li> </ul>"},{"location":"advanced/testing/#medium-priority-should-test","title":"Medium Priority (Should Test)","text":"<ul> <li>Multi-project coordination (with parallel TDD cycles)</li> <li>TDD Error Handling: Recovery from failed TDD phases</li> <li>TDD Performance: Performance under load with multiple TDD cycles</li> <li>Dual State Visualization: Both workflow and TDD state visualization</li> <li>Configuration management (including TDD settings)</li> <li>TDD Metrics: Cycle time tracking and quality metrics</li> <li>Test Coverage Integration: Coverage reporting and CI integration</li> </ul>"},{"location":"advanced/testing/#low-priority-nice-to-test","title":"Low Priority (Nice to Test)","text":"<ul> <li>Edge case error scenarios (including TDD edge cases)</li> <li>TDD Stress Testing: Many concurrent TDD cycles beyond normal limits</li> <li>UI polish and formatting (including TDD visualizations)</li> <li>Advanced Discord features (including TDD interactive elements)</li> <li>TDD Analytics: Advanced TDD metrics and reporting features</li> <li>Test File Recovery: Advanced test preservation recovery scenarios</li> </ul>"},{"location":"architecture/context-algorithms/","title":"Context Management Algorithms and Research","text":""},{"location":"architecture/context-algorithms/#overview","title":"Overview","text":"<p>This document details the core algorithms powering the Context Management System, including relevance scoring, content compression, dependency analysis, and token optimization. Each algorithm is designed to address specific challenges in managing context for AI agents while respecting token limitations.</p>"},{"location":"architecture/context-algorithms/#relevance-scoring-algorithm","title":"Relevance Scoring Algorithm","text":""},{"location":"architecture/context-algorithms/#multi-factor-relevance-scoring","title":"Multi-Factor Relevance Scoring","text":"<p>The relevance scoring algorithm combines multiple factors to determine how relevant a file is to the current task context.</p> <pre><code>def calculate_relevance_score(file_path: str, task: TDDTask, \n                            context: ContextRequest) -&gt; float:\n    \"\"\"\n    Calculate multi-factor relevance score (0.0 to 1.0)\n\n    Factors:\n    - Direct mention (40% weight): File explicitly referenced in task\n    - Dependency analysis (25% weight): Code dependencies and imports\n    - Historical relevance (20% weight): Past usage patterns\n    - Semantic similarity (10% weight): Content similarity to task\n    - TDD phase relevance (5% weight): Phase-specific importance\n    \"\"\"\n\n    # Factor 1: Direct mention in task description or files\n    direct_mention_score = calculate_direct_mention_score(file_path, task)\n\n    # Factor 2: Static dependency analysis\n    dependency_score = calculate_dependency_score(file_path, task.source_files)\n\n    # Factor 3: Historical usage patterns\n    historical_score = calculate_historical_relevance(file_path, context.agent_type, task.story_id)\n\n    # Factor 4: Semantic content similarity\n    semantic_score = calculate_semantic_similarity(file_path, task.description)\n\n    # Factor 5: TDD phase-specific relevance\n    phase_score = calculate_phase_relevance(file_path, task.current_state)\n\n    # Weighted combination\n    total_score = (\n        0.40 * direct_mention_score +\n        0.25 * dependency_score +\n        0.20 * historical_score +\n        0.10 * semantic_score +\n        0.05 * phase_score\n    )\n\n    # Apply boost factors\n    boost_factor = calculate_boost_factors(file_path, task)\n\n    return min(1.0, total_score * boost_factor)\n</code></pre>"},{"location":"architecture/context-algorithms/#component-algorithms","title":"Component Algorithms","text":""},{"location":"architecture/context-algorithms/#direct-mention-scoring","title":"Direct Mention Scoring","text":"<pre><code>def calculate_direct_mention_score(file_path: str, task: TDDTask) -&gt; float:\n    \"\"\"Calculate score based on direct mentions of file in task context\"\"\"\n    score = 0.0\n\n    # Check if file is explicitly mentioned in task description\n    if file_path in task.description or os.path.basename(file_path) in task.description:\n        score += 0.8\n\n    # Check if file is in task source files\n    if file_path in task.source_files:\n        score += 1.0\n\n    # Check if file is in test files\n    if file_path in task.test_files:\n        score += 0.9\n\n    # Check for file name mentions in acceptance criteria\n    for criteria in task.acceptance_criteria:\n        if os.path.basename(file_path) in criteria:\n            score += 0.6\n\n    return min(1.0, score)\n</code></pre>"},{"location":"architecture/context-algorithms/#dependency-analysis-scoring","title":"Dependency Analysis Scoring","text":"<pre><code>def calculate_dependency_score(file_path: str, source_files: List[str]) -&gt; float:\n    \"\"\"Calculate relevance based on code dependencies\"\"\"\n\n    # Get direct dependencies (imports)\n    direct_deps = get_direct_dependencies(file_path)\n\n    # Get reverse dependencies (what imports this file)\n    reverse_deps = get_reverse_dependencies(file_path)\n\n    # Calculate overlap with task source files\n    source_set = set(source_files)\n\n    # Score based on direct dependencies overlap\n    direct_overlap = len(set(direct_deps) &amp; source_set) / max(len(direct_deps), 1)\n\n    # Score based on reverse dependencies overlap\n    reverse_overlap = len(set(reverse_deps) &amp; source_set) / max(len(reverse_deps), 1)\n\n    # Calculate transitive dependency score\n    transitive_score = calculate_transitive_dependency_score(file_path, source_files, max_depth=3)\n\n    # Weighted combination\n    dependency_score = (\n        0.5 * direct_overlap +\n        0.3 * reverse_overlap +\n        0.2 * transitive_score\n    )\n\n    return dependency_score\n\ndef get_direct_dependencies(file_path: str) -&gt; List[str]:\n    \"\"\"Extract direct dependencies from Python file\"\"\"\n    try:\n        with open(file_path, 'r') as f:\n            content = f.read()\n\n        tree = ast.parse(content)\n        dependencies = []\n\n        for node in ast.walk(tree):\n            if isinstance(node, ast.Import):\n                for alias in node.names:\n                    dependencies.append(alias.name)\n            elif isinstance(node, ast.ImportFrom):\n                if node.module:\n                    dependencies.append(node.module)\n\n        # Convert module names to file paths\n        return resolve_module_paths(dependencies, file_path)\n\n    except Exception:\n        return []\n</code></pre>"},{"location":"architecture/context-algorithms/#historical-relevance-scoring","title":"Historical Relevance Scoring","text":"<pre><code>def calculate_historical_relevance(file_path: str, agent_type: str, story_id: str) -&gt; float:\n    \"\"\"Calculate relevance based on historical usage patterns\"\"\"\n\n    # Get historical access patterns\n    access_history = get_file_access_history(file_path, agent_type)\n\n    # Get similar story patterns\n    similar_stories = get_similar_story_files(story_id, file_path)\n\n    # Calculate access frequency score\n    frequency_score = calculate_access_frequency_score(access_history)\n\n    # Calculate recency score (more recent = higher score)\n    recency_score = calculate_recency_score(access_history)\n\n    # Calculate similar story score\n    similarity_score = calculate_story_similarity_score(similar_stories)\n\n    # Weighted combination\n    historical_score = (\n        0.4 * frequency_score +\n        0.3 * recency_score +\n        0.3 * similarity_score\n    )\n\n    return historical_score\n\ndef calculate_access_frequency_score(access_history: List[Dict]) -&gt; float:\n    \"\"\"Score based on how frequently file has been accessed\"\"\"\n    if not access_history:\n        return 0.0\n\n    # Count accesses in different time windows\n    now = datetime.utcnow()\n\n    recent_accesses = sum(1 for access in access_history \n                         if (now - access['timestamp']).days &lt;= 7)\n    total_accesses = len(access_history)\n\n    # Normalize based on total project activity\n    project_activity = get_project_activity_baseline()\n\n    frequency_ratio = total_accesses / max(project_activity, 1)\n    recency_boost = min(1.0, recent_accesses / 5)  # Boost for recent activity\n\n    return min(1.0, frequency_ratio * (1.0 + recency_boost))\n</code></pre>"},{"location":"architecture/context-algorithms/#semantic-similarity-scoring","title":"Semantic Similarity Scoring","text":"<pre><code>def calculate_semantic_similarity(file_path: str, task_description: str) -&gt; float:\n    \"\"\"Calculate semantic similarity between file content and task description\"\"\"\n\n    # Extract key content from file\n    file_content = extract_file_summary(file_path)\n\n    # Use sentence embeddings for similarity\n    task_embedding = get_sentence_embedding(task_description)\n    file_embedding = get_sentence_embedding(file_content)\n\n    # Calculate cosine similarity\n    similarity = cosine_similarity(task_embedding, file_embedding)\n\n    # Apply content type boosts\n    content_boost = get_content_type_boost(file_path, task_description)\n\n    return min(1.0, similarity * content_boost)\n\ndef extract_file_summary(file_path: str) -&gt; str:\n    \"\"\"Extract meaningful summary from file for semantic analysis\"\"\"\n\n    if file_path.endswith('.py'):\n        return extract_python_summary(file_path)\n    elif file_path.endswith('.md'):\n        return extract_markdown_summary(file_path)\n    elif file_path.endswith(('.yml', '.yaml')):\n        return extract_yaml_summary(file_path)\n    else:\n        return extract_generic_summary(file_path)\n\ndef extract_python_summary(file_path: str) -&gt; str:\n    \"\"\"Extract Python file summary including docstrings and key elements\"\"\"\n    try:\n        with open(file_path, 'r') as f:\n            content = f.read()\n\n        tree = ast.parse(content)\n        summary_parts = []\n\n        # Extract module docstring\n        if ast.get_docstring(tree):\n            summary_parts.append(ast.get_docstring(tree))\n\n        # Extract class and function names and docstrings\n        for node in ast.walk(tree):\n            if isinstance(node, (ast.ClassDef, ast.FunctionDef)):\n                summary_parts.append(node.name)\n                if ast.get_docstring(node):\n                    summary_parts.append(ast.get_docstring(node))\n\n        # Extract comments\n        comments = extract_comments(content)\n        summary_parts.extend(comments)\n\n        return ' '.join(summary_parts)\n\n    except Exception:\n        return \"\"\n</code></pre>"},{"location":"architecture/context-algorithms/#content-compression-algorithms","title":"Content Compression Algorithms","text":""},{"location":"architecture/context-algorithms/#adaptive-python-code-compression","title":"Adaptive Python Code Compression","text":"<pre><code>def compress_python_code(content: str, target_tokens: int, \n                        preserve_structure: bool = True) -&gt; CompressionResult:\n    \"\"\"\n    Compress Python code while preserving semantic meaning and structure\n\n    Compression Strategy:\n    1. Parse AST to understand code structure\n    2. Identify critical elements (classes, functions, key logic)\n    3. Remove or summarize non-critical elements\n    4. Reconstruct code with preserved structure\n    \"\"\"\n\n    original_tokens = estimate_tokens(content)\n\n    if original_tokens &lt;= target_tokens:\n        return CompressionResult(\n            compressed_content=content,\n            original_tokens=original_tokens,\n            compressed_tokens=original_tokens,\n            compression_ratio=1.0,\n            semantic_preservation_score=1.0\n        )\n\n    # Parse code into AST\n    try:\n        tree = ast.parse(content)\n    except SyntaxError:\n        # Fallback to line-based compression for invalid syntax\n        return compress_python_lines(content, target_tokens)\n\n    # Analyze code elements\n    elements = analyze_code_elements(tree)\n\n    # Determine compression strategy based on target ratio\n    target_ratio = target_tokens / original_tokens\n    compression_strategy = select_compression_strategy(target_ratio)\n\n    # Apply compression strategy\n    compressed_tree = apply_compression_strategy(tree, elements, compression_strategy)\n\n    # Reconstruct code\n    compressed_content = ast.unparse(compressed_tree)\n    compressed_tokens = estimate_tokens(compressed_content)\n\n    # Calculate semantic preservation score\n    semantic_score = calculate_semantic_preservation(content, compressed_content)\n\n    return CompressionResult(\n        compressed_content=compressed_content,\n        original_tokens=original_tokens,\n        compressed_tokens=compressed_tokens,\n        compression_ratio=original_tokens / compressed_tokens,\n        semantic_preservation_score=semantic_score\n    )\n\ndef analyze_code_elements(tree: ast.AST) -&gt; Dict[str, List]:\n    \"\"\"Analyze and categorize code elements by importance\"\"\"\n    elements = {\n        'critical': [],      # Core classes, main functions\n        'important': [],     # Helper functions, key methods\n        'standard': [],      # Regular methods, properties\n        'optional': [],      # Comments, docstrings, debug code\n        'removable': []      # Dead code, unused imports\n    }\n\n    for node in ast.walk(tree):\n        if isinstance(node, ast.ClassDef):\n            importance = classify_class_importance(node)\n            elements[importance].append(node)\n        elif isinstance(node, ast.FunctionDef):\n            importance = classify_function_importance(node)\n            elements[importance].append(node)\n        elif isinstance(node, ast.Import):\n            if is_unused_import(node, tree):\n                elements['removable'].append(node)\n            else:\n                elements['standard'].append(node)\n\n    return elements\n\ndef select_compression_strategy(target_ratio: float) -&gt; str:\n    \"\"\"Select compression strategy based on target compression ratio\"\"\"\n    if target_ratio &gt; 0.8:\n        return 'conservative'  # Remove only comments and dead code\n    elif target_ratio &gt; 0.6:\n        return 'moderate'      # Remove optional elements, compress docstrings\n    elif target_ratio &gt; 0.4:\n        return 'aggressive'    # Keep only critical and important elements\n    else:\n        return 'extreme'       # Keep only critical elements, summarize everything else\n\ndef apply_compression_strategy(tree: ast.AST, elements: Dict, strategy: str) -&gt; ast.AST:\n    \"\"\"Apply selected compression strategy to AST\"\"\"\n\n    if strategy == 'conservative':\n        return compress_conservative(tree, elements)\n    elif strategy == 'moderate':\n        return compress_moderate(tree, elements)\n    elif strategy == 'aggressive':\n        return compress_aggressive(tree, elements)\n    elif strategy == 'extreme':\n        return compress_extreme(tree, elements)\n\n    return tree\n\ndef compress_conservative(tree: ast.AST, elements: Dict) -&gt; ast.AST:\n    \"\"\"Conservative compression: remove only non-essential elements\"\"\"\n    transformer = ConservativeTransformer(elements)\n    return transformer.visit(tree)\n\nclass ConservativeTransformer(ast.NodeTransformer):\n    def __init__(self, elements):\n        self.elements = elements\n\n    def visit_FunctionDef(self, node):\n        # Remove docstrings but keep function structure\n        if ast.get_docstring(node):\n            node.body = [stmt for stmt in node.body \n                        if not isinstance(stmt, ast.Expr) or \n                        not isinstance(stmt.value, ast.Constant)]\n\n        # Remove comments (handled at line level)\n        return self.generic_visit(node)\n\n    def visit_Import(self, node):\n        # Remove unused imports\n        if node in self.elements['removable']:\n            return None\n        return node\n</code></pre>"},{"location":"architecture/context-algorithms/#test-file-compression","title":"Test File Compression","text":"<pre><code>def compress_test_file(content: str, target_tokens: int) -&gt; CompressionResult:\n    \"\"\"\n    Compress test files while preserving test intent and assertions\n\n    Strategy:\n    1. Preserve all test method signatures\n    2. Preserve all assertions\n    3. Compress setup/teardown code\n    4. Summarize test data and mocks\n    \"\"\"\n\n    original_tokens = estimate_tokens(content)\n\n    if original_tokens &lt;= target_tokens:\n        return CompressionResult(\n            compressed_content=content,\n            original_tokens=original_tokens,\n            compressed_tokens=original_tokens,\n            compression_ratio=1.0\n        )\n\n    try:\n        tree = ast.parse(content)\n    except SyntaxError:\n        return compress_test_lines(content, target_tokens)\n\n    # Identify test structure\n    test_structure = analyze_test_structure(tree)\n\n    # Compress based on test elements\n    compressed_tree = compress_test_elements(tree, test_structure, target_tokens)\n\n    compressed_content = ast.unparse(compressed_tree)\n    compressed_tokens = estimate_tokens(compressed_content)\n\n    return CompressionResult(\n        compressed_content=compressed_content,\n        original_tokens=original_tokens,\n        compressed_tokens=compressed_tokens,\n        compression_ratio=original_tokens / compressed_tokens\n    )\n\ndef analyze_test_structure(tree: ast.AST) -&gt; Dict:\n    \"\"\"Analyze test file structure and categorize elements\"\"\"\n    structure = {\n        'test_methods': [],\n        'setup_methods': [],\n        'helper_methods': [],\n        'assertions': [],\n        'test_data': [],\n        'imports': []\n    }\n\n    for node in ast.walk(tree):\n        if isinstance(node, ast.FunctionDef):\n            if node.name.startswith('test_'):\n                structure['test_methods'].append(node)\n                # Extract assertions from test method\n                assertions = extract_assertions(node)\n                structure['assertions'].extend(assertions)\n            elif node.name in ['setUp', 'tearDown', 'setUpClass', 'tearDownClass']:\n                structure['setup_methods'].append(node)\n            else:\n                structure['helper_methods'].append(node)\n\n    return structure\n\ndef extract_assertions(test_method: ast.FunctionDef) -&gt; List[ast.stmt]:\n    \"\"\"Extract assertion statements from test method\"\"\"\n    assertions = []\n\n    for node in ast.walk(test_method):\n        if isinstance(node, ast.Call):\n            if (isinstance(node.func, ast.Attribute) and \n                node.func.attr.startswith('assert')):\n                assertions.append(node)\n        elif isinstance(node, ast.Assert):\n            assertions.append(node)\n\n    return assertions\n</code></pre>"},{"location":"architecture/context-algorithms/#token-budget-allocation-algorithm","title":"Token Budget Allocation Algorithm","text":""},{"location":"architecture/context-algorithms/#dynamic-budget-allocation","title":"Dynamic Budget Allocation","text":"<pre><code>def calculate_optimal_budget(total_tokens: int, \n                           context_components: Dict[str, Any],\n                           agent_type: str,\n                           tdd_phase: TDDState) -&gt; TokenBudget:\n    \"\"\"\n    Calculate optimal token budget allocation based on:\n    - Available content in each category\n    - Agent type preferences\n    - TDD phase requirements\n    - Historical usage patterns\n    \"\"\"\n\n    # Base allocation percentages by agent type\n    base_allocations = get_agent_base_allocations(agent_type)\n\n    # Adjust allocations based on TDD phase\n    phase_adjustments = get_phase_adjustments(tdd_phase)\n\n    # Apply adjustments\n    adjusted_allocations = apply_allocation_adjustments(base_allocations, phase_adjustments)\n\n    # Calculate actual needs vs available content\n    component_needs = calculate_component_needs(context_components)\n\n    # Optimize allocation based on needs\n    optimized_budget = optimize_budget_allocation(\n        total_tokens, adjusted_allocations, component_needs\n    )\n\n    return optimized_budget\n\ndef get_agent_base_allocations(agent_type: str) -&gt; Dict[str, float]:\n    \"\"\"Get base allocation percentages for different agent types\"\"\"\n    allocations = {\n        'DesignAgent': {\n            'core_context': 0.30,\n            'dependencies': 0.15,\n            'historical': 0.25,\n            'agent_memory': 0.15,\n            'documentation': 0.10,\n            'buffer': 0.05\n        },\n        'QAAgent': {\n            'core_context': 0.45,  # Tests need more specific context\n            'dependencies': 0.20,\n            'historical': 0.15,\n            'agent_memory': 0.10,\n            'documentation': 0.05,\n            'buffer': 0.05\n        },\n        'CodeAgent': {\n            'core_context': 0.40,\n            'dependencies': 0.25,  # Code needs more dependency context\n            'historical': 0.15,\n            'agent_memory': 0.10,\n            'documentation': 0.05,\n            'buffer': 0.05\n        },\n        'DataAgent': {\n            'core_context': 0.35,\n            'dependencies': 0.10,\n            'historical': 0.30,    # Data analysis benefits from historical patterns\n            'agent_memory': 0.15,\n            'documentation': 0.05,\n            'buffer': 0.05\n        }\n    }\n\n    return allocations.get(agent_type, allocations['CodeAgent'])\n\ndef get_phase_adjustments(tdd_phase: TDDState) -&gt; Dict[str, float]:\n    \"\"\"Get allocation adjustments based on TDD phase\"\"\"\n    adjustments = {\n        TDDState.DESIGN: {\n            'documentation': 1.5,  # Boost documentation for design\n            'historical': 1.3,     # Boost historical patterns\n            'dependencies': 0.8    # Reduce dependency focus\n        },\n        TDDState.TEST_RED: {\n            'core_context': 1.4,   # Boost current context for test writing\n            'agent_memory': 1.2,   # Boost memory for test patterns\n            'dependencies': 0.9    # Slight reduction in dependencies\n        },\n        TDDState.CODE_GREEN: {\n            'dependencies': 1.4,   # Boost dependencies for implementation\n            'core_context': 1.2,   # Boost current context\n            'historical': 0.8      # Reduce historical patterns\n        },\n        TDDState.REFACTOR: {\n            'historical': 1.5,     # Boost historical patterns for best practices\n            'agent_memory': 1.3,   # Boost memory for refactoring patterns\n            'core_context': 1.1    # Slight boost to current context\n        },\n        TDDState.COMMIT: {\n            'core_context': 1.3,   # Boost current context for commit validation\n            'dependencies': 1.1,   # Slight boost for integration validation\n            'agent_memory': 0.9    # Slight reduction in memory\n        }\n    }\n\n    return adjustments.get(tdd_phase, {})\n\ndef optimize_budget_allocation(total_tokens: int, \n                             base_allocations: Dict[str, float],\n                             component_needs: Dict[str, int]) -&gt; TokenBudget:\n    \"\"\"\n    Optimize budget allocation by redistributing unused allocations\n    and handling over-allocations\n    \"\"\"\n\n    # Calculate initial allocations\n    initial_budget = {}\n    for component, percentage in base_allocations.items():\n        initial_budget[component] = int(total_tokens * percentage)\n\n    # Identify over and under allocations\n    adjustments = {}\n    unused_tokens = 0\n    needed_tokens = 0\n\n    for component, allocated in initial_budget.items():\n        needed = component_needs.get(component, 0)\n\n        if needed == 0:\n            # No content available, free up allocation\n            unused_tokens += allocated\n            adjustments[component] = 0\n        elif needed &lt; allocated:\n            # Less content than allocation, free up excess\n            excess = allocated - needed\n            unused_tokens += excess\n            adjustments[component] = needed\n        elif needed &gt; allocated:\n            # More content than allocation, track need\n            deficit = needed - allocated\n            needed_tokens += deficit\n            adjustments[component] = allocated\n        else:\n            # Perfect match\n            adjustments[component] = allocated\n\n    # Redistribute unused tokens to components that need more\n    if unused_tokens &gt; 0 and needed_tokens &gt; 0:\n        redistribution_ratio = min(1.0, unused_tokens / needed_tokens)\n\n        for component, allocated in adjustments.items():\n            needed = component_needs.get(component, 0)\n            if needed &gt; allocated:\n                additional = int((needed - allocated) * redistribution_ratio)\n                adjustments[component] += additional\n                unused_tokens -= additional\n\n    # Any remaining unused tokens go to buffer\n    adjustments['buffer'] = adjustments.get('buffer', 0) + unused_tokens\n\n    return TokenBudget(\n        total_budget=total_tokens,\n        core_context=adjustments.get('core_context', 0),\n        dependencies=adjustments.get('dependencies', 0),\n        agent_memory=adjustments.get('agent_memory', 0),\n        metadata=adjustments.get('documentation', 0),\n        buffer=adjustments.get('buffer', 0)\n    )\n</code></pre>"},{"location":"architecture/context-algorithms/#dependency-analysis-algorithm","title":"Dependency Analysis Algorithm","text":""},{"location":"architecture/context-algorithms/#static-dependency-analysis","title":"Static Dependency Analysis","text":"<pre><code>def build_dependency_graph(project_path: str) -&gt; Dict[str, Set[str]]:\n    \"\"\"\n    Build comprehensive dependency graph for project\n\n    Returns:\n        Dict mapping file paths to sets of their dependencies\n    \"\"\"\n\n    dependency_graph = {}\n\n    # Find all Python files\n    python_files = find_python_files(project_path)\n\n    for file_path in python_files:\n        dependencies = extract_file_dependencies(file_path, project_path)\n        dependency_graph[file_path] = set(dependencies)\n\n    # Add reverse dependencies\n    reverse_graph = build_reverse_dependencies(dependency_graph)\n\n    return {\n        'forward': dependency_graph,\n        'reverse': reverse_graph\n    }\n\ndef extract_file_dependencies(file_path: str, project_root: str) -&gt; List[str]:\n    \"\"\"Extract dependencies from a single Python file\"\"\"\n\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            content = f.read()\n\n        tree = ast.parse(content)\n        dependencies = []\n\n        for node in ast.walk(tree):\n            if isinstance(node, ast.Import):\n                for alias in node.names:\n                    dep_path = resolve_import_path(alias.name, file_path, project_root)\n                    if dep_path:\n                        dependencies.append(dep_path)\n\n            elif isinstance(node, ast.ImportFrom):\n                if node.module:\n                    dep_path = resolve_import_path(node.module, file_path, project_root)\n                    if dep_path:\n                        dependencies.append(dep_path)\n\n        return dependencies\n\n    except Exception as e:\n        logger.warning(f\"Could not analyze dependencies for {file_path}: {e}\")\n        return []\n\ndef resolve_import_path(module_name: str, source_file: str, project_root: str) -&gt; Optional[str]:\n    \"\"\"Resolve import module name to actual file path\"\"\"\n\n    # Handle relative imports\n    if module_name.startswith('.'):\n        return resolve_relative_import(module_name, source_file, project_root)\n\n    # Handle absolute imports within project\n    if is_project_module(module_name, project_root):\n        return resolve_project_import(module_name, project_root)\n\n    # External dependencies (not resolved to file paths)\n    return None\n\ndef calculate_transitive_dependencies(file_path: str, \n                                    dependency_graph: Dict[str, Set[str]], \n                                    max_depth: int = 3) -&gt; Set[str]:\n    \"\"\"Calculate transitive dependencies up to max_depth\"\"\"\n\n    visited = set()\n    to_visit = [(file_path, 0)]\n    transitive_deps = set()\n\n    while to_visit:\n        current_file, depth = to_visit.pop(0)\n\n        if current_file in visited or depth &gt;= max_depth:\n            continue\n\n        visited.add(current_file)\n\n        # Get direct dependencies\n        direct_deps = dependency_graph.get(current_file, set())\n\n        for dep in direct_deps:\n            if dep not in visited:\n                transitive_deps.add(dep)\n                to_visit.append((dep, depth + 1))\n\n    return transitive_deps\n\ndef calculate_dependency_impact_score(file_path: str, \n                                    dependency_graph: Dict[str, Set[str]]) -&gt; float:\n    \"\"\"\n    Calculate impact score based on how many files depend on this file\n    Higher score = more files depend on this file\n    \"\"\"\n\n    reverse_deps = dependency_graph.get('reverse', {}).get(file_path, set())\n\n    # Calculate direct impact\n    direct_impact = len(reverse_deps)\n\n    # Calculate transitive impact (files that depend on dependents)\n    transitive_impact = 0\n    for dep_file in reverse_deps:\n        transitive_deps = dependency_graph.get('reverse', {}).get(dep_file, set())\n        transitive_impact += len(transitive_deps)\n\n    # Normalize impact score\n    max_files = len(dependency_graph.get('forward', {}))\n    if max_files == 0:\n        return 0.0\n\n    # Weight direct impact more heavily than transitive\n    total_impact = direct_impact + (0.5 * transitive_impact)\n    normalized_score = min(1.0, total_impact / max_files)\n\n    return normalized_score\n</code></pre>"},{"location":"architecture/context-algorithms/#caching-and-performance-algorithms","title":"Caching and Performance Algorithms","text":""},{"location":"architecture/context-algorithms/#intelligent-cache-management","title":"Intelligent Cache Management","text":"<pre><code>class IntelligentCache:\n    \"\"\"\n    Intelligent caching system with predictive pre-loading and adaptive eviction\n    \"\"\"\n\n    def __init__(self, max_size_mb: int = 1000):\n        self.max_size_mb = max_size_mb\n        self.cache = {}\n        self.access_patterns = {}\n        self.prediction_model = CachePredictor()\n\n    async def get_context(self, request: ContextRequest) -&gt; Optional[AgentContext]:\n        \"\"\"Get context from cache with pattern learning\"\"\"\n\n        cache_key = self.generate_cache_key(request)\n\n        # Record access pattern\n        self.record_access_pattern(cache_key, request)\n\n        # Check cache\n        if cache_key in self.cache:\n            context = self.cache[cache_key]\n            if self.is_context_valid(context, request):\n                self.update_access_time(cache_key)\n                return context\n\n        return None\n\n    async def store_context(self, request: ContextRequest, context: AgentContext):\n        \"\"\"Store context with intelligent eviction\"\"\"\n\n        cache_key = self.generate_cache_key(request)\n\n        # Check if we need to evict items\n        if self.should_evict():\n            await self.intelligent_eviction()\n\n        # Store context\n        self.cache[cache_key] = context\n        self.update_cache_metadata(cache_key, context)\n\n        # Trigger predictive caching\n        await self.predictive_cache_warming(request)\n\n    def generate_cache_key(self, request: ContextRequest) -&gt; str:\n        \"\"\"Generate cache key considering context factors\"\"\"\n\n        # Include factors that affect context relevance\n        factors = [\n            request.agent_type,\n            request.story_id,\n            request.task.current_state.value,\n            hash(tuple(sorted(request.task.source_files))),\n            hash(tuple(sorted(request.task.test_files))),\n            request.compression_level\n        ]\n\n        return hashlib.md5(str(factors).encode()).hexdigest()\n\n    def is_context_valid(self, context: AgentContext, request: ContextRequest) -&gt; bool:\n        \"\"\"Check if cached context is still valid\"\"\"\n\n        # Check context age\n        context_age = datetime.utcnow() - context.created_at\n        if context_age &gt; timedelta(hours=24):\n            return False\n\n        # Check if source files have changed\n        if self.have_files_changed(context.source_files):\n            return False\n\n        # Check if task requirements have significantly changed\n        if self.has_task_changed_significantly(context.task_hash, request.task):\n            return False\n\n        return True\n\n    async def intelligent_eviction(self):\n        \"\"\"Evict cache items using intelligent strategy\"\"\"\n\n        # Calculate eviction scores for all cached items\n        eviction_scores = {}\n\n        for cache_key, context in self.cache.items():\n            score = self.calculate_eviction_score(cache_key, context)\n            eviction_scores[cache_key] = score\n\n        # Sort by eviction score (higher = more likely to evict)\n        sorted_items = sorted(eviction_scores.items(), key=lambda x: x[1], reverse=True)\n\n        # Evict items until we're under the size limit\n        current_size = self.get_cache_size_mb()\n        target_size = self.max_size_mb * 0.8  # Leave 20% buffer\n\n        for cache_key, score in sorted_items:\n            if current_size &lt;= target_size:\n                break\n\n            context = self.cache.pop(cache_key)\n            current_size -= self.estimate_context_size_mb(context)\n\n            logger.debug(f\"Evicted cache item {cache_key} (score: {score:.2f})\")\n\n    def calculate_eviction_score(self, cache_key: str, context: AgentContext) -&gt; float:\n        \"\"\"Calculate eviction score (higher = more likely to evict)\"\"\"\n\n        # Factor 1: Age (older = higher eviction score)\n        age_hours = (datetime.utcnow() - context.created_at).total_seconds() / 3600\n        age_score = min(1.0, age_hours / 24)  # Normalize to 24 hours\n\n        # Factor 2: Access frequency (less frequent = higher eviction score)\n        access_count = self.access_patterns.get(cache_key, {}).get('count', 0)\n        max_access = max((p.get('count', 0) for p in self.access_patterns.values()), default=1)\n        frequency_score = 1.0 - (access_count / max_access)\n\n        # Factor 3: Size (larger = higher eviction score for equal other factors)\n        size_mb = self.estimate_context_size_mb(context)\n        max_size = max((self.estimate_context_size_mb(c) for c in self.cache.values()), default=1)\n        size_score = size_mb / max_size\n\n        # Factor 4: Prediction score (less likely to be accessed = higher eviction score)\n        prediction_score = 1.0 - self.prediction_model.predict_access_probability(cache_key)\n\n        # Weighted combination\n        eviction_score = (\n            0.3 * age_score +\n            0.3 * frequency_score +\n            0.2 * size_score +\n            0.2 * prediction_score\n        )\n\n        return eviction_score\n\n    async def predictive_cache_warming(self, request: ContextRequest):\n        \"\"\"Pre-warm cache with likely future requests\"\"\"\n\n        # Predict likely next requests based on current request\n        predicted_requests = self.prediction_model.predict_next_requests(request)\n\n        for predicted_request in predicted_requests:\n            cache_key = self.generate_cache_key(predicted_request)\n\n            # Only pre-warm if not already cached and high confidence\n            if cache_key not in self.cache and predicted_request.confidence &gt; 0.7:\n                try:\n                    # Prepare context in background\n                    context = await self.context_manager.prepare_context(predicted_request)\n                    await self.store_context(predicted_request, context)\n\n                    logger.debug(f\"Pre-warmed cache for predicted request: {cache_key}\")\n\n                except Exception as e:\n                    logger.warning(f\"Failed to pre-warm cache: {e}\")\n\nclass CachePredictor:\n    \"\"\"Predict future cache access patterns\"\"\"\n\n    def __init__(self):\n        self.pattern_history = []\n        self.transition_matrix = {}\n\n    def predict_access_probability(self, cache_key: str) -&gt; float:\n        \"\"\"Predict probability that cache_key will be accessed soon\"\"\"\n\n        # Use simple frequency-based prediction for now\n        # Can be enhanced with ML models\n\n        recent_accesses = self.get_recent_access_patterns()\n        if not recent_accesses:\n            return 0.5  # Default probability\n\n        # Count how often this key appears in recent patterns\n        appearances = sum(1 for pattern in recent_accesses if cache_key in pattern)\n        probability = appearances / len(recent_accesses)\n\n        return probability\n\n    def predict_next_requests(self, current_request: ContextRequest) -&gt; List[ContextRequest]:\n        \"\"\"Predict likely next context requests\"\"\"\n\n        predictions = []\n\n        # Pattern 1: Same agent, next TDD phase\n        next_phase = self.get_next_tdd_phase(current_request.task.current_state)\n        if next_phase:\n            predicted_request = self.create_predicted_request(\n                current_request, tdd_phase=next_phase, confidence=0.8\n            )\n            predictions.append(predicted_request)\n\n        # Pattern 2: Different agent, same phase (parallel work)\n        for agent_type in ['DesignAgent', 'QAAgent', 'CodeAgent', 'DataAgent']:\n            if agent_type != current_request.agent_type:\n                predicted_request = self.create_predicted_request(\n                    current_request, agent_type=agent_type, confidence=0.6\n                )\n                predictions.append(predicted_request)\n\n        # Pattern 3: Same agent, related story\n        related_stories = self.get_related_stories(current_request.story_id)\n        for story_id in related_stories[:2]:  # Limit to top 2 related\n            predicted_request = self.create_predicted_request(\n                current_request, story_id=story_id, confidence=0.4\n            )\n            predictions.append(predicted_request)\n\n        return predictions\n</code></pre> <p>This comprehensive set of algorithms provides the foundation for intelligent context management, covering relevance scoring, content compression, dependency analysis, and caching strategies. Each algorithm is designed to be configurable and extensible, allowing for continuous improvement based on real-world usage patterns.</p>"},{"location":"architecture/context-api-specification/","title":"Context Management System API Specification","text":""},{"location":"architecture/context-api-specification/#overview","title":"Overview","text":"<p>This document defines the API interfaces for the Context Management System components, providing detailed specifications for inter-component communication and external integrations.</p>"},{"location":"architecture/context-api-specification/#core-api-interfaces","title":"Core API Interfaces","text":""},{"location":"architecture/context-api-specification/#context-manager-api","title":"Context Manager API","text":""},{"location":"architecture/context-api-specification/#icontextmanager","title":"<code>IContextManager</code>","text":"<p>The primary interface for context management operations.</p> <pre><code>from abc import ABC, abstractmethod\nfrom typing import Dict, Any, List, Optional\nfrom dataclasses import dataclass\nfrom enum import Enum\n\nclass ContextPriority(Enum):\n    CRITICAL = \"critical\"\n    HIGH = \"high\" \n    MEDIUM = \"medium\"\n    LOW = \"low\"\n\n@dataclass\nclass ContextRequest:\n    \"\"\"Request for agent context preparation\"\"\"\n    agent_type: str\n    task: 'TDDTask'\n    story_id: str\n    max_tokens: int\n    priority: ContextPriority = ContextPriority.MEDIUM\n    include_memory: bool = True\n    compression_level: str = \"moderate\"  # low, moderate, high\n    cache_enabled: bool = True\n\n@dataclass\nclass AgentContext:\n    \"\"\"Prepared context for agent execution\"\"\"\n    context_id: str\n    agent_type: str\n    story_id: str\n    core_context: str\n    dependencies: Optional[str] = None\n    agent_memory: Optional[str] = None\n    metadata: Dict[str, Any] = None\n    token_usage: Dict[str, int] = None\n    preparation_time: float = 0.0\n    cache_hit: bool = False\n\nclass IContextManager(ABC):\n    \"\"\"Primary interface for context management\"\"\"\n\n    @abstractmethod\n    async def prepare_context(self, request: ContextRequest) -&gt; AgentContext:\n        \"\"\"Prepare optimized context for agent task execution\"\"\"\n        pass\n\n    @abstractmethod\n    async def update_context(self, context_id: str, changes: Dict[str, Any]) -&gt; None:\n        \"\"\"Update existing context with incremental changes\"\"\"\n        pass\n\n    @abstractmethod\n    async def invalidate_context(self, context_id: str) -&gt; None:\n        \"\"\"Invalidate cached context\"\"\"\n        pass\n\n    @abstractmethod\n    async def get_context_metrics(self, context_id: str) -&gt; Dict[str, Any]:\n        \"\"\"Get context usage and performance metrics\"\"\"\n        pass\n\n    @abstractmethod\n    async def cleanup_expired_contexts(self, max_age_hours: int = 24) -&gt; int:\n        \"\"\"Clean up expired contexts and return count removed\"\"\"\n        pass\n</code></pre>"},{"location":"architecture/context-api-specification/#context-filter-api","title":"Context Filter API","text":""},{"location":"architecture/context-api-specification/#icontextfilter","title":"<code>IContextFilter</code>","text":"<p>Interface for relevance-based context filtering.</p> <pre><code>@dataclass\nclass FilterCriteria:\n    \"\"\"Criteria for context filtering\"\"\"\n    task_description: str\n    source_files: List[str]\n    test_files: List[str]\n    tdd_phase: 'TDDState'\n    agent_type: str\n    story_id: str\n    include_patterns: List[str] = None\n    exclude_patterns: List[str] = None\n    max_files: int = 100\n\n@dataclass\nclass FilterResult:\n    \"\"\"Result of context filtering\"\"\"\n    relevant_files: List[str]\n    relevance_scores: Dict[str, float]\n    excluded_files: List[str]\n    filter_reason: Dict[str, str]\n    processing_time: float\n\nclass IContextFilter(ABC):\n    \"\"\"Interface for intelligent context filtering\"\"\"\n\n    @abstractmethod\n    async def filter_relevant_files(self, criteria: FilterCriteria) -&gt; FilterResult:\n        \"\"\"Filter files based on relevance criteria\"\"\"\n        pass\n\n    @abstractmethod\n    async def calculate_relevance_score(self, file_path: str, criteria: FilterCriteria) -&gt; float:\n        \"\"\"Calculate relevance score for a single file\"\"\"\n        pass\n\n    @abstractmethod\n    async def get_dependency_chain(self, file_path: str, max_depth: int = 3) -&gt; List[str]:\n        \"\"\"Get dependency chain for a file\"\"\"\n        pass\n\n    @abstractmethod\n    async def update_relevance_model(self, feedback: Dict[str, Any]) -&gt; None:\n        \"\"\"Update relevance scoring based on usage feedback\"\"\"\n        pass\n</code></pre>"},{"location":"architecture/context-api-specification/#token-calculator-api","title":"Token Calculator API","text":""},{"location":"architecture/context-api-specification/#itokencalculator","title":"<code>ITokenCalculator</code>","text":"<p>Interface for token counting and budget management.</p> <pre><code>@dataclass\nclass TokenBudget:\n    \"\"\"Token budget allocation\"\"\"\n    total_budget: int\n    core_context: int\n    dependencies: int\n    agent_memory: int\n    metadata: int\n    buffer: int\n\n    def validate(self) -&gt; bool:\n        \"\"\"Validate budget allocation doesn't exceed total\"\"\"\n        allocated = self.core_context + self.dependencies + self.agent_memory + self.metadata + self.buffer\n        return allocated &lt;= self.total_budget\n\n@dataclass\nclass TokenUsage:\n    \"\"\"Actual token usage\"\"\"\n    estimated_tokens: int\n    actual_tokens: int\n    by_component: Dict[str, int]\n    accuracy_percentage: float\n\nclass ITokenCalculator(ABC):\n    \"\"\"Interface for token calculation and budget management\"\"\"\n\n    @abstractmethod\n    def estimate_tokens(self, content: str, model: str = \"claude-3\") -&gt; int:\n        \"\"\"Estimate token count for content\"\"\"\n        pass\n\n    @abstractmethod\n    async def calculate_budget(self, total_tokens: int, context_components: Dict[str, Any]) -&gt; TokenBudget:\n        \"\"\"Calculate optimal token budget allocation\"\"\"\n        pass\n\n    @abstractmethod\n    async def validate_budget_usage(self, budget: TokenBudget, actual_usage: Dict[str, str]) -&gt; TokenUsage:\n        \"\"\"Validate actual usage against budget\"\"\"\n        pass\n\n    @abstractmethod\n    def get_compression_recommendation(self, content_size: int, target_size: int) -&gt; str:\n        \"\"\"Recommend compression level to meet target size\"\"\"\n        pass\n</code></pre>"},{"location":"architecture/context-api-specification/#context-compressor-api","title":"Context Compressor API","text":""},{"location":"architecture/context-api-specification/#icontextcompressor","title":"<code>IContextCompressor</code>","text":"<p>Interface for intelligent content compression.</p> <pre><code>@dataclass\nclass CompressionRequest:\n    \"\"\"Request for content compression\"\"\"\n    content: str\n    content_type: str  # python, test, markdown, json, etc.\n    target_tokens: int\n    preserve_structure: bool = True\n    preserve_semantics: bool = True\n    compression_strategy: str = \"adaptive\"  # aggressive, moderate, conservative, adaptive\n\n@dataclass\nclass CompressionResult:\n    \"\"\"Result of content compression\"\"\"\n    compressed_content: str\n    original_tokens: int\n    compressed_tokens: int\n    compression_ratio: float\n    semantic_preservation_score: float\n    processing_time: float\n    strategy_used: str\n\nclass IContextCompressor(ABC):\n    \"\"\"Interface for intelligent context compression\"\"\"\n\n    @abstractmethod\n    async def compress_content(self, request: CompressionRequest) -&gt; CompressionResult:\n        \"\"\"Compress content according to specifications\"\"\"\n        pass\n\n    @abstractmethod\n    async def compress_file_collection(self, files: Dict[str, str], target_tokens: int) -&gt; Dict[str, CompressionResult]:\n        \"\"\"Compress multiple files with coordinated token budget\"\"\"\n        pass\n\n    @abstractmethod\n    def estimate_compression_ratio(self, content: str, content_type: str) -&gt; float:\n        \"\"\"Estimate achievable compression ratio\"\"\"\n        pass\n\n    @abstractmethod\n    async def decompress_content(self, compressed_content: str, metadata: Dict[str, Any]) -&gt; str:\n        \"\"\"Decompress content if reversible compression was used\"\"\"\n        pass\n</code></pre>"},{"location":"architecture/context-api-specification/#agent-memory-api","title":"Agent Memory API","text":""},{"location":"architecture/context-api-specification/#iagentmemory","title":"<code>IAgentMemory</code>","text":"<p>Interface for persistent agent memory management.</p> <pre><code>@dataclass\nclass Decision:\n    \"\"\"Agent decision record\"\"\"\n    id: str\n    agent_type: str\n    task_id: str\n    decision_type: str\n    context: Dict[str, Any]\n    rationale: str\n    outcome: str\n    timestamp: str\n    confidence: float\n\n@dataclass\nclass PhaseHandoff:\n    \"\"\"TDD phase handoff record\"\"\"\n    from_phase: 'TDDState'\n    to_phase: 'TDDState'\n    artifacts: Dict[str, str]\n    context_summary: str\n    handoff_notes: str\n    timestamp: str\n\n@dataclass\nclass AgentMemory:\n    \"\"\"Complete agent memory\"\"\"\n    agent_type: str\n    story_id: str\n    decisions: List[Decision]\n    artifacts: Dict[str, str]\n    learned_patterns: List[str]\n    phase_handoffs: List[PhaseHandoff]\n    context_preferences: Dict[str, Any]\n    performance_metrics: Dict[str, float]\n\nclass IAgentMemory(ABC):\n    \"\"\"Interface for agent memory management\"\"\"\n\n    @abstractmethod\n    async def store_decision(self, decision: Decision) -&gt; None:\n        \"\"\"Store agent decision\"\"\"\n        pass\n\n    @abstractmethod\n    async def store_artifacts(self, agent_type: str, story_id: str, artifacts: Dict[str, str]) -&gt; None:\n        \"\"\"Store agent artifacts\"\"\"\n        pass\n\n    @abstractmethod\n    async def store_phase_handoff(self, handoff: PhaseHandoff) -&gt; None:\n        \"\"\"Store TDD phase handoff\"\"\"\n        pass\n\n    @abstractmethod\n    async def get_agent_memory(self, agent_type: str, story_id: str) -&gt; AgentMemory:\n        \"\"\"Retrieve complete agent memory\"\"\"\n        pass\n\n    @abstractmethod\n    async def get_relevant_decisions(self, agent_type: str, task_context: Dict[str, Any], limit: int = 10) -&gt; List[Decision]:\n        \"\"\"Get relevant past decisions for current task\"\"\"\n        pass\n\n    @abstractmethod\n    async def update_performance_metrics(self, agent_type: str, story_id: str, metrics: Dict[str, float]) -&gt; None:\n        \"\"\"Update agent performance metrics\"\"\"\n        pass\n</code></pre>"},{"location":"architecture/context-api-specification/#context-index-api","title":"Context Index API","text":""},{"location":"architecture/context-api-specification/#icontextindex","title":"<code>IContextIndex</code>","text":"<p>Interface for searchable context indexing.</p> <pre><code>@dataclass\nclass IndexEntry:\n    \"\"\"Context index entry\"\"\"\n    file_path: str\n    content_type: str\n    symbols: List[str]  # classes, functions, variables\n    dependencies: List[str]\n    reverse_dependencies: List[str]\n    last_modified: str\n    content_hash: str\n    metadata: Dict[str, Any]\n\n@dataclass\nclass SearchQuery:\n    \"\"\"Context search query\"\"\"\n    query_text: str\n    file_types: List[str] = None\n    symbols: List[str] = None\n    max_results: int = 50\n    include_dependencies: bool = False\n    similarity_threshold: float = 0.7\n\n@dataclass\nclass SearchResult:\n    \"\"\"Context search result\"\"\"\n    entries: List[IndexEntry]\n    relevance_scores: Dict[str, float]\n    query_time: float\n    total_matches: int\n\nclass IContextIndex(ABC):\n    \"\"\"Interface for context indexing and search\"\"\"\n\n    @abstractmethod\n    async def index_file(self, file_path: str) -&gt; IndexEntry:\n        \"\"\"Index a single file\"\"\"\n        pass\n\n    @abstractmethod\n    async def index_directory(self, directory_path: str, patterns: List[str] = None) -&gt; List[IndexEntry]:\n        \"\"\"Index all files in directory matching patterns\"\"\"\n        pass\n\n    @abstractmethod\n    async def search(self, query: SearchQuery) -&gt; SearchResult:\n        \"\"\"Search indexed content\"\"\"\n        pass\n\n    @abstractmethod\n    async def get_dependencies(self, file_path: str, include_reverse: bool = False) -&gt; List[str]:\n        \"\"\"Get file dependencies\"\"\"\n        pass\n\n    @abstractmethod\n    async def invalidate_file(self, file_path: str) -&gt; None:\n        \"\"\"Remove file from index\"\"\"\n        pass\n\n    @abstractmethod\n    async def rebuild_index(self, project_path: str) -&gt; int:\n        \"\"\"Rebuild complete index and return entry count\"\"\"\n        pass\n</code></pre>"},{"location":"architecture/context-api-specification/#configuration-apis","title":"Configuration APIs","text":""},{"location":"architecture/context-api-specification/#context-configuration","title":"Context Configuration","text":"<pre><code>@dataclass\nclass ContextConfig:\n    \"\"\"Context management configuration\"\"\"\n    max_context_tokens: int = 200000\n    default_compression_level: str = \"moderate\"\n    cache_ttl_hours: int = 24\n    max_cache_size_mb: int = 1000\n    enable_predictive_caching: bool = True\n    relevance_threshold: float = 0.5\n    max_dependency_depth: int = 3\n    token_buffer_percentage: float = 0.05\n\n@dataclass\nclass AgentConfig:\n    \"\"\"Agent-specific context configuration\"\"\"\n    agent_type: str\n    preferred_context_size: int\n    compression_tolerance: str = \"moderate\"\n    memory_retention_days: int = 30\n    context_priorities: Dict[str, float] = None\n\nclass IContextConfig(ABC):\n    \"\"\"Interface for context configuration management\"\"\"\n\n    @abstractmethod\n    def get_context_config(self) -&gt; ContextConfig:\n        \"\"\"Get current context configuration\"\"\"\n        pass\n\n    @abstractmethod\n    def get_agent_config(self, agent_type: str) -&gt; AgentConfig:\n        \"\"\"Get agent-specific configuration\"\"\"\n        pass\n\n    @abstractmethod\n    async def update_config(self, config: ContextConfig) -&gt; None:\n        \"\"\"Update context configuration\"\"\"\n        pass\n\n    @abstractmethod\n    async def update_agent_config(self, agent_type: str, config: AgentConfig) -&gt; None:\n        \"\"\"Update agent-specific configuration\"\"\"\n        pass\n</code></pre>"},{"location":"architecture/context-api-specification/#external-integration-apis","title":"External Integration APIs","text":""},{"location":"architecture/context-api-specification/#claude-code-integration","title":"Claude Code Integration","text":"<pre><code>class IClaudeCodeIntegration(ABC):\n    \"\"\"Interface for Claude Code CLI integration\"\"\"\n\n    @abstractmethod\n    async def prepare_claude_prompt(self, context: AgentContext, task: 'TDDTask') -&gt; str:\n        \"\"\"Prepare optimized prompt for Claude Code CLI\"\"\"\n        pass\n\n    @abstractmethod\n    async def estimate_claude_tokens(self, prompt: str) -&gt; int:\n        \"\"\"Estimate token usage for Claude Code prompt\"\"\"\n        pass\n\n    @abstractmethod\n    async def execute_with_context(self, agent_type: str, prompt: str, context: AgentContext) -&gt; Dict[str, Any]:\n        \"\"\"Execute Claude Code with prepared context\"\"\"\n        pass\n</code></pre>"},{"location":"architecture/context-api-specification/#tdd-state-machine-integration","title":"TDD State Machine Integration","text":"<pre><code>class ITDDContextIntegration(ABC):\n    \"\"\"Interface for TDD state machine integration\"\"\"\n\n    @abstractmethod\n    def get_phase_context_requirements(self, phase: 'TDDState') -&gt; Dict[str, Any]:\n        \"\"\"Get context requirements for TDD phase\"\"\"\n        pass\n\n    @abstractmethod\n    async def prepare_phase_handoff(self, from_phase: 'TDDState', to_phase: 'TDDState', context: AgentContext) -&gt; PhaseHandoff:\n        \"\"\"Prepare context for TDD phase transition\"\"\"\n        pass\n\n    @abstractmethod\n    async def validate_phase_context(self, phase: 'TDDState', context: AgentContext) -&gt; bool:\n        \"\"\"Validate context completeness for TDD phase\"\"\"\n        pass\n</code></pre>"},{"location":"architecture/context-api-specification/#error-handling-apis","title":"Error Handling APIs","text":""},{"location":"architecture/context-api-specification/#context-exceptions","title":"Context Exceptions","text":"<pre><code>class ContextException(Exception):\n    \"\"\"Base exception for context management errors\"\"\"\n    pass\n\nclass TokenLimitExceededException(ContextException):\n    \"\"\"Raised when context exceeds token limits\"\"\"\n    def __init__(self, required_tokens: int, max_tokens: int):\n        self.required_tokens = required_tokens\n        self.max_tokens = max_tokens\n        super().__init__(f\"Context requires {required_tokens} tokens, but limit is {max_tokens}\")\n\nclass ContextNotFoundError(ContextException):\n    \"\"\"Raised when requested context is not available\"\"\"\n    pass\n\nclass CompressionFailedException(ContextException):\n    \"\"\"Raised when content compression fails\"\"\"\n    pass\n\nclass IndexCorruptedException(ContextException):\n    \"\"\"Raised when context index is corrupted\"\"\"\n    pass\n</code></pre>"},{"location":"architecture/context-api-specification/#error-recovery-interface","title":"Error Recovery Interface","text":"<pre><code>class IContextErrorRecovery(ABC):\n    \"\"\"Interface for context error recovery\"\"\"\n\n    @abstractmethod\n    async def handle_token_limit_exceeded(self, request: ContextRequest, current_size: int) -&gt; AgentContext:\n        \"\"\"Handle token limit exceeded by applying aggressive compression\"\"\"\n        pass\n\n    @abstractmethod\n    async def recover_from_index_corruption(self, project_path: str) -&gt; bool:\n        \"\"\"Recover from index corruption by rebuilding\"\"\"\n        pass\n\n    @abstractmethod\n    async def fallback_to_basic_context(self, request: ContextRequest) -&gt; AgentContext:\n        \"\"\"Provide basic context when advanced features fail\"\"\"\n        pass\n</code></pre>"},{"location":"architecture/context-api-specification/#monitoring-and-metrics-apis","title":"Monitoring and Metrics APIs","text":""},{"location":"architecture/context-api-specification/#context-metrics","title":"Context Metrics","text":"<pre><code>@dataclass\nclass ContextMetrics:\n    \"\"\"Context management metrics\"\"\"\n    total_requests: int\n    cache_hit_rate: float\n    average_preparation_time: float\n    token_utilization_rate: float\n    compression_effectiveness: float\n    context_relevance_score: float\n\n@dataclass\nclass PerformanceMetrics:\n    \"\"\"Performance metrics\"\"\"\n    cpu_usage_percentage: float\n    memory_usage_mb: float\n    disk_io_rate: float\n    network_io_rate: float\n    cache_size_mb: float\n    index_size_mb: float\n\nclass IContextMetrics(ABC):\n    \"\"\"Interface for context metrics collection\"\"\"\n\n    @abstractmethod\n    async def collect_context_metrics(self, time_range_hours: int = 24) -&gt; ContextMetrics:\n        \"\"\"Collect context management metrics\"\"\"\n        pass\n\n    @abstractmethod\n    async def collect_performance_metrics(self) -&gt; PerformanceMetrics:\n        \"\"\"Collect system performance metrics\"\"\"\n        pass\n\n    @abstractmethod\n    async def export_metrics(self, format: str = \"json\") -&gt; str:\n        \"\"\"Export metrics in specified format\"\"\"\n        pass\n</code></pre>"},{"location":"architecture/context-api-specification/#usage-examples","title":"Usage Examples","text":""},{"location":"architecture/context-api-specification/#basic-context-preparation","title":"Basic Context Preparation","text":"<pre><code># Example: Prepare context for QA Agent in TEST_RED phase\nasync def prepare_qa_context_example():\n    context_manager = get_context_manager()\n\n    request = ContextRequest(\n        agent_type=\"QAAgent\",\n        task=current_tdd_task,\n        story_id=\"story-123\",\n        max_tokens=80000,\n        priority=ContextPriority.HIGH,\n        compression_level=\"moderate\"\n    )\n\n    context = await context_manager.prepare_context(request)\n\n    # Use context with QA Agent\n    qa_agent = QAAgent()\n    result = await qa_agent.execute_task(context)\n\n    return result\n</code></pre>"},{"location":"architecture/context-api-specification/#advanced-context-filtering","title":"Advanced Context Filtering","text":"<pre><code># Example: Filter files for Code Agent implementation\nasync def filter_implementation_context():\n    context_filter = get_context_filter()\n\n    criteria = FilterCriteria(\n        task_description=\"Implement user authentication service\",\n        source_files=[\"src/auth/\", \"src/user/\"],\n        test_files=[\"tests/tdd/auth_test.py\"],\n        tdd_phase=TDDState.CODE_GREEN,\n        agent_type=\"CodeAgent\",\n        story_id=\"story-123\",\n        include_patterns=[\"*.py\", \"*.md\"],\n        exclude_patterns=[\"*__pycache__*\", \"*.pyc\"],\n        max_files=50\n    )\n\n    result = await context_filter.filter_relevant_files(criteria)\n\n    print(f\"Found {len(result.relevant_files)} relevant files\")\n    for file_path, score in result.relevance_scores.items():\n        print(f\"  {file_path}: {score:.2f}\")\n\n    return result\n</code></pre>"},{"location":"architecture/context-api-specification/#context-compression","title":"Context Compression","text":"<pre><code># Example: Compress large implementation files\nasync def compress_implementation_files():\n    compressor = get_context_compressor()\n\n    files = {\n        \"src/auth/service.py\": read_file(\"src/auth/service.py\"),\n        \"src/auth/models.py\": read_file(\"src/auth/models.py\"),\n        \"src/auth/repository.py\": read_file(\"src/auth/repository.py\")\n    }\n\n    compressed_files = await compressor.compress_file_collection(\n        files=files,\n        target_tokens=30000\n    )\n\n    for file_path, result in compressed_files.items():\n        print(f\"{file_path}: {result.original_tokens} -&gt; {result.compressed_tokens} tokens \"\n              f\"({result.compression_ratio:.2f}x compression)\")\n\n    return compressed_files\n</code></pre> <p>This API specification provides a comprehensive interface for all Context Management System components, enabling clean separation of concerns and easy testing and integration.</p>"},{"location":"architecture/context-evaluation-framework/","title":"Context Management System Evaluation Framework","text":""},{"location":"architecture/context-evaluation-framework/#overview","title":"Overview","text":"<p>This document defines a comprehensive evaluation framework for the Context Management System, including success metrics, benchmarking strategies, performance validation, and continuous improvement methodologies.</p>"},{"location":"architecture/context-evaluation-framework/#success-metrics-framework","title":"Success Metrics Framework","text":""},{"location":"architecture/context-evaluation-framework/#primary-success-metrics","title":"Primary Success Metrics","text":""},{"location":"architecture/context-evaluation-framework/#1-context-efficiency-metrics","title":"1. Context Efficiency Metrics","text":"<p>Token Utilization Rate <pre><code>Token Utilization = (Tokens Actually Used by Agent) / (Total Tokens Provided)\nTarget: &gt;90%\nMeasurement: Track agent consumption of provided context\n</code></pre></p> <p>Context Relevance Score <pre><code>Relevance Score = (Relevant Context Items Used) / (Total Context Items Provided)\nTarget: &gt;95%\nMeasurement: Agent feedback on context usefulness\n</code></pre></p> <p>Redundancy Reduction <pre><code>Redundancy Rate = (Duplicate Information in Context) / (Total Context Size)\nTarget: &lt;5%\nMeasurement: Automatic detection of duplicate content\n</code></pre></p>"},{"location":"architecture/context-evaluation-framework/#2-system-performance-metrics","title":"2. System Performance Metrics","text":"<p>Context Preparation Latency <pre><code>Preparation Time = Time to prepare optimized context for agent\nTarget: &lt;2 seconds for typical tasks\nMeasurement: End-to-end timing from request to delivery\n</code></pre></p> <p>Cache Hit Rate <pre><code>Cache Hit Rate = (Cache Hits) / (Total Context Requests)\nTarget: &gt;80%\nMeasurement: Cache access patterns and effectiveness\n</code></pre></p> <p>Throughput <pre><code>System Throughput = Concurrent context requests handled successfully\nTarget: 10+ parallel TDD cycles\nMeasurement: Load testing with multiple simultaneous operations\n</code></pre></p>"},{"location":"architecture/context-evaluation-framework/#3-quality-metrics","title":"3. Quality Metrics","text":"<p>Agent Task Success Rate <pre><code>Success Rate = (Successful Agent Task Completions) / (Total Agent Tasks)\nTarget: &gt;95% (improvement from baseline)\nMeasurement: Task completion tracking with context attribution\n</code></pre></p> <p>Context Completeness <pre><code>Completeness = 1 - (Missing Critical Information Reports) / (Total Tasks)\nTarget: &gt;98%\nMeasurement: Agent reports of insufficient context\n</code></pre></p> <p>Cross-Phase Continuity <pre><code>Continuity Rate = (Successful Phase Handoffs) / (Total Phase Transitions)\nTarget: &gt;98%\nMeasurement: TDD phase transition success tracking\n</code></pre></p>"},{"location":"architecture/context-evaluation-framework/#secondary-success-metrics","title":"Secondary Success Metrics","text":""},{"location":"architecture/context-evaluation-framework/#4-resource-utilization-metrics","title":"4. Resource Utilization Metrics","text":"<p>Memory Efficiency <pre><code>Memory Usage = Peak memory consumption during context operations\nTarget: &lt;70% of available system memory\nMeasurement: System resource monitoring\n</code></pre></p> <p>CPU Efficiency <pre><code>CPU Usage = Average CPU utilization during context preparation\nTarget: &lt;70% of available CPU capacity\nMeasurement: System performance monitoring\n</code></pre></p> <p>Storage Efficiency <pre><code>Storage Growth Rate = Context storage size growth over time\nTarget: Linear growth with project size\nMeasurement: Storage usage tracking and projections\n</code></pre></p>"},{"location":"architecture/context-evaluation-framework/#5-scalability-metrics","title":"5. Scalability Metrics","text":"<p>Codebase Size Scalability <pre><code>Response Time vs. Codebase Size = Context preparation time across project sizes\nTarget: Logarithmic growth (not linear)\nMeasurement: Testing across projects of varying sizes\n</code></pre></p> <p>Concurrent User Scalability <pre><code>Performance Degradation = Response time increase with concurrent users\nTarget: &lt;20% degradation with 10x concurrent load\nMeasurement: Load testing with multiple simulated users\n</code></pre></p>"},{"location":"architecture/context-evaluation-framework/#benchmarking-strategy","title":"Benchmarking Strategy","text":""},{"location":"architecture/context-evaluation-framework/#synthetic-benchmarks","title":"Synthetic Benchmarks","text":""},{"location":"architecture/context-evaluation-framework/#benchmark-suite-1-token-budget-stress-tests","title":"Benchmark Suite 1: Token Budget Stress Tests","text":"<p>Test Case 1.1: Extreme Token Limits <pre><code>def test_extreme_token_limits():\n    \"\"\"Test context management with very limited token budgets\"\"\"\n    test_cases = [\n        {\"budget\": 1000, \"project_size\": \"large\", \"expected_relevance\": 0.8},\n        {\"budget\": 5000, \"project_size\": \"medium\", \"expected_relevance\": 0.9},\n        {\"budget\": 10000, \"project_size\": \"small\", \"expected_relevance\": 0.95}\n    ]\n\n    for case in test_cases:\n        context = prepare_context_with_budget(case[\"budget\"])\n        relevance = measure_context_relevance(context)\n        assert relevance &gt;= case[\"expected_relevance\"]\n</code></pre></p> <p>Test Case 1.2: Token Budget Allocation <pre><code>def test_token_budget_allocation():\n    \"\"\"Test optimal token budget allocation across context types\"\"\"\n    total_budget = 50000\n    allocation = calculate_optimal_budget(total_budget, context_components)\n\n    # Validate allocation efficiency\n    assert allocation.validate()\n    assert sum(allocation.values()) &lt;= total_budget\n\n    # Test actual usage vs allocation\n    actual_usage = execute_with_allocation(allocation)\n    efficiency = calculate_allocation_efficiency(allocation, actual_usage)\n    assert efficiency &gt; 0.85\n</code></pre></p>"},{"location":"architecture/context-evaluation-framework/#benchmark-suite-2-large-codebase-performance","title":"Benchmark Suite 2: Large Codebase Performance","text":"<p>Test Case 2.1: Massive Project Handling <pre><code>def test_massive_project_performance():\n    \"\"\"Test performance with very large codebases\"\"\"\n    project_sizes = [\n        {\"files\": 1000, \"max_prep_time\": 2.0},\n        {\"files\": 10000, \"max_prep_time\": 5.0},\n        {\"files\": 50000, \"max_prep_time\": 15.0},\n        {\"files\": 100000, \"max_prep_time\": 30.0}\n    ]\n\n    for size_config in project_sizes:\n        project = generate_synthetic_project(size_config[\"files\"])\n\n        start_time = time.time()\n        context = prepare_context(project, sample_task)\n        prep_time = time.time() - start_time\n\n        assert prep_time &lt; size_config[\"max_prep_time\"]\n        assert context.relevance_score &gt; 0.9\n</code></pre></p> <p>Test Case 2.2: Memory Pressure Testing <pre><code>def test_memory_pressure_scenarios():\n    \"\"\"Test system behavior under memory constraints\"\"\"\n    memory_limits = [512, 1024, 2048, 4096]  # MB\n\n    for limit_mb in memory_limits:\n        with memory_constraint(limit_mb):\n            # Test context preparation under memory pressure\n            context = prepare_context_with_memory_limit(large_project, limit_mb)\n\n            # Validate quality doesn't degrade significantly\n            assert context.quality_score &gt; 0.8\n            assert not memory_exceeded()\n</code></pre></p>"},{"location":"architecture/context-evaluation-framework/#benchmark-suite-3-concurrent-load-testing","title":"Benchmark Suite 3: Concurrent Load Testing","text":"<p>Test Case 3.1: Parallel TDD Cycles <pre><code>async def test_concurrent_tdd_cycles():\n    \"\"\"Test multiple parallel TDD cycles\"\"\"\n    num_cycles = 10\n\n    tasks = []\n    for i in range(num_cycles):\n        task = asyncio.create_task(execute_full_tdd_cycle(f\"story-{i}\"))\n        tasks.append(task)\n\n    start_time = time.time()\n    results = await asyncio.gather(*tasks)\n    total_time = time.time() - start_time\n\n    # Validate all cycles completed successfully\n    assert all(result.success for result in results)\n\n    # Validate performance doesn't degrade significantly\n    avg_cycle_time = total_time / num_cycles\n    assert avg_cycle_time &lt; baseline_cycle_time * 1.5\n</code></pre></p>"},{"location":"architecture/context-evaluation-framework/#real-world-benchmarks","title":"Real-World Benchmarks","text":""},{"location":"architecture/context-evaluation-framework/#benchmark-suite-4-open-source-projects","title":"Benchmark Suite 4: Open Source Projects","text":"<p>Test Case 4.1: Popular GitHub Repositories <pre><code>def test_popular_repositories():\n    \"\"\"Test context management on real open source projects\"\"\"\n    test_repositories = [\n        {\"repo\": \"django/django\", \"complexity\": \"high\", \"size\": \"large\"},\n        {\"repo\": \"pallets/flask\", \"complexity\": \"medium\", \"size\": \"medium\"},\n        {\"repo\": \"requests/requests\", \"complexity\": \"low\", \"size\": \"small\"}\n    ]\n\n    for repo_config in test_repositories:\n        repo_path = clone_repository(repo_config[\"repo\"])\n\n        # Generate realistic tasks based on repo history\n        tasks = generate_tasks_from_commit_history(repo_path)\n\n        for task in tasks[:10]:  # Test first 10 tasks\n            context = prepare_context(repo_path, task)\n\n            # Validate context quality\n            assert context.relevance_score &gt; 0.85\n            assert context.preparation_time &lt; 5.0\n\n            # Validate agent can work with context\n            agent_result = simulate_agent_execution(context, task)\n            assert agent_result.success_rate &gt; 0.9\n</code></pre></p> <p>Test Case 4.2: Legacy Codebase Challenges <pre><code>def test_legacy_codebase_handling():\n    \"\"\"Test handling of complex legacy codebases\"\"\"\n    legacy_characteristics = [\n        \"minimal_documentation\",\n        \"complex_dependencies\", \n        \"mixed_languages\",\n        \"large_files\",\n        \"deep_inheritance\"\n    ]\n\n    for characteristic in legacy_characteristics:\n        project = generate_legacy_project_with_characteristic(characteristic)\n\n        # Test context preparation for challenging scenarios\n        context = prepare_context(project, complex_task)\n\n        # Validate system handles challenges gracefully\n        assert context is not None\n        assert context.preparation_time &lt; 10.0\n        assert context.error_count == 0\n</code></pre></p>"},{"location":"architecture/context-evaluation-framework/#performance-validation-framework","title":"Performance Validation Framework","text":""},{"location":"architecture/context-evaluation-framework/#automated-performance-testing","title":"Automated Performance Testing","text":""},{"location":"architecture/context-evaluation-framework/#continuous-performance-monitoring","title":"Continuous Performance Monitoring","text":"<pre><code>class PerformanceMonitor:\n    \"\"\"Continuous monitoring of context management performance\"\"\"\n\n    def __init__(self):\n        self.metrics_collector = MetricsCollector()\n        self.alerting = AlertingSystem()\n        self.baseline_metrics = load_baseline_metrics()\n\n    async def monitor_context_preparation(self, request: ContextRequest) -&gt; PerformanceReport:\n        \"\"\"Monitor single context preparation operation\"\"\"\n\n        start_time = time.time()\n        start_memory = psutil.Process().memory_info().rss\n\n        try:\n            context = await prepare_context(request)\n            success = True\n            error = None\n        except Exception as e:\n            success = False\n            error = str(e)\n            context = None\n\n        end_time = time.time()\n        end_memory = psutil.Process().memory_info().rss\n\n        metrics = PerformanceMetrics(\n            preparation_time=end_time - start_time,\n            memory_delta=end_memory - start_memory,\n            success=success,\n            error=error,\n            context_size=len(context.compressed_content) if context else 0,\n            token_count=context.token_usage.total if context else 0\n        )\n\n        # Check against baseline and alert if degraded\n        self.check_performance_regression(metrics)\n\n        return PerformanceReport(metrics, context)\n\n    def check_performance_regression(self, metrics: PerformanceMetrics):\n        \"\"\"Check for performance regression against baseline\"\"\"\n\n        baseline = self.baseline_metrics\n\n        # Check preparation time regression\n        if metrics.preparation_time &gt; baseline.preparation_time * 1.5:\n            self.alerting.send_alert(\n                \"Performance Regression\",\n                f\"Context preparation time: {metrics.preparation_time:.2f}s \"\n                f\"vs baseline {baseline.preparation_time:.2f}s\"\n            )\n\n        # Check memory usage regression\n        if metrics.memory_delta &gt; baseline.memory_delta * 2.0:\n            self.alerting.send_alert(\n                \"Memory Usage Spike\",\n                f\"Memory delta: {metrics.memory_delta / 1024 / 1024:.1f}MB \"\n                f\"vs baseline {baseline.memory_delta / 1024 / 1024:.1f}MB\"\n            )\n</code></pre>"},{"location":"architecture/context-evaluation-framework/#performance-regression-testing","title":"Performance Regression Testing","text":"<pre><code>def test_performance_regression():\n    \"\"\"Comprehensive performance regression test suite\"\"\"\n\n    # Load baseline performance metrics\n    baseline = load_baseline_performance_metrics()\n\n    # Test scenarios\n    test_scenarios = [\n        {\"name\": \"small_project\", \"files\": 100, \"complexity\": \"low\"},\n        {\"name\": \"medium_project\", \"files\": 1000, \"complexity\": \"medium\"},\n        {\"name\": \"large_project\", \"files\": 10000, \"complexity\": \"high\"}\n    ]\n\n    for scenario in test_scenarios:\n        current_metrics = measure_scenario_performance(scenario)\n        baseline_metrics = baseline[scenario[\"name\"]]\n\n        # Validate no significant regression\n        assert_no_regression(current_metrics, baseline_metrics)\n\ndef assert_no_regression(current: PerformanceMetrics, baseline: PerformanceMetrics):\n    \"\"\"Assert no performance regression beyond acceptable thresholds\"\"\"\n\n    # Allow 10% degradation in preparation time\n    assert current.preparation_time &lt;= baseline.preparation_time * 1.1, \\\n        f\"Preparation time regressed: {current.preparation_time:.2f}s vs {baseline.preparation_time:.2f}s\"\n\n    # Allow 20% increase in memory usage\n    assert current.memory_usage &lt;= baseline.memory_usage * 1.2, \\\n        f\"Memory usage regressed: {current.memory_usage:.1f}MB vs {baseline.memory_usage:.1f}MB\"\n\n    # Require same or better relevance score\n    assert current.relevance_score &gt;= baseline.relevance_score, \\\n        f\"Relevance score regressed: {current.relevance_score:.3f} vs {baseline.relevance_score:.3f}\"\n</code></pre>"},{"location":"architecture/context-evaluation-framework/#user-experience-validation","title":"User Experience Validation","text":""},{"location":"architecture/context-evaluation-framework/#agent-effectiveness-measurement","title":"Agent Effectiveness Measurement","text":"<pre><code>class AgentEffectivenessEvaluator:\n    \"\"\"Evaluate how context improvements affect agent performance\"\"\"\n\n    def __init__(self):\n        self.baseline_agent_performance = load_baseline_agent_metrics()\n\n    async def evaluate_agent_performance_improvement(self, agent_type: str, \n                                                   num_tasks: int = 100) -&gt; EffectivenessReport:\n        \"\"\"Evaluate agent performance with new context system vs baseline\"\"\"\n\n        # Generate test tasks\n        test_tasks = generate_test_tasks(agent_type, num_tasks)\n\n        # Test with new context system\n        new_system_results = []\n        for task in test_tasks:\n            context = await prepare_optimized_context(agent_type, task)\n            result = await execute_agent_task(agent_type, task, context)\n            new_system_results.append(result)\n\n        # Test with baseline context system\n        baseline_results = []\n        for task in test_tasks:\n            context = await prepare_baseline_context(agent_type, task)\n            result = await execute_agent_task(agent_type, task, context)\n            baseline_results.append(result)\n\n        # Calculate improvement metrics\n        improvement = calculate_performance_improvement(\n            new_system_results, baseline_results\n        )\n\n        return EffectivenessReport(\n            agent_type=agent_type,\n            improvement_percentage=improvement.percentage,\n            success_rate_improvement=improvement.success_rate,\n            task_completion_time_improvement=improvement.completion_time,\n            context_satisfaction_improvement=improvement.satisfaction\n        )\n\ndef calculate_performance_improvement(new_results: List[TaskResult], \n                                    baseline_results: List[TaskResult]) -&gt; PerformanceImprovement:\n    \"\"\"Calculate performance improvement metrics\"\"\"\n\n    # Success rate improvement\n    new_success_rate = sum(1 for r in new_results if r.success) / len(new_results)\n    baseline_success_rate = sum(1 for r in baseline_results if r.success) / len(baseline_results)\n    success_improvement = new_success_rate - baseline_success_rate\n\n    # Task completion time improvement\n    new_avg_time = sum(r.completion_time for r in new_results) / len(new_results)\n    baseline_avg_time = sum(r.completion_time for r in baseline_results) / len(baseline_results)\n    time_improvement = (baseline_avg_time - new_avg_time) / baseline_avg_time\n\n    # Context satisfaction improvement\n    new_satisfaction = sum(r.context_satisfaction for r in new_results) / len(new_results)\n    baseline_satisfaction = sum(r.context_satisfaction for r in baseline_results) / len(baseline_results)\n    satisfaction_improvement = new_satisfaction - baseline_satisfaction\n\n    overall_improvement = (success_improvement + time_improvement + satisfaction_improvement) / 3\n\n    return PerformanceImprovement(\n        percentage=overall_improvement * 100,\n        success_rate=success_improvement,\n        completion_time=time_improvement,\n        satisfaction=satisfaction_improvement\n    )\n</code></pre>"},{"location":"architecture/context-evaluation-framework/#continuous-improvement-framework","title":"Continuous Improvement Framework","text":""},{"location":"architecture/context-evaluation-framework/#feedback-collection-system","title":"Feedback Collection System","text":""},{"location":"architecture/context-evaluation-framework/#agent-context-feedback","title":"Agent Context Feedback","text":"<pre><code>class ContextFeedbackCollector:\n    \"\"\"Collect feedback from agents about context quality\"\"\"\n\n    def __init__(self):\n        self.feedback_storage = FeedbackStorage()\n        self.analyzer = FeedbackAnalyzer()\n\n    async def collect_agent_feedback(self, agent_type: str, context: AgentContext, \n                                   task_result: TaskResult) -&gt; ContextFeedback:\n        \"\"\"Collect comprehensive feedback about context usefulness\"\"\"\n\n        feedback = ContextFeedback(\n            context_id=context.context_id,\n            agent_type=agent_type,\n            task_success=task_result.success,\n\n            # Relevance feedback\n            relevant_files=task_result.files_actually_used,\n            irrelevant_files=task_result.files_not_used,\n            missing_files=task_result.missing_context_files,\n\n            # Quality feedback\n            context_completeness_score=task_result.context_completeness,\n            context_accuracy_score=task_result.context_accuracy,\n            compression_quality_score=task_result.compression_quality,\n\n            # Performance feedback\n            preparation_time_acceptable=task_result.preparation_time &lt; 3.0,\n            token_usage_efficient=task_result.token_efficiency &gt; 0.8,\n\n            # Improvement suggestions\n            suggested_inclusions=task_result.suggested_additional_files,\n            suggested_exclusions=task_result.suggested_file_removals,\n\n            timestamp=datetime.utcnow()\n        )\n\n        await self.feedback_storage.store_feedback(feedback)\n\n        # Trigger feedback analysis for continuous improvement\n        await self.analyzer.analyze_new_feedback(feedback)\n\n        return feedback\n\n    async def analyze_feedback_patterns(self, time_window_hours: int = 24) -&gt; FeedbackAnalysis:\n        \"\"\"Analyze feedback patterns to identify improvement opportunities\"\"\"\n\n        recent_feedback = await self.feedback_storage.get_recent_feedback(time_window_hours)\n\n        analysis = FeedbackAnalysis(\n            total_feedback_count=len(recent_feedback),\n            average_completeness_score=calculate_average_score(recent_feedback, 'completeness'),\n            average_accuracy_score=calculate_average_score(recent_feedback, 'accuracy'),\n            common_missing_files=identify_commonly_missing_files(recent_feedback),\n            common_irrelevant_files=identify_commonly_irrelevant_files(recent_feedback),\n            improvement_opportunities=identify_improvement_opportunities(recent_feedback)\n        )\n\n        return analysis\n</code></pre>"},{"location":"architecture/context-evaluation-framework/#ab-testing-framework","title":"A/B Testing Framework","text":"<pre><code>class ContextABTester:\n    \"\"\"A/B testing framework for context management strategies\"\"\"\n\n    def __init__(self):\n        self.experiment_config = ExperimentConfig()\n        self.results_analyzer = ABTestAnalyzer()\n\n    async def run_ab_test(self, experiment_name: str, \n                         strategy_a: ContextStrategy,\n                         strategy_b: ContextStrategy,\n                         num_samples: int = 1000) -&gt; ABTestResult:\n        \"\"\"Run A/B test comparing two context strategies\"\"\"\n\n        # Generate test samples\n        test_tasks = generate_test_task_sample(num_samples)\n\n        # Randomly assign tasks to strategies\n        strategy_assignments = randomly_assign_strategies(test_tasks, 0.5)\n\n        # Execute tasks with assigned strategies\n        results_a = []\n        results_b = []\n\n        for task, strategy in strategy_assignments:\n            if strategy == 'A':\n                context = await strategy_a.prepare_context(task)\n                result = await execute_task_with_context(task, context)\n                results_a.append(result)\n            else:\n                context = await strategy_b.prepare_context(task)\n                result = await execute_task_with_context(task, context)\n                results_b.append(result)\n\n        # Analyze results for statistical significance\n        analysis = await self.results_analyzer.analyze_ab_results(results_a, results_b)\n\n        return ABTestResult(\n            experiment_name=experiment_name,\n            strategy_a_performance=calculate_strategy_performance(results_a),\n            strategy_b_performance=calculate_strategy_performance(results_b),\n            statistical_significance=analysis.p_value &lt; 0.05,\n            confidence_interval=analysis.confidence_interval,\n            recommended_strategy=analysis.recommended_strategy,\n            improvement_magnitude=analysis.improvement_percentage\n        )\n</code></pre>"},{"location":"architecture/context-evaluation-framework/#automated-optimization","title":"Automated Optimization","text":""},{"location":"architecture/context-evaluation-framework/#self-tuning-parameters","title":"Self-Tuning Parameters","text":"<pre><code>class ContextSystemAutoTuner:\n    \"\"\"Automatically tune context system parameters based on performance\"\"\"\n\n    def __init__(self):\n        self.parameter_optimizer = BayesianOptimizer()\n        self.performance_tracker = PerformanceTracker()\n\n    async def optimize_relevance_weights(self) -&gt; OptimizationResult:\n        \"\"\"Optimize relevance scoring weights using Bayesian optimization\"\"\"\n\n        # Define parameter space\n        parameter_space = {\n            'direct_mention_weight': (0.2, 0.6),\n            'dependency_weight': (0.1, 0.4),\n            'historical_weight': (0.1, 0.3),\n            'semantic_weight': (0.05, 0.2),\n            'phase_weight': (0.01, 0.1)\n        }\n\n        # Define objective function\n        async def objective_function(params):\n            # Apply parameters to relevance scoring\n            configure_relevance_weights(params)\n\n            # Test performance with new weights\n            test_results = await run_relevance_test_suite()\n\n            # Return optimization target (negative because we minimize)\n            return -test_results.average_relevance_score\n\n        # Run Bayesian optimization\n        optimal_params = await self.parameter_optimizer.optimize(\n            objective_function, parameter_space, num_iterations=50\n        )\n\n        # Validate optimal parameters\n        validation_results = await validate_optimal_parameters(optimal_params)\n\n        return OptimizationResult(\n            optimal_parameters=optimal_params,\n            performance_improvement=validation_results.improvement_percentage,\n            validation_successful=validation_results.validation_passed\n        )\n\n    async def optimize_compression_strategies(self) -&gt; OptimizationResult:\n        \"\"\"Optimize compression strategies for different content types\"\"\"\n\n        content_types = ['python', 'test', 'markdown', 'json']\n        optimization_results = {}\n\n        for content_type in content_types:\n            # Define compression parameter space for this content type\n            param_space = get_compression_parameter_space(content_type)\n\n            # Optimize compression parameters\n            optimal_params = await self.optimize_compression_for_type(\n                content_type, param_space\n            )\n\n            optimization_results[content_type] = optimal_params\n\n        return OptimizationResult(\n            optimal_parameters=optimization_results,\n            performance_improvement=await validate_compression_optimization(optimization_results)\n        )\n</code></pre>"},{"location":"architecture/context-evaluation-framework/#reporting-and-dashboard-framework","title":"Reporting and Dashboard Framework","text":""},{"location":"architecture/context-evaluation-framework/#performance-dashboard","title":"Performance Dashboard","text":"<pre><code>class ContextPerformanceDashboard:\n    \"\"\"Real-time performance dashboard for context management system\"\"\"\n\n    def __init__(self):\n        self.metrics_aggregator = MetricsAggregator()\n        self.visualizer = DashboardVisualizer()\n\n    async def generate_performance_report(self, time_range: str = \"24h\") -&gt; PerformanceReport:\n        \"\"\"Generate comprehensive performance report\"\"\"\n\n        # Collect metrics for time range\n        metrics = await self.metrics_aggregator.aggregate_metrics(time_range)\n\n        report = PerformanceReport(\n            # System Performance\n            average_preparation_time=metrics.avg_preparation_time,\n            p95_preparation_time=metrics.p95_preparation_time,\n            cache_hit_rate=metrics.cache_hit_rate,\n            throughput=metrics.requests_per_second,\n\n            # Quality Metrics\n            average_relevance_score=metrics.avg_relevance_score,\n            context_completeness_rate=metrics.completeness_rate,\n            agent_success_rate=metrics.agent_success_rate,\n\n            # Resource Utilization\n            average_memory_usage=metrics.avg_memory_usage,\n            peak_memory_usage=metrics.peak_memory_usage,\n            cpu_utilization=metrics.avg_cpu_utilization,\n\n            # Trend Analysis\n            performance_trends=self.analyze_performance_trends(metrics),\n            improvement_opportunities=self.identify_improvement_opportunities(metrics),\n\n            # Alerts and Issues\n            active_alerts=self.get_active_performance_alerts(),\n            resolved_issues=self.get_recently_resolved_issues()\n        )\n\n        return report\n\n    def create_real_time_dashboard(self) -&gt; Dashboard:\n        \"\"\"Create real-time monitoring dashboard\"\"\"\n\n        dashboard = Dashboard(\"Context Management Performance\")\n\n        # Key Performance Indicators\n        dashboard.add_widget(KPIWidget(\n            title=\"System Performance\",\n            metrics=[\n                \"Average Preparation Time\",\n                \"Cache Hit Rate\", \n                \"Throughput\",\n                \"System Uptime\"\n            ]\n        ))\n\n        # Quality Metrics\n        dashboard.add_widget(KPIWidget(\n            title=\"Context Quality\",\n            metrics=[\n                \"Relevance Score\",\n                \"Completeness Rate\",\n                \"Agent Success Rate\",\n                \"User Satisfaction\"\n            ]\n        ))\n\n        # Time Series Charts\n        dashboard.add_widget(TimeSeriesChart(\n            title=\"Preparation Time Trend\",\n            metric=\"preparation_time\",\n            time_range=\"24h\"\n        ))\n\n        dashboard.add_widget(TimeSeriesChart(\n            title=\"Cache Performance\",\n            metrics=[\"cache_hit_rate\", \"cache_size\"],\n            time_range=\"24h\"\n        ))\n\n        # Performance Distribution\n        dashboard.add_widget(HistogramWidget(\n            title=\"Preparation Time Distribution\",\n            metric=\"preparation_time\",\n            bins=50\n        ))\n\n        return dashboard\n</code></pre> <p>This comprehensive evaluation framework provides the tools and metrics necessary to validate the Context Management System's effectiveness, monitor its performance in production, and continuously improve its capabilities based on real-world usage patterns and feedback.</p>"},{"location":"architecture/context-implementation-plan/","title":"Context Management System Implementation Plan","text":""},{"location":"architecture/context-implementation-plan/#overview","title":"Overview","text":"<p>This document outlines the detailed implementation plan for the Context Management System, including component development order, integration milestones, testing strategies, and deployment considerations.</p>"},{"location":"architecture/context-implementation-plan/#implementation-phases","title":"Implementation Phases","text":""},{"location":"architecture/context-implementation-plan/#phase-1-core-infrastructure-weeks-1-2","title":"Phase 1: Core Infrastructure (Weeks 1-2)","text":""},{"location":"architecture/context-implementation-plan/#week-1-foundation-components","title":"Week 1: Foundation Components","text":"<p>1.1 Context Manager Core (Days 1-3) - Implement <code>ContextManager</code> class with basic coordination logic - Create <code>ContextRequest</code> and <code>AgentContext</code> data structures - Implement simple context assembly and caching mechanism - Add basic error handling and logging</p> <p>Deliverables: <pre><code>lib/context/\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 manager.py           # ContextManager implementation\n\u251c\u2500\u2500 models.py           # Data structures (ContextRequest, AgentContext)\n\u2514\u2500\u2500 exceptions.py       # Context-specific exceptions\n</code></pre></p> <p>Acceptance Criteria: - [ ] Context manager can prepare basic context from file system - [ ] Basic caching mechanism working - [ ] Error handling for missing files implemented - [ ] Unit tests with &gt;90% coverage</p> <p>1.2 Token Calculator Implementation (Days 4-5) - Implement token estimation algorithms for different content types - Create budget allocation logic with configurable percentages - Add token usage validation and reporting - Implement compression recommendations</p> <p>Deliverables: <pre><code>lib/context/\n\u251c\u2500\u2500 token_calculator.py  # ITokenCalculator implementation\n\u2514\u2500\u2500 token_models.py     # TokenBudget, TokenUsage models\n</code></pre></p> <p>Acceptance Criteria: - [ ] Accurate token estimation within 5% of actual usage - [ ] Dynamic budget allocation based on content availability - [ ] Token usage validation and reporting - [ ] Performance: &lt;100ms for token calculations</p> <p>1.3 Basic Storage and Configuration (Day 6-7) - Implement file-based context storage - Create configuration management for context settings - Add basic context persistence and retrieval - Implement context lifecycle management</p> <p>Deliverables: <pre><code>lib/context/\n\u251c\u2500\u2500 storage.py          # Context storage implementation\n\u251c\u2500\u2500 config.py          # Configuration management\n\u2514\u2500\u2500 lifecycle.py       # Context lifecycle management\n</code></pre></p>"},{"location":"architecture/context-implementation-plan/#week-2-agent-memory-foundation","title":"Week 2: Agent Memory Foundation","text":"<p>2.1 Agent Memory Storage (Days 1-3) - Implement <code>AgentMemory</code> class with JSON persistence - Create decision and artifact storage mechanisms - Add phase handoff tracking - Implement memory retrieval and search</p> <p>Deliverables: <pre><code>lib/context/\n\u251c\u2500\u2500 agent_memory.py     # IAgentMemory implementation\n\u251c\u2500\u2500 memory_models.py    # Decision, PhaseHandoff, AgentMemory models\n\u2514\u2500\u2500 memory_storage.py   # Persistent storage for agent memory\n</code></pre></p> <p>Acceptance Criteria: - [ ] Agent decisions stored with full context - [ ] Artifacts tracked across TDD phases - [ ] Phase handoffs properly recorded - [ ] Memory retrieval within 100ms</p> <p>2.2 Basic File System Interface (Days 4-5) - Implement file discovery and reading mechanisms - Add basic file change detection - Create file metadata extraction - Implement basic dependency detection</p> <p>Deliverables: <pre><code>lib/context/\n\u251c\u2500\u2500 file_system.py      # File system operations\n\u251c\u2500\u2500 file_scanner.py     # File discovery and scanning\n\u2514\u2500\u2500 metadata.py        # File metadata extraction\n</code></pre></p> <p>2.3 Integration Testing (Days 6-7) - Create integration tests for Phase 1 components - Test context manager with real TDD scenarios - Performance testing for basic operations - Documentation for Phase 1 APIs</p> <p>Phase 1 Milestone: - [ ] Basic context preparation working - [ ] Token budget management functional - [ ] Agent memory storage operational - [ ] All unit tests passing - [ ] Integration tests covering basic workflows</p>"},{"location":"architecture/context-implementation-plan/#phase-2-intelligence-layer-weeks-3-4","title":"Phase 2: Intelligence Layer (Weeks 3-4)","text":""},{"location":"architecture/context-implementation-plan/#week-3-context-filtering","title":"Week 3: Context Filtering","text":"<p>3.1 Relevance Scoring Engine (Days 1-3) - Implement relevance scoring algorithms - Create dependency analysis for code files - Add semantic similarity calculations - Implement historical relevance tracking</p> <p>Deliverables: <pre><code>lib/context/\n\u251c\u2500\u2500 filter.py           # IContextFilter implementation\n\u251c\u2500\u2500 relevance.py        # Relevance scoring algorithms\n\u251c\u2500\u2500 dependency.py       # Dependency analysis\n\u2514\u2500\u2500 semantic.py         # Semantic similarity\n</code></pre></p> <p>Acceptance Criteria: - [ ] Relevance scores correlate with actual usage (&gt;80% accuracy) - [ ] Dependency analysis for Python projects working - [ ] Historical relevance tracking functional - [ ] Filter performance: &lt;2 seconds for 1000+ files</p> <p>3.2 Advanced Filtering Strategies (Days 4-5) - Implement TDD phase-specific filtering - Add project structure awareness - Create file type-specific filtering rules - Implement inclusion/exclusion pattern matching</p> <p>3.3 Filter Optimization and Tuning (Days 6-7) - Performance optimization for large codebases - Caching of relevance calculations - Feedback loop for filter improvement - A/B testing framework for filter strategies</p>"},{"location":"architecture/context-implementation-plan/#week-4-context-compression","title":"Week 4: Context Compression","text":"<p>4.1 Basic Compression Implementation (Days 1-3) - Implement Python code compression (AST-based) - Create test file compression preserving assertions - Add documentation compression - Implement JSON/YAML compression</p> <p>Deliverables: <pre><code>lib/context/\n\u251c\u2500\u2500 compressor.py       # IContextCompressor implementation\n\u251c\u2500\u2500 compression/\n\u2502   \u251c\u2500\u2500 python.py      # Python code compression\n\u2502   \u251c\u2500\u2500 test.py        # Test file compression\n\u2502   \u251c\u2500\u2500 docs.py        # Documentation compression\n\u2502   \u2514\u2500\u2500 structured.py  # JSON/YAML compression\n</code></pre></p> <p>Acceptance Criteria: - [ ] 50%+ compression ratio while preserving semantics - [ ] Code structure and critical logic preserved - [ ] Test assertions and test intent preserved - [ ] Compression performance: &lt;1 second per 10KB</p> <p>4.2 Advanced Compression Strategies (Days 4-5) - Implement adaptive compression based on token budget - Create reversible compression for critical files - Add intelligent summarization algorithms - Implement compression quality metrics</p> <p>4.3 Compression Testing and Validation (Days 6-7) - Comprehensive testing on real codebases - Semantic preservation validation - Performance benchmarking - Compression strategy comparison</p> <p>Phase 2 Milestone: - [ ] Intelligent context filtering operational - [ ] Context compression reducing token usage by 50%+ - [ ] Filter accuracy &gt;80% on test scenarios - [ ] Compression maintaining semantic integrity - [ ] Performance targets met for filtering and compression</p>"},{"location":"architecture/context-implementation-plan/#phase-3-advanced-features-weeks-5-6","title":"Phase 3: Advanced Features (Weeks 5-6)","text":""},{"location":"architecture/context-implementation-plan/#week-5-context-indexing","title":"Week 5: Context Indexing","text":"<p>5.1 Context Index Implementation (Days 1-3) - Implement file indexing with symbol extraction - Create searchable index with full-text search - Add dependency graph construction - Implement incremental index updates</p> <p>Deliverables: <pre><code>lib/context/\n\u251c\u2500\u2500 index.py            # IContextIndex implementation\n\u251c\u2500\u2500 indexing/\n\u2502   \u251c\u2500\u2500 symbols.py     # Symbol extraction\n\u2502   \u251c\u2500\u2500 search.py      # Search implementation\n\u2502   \u251c\u2500\u2500 graph.py       # Dependency graph\n\u2502   \u2514\u2500\u2500 incremental.py # Incremental updates\n</code></pre></p> <p>Acceptance Criteria: - [ ] Complete project indexing in &lt;5 minutes for 50k files - [ ] Sub-second search response times - [ ] Accurate dependency graph construction - [ ] Incremental updates working correctly</p> <p>5.2 Advanced Search and Discovery (Days 4-5) - Implement semantic search capabilities - Create query suggestion and auto-completion - Add faceted search with filters - Implement search result ranking</p> <p>5.3 Index Optimization (Days 6-7) - Performance optimization for large indexes - Memory usage optimization - Index persistence and recovery - Distributed indexing preparation</p>"},{"location":"architecture/context-implementation-plan/#week-6-predictive-caching-and-optimization","title":"Week 6: Predictive Caching and Optimization","text":"<p>6.1 Predictive Caching (Days 1-3) - Implement pattern-based context prediction - Create cache warming strategies - Add context pre-computation - Implement intelligent cache eviction</p> <p>Deliverables: <pre><code>lib/context/\n\u251c\u2500\u2500 cache.py            # Advanced caching implementation\n\u251c\u2500\u2500 prediction.py       # Context prediction algorithms\n\u2514\u2500\u2500 precompute.py      # Context pre-computation\n</code></pre></p> <p>6.2 Performance Optimization (Days 4-5) - Profiling and bottleneck identification - Algorithm optimization for core operations - Memory usage optimization - Concurrent processing implementation</p> <p>6.3 Auto-tuning and Adaptation (Days 6-7) - Implement self-tuning parameters - Create feedback-based optimization - Add A/B testing for different strategies - Performance monitoring and alerting</p> <p>Phase 3 Milestone: - [ ] Complete context indexing and search working - [ ] Predictive caching improving response times by 50%+ - [ ] System auto-tuning based on usage patterns - [ ] Performance targets exceeded - [ ] Scalability validated for large projects</p>"},{"location":"architecture/context-implementation-plan/#phase-4-integration-and-deployment-weeks-7-8","title":"Phase 4: Integration and Deployment (Weeks 7-8)","text":""},{"location":"architecture/context-implementation-plan/#week-7-system-integration","title":"Week 7: System Integration","text":"<p>7.1 TDD State Machine Integration (Days 1-2) - Integrate with existing TDD state machine - Implement phase-aware context preparation - Add phase handoff optimization - Test complete TDD workflows</p> <p>7.2 Agent Integration (Days 3-4) - Integrate with all agent types (Design, QA, Code, Data) - Implement agent-specific context optimization - Add context feedback collection from agents - Test agent performance improvements</p> <p>7.3 Claude Code CLI Integration (Days 5-7) - Implement Claude Code prompt optimization - Add token usage monitoring and optimization - Create fallback mechanisms for CLI failures - Test prompt effectiveness and token efficiency</p>"},{"location":"architecture/context-implementation-plan/#week-8-production-readiness","title":"Week 8: Production Readiness","text":"<p>8.1 Error Handling and Recovery (Days 1-2) - Implement comprehensive error recovery - Add graceful degradation mechanisms - Create system health monitoring - Test failure scenarios and recovery</p> <p>8.2 Performance and Scalability Testing (Days 3-4) - Load testing with concurrent TDD cycles - Memory and CPU usage optimization - Large codebase scalability testing - Performance regression testing</p> <p>8.3 Documentation and Deployment (Days 5-7) - Complete API documentation - Create deployment guides - Add monitoring and alerting setup - Prepare production configuration</p> <p>Phase 4 Milestone: - [ ] Complete integration with TDD system - [ ] All agents using optimized context - [ ] Claude Code integration operational - [ ] Production deployment ready - [ ] Comprehensive documentation complete</p>"},{"location":"architecture/context-implementation-plan/#implementation-details","title":"Implementation Details","text":""},{"location":"architecture/context-implementation-plan/#technology-stack","title":"Technology Stack","text":"<p>Core Languages: - Python 3.9+ for all implementation - TypeScript for any web interfaces - Shell scripts for deployment automation</p> <p>Storage Technologies: - SQLite for development and small deployments - PostgreSQL for production deployments - Redis for caching layer - File system for artifact storage</p> <p>Search and Indexing: - Elasticsearch for full-text search (optional) - Custom implementation for basic search - Whoosh for Python-native full-text search</p> <p>Machine Learning: - scikit-learn for basic ML features - sentence-transformers for semantic similarity - spaCy for natural language processing</p>"},{"location":"architecture/context-implementation-plan/#development-environment-setup","title":"Development Environment Setup","text":"<pre><code># Install development dependencies\npip install -r requirements-dev.txt\n\n# Install optional ML dependencies\npip install -r requirements-ml.txt\n\n# Setup development database\npython scripts/setup_dev_db.py\n\n# Run tests\npytest tests/context/\n\n# Start development server\npython -m lib.context.server --dev\n</code></pre>"},{"location":"architecture/context-implementation-plan/#testing-strategy","title":"Testing Strategy","text":""},{"location":"architecture/context-implementation-plan/#unit-testing","title":"Unit Testing","text":"<ul> <li>Each component tested in isolation</li> <li>Mock external dependencies</li> <li>90%+ code coverage required</li> <li>Property-based testing for algorithms</li> </ul>"},{"location":"architecture/context-implementation-plan/#integration-testing","title":"Integration Testing","text":"<ul> <li>Test component interactions</li> <li>Use real file systems and databases</li> <li>Test TDD workflow integration</li> <li>Performance regression testing</li> </ul>"},{"location":"architecture/context-implementation-plan/#performance-testing","title":"Performance Testing","text":"<ul> <li>Load testing with concurrent operations</li> <li>Memory usage profiling</li> <li>Token efficiency validation</li> <li>Scalability testing with large codebases</li> </ul>"},{"location":"architecture/context-implementation-plan/#end-to-end-testing","title":"End-to-End Testing","text":"<ul> <li>Complete TDD cycle execution</li> <li>Real project testing</li> <li>Agent effectiveness measurement</li> <li>User acceptance testing</li> </ul>"},{"location":"architecture/context-implementation-plan/#deployment-strategy","title":"Deployment Strategy","text":""},{"location":"architecture/context-implementation-plan/#development-deployment","title":"Development Deployment","text":"<pre><code># docker-compose.dev.yml\nversion: '3.8'\nservices:\n  context-manager:\n    build: .\n    environment:\n      - ENVIRONMENT=development\n      - DATABASE_URL=sqlite:///dev.db\n    volumes:\n      - ./lib:/app/lib\n      - ./tests:/app/tests\n</code></pre>"},{"location":"architecture/context-implementation-plan/#production-deployment","title":"Production Deployment","text":"<pre><code># docker-compose.prod.yml\nversion: '3.8'\nservices:\n  context-manager:\n    image: agent-workflow/context-manager:latest\n    environment:\n      - ENVIRONMENT=production\n      - DATABASE_URL=postgresql://user:pass@db:5432/context\n    depends_on:\n      - db\n      - redis\n\n  db:\n    image: postgres:13\n    environment:\n      - POSTGRES_DB=context\n      - POSTGRES_USER=user\n      - POSTGRES_PASSWORD=pass\n\n  redis:\n    image: redis:6\n</code></pre>"},{"location":"architecture/context-implementation-plan/#risk-management","title":"Risk Management","text":""},{"location":"architecture/context-implementation-plan/#technical-risks","title":"Technical Risks","text":"<p>Risk: Token estimation accuracy - Impact: High - Affects context quality - Mitigation: Extensive testing with real Claude Code usage - Contingency: Fallback to conservative estimates</p> <p>Risk: Performance degradation with large codebases - Impact: Medium - Affects user experience - Mitigation: Continuous performance testing and optimization - Contingency: Implement project size limits and warnings</p> <p>Risk: Context relevance accuracy - Impact: High - Affects agent effectiveness - Mitigation: Feedback collection and continuous improvement - Contingency: Manual context selection fallback</p>"},{"location":"architecture/context-implementation-plan/#integration-risks","title":"Integration Risks","text":"<p>Risk: Claude Code API changes - Impact: High - Could break integration - Mitigation: Monitor API changes and maintain compatibility - Contingency: Abstract Claude Code interface</p> <p>Risk: TDD state machine changes - Impact: Medium - Could affect context preparation - Mitigation: Loose coupling and interface abstraction - Contingency: Configuration-based adaptation</p>"},{"location":"architecture/context-implementation-plan/#operational-risks","title":"Operational Risks","text":"<p>Risk: Storage scaling issues - Impact: Medium - Could affect performance - Mitigation: Monitoring and auto-scaling - Contingency: Storage cleanup and archiving</p> <p>Risk: Memory leaks in long-running processes - Impact: Medium - Could cause system instability - Mitigation: Memory profiling and testing - Contingency: Process restart mechanisms</p>"},{"location":"architecture/context-implementation-plan/#success-metrics-and-validation","title":"Success Metrics and Validation","text":""},{"location":"architecture/context-implementation-plan/#development-metrics","title":"Development Metrics","text":"<ul> <li> Code coverage &gt;90% for all components</li> <li> Performance targets met for all operations</li> <li> Integration tests passing for all workflows</li> <li> Documentation completeness &gt;95%</li> </ul>"},{"location":"architecture/context-implementation-plan/#system-performance-metrics","title":"System Performance Metrics","text":"<ul> <li> Context preparation time &lt;2 seconds</li> <li> Token utilization &gt;90%</li> <li> Context relevance accuracy &gt;95%</li> <li> Cache hit rate &gt;80%</li> </ul>"},{"location":"architecture/context-implementation-plan/#business-impact-metrics","title":"Business Impact Metrics","text":"<ul> <li> Agent task success rate improvement &gt;10%</li> <li> Developer satisfaction with context quality</li> <li> Reduction in context-related errors</li> <li> System scalability to target project sizes</li> </ul>"},{"location":"architecture/context-implementation-plan/#rollout-plan","title":"Rollout Plan","text":""},{"location":"architecture/context-implementation-plan/#phase-1-rollout-internal-testing","title":"Phase 1 Rollout (Internal Testing)","text":"<ul> <li>Deploy to development environment</li> <li>Test with sample projects</li> <li>Validate basic functionality</li> <li>Collect initial performance metrics</li> </ul>"},{"location":"architecture/context-implementation-plan/#phase-2-rollout-alpha-testing","title":"Phase 2 Rollout (Alpha Testing)","text":"<ul> <li>Deploy to staging environment</li> <li>Test with real projects</li> <li>Limited user group testing</li> <li>Performance optimization based on feedback</li> </ul>"},{"location":"architecture/context-implementation-plan/#phase-3-rollout-beta-testing","title":"Phase 3 Rollout (Beta Testing)","text":"<ul> <li>Deploy to production environment</li> <li>Gradual feature rollout</li> <li>Monitor system performance</li> <li>Collect user feedback</li> </ul>"},{"location":"architecture/context-implementation-plan/#phase-4-rollout-general-availability","title":"Phase 4 Rollout (General Availability)","text":"<ul> <li>Full feature availability</li> <li>Production monitoring and alerting</li> <li>Continuous improvement based on metrics</li> <li>Documentation and training materials</li> </ul> <p>This implementation plan provides a structured approach to building the Context Management System with clear milestones, risk mitigation, and success criteria.</p>"},{"location":"architecture/context-management-system/","title":"Context Management System Design","text":""},{"location":"architecture/context-management-system/#executive-summary","title":"Executive Summary","text":"<p>The Context Management System (CMS) is a foundational component that enables intelligent agent communication, manages Claude Code token limits, and optimizes information flow between agents and the orchestrator. This system addresses the critical challenge of efficiently sharing context across TDD phases while respecting Claude Code's ~200k token limitations.</p>"},{"location":"architecture/context-management-system/#system-overview","title":"System Overview","text":"<p>The CMS acts as an intelligent middleware layer between the orchestrator and individual agents, providing:</p> <ul> <li>Context Filtering: Intelligent selection of relevant files based on current task</li> <li>Token Budget Management: Optimal allocation of context within Claude Code limits  </li> <li>Agent Memory: Persistent storage of agent decisions and artifacts</li> <li>Content Piping: Efficient handoff of work products between TDD phases</li> <li>Context Compression: Intelligent summarization of large codebases</li> </ul>"},{"location":"architecture/context-management-system/#architecture-design","title":"Architecture Design","text":""},{"location":"architecture/context-management-system/#high-level-architecture","title":"High-Level Architecture","text":"<pre><code>graph TB\n    subgraph \"Orchestrator Layer\"\n        O[Orchestrator]\n    end\n\n    subgraph \"Context Management System\"\n        CM[Context Manager]\n        CF[Context Filter]\n        TC[Token Calculator]\n        AM[Agent Memory]\n        CC[Context Compressor]\n        CI[Context Index]\n    end\n\n    subgraph \"Agent Layer\"\n        DA[Design Agent]\n        QA[QA Agent] \n        CA[Code Agent]\n        DTA[Data Agent]\n    end\n\n    subgraph \"Storage Layer\"\n        CS[Context Storage]\n        AC[Artifact Cache]\n        MI[Memory Index]\n        FS[File System]\n    end\n\n    O --&gt; CM\n    CM --&gt; CF\n    CM --&gt; TC\n    CM --&gt; AM\n    CM --&gt; CC\n    CM --&gt; CI\n\n    CM --&gt; DA\n    CM --&gt; QA\n    CM --&gt; CA\n    CM --&gt; DTA\n\n    CM --&gt; CS\n    AM --&gt; AC\n    CI --&gt; MI\n    CS --&gt; FS</code></pre>"},{"location":"architecture/context-management-system/#core-components","title":"Core Components","text":""},{"location":"architecture/context-management-system/#1-context-manager-central-coordinator","title":"1. Context Manager (Central Coordinator)","text":"<p>Responsibilities: - Orchestrate context preparation for agent tasks - Coordinate between filtering, compression, and caching components - Manage context lifecycle and invalidation - Interface with agents and orchestrator</p> <p>Key Methods: <pre><code>async def prepare_context(agent_type: str, task: TDDTask, max_tokens: int) -&gt; AgentContext\nasync def update_context(context_id: str, changes: Dict[str, Any]) -&gt; None  \nasync def invalidate_context(context_id: str) -&gt; None\nasync def get_agent_memory(agent_type: str, story_id: str) -&gt; AgentMemory\n</code></pre></p>"},{"location":"architecture/context-management-system/#2-context-filter-relevance-engine","title":"2. Context Filter (Relevance Engine)","text":"<p>Responsibilities: - Analyze task requirements to determine relevant files - Apply relevance scoring algorithms - Filter out noise while preserving critical dependencies - Handle cross-story context isolation</p> <p>Filtering Strategies: - Direct Relevance: Files explicitly mentioned in task or tests - Dependency Analysis: Static analysis of imports and references - Historical Relevance: Files frequently accessed in similar tasks - Semantic Similarity: Content similarity to current task description - TDD Phase Relevance: Phase-specific context requirements</p>"},{"location":"architecture/context-management-system/#3-token-calculator-budget-manager","title":"3. Token Calculator (Budget Manager)","text":"<p>Responsibilities: - Calculate token usage for context components - Optimize context selection within budget constraints - Provide token usage analytics and warnings - Handle budget allocation across context types</p> <p>Budget Allocation Strategy: <pre><code>Total Budget: ~200k tokens\n- Core Task Context: 40% (80k tokens)\n- Historical Context: 25% (50k tokens)  \n- Dependency Context: 20% (40k tokens)\n- Agent Memory: 10% (20k tokens)\n- Buffer/Metadata: 5% (10k tokens)\n</code></pre></p>"},{"location":"architecture/context-management-system/#4-agent-memory-persistent-context","title":"4. Agent Memory (Persistent Context)","text":"<p>Responsibilities: - Store agent decisions, rationale, and learned patterns - Maintain context across TDD phases and sessions - Track evolution of understanding over time - Provide context inheritance between phases</p> <p>Memory Structure: <pre><code>@dataclass\nclass AgentMemory:\n    agent_type: str\n    story_id: str\n    decisions: List[Decision]\n    artifacts: Dict[str, str]\n    learned_patterns: List[Pattern]\n    context_history: List[ContextSnapshot]\n    phase_handoffs: List[PhaseHandoff]\n</code></pre></p>"},{"location":"architecture/context-management-system/#5-context-compressor-intelligent-summarization","title":"5. Context Compressor (Intelligent Summarization)","text":"<p>Responsibilities: - Compress large files into relevant summaries - Maintain semantic meaning while reducing token count - Apply compression strategies based on content type - Preserve critical information for agent tasks</p> <p>Compression Techniques: - Code Summarization: Extract signatures, docstrings, key logic - Test Summarization: Preserve test intent and assertions - Documentation Compression: Extract key requirements and specs - Git History Compression: Relevant commits and change patterns</p>"},{"location":"architecture/context-management-system/#6-context-index-search-and-discovery","title":"6. Context Index (Search and Discovery)","text":"<p>Responsibilities: - Build searchable indexes of codebase content - Enable fast lookup of relevant code sections - Track file relationships and dependencies - Support semantic search for context discovery</p>"},{"location":"architecture/context-management-system/#data-flow-diagrams","title":"Data Flow Diagrams","text":""},{"location":"architecture/context-management-system/#context-preparation-flow","title":"Context Preparation Flow","text":"<pre><code>sequenceDiagram\n    participant O as Orchestrator\n    participant CM as Context Manager\n    participant CF as Context Filter\n    participant TC as Token Calculator\n    participant CC as Context Compressor\n    participant AM as Agent Memory\n    participant A as Agent\n\n    O-&gt;&gt;CM: prepare_context(agent_type, task, max_tokens)\n    CM-&gt;&gt;CF: filter_relevant_files(task, story_id)\n    CF-&gt;&gt;CM: relevant_files[]\n    CM-&gt;&gt;TC: calculate_token_budget(relevant_files, max_tokens)\n    TC-&gt;&gt;CM: budget_allocation\n    CM-&gt;&gt;CC: compress_if_needed(files, budget)\n    CC-&gt;&gt;CM: compressed_context\n    CM-&gt;&gt;AM: get_agent_memory(agent_type, story_id)\n    AM-&gt;&gt;CM: agent_memory\n    CM-&gt;&gt;CM: assemble_final_context()\n    CM-&gt;&gt;O: agent_context\n    O-&gt;&gt;A: execute_task(context)</code></pre>"},{"location":"architecture/context-management-system/#agent-handoff-flow","title":"Agent Handoff Flow","text":"<pre><code>sequenceDiagram\n    participant DA as Design Agent\n    participant CM as Context Manager\n    participant AM as Agent Memory\n    participant QA as QA Agent\n\n    DA-&gt;&gt;CM: complete_phase(design_artifacts)\n    CM-&gt;&gt;AM: store_artifacts(design_artifacts)\n    AM-&gt;&gt;CM: artifacts_stored\n    CM-&gt;&gt;CM: prepare_handoff_context(DESIGN-&gt;TEST_RED)\n    CM-&gt;&gt;QA: provide_context(design_context + requirements)\n    QA-&gt;&gt;CM: request_additional_context(specific_files)\n    CM-&gt;&gt;QA: filtered_context(specific_files)</code></pre>"},{"location":"architecture/context-management-system/#implementation-strategy","title":"Implementation Strategy","text":""},{"location":"architecture/context-management-system/#phase-1-core-infrastructure-weeks-1-2","title":"Phase 1: Core Infrastructure (Weeks 1-2)","text":"<ol> <li>Context Manager: Central coordination component</li> <li>Basic Token Calculator: Simple token counting and budget allocation</li> <li>File System Interface: Direct file access and basic caching</li> <li>Agent Memory Storage: Simple JSON-based persistence</li> </ol>"},{"location":"architecture/context-management-system/#phase-2-intelligence-layer-weeks-3-4","title":"Phase 2: Intelligence Layer (Weeks 3-4)","text":"<ol> <li>Context Filter: Relevance scoring and file filtering</li> <li>Context Compressor: Basic summarization for code and docs</li> <li>Context Index: File relationship mapping and search</li> <li>Agent Memory Intelligence: Pattern recognition and learning</li> </ol>"},{"location":"architecture/context-management-system/#phase-3-optimization-weeks-5-6","title":"Phase 3: Optimization (Weeks 5-6)","text":"<ol> <li>Advanced Compression: ML-based summarization</li> <li>Predictive Caching: Anticipate context needs</li> <li>Performance Optimization: Caching strategies and performance tuning</li> <li>Cross-Story Context: Handle multiple concurrent stories</li> </ol>"},{"location":"architecture/context-management-system/#phase-4-advanced-features-weeks-7-8","title":"Phase 4: Advanced Features (Weeks 7-8)","text":"<ol> <li>Semantic Search: Content-based context discovery</li> <li>Auto-tuning: Dynamic optimization based on usage patterns</li> <li>Integration Testing: End-to-end TDD workflow validation</li> <li>Documentation and Training: Complete system documentation</li> </ol>"},{"location":"architecture/context-management-system/#algorithm-designs","title":"Algorithm Designs","text":""},{"location":"architecture/context-management-system/#relevance-scoring-algorithm","title":"Relevance Scoring Algorithm","text":"<pre><code>def calculate_relevance_score(file_path: str, task: TDDTask, story_context: Dict) -&gt; float:\n    \"\"\"Calculate relevance score (0-1) for a file given current task\"\"\"\n    score = 0.0\n\n    # Direct mention in task (40% weight)\n    if file_mentioned_in_task(file_path, task):\n        score += 0.4\n\n    # Dependency analysis (25% weight)  \n    dependency_score = analyze_dependencies(file_path, task.source_files)\n    score += 0.25 * dependency_score\n\n    # Historical relevance (20% weight)\n    historical_score = get_historical_relevance(file_path, task.agent_type)\n    score += 0.20 * historical_score\n\n    # Semantic similarity (10% weight)\n    semantic_score = calculate_semantic_similarity(file_path, task.description)\n    score += 0.10 * semantic_score\n\n    # TDD phase relevance (5% weight)\n    phase_score = get_phase_relevance(file_path, task.current_state)\n    score += 0.05 * phase_score\n\n    return min(1.0, score)\n</code></pre>"},{"location":"architecture/context-management-system/#context-compression-algorithm","title":"Context Compression Algorithm","text":"<pre><code>def compress_file_content(content: str, target_tokens: int, file_type: str) -&gt; str:\n    \"\"\"Compress file content to target token count while preserving meaning\"\"\"\n\n    if file_type == \"python\":\n        return compress_python_code(content, target_tokens)\n    elif file_type == \"test\":\n        return compress_test_file(content, target_tokens)\n    elif file_type == \"markdown\":\n        return compress_documentation(content, target_tokens)\n    else:\n        return compress_generic_text(content, target_tokens)\n\ndef compress_python_code(content: str, target_tokens: int) -&gt; str:\n    \"\"\"Python-specific compression preserving structure and key logic\"\"\"\n    ast_tree = ast.parse(content)\n\n    # Extract critical elements\n    imports = extract_imports(ast_tree)\n    class_signatures = extract_class_signatures(ast_tree)\n    method_signatures = extract_method_signatures(ast_tree)\n    key_logic = extract_key_logic_blocks(ast_tree)\n\n    # Reconstruct with compression\n    compressed = rebuild_compressed_code(\n        imports, class_signatures, method_signatures, key_logic, target_tokens\n    )\n\n    return compressed\n</code></pre>"},{"location":"architecture/context-management-system/#token-budget-allocation-algorithm","title":"Token Budget Allocation Algorithm","text":"<pre><code>def allocate_token_budget(total_budget: int, context_components: Dict) -&gt; Dict[str, int]:\n    \"\"\"Dynamically allocate token budget based on task priority and available content\"\"\"\n\n    allocation = {}\n\n    # Base allocation percentages\n    base_allocations = {\n        \"core_task\": 0.40,\n        \"historical\": 0.25, \n        \"dependencies\": 0.20,\n        \"agent_memory\": 0.10,\n        \"buffer\": 0.05\n    }\n\n    # Adjust based on context availability\n    for component, base_pct in base_allocations.items():\n        available_content = context_components.get(component, {})\n\n        if not available_content:\n            # Redistribute unused allocation\n            base_allocations = redistribute_unused_allocation(base_allocations, component)\n        else:\n            # Calculate actual need vs available content\n            content_size = estimate_token_size(available_content)\n            base_allocation = int(total_budget * base_pct)\n\n            # Don't over-allocate if content is smaller than allocation\n            allocation[component] = min(base_allocation, content_size)\n\n    return allocation\n</code></pre>"},{"location":"architecture/context-management-system/#performance-requirements","title":"Performance Requirements","text":""},{"location":"architecture/context-management-system/#latency-targets","title":"Latency Targets","text":"<ul> <li>Context Preparation: &lt; 2 seconds for typical tasks</li> <li>Agent Handoff: &lt; 1 second for artifact transfer</li> <li>Context Invalidation: &lt; 500ms for cache updates</li> <li>Memory Retrieval: &lt; 100ms for agent memory access</li> </ul>"},{"location":"architecture/context-management-system/#throughput-targets","title":"Throughput Targets","text":"<ul> <li>Concurrent Contexts: Support 10+ parallel TDD cycles</li> <li>File Processing: 1000+ files/second for relevance scoring</li> <li>Compression: 100KB/second sustained compression rate</li> <li>Cache Hit Rate: &gt;80% for repeated context requests</li> </ul>"},{"location":"architecture/context-management-system/#scalability-targets","title":"Scalability Targets","text":"<ul> <li>Codebase Size: Support projects with 100k+ lines of code</li> <li>Context History: 1000+ context snapshots per story</li> <li>Agent Memory: 10MB+ per agent across all stories</li> <li>File Index: 50k+ files with sub-second search</li> </ul>"},{"location":"architecture/context-management-system/#error-handling-strategy","title":"Error Handling Strategy","text":""},{"location":"architecture/context-management-system/#graceful-degradation","title":"Graceful Degradation","text":"<ol> <li>Token Limit Exceeded: Automatic compression and pruning</li> <li>Context Service Unavailable: Fall back to basic file access</li> <li>Memory Corruption: Rebuild from artifacts and git history</li> <li>Index Corruption: Rebuild from filesystem scan</li> </ol>"},{"location":"architecture/context-management-system/#recovery-mechanisms","title":"Recovery Mechanisms","text":"<ol> <li>Context Snapshots: Regular snapshots for quick recovery</li> <li>Incremental Rebuilds: Rebuild only affected components</li> <li>Fallback Modes: Progressively simpler context provision</li> <li>Health Monitoring: Continuous monitoring with automatic recovery</li> </ol>"},{"location":"architecture/context-management-system/#evaluation-framework","title":"Evaluation Framework","text":""},{"location":"architecture/context-management-system/#success-metrics","title":"Success Metrics","text":""},{"location":"architecture/context-management-system/#efficiency-metrics","title":"Efficiency Metrics","text":"<ul> <li>Context Relevance: &gt;95% of provided context is used by agents</li> <li>Token Utilization: &gt;90% of allocated tokens are effectively used</li> <li>Redundancy Reduction: &lt;5% duplicate information in context</li> <li>Preparation Speed: Context preparation within latency targets</li> </ul>"},{"location":"architecture/context-management-system/#quality-metrics","title":"Quality Metrics","text":"<ul> <li>Agent Task Success: &gt;95% agent task completion rate</li> <li>Context Completeness: &lt;2% missing critical information</li> <li>Cross-Phase Continuity: &gt;98% successful phase handoffs</li> <li>Memory Accuracy: &gt;95% accurate agent memory retrieval</li> </ul>"},{"location":"architecture/context-management-system/#performance-metrics","title":"Performance Metrics","text":"<ul> <li>System Throughput: Support target concurrent operations</li> <li>Resource Utilization: &lt;70% CPU and memory usage</li> <li>Cache Effectiveness: &gt;80% cache hit rate</li> <li>Scalability: Linear performance degradation with codebase size</li> </ul>"},{"location":"architecture/context-management-system/#benchmarking-strategy","title":"Benchmarking Strategy","text":""},{"location":"architecture/context-management-system/#synthetic-benchmarks","title":"Synthetic Benchmarks","text":"<ul> <li>Token Budget Stress Tests: Extreme token limit scenarios</li> <li>Large Codebase Tests: 100k+ file repositories</li> <li>Concurrent Load Tests: Multiple parallel TDD cycles</li> <li>Memory Pressure Tests: Limited system memory scenarios</li> </ul>"},{"location":"architecture/context-management-system/#real-world-benchmarks","title":"Real-World Benchmarks","text":"<ul> <li>Open Source Projects: Test on popular GitHub repositories</li> <li>Legacy Codebase: Test on complex, undocumented codebases</li> <li>Multi-Language: Test cross-language context management</li> <li>Long-Running Sessions: Extended TDD sessions over days</li> </ul>"},{"location":"architecture/context-management-system/#integration-points","title":"Integration Points","text":""},{"location":"architecture/context-management-system/#claude-code-cli-integration","title":"Claude Code CLI Integration","text":"<pre><code>class ClaudeCodeContextProvider:\n    \"\"\"Integration with Claude Code CLI for optimized prompts\"\"\"\n\n    async def prepare_claude_prompt(self, context: AgentContext) -&gt; str:\n        \"\"\"Prepare optimized prompt for Claude Code CLI\"\"\"\n        prompt_parts = []\n\n        # Add core context with highest priority\n        prompt_parts.append(f\"## Core Task Context\\n{context.core_context}\")\n\n        # Add compressed dependencies \n        if context.dependencies:\n            prompt_parts.append(f\"## Dependencies\\n{context.dependencies}\")\n\n        # Add agent memory if relevant\n        if context.agent_memory:\n            prompt_parts.append(f\"## Previous Decisions\\n{context.agent_memory}\")\n\n        # Add specific instructions based on TDD phase\n        phase_instructions = get_phase_specific_instructions(context.tdd_phase)\n        prompt_parts.append(f\"## Phase Instructions\\n{phase_instructions}\")\n\n        return \"\\n\\n\".join(prompt_parts)\n</code></pre>"},{"location":"architecture/context-management-system/#tdd-state-machine-integration","title":"TDD State Machine Integration","text":"<pre><code>class TDDContextManager:\n    \"\"\"Integration with TDD state machine for phase-aware context\"\"\"\n\n    def get_phase_context_requirements(self, phase: TDDState) -&gt; Dict[str, Any]:\n        \"\"\"Get context requirements specific to TDD phase\"\"\"\n        requirements = {\n            TDDState.DESIGN: {\n                \"focus\": [\"requirements\", \"architecture\", \"existing_patterns\"],\n                \"exclude\": [\"implementation_details\", \"test_specifics\"],\n                \"compression_level\": \"moderate\"\n            },\n            TDDState.TEST_RED: {\n                \"focus\": [\"design_specs\", \"acceptance_criteria\", \"existing_tests\"],\n                \"exclude\": [\"implementation_files\"],\n                \"compression_level\": \"low\"\n            },\n            TDDState.CODE_GREEN: {\n                \"focus\": [\"failing_tests\", \"minimal_examples\", \"interfaces\"],\n                \"exclude\": [\"refactoring_notes\", \"performance_docs\"],\n                \"compression_level\": \"moderate\"\n            },\n            TDDState.REFACTOR: {\n                \"focus\": [\"current_implementation\", \"quality_patterns\", \"best_practices\"],\n                \"exclude\": [\"test_files\"],\n                \"compression_level\": \"high\"\n            },\n            TDDState.COMMIT: {\n                \"focus\": [\"all_changes\", \"commit_history\", \"integration_tests\"],\n                \"exclude\": [\"draft_files\"],\n                \"compression_level\": \"low\"\n            }\n        }\n        return requirements.get(phase, {})\n</code></pre>"},{"location":"architecture/context-management-system/#future-enhancements","title":"Future Enhancements","text":""},{"location":"architecture/context-management-system/#machine-learning-integration","title":"Machine Learning Integration","text":"<ul> <li>Context Relevance ML: Train models on agent context usage patterns</li> <li>Compression Optimization: ML-powered compression for better semantic preservation</li> <li>Predictive Caching: Predict future context needs based on TDD patterns</li> <li>Agent Behavior Learning: Learn optimal context for each agent type</li> </ul>"},{"location":"architecture/context-management-system/#advanced-features","title":"Advanced Features","text":"<ul> <li>Multi-Project Context: Share learnings across related projects</li> <li>Team Context Sharing: Share context insights across team members</li> <li>Real-time Collaboration: Support concurrent agent operations</li> <li>Version-Aware Context: Context management across git branches</li> </ul>"},{"location":"architecture/context-management-system/#performance-optimizations","title":"Performance Optimizations","text":"<ul> <li>Distributed Context: Distribute context processing across nodes</li> <li>Streaming Context: Stream large contexts to agents incrementally</li> <li>Edge Caching: Cache contexts at network edges for global teams</li> <li>Hardware Acceleration: GPU acceleration for large-scale compression</li> </ul> <p>This Context Management System design provides the foundation for efficient agent communication while respecting Claude Code's token limitations. The system is designed to be extensible, performant, and maintainable while providing the intelligent context filtering necessary for effective TDD workflow execution.</p>"},{"location":"architecture/overview/","title":"Architecture Overview","text":"<p>The AI Agent TDD-Scrum Workflow system implements a sophisticated multi-layered architecture that coordinates Test-Driven Development (TDD) cycles within a broader Scrum workflow management framework. The system supports both single-project workflows and advanced multi-project orchestration with intelligent resource allocation, context management, and cross-project intelligence.</p>"},{"location":"architecture/overview/#system-architecture-layers","title":"System Architecture Layers","text":""},{"location":"architecture/overview/#1-multi-project-orchestration-layer","title":"1. Multi-Project Orchestration Layer","text":"<p>The top-level orchestration system manages multiple projects simultaneously:</p> <pre><code>graph TB\n    subgraph \"\ud83c\udf10 Multi-Project Orchestration\"\n        MPO[Multi-Project Orchestrator]\n        GOS[Global Orchestrator]\n        RES[Resource Scheduler]\n        SEC[Security System]\n        MON[Monitoring System]\n        INT[Intelligence System]\n    end\n\n    subgraph \"\ud83d\udcca Context Management\"\n        CM[Context Manager]\n        TC[Token Calculator]\n        AM[Agent Memory]\n        CC[Context Cache]\n    end\n\n    subgraph \"\ud83c\udfaf Project A\"\n        PA_WSM[Workflow State Machine A]\n        PA_TDD[TDD State Machines A]\n        PA_AGENTS[Agent Pool A]\n    end\n\n    subgraph \"\ud83c\udfaf Project B\" \n        PB_WSM[Workflow State Machine B]\n        PB_TDD[TDD State Machines B]\n        PB_AGENTS[Agent Pool B]\n    end\n\n    MPO --&gt; GOS\n    MPO --&gt; RES\n    MPO --&gt; SEC\n    MPO --&gt; MON\n    MPO --&gt; INT\n\n    GOS --&gt; PA_WSM\n    GOS --&gt; PB_WSM\n\n    CM --&gt; PA_AGENTS\n    CM --&gt; PB_AGENTS\n\n    PA_WSM --&gt; PA_TDD\n    PB_WSM --&gt; PB_TDD\n\n    RES --&gt; PA_AGENTS\n    RES --&gt; PB_AGENTS\n\n    style MPO fill:#ff6b6b,stroke:#c92a2a,stroke-width:3px\n    style CM fill:#4dabf7,stroke:#1971c2,stroke-width:3px</code></pre>"},{"location":"architecture/overview/#2-context-management-layer","title":"2. Context Management Layer","text":"<p>Intelligent context sharing and memory management across agents:</p> <ul> <li>Context Manager: Optimizes agent communication and context sharing</li> <li>Token Calculator: Manages context size and token usage optimization</li> <li>Agent Memory: Persistent memory across agent interactions</li> <li>Context Cache: Efficient caching of frequently used context data</li> </ul>"},{"location":"architecture/overview/#3-project-coordination-layer","title":"3. Project Coordination Layer","text":"<p>Individual project management with dual state machines:</p> <ul> <li>Workflow State Machine: High-level Scrum process coordination</li> <li>TDD State Machines: Parallel story-level TDD cycle management</li> <li>Agent Pools: Project-specific ephemeral agent management</li> </ul>"},{"location":"architecture/overview/#dual-state-machine-architecture","title":"Dual State Machine Architecture","text":"<p>The system operates two parallel state machines that work in coordination:</p>"},{"location":"architecture/overview/#1-workflow-state-machine-primary","title":"1. Workflow State Machine (Primary)","text":"<p>Manages the high-level Scrum development lifecycle: - IDLE \u2192 BACKLOG_READY \u2192 SPRINT_PLANNED \u2192 SPRINT_ACTIVE \u2192 SPRINT_REVIEW - Handles epic creation, sprint planning, and project coordination - Enforces proper development sequences and human approval gates - Persists project management data across sprint cycles</p>"},{"location":"architecture/overview/#2-tdd-state-machine-secondary","title":"2. TDD State Machine (Secondary)","text":"<p>Manages individual story implementation through proper TDD cycles: - DESIGN \u2192 TEST_RED \u2192 CODE_GREEN \u2192 REFACTOR \u2192 COMMIT - Activated when the primary state machine enters SPRINT_ACTIVE - Runs in parallel for each story in the active sprint - Ensures proper RED-GREEN-REFACTOR TDD methodology</p>"},{"location":"architecture/overview/#architecture-diagram","title":"Architecture Diagram","text":"<pre><code>graph TB\n    subgraph \"\ud83d\udc64 Solo Engineer\"\n        User[User]\n    end\n\n    subgraph DISCORD [\"\ud83c\udfae Discord Interface\"]\n        Discord[\"/epic /sprint /tdd&lt;br/&gt;Slash Commands\"]\n        State[Interactive State&lt;br/&gt;Visualization]\n    end\n\n    subgraph WORKFLOW [\"\ud83e\udd16 Dual State Machine System\"]\n        subgraph \"\ud83c\udf9b\ufe0f Primary Control Layer\"\n            WSM[Workflow State Machine&lt;br/&gt;IDLE - BACKLOG - SPRINT]\n            HITL[Approval Gates&lt;br/&gt;Strategic Decisions]\n            PM[Persistent Storage&lt;br/&gt;Epics - Stories - Tasks]\n        end\n\n        subgraph \"\ud83c\udfad Ephemeral Orchestration\"\n            Orch[\ud83c\udfad Orchestrator Agent&lt;br/&gt;Scrum Master&lt;br/&gt;spun up on demand]\n            Coord[\ud83c\udfaf Multi-Task Coordinator&lt;br/&gt;Parallel Story Execution]\n        end\n\n        subgraph \"\ud83d\udd04 TDD Execution Layer\"\n            subgraph \"Story A TDD Cycle\"\n                TDD_A[TDD State Machine A&lt;br/&gt;DESIGN - TEST - CODE - REFACTOR]\n                Design_A[\ud83c\udfa8 Design Agent A]\n                QA_A[\ud83e\uddea Test Agent A]\n                Code_A[\ud83d\udcbb Code Agent A]\n            end\n\n            subgraph \"Story B TDD Cycle\"\n                TDD_B[TDD State Machine B&lt;br/&gt;DESIGN - TEST - CODE - REFACTOR]\n                Design_B[\ud83c\udfa8 Design Agent B]\n                QA_B[\ud83e\uddea Test Agent B]\n                Code_B[\ud83d\udcbb Code Agent B]\n            end\n\n            Data[\ud83d\udcca Analytics Agent&lt;br/&gt;Cross-Story Metrics]\n        end\n    end\n\n    subgraph PROJECT [\"\ud83d\udcbe Your Project\"]\n        Tests[\ud83e\uddea Test Suite&lt;br/&gt;RED - GREEN - REFACTOR]\n        Repo[\ud83d\udcc1 Git Repository&lt;br/&gt;Code &amp; Documentation]\n        State_Dir[\ud83d\udcc2 .orch-state/&lt;br/&gt;Sprint &amp; TDD State]\n    end\n\n    User --&gt;|\"Commands\"| Discord\n    Discord &lt;--&gt;|\"Validates\"| WSM\n    Discord --&gt;|\"Updates\"| State\n    State --&gt;|\"Progress\"| User\n\n    WSM --&gt;|\"Spins up\"| Orch\n    Orch --&gt;|\"Coordinates\"| Coord\n    WSM &lt;--&gt;|\"Enforces\"| HITL\n    WSM &lt;--&gt;|\"Reads/Writes\"| PM\n\n    Coord --&gt;|\"Assigns Stories\"| TDD_A\n    Coord --&gt;|\"Assigns Stories\"| TDD_B\n\n    TDD_A --&gt;|\"1 Design\"| Design_A\n    TDD_A --&gt;|\"2 Test\"| QA_A\n    TDD_A --&gt;|\"3 Code\"| Code_A\n\n    TDD_B --&gt;|\"1 Design\"| Design_B\n    TDD_B --&gt;|\"2 Test\"| QA_B\n    TDD_B --&gt;|\"3 Code\"| Code_B\n\n    Design_A --&gt;|\"Specs\"| Tests\n    QA_A --&gt;|\"Tests\"| Tests\n    Code_A --&gt;|\"Implementation\"| Tests\n\n    Design_B --&gt;|\"Specs\"| Tests\n    QA_B --&gt;|\"Tests\"| Tests\n    Code_B --&gt;|\"Implementation\"| Tests\n\n    Data --&gt;|\"Metrics\"| State_Dir\n    TDD_A --&gt;|\"Story State\"| State_Dir\n    TDD_B --&gt;|\"Story State\"| State_Dir\n\n    Tests --&gt;|\"Validates\"| Repo\n    Code_A --&gt;|\"Commits\"| Repo\n    Code_B --&gt;|\"Commits\"| Repo\n\n    HITL &lt;--&gt;|\"Approvals\"| Discord\n\n    style User fill:#e1f5fe,stroke:#0277bd,stroke-width:3px\n    style DISCORD fill:#f8f4ff,stroke:#7b1fa2,stroke-width:3px\n    style WORKFLOW fill:#f0f8f0,stroke:#388e3c,stroke-width:3px\n    style PROJECT fill:#fff8e1,stroke:#f57c00,stroke-width:3px\n    style WSM fill:#ff6b6b,stroke:#c92a2a,stroke-width:3px\n    style TDD_A fill:#4dabf7,stroke:#1971c2,stroke-width:3px\n    style TDD_B fill:#4dabf7,stroke:#1971c2,stroke-width:3px\n    style Coord fill:#ffd43b,stroke:#fab005,stroke-width:3px</code></pre>"},{"location":"architecture/overview/#ephemeral-agent-pattern","title":"Ephemeral Agent Pattern","text":""},{"location":"architecture/overview/#on-demand-orchestration","title":"On-Demand Orchestration","text":"<ul> <li>Orchestrator Agent: Spun up when entering SPRINT_ACTIVE state</li> <li>Multi-Task Coordination: Manages parallel TDD cycles for multiple stories</li> <li>Resource Optimization: Agents created and destroyed based on workload</li> <li>State Isolation: Each TDD cycle operates independently with shared coordination</li> </ul>"},{"location":"architecture/overview/#agent-lifecycle","title":"Agent Lifecycle","text":"<ol> <li>Workflow State Transition: Primary state machine triggers agent creation</li> <li>Story Assignment: Coordinator assigns stories to TDD state machines</li> <li>Parallel Execution: Multiple TDD cycles run simultaneously</li> <li>Coordination: Shared analytics and progress reporting</li> <li>Cleanup: Agents destroyed when stories complete or sprint ends</li> </ol>"},{"location":"architecture/overview/#tdd-state-machine-lifecycle","title":"TDD State Machine Lifecycle","text":"<p>Each story follows a strict TDD methodology enforced by the secondary state machine:</p>"},{"location":"architecture/overview/#1-design-phase","title":"1. DESIGN Phase","text":"<ul> <li>Design Agent creates technical specifications</li> <li>Defines interfaces, data structures, and architecture</li> <li>Outputs design documents and acceptance criteria</li> <li>Transition: Automatic to TEST_RED when design approved</li> </ul>"},{"location":"architecture/overview/#2-test_red-phase","title":"2. TEST_RED Phase","text":"<ul> <li>QA Agent writes failing tests based on design specs</li> <li>Implements unit tests, integration tests, and acceptance tests</li> <li>Ensures tests fail appropriately (RED state)</li> <li>Transition: Automatic to CODE_GREEN when tests written and failing</li> </ul>"},{"location":"architecture/overview/#3-code_green-phase","title":"3. CODE_GREEN Phase","text":"<ul> <li>Code Agent implements minimal code to make tests pass</li> <li>Focuses on making tests green without over-engineering</li> <li>Validates implementation against test suite</li> <li>Transition: Automatic to REFACTOR when all tests pass</li> </ul>"},{"location":"architecture/overview/#4-refactor-phase","title":"4. REFACTOR Phase","text":"<ul> <li>Code Agent improves code quality while maintaining green tests</li> <li>Applies design patterns, removes duplication, improves readability</li> <li>Ensures tests remain green throughout refactoring</li> <li>Transition: Manual approval or automatic after quality gates</li> </ul>"},{"location":"architecture/overview/#5-commit-phase","title":"5. COMMIT Phase","text":"<ul> <li>Code Agent commits changes to version control</li> <li>Updates documentation and changelog</li> <li>Triggers CI/CD pipeline for validation</li> <li>Transition: Story marked complete, returns to coordinator</li> </ul>"},{"location":"architecture/overview/#state-machine-interactions","title":"State Machine Interactions","text":""},{"location":"architecture/overview/#primary-secondary-activation","title":"Primary \u2192 Secondary Activation","text":"<pre><code>sequenceDiagram\n    participant WSM as Workflow State Machine\n    participant Coord as Multi-Task Coordinator\n    participant TDD as TDD State Machine\n    participant Agents as TDD Agents\n\n    WSM-&gt;&gt;Coord: SPRINT_ACTIVE triggered\n    Coord-&gt;&gt;TDD: Create TDD instance for Story A\n    Coord-&gt;&gt;TDD: Create TDD instance for Story B\n    TDD-&gt;&gt;Agents: Spawn Design/QA/Code agents\n    Agents-&gt;&gt;TDD: Report progress\n    TDD-&gt;&gt;Coord: Story completion status\n    Coord-&gt;&gt;WSM: Sprint progress update</code></pre>"},{"location":"architecture/overview/#parallel-story-execution","title":"Parallel Story Execution","text":"<pre><code>gantt\n    title Parallel TDD Cycles in Active Sprint\n    dateFormat X\n    axisFormat %d\n\n    section Story A TDD\n    Design A     :done, design_a, 0, 1\n    Test RED A   :done, red_a, after design_a, 2\n    Code GREEN A :active, green_a, after red_a, 3\n    Refactor A   :refactor_a, after green_a, 1\n    Commit A     :commit_a, after refactor_a, 1\n\n    section Story B TDD\n    Design B     :done, design_b, 0, 1\n    Test RED B   :done, red_b, after design_b, 2\n    Code GREEN B :done, green_b, after red_b, 3\n    Refactor B   :active, refactor_b, after green_b, 1\n    Commit B     :commit_b, after refactor_b, 1\n\n    section Coordination\n    Analytics    :analytics, 2, 6\n    Progress     :progress, 1, 7</code></pre>"},{"location":"architecture/overview/#key-architectural-principles","title":"Key Architectural Principles","text":""},{"location":"architecture/overview/#1-separation-of-concerns","title":"1. Separation of Concerns","text":"<ul> <li>Workflow Management: High-level project coordination and human interaction</li> <li>TDD Implementation: Technical development methodology enforcement</li> <li>State Persistence: Project data versioned with code, runtime state isolated</li> </ul>"},{"location":"architecture/overview/#2-human-in-the-loop-integration","title":"2. Human-In-The-Loop Integration","text":"<ul> <li>Strategic Approval: Workflow state machine requires human approval for major decisions</li> <li>TDD Oversight: Optional human intervention at any TDD phase</li> <li>Error Escalation: Automatic escalation to humans after failed automation attempts</li> </ul>"},{"location":"architecture/overview/#3-parallel-processing","title":"3. Parallel Processing","text":"<ul> <li>Multi-Story Execution: Independent TDD cycles for parallel development</li> <li>Resource Optimization: Agents created/destroyed based on workload</li> <li>Shared Analytics: Cross-story metrics and progress reporting</li> </ul>"},{"location":"architecture/overview/#4-state-isolation-and-recovery","title":"4. State Isolation and Recovery","text":"<ul> <li>Independent Cycles: TDD state machines operate independently</li> <li>Failure Isolation: Failed story doesn't impact other parallel stories</li> <li>State Recovery: System can resume from any state after interruption</li> </ul>"},{"location":"architecture/overview/#security-and-tool-access","title":"Security and Tool Access","text":""},{"location":"architecture/overview/#agent-security-profiles","title":"Agent Security Profiles","text":"<p>Each agent type has restricted tool access based on their role in the TDD cycle:</p> <ul> <li>Orchestrator Agent: Full system access for coordination</li> <li>Design Agent: Read-only access for architecture and documentation</li> <li>QA Agent: Test execution and quality analysis tools only</li> <li>Code Agent: Code editing, compilation, and version control</li> <li>Analytics Agent: Data analysis and reporting tools only</li> </ul>"},{"location":"architecture/overview/#security-boundaries","title":"Security Boundaries","text":"<ul> <li>Process Isolation: Each TDD cycle runs in isolated environment</li> <li>Tool Restrictions: Agents cannot access tools outside their domain</li> <li>Audit Trail: All agent actions logged for security and debugging</li> <li>Human Oversight: Security-critical operations require human approval</li> </ul>"},{"location":"architecture/overview/#data-flow-and-persistence","title":"Data Flow and Persistence","text":""},{"location":"architecture/overview/#persistent-data-orch-state","title":"Persistent Data (.orch-state/)","text":"<ul> <li>Sprint Plans: Active and historical sprint configurations</li> <li>Story Status: Current state of each TDD cycle</li> <li>Analytics Data: Metrics, coverage, and performance data</li> <li>Error Logs: Failed attempts and recovery information</li> </ul>"},{"location":"architecture/overview/#runtime-state","title":"Runtime State","text":"<ul> <li>State Machine Status: Current states of both state machines</li> <li>Agent Registry: Active agents and their assignments</li> <li>Coordination Data: Inter-story dependencies and shared resources</li> <li>Progress Tracking: Real-time status for Discord interface</li> </ul> <p>This dual state machine architecture provides a robust foundation for AI-assisted development that maintains proper TDD methodology while enabling parallel processing and human oversight of the overall development workflow.</p>"},{"location":"architecture/parallel-agent-pool-management/","title":"Parallel Agent Pool Management and Resource Allocation","text":""},{"location":"architecture/parallel-agent-pool-management/#executive-summary","title":"Executive Summary","text":"<p>This document specifies the agent pool management and resource allocation system for parallel TDD execution. The system provides dynamic scaling, intelligent load balancing, and optimal resource utilization across concurrent TDD cycles while maintaining agent security boundaries and quality standards.</p>"},{"location":"architecture/parallel-agent-pool-management/#agent-pool-architecture","title":"Agent Pool Architecture","text":""},{"location":"architecture/parallel-agent-pool-management/#1-multi-tier-pool-structure","title":"1. Multi-Tier Pool Structure","text":"<pre><code>class AgentPoolManager:\n    \"\"\"Central manager for all agent pools with sophisticated allocation\"\"\"\n\n    def __init__(self, config: PoolManagerConfig):\n        self.pools = {\n            AgentType.DESIGN: DynamicAgentPool(AgentType.DESIGN, config.design_pool),\n            AgentType.QA: DynamicAgentPool(AgentType.QA, config.qa_pool),\n            AgentType.CODE: DynamicAgentPool(AgentType.CODE, config.code_pool),\n            AgentType.DATA: DynamicAgentPool(AgentType.DATA, config.data_pool)\n        }\n        self.resource_allocator = ResourceAllocator(config.resource_limits)\n        self.load_balancer = AgentLoadBalancer()\n        self.metrics_collector = PoolMetricsCollector()\n        self.scaler = AutoScaler(config.scaling_policies)\n\n    async def acquire_agent(\n        self, \n        agent_type: AgentType, \n        cycle_id: str,\n        requirements: AgentRequirements,\n        timeout: int = 30\n    ) -&gt; AgentAllocation:\n        \"\"\"Acquire agent with specific requirements for a cycle\"\"\"\n\n        # Check resource availability\n        resource_check = await self.resource_allocator.check_availability(\n            agent_type, requirements\n        )\n        if not resource_check.available:\n            raise ResourceExhausted(f\"Insufficient resources for {agent_type}\")\n\n        # Get agent from pool\n        pool = self.pools[agent_type]\n\n        try:\n            # Try to acquire from pool\n            agent = await asyncio.wait_for(\n                pool.acquire_with_requirements(cycle_id, requirements),\n                timeout=timeout\n            )\n\n            # Allocate resources\n            allocation = await self.resource_allocator.allocate(\n                agent, cycle_id, requirements\n            )\n\n            # Record metrics\n            await self.metrics_collector.record_acquisition(\n                agent_type, cycle_id, allocation\n            )\n\n            return AgentAllocation(\n                agent=agent,\n                allocation=allocation,\n                acquired_at=datetime.now(),\n                cycle_id=cycle_id\n            )\n\n        except asyncio.TimeoutError:\n            # Try scaling up pool\n            if await self.scaler.can_scale_up(agent_type):\n                await self.scaler.scale_up(agent_type, 1)\n                # Retry once after scaling\n                agent = await asyncio.wait_for(\n                    pool.acquire_with_requirements(cycle_id, requirements),\n                    timeout=timeout // 2\n                )\n                allocation = await self.resource_allocator.allocate(\n                    agent, cycle_id, requirements\n                )\n                return AgentAllocation(agent=agent, allocation=allocation, \n                                     acquired_at=datetime.now(), cycle_id=cycle_id)\n            else:\n                raise AgentPoolExhausted(f\"No {agent_type} agents available\")\n\n@dataclass\nclass AgentRequirements:\n    \"\"\"Requirements for agent allocation\"\"\"\n    memory_mb: int = 1024\n    cpu_cores: float = 1.0\n    token_budget: int = 50000\n    disk_space_mb: int = 500\n    network_access: bool = True\n    special_tools: List[str] = field(default_factory=list)\n    security_level: SecurityLevel = SecurityLevel.STANDARD\n    isolation_level: IsolationLevel = IsolationLevel.PROCESS\n\nclass DynamicAgentPool:\n    \"\"\"Self-managing pool of agents with dynamic scaling\"\"\"\n\n    def __init__(self, agent_type: AgentType, config: PoolConfig):\n        self.agent_type = agent_type\n        self.config = config\n        self.available_agents: asyncio.Queue = asyncio.Queue(maxsize=config.max_size)\n        self.busy_agents: Dict[str, AgentInstance] = {}\n        self.standby_agents: Dict[str, AgentInstance] = {}\n        self.metrics = PoolMetrics()\n        self.health_monitor = AgentHealthMonitor(self)\n\n    async def acquire_with_requirements(\n        self, \n        cycle_id: str, \n        requirements: AgentRequirements\n    ) -&gt; AgentInstance:\n        \"\"\"Acquire agent that meets specific requirements\"\"\"\n\n        # Try to find suitable agent in available pool\n        suitable_agent = await self._find_suitable_agent(requirements)\n\n        if suitable_agent:\n            # Configure agent for requirements\n            await self._configure_agent(suitable_agent, requirements)\n            self.busy_agents[cycle_id] = suitable_agent\n            self.metrics.record_acquisition()\n            return suitable_agent\n\n        # No suitable agent - try to create one\n        if await self._can_create_agent():\n            new_agent = await self._create_agent(requirements)\n            await self._configure_agent(new_agent, requirements)\n            self.busy_agents[cycle_id] = new_agent\n            self.metrics.record_acquisition()\n            return new_agent\n\n        # Wait for agent to become available\n        return await self._wait_for_suitable_agent(cycle_id, requirements)\n\n    async def _find_suitable_agent(self, requirements: AgentRequirements) -&gt; Optional[AgentInstance]:\n        \"\"\"Find agent that meets requirements from available pool\"\"\"\n        # Check available agents\n        available_list = []\n        while not self.available_agents.empty():\n            try:\n                agent = self.available_agents.get_nowait()\n                available_list.append(agent)\n            except asyncio.QueueEmpty:\n                break\n\n        suitable_agent = None\n        for agent in available_list:\n            if await self._agent_meets_requirements(agent, requirements):\n                suitable_agent = agent\n                break\n            else:\n                # Put back in queue\n                await self.available_agents.put(agent)\n\n        return suitable_agent\n\n    async def _agent_meets_requirements(\n        self, \n        agent: AgentInstance, \n        requirements: AgentRequirements\n    ) -&gt; bool:\n        \"\"\"Check if agent can meet the requirements\"\"\"\n        # Check resource capacity\n        if agent.max_memory_mb &lt; requirements.memory_mb:\n            return False\n        if agent.max_cpu_cores &lt; requirements.cpu_cores:\n            return False\n        if agent.max_token_budget &lt; requirements.token_budget:\n            return False\n\n        # Check security constraints\n        if agent.security_level.value &lt; requirements.security_level.value:\n            return False\n\n        # Check tool availability\n        available_tools = set(agent.available_tools)\n        required_tools = set(requirements.special_tools)\n        if not required_tools.issubset(available_tools):\n            return False\n\n        return True\n\n    async def _create_agent(self, requirements: AgentRequirements) -&gt; AgentInstance:\n        \"\"\"Create new agent instance optimized for requirements\"\"\"\n        agent_config = AgentConfig(\n            agent_type=self.agent_type,\n            memory_mb=max(requirements.memory_mb, self.config.default_memory),\n            cpu_cores=max(requirements.cpu_cores, self.config.default_cpu),\n            token_budget=max(requirements.token_budget, self.config.default_tokens),\n            security_level=requirements.security_level,\n            isolation_level=requirements.isolation_level,\n            enabled_tools=self._get_tools_for_type(self.agent_type) + requirements.special_tools\n        )\n\n        agent = await AgentFactory.create_agent(agent_config)\n        await agent.initialize()\n\n        return agent\n</code></pre>"},{"location":"architecture/parallel-agent-pool-management/#2-intelligent-load-balancing","title":"2. Intelligent Load Balancing","text":"<pre><code>class AgentLoadBalancer:\n    \"\"\"Intelligent load balancing across agent pools\"\"\"\n\n    def __init__(self):\n        self.load_algorithms = {\n            LoadBalancingStrategy.ROUND_ROBIN: RoundRobinBalancer(),\n            LoadBalancingStrategy.LEAST_LOADED: LeastLoadedBalancer(),\n            LoadBalancingStrategy.WORKLOAD_AWARE: WorkloadAwareBalancer(),\n            LoadBalancingStrategy.PREDICTIVE: PredictiveBalancer()\n        }\n        self.current_strategy = LoadBalancingStrategy.WORKLOAD_AWARE\n\n    async def select_optimal_agent(\n        self, \n        agent_type: AgentType,\n        cycle_context: CycleContext,\n        available_agents: List[AgentInstance]\n    ) -&gt; AgentInstance:\n        \"\"\"Select optimal agent based on current strategy and context\"\"\"\n\n        balancer = self.load_algorithms[self.current_strategy]\n\n        # Score all available agents\n        agent_scores = []\n        for agent in available_agents:\n            score = await balancer.score_agent(agent, cycle_context)\n            agent_scores.append((agent, score))\n\n        # Select highest scoring agent\n        if agent_scores:\n            best_agent, best_score = max(agent_scores, key=lambda x: x[1])\n            return best_agent\n        else:\n            raise NoSuitableAgent(\"No agents meet the requirements\")\n\nclass WorkloadAwareBalancer:\n    \"\"\"Load balancer that considers workload characteristics\"\"\"\n\n    async def score_agent(\n        self, \n        agent: AgentInstance, \n        cycle_context: CycleContext\n    ) -&gt; float:\n        \"\"\"Score agent based on workload suitability\"\"\"\n        score = 0.0\n\n        # Current load factor (lower is better)\n        load_factor = await self._calculate_load_factor(agent)\n        score += (1.0 - load_factor) * 0.3\n\n        # Specialization match\n        specialization_score = await self._calculate_specialization_match(\n            agent, cycle_context\n        )\n        score += specialization_score * 0.25\n\n        # Resource availability\n        resource_score = await self._calculate_resource_availability(\n            agent, cycle_context.requirements\n        )\n        score += resource_score * 0.2\n\n        # Historical performance\n        performance_score = await self._get_historical_performance(\n            agent, cycle_context.story_type\n        )\n        score += performance_score * 0.15\n\n        # Context affinity (worked on similar code recently)\n        context_score = await self._calculate_context_affinity(\n            agent, cycle_context\n        )\n        score += context_score * 0.1\n\n        return score\n\n    async def _calculate_specialization_match(\n        self, \n        agent: AgentInstance, \n        cycle_context: CycleContext\n    ) -&gt; float:\n        \"\"\"Calculate how well agent's specialization matches the workload\"\"\"\n        agent_specializations = agent.get_specializations()\n        workload_tags = cycle_context.story.tags\n\n        # Calculate overlap between agent skills and workload requirements\n        if not workload_tags:\n            return 0.5  # Neutral score for untagged work\n\n        skill_overlap = len(set(agent_specializations) &amp; set(workload_tags))\n        max_possible_overlap = len(workload_tags)\n\n        return skill_overlap / max_possible_overlap if max_possible_overlap &gt; 0 else 0.0\n\nclass PredictiveBalancer:\n    \"\"\"ML-based predictive load balancing\"\"\"\n\n    def __init__(self):\n        self.performance_predictor = AgentPerformancePredictor()\n        self.completion_time_model = CompletionTimeModel()\n\n    async def score_agent(\n        self, \n        agent: AgentInstance, \n        cycle_context: CycleContext\n    ) -&gt; float:\n        \"\"\"Score based on predicted performance\"\"\"\n\n        # Predict task completion time\n        predicted_time = await self.completion_time_model.predict(\n            agent, cycle_context\n        )\n\n        # Predict success probability\n        success_probability = await self.performance_predictor.predict_success(\n            agent, cycle_context\n        )\n\n        # Predict resource efficiency\n        efficiency_score = await self.performance_predictor.predict_efficiency(\n            agent, cycle_context\n        )\n\n        # Combine predictions into overall score\n        # Favor agents with shorter predicted times, higher success rate, better efficiency\n        time_score = 1.0 / (1.0 + predicted_time.total_seconds() / 3600)  # Normalize by hours\n\n        overall_score = (\n            success_probability * 0.4 +\n            efficiency_score * 0.3 +\n            time_score * 0.3\n        )\n\n        return overall_score\n</code></pre>"},{"location":"architecture/parallel-agent-pool-management/#3-advanced-auto-scaling","title":"3. Advanced Auto-Scaling","text":"<pre><code>class AutoScaler:\n    \"\"\"Sophisticated auto-scaling for agent pools\"\"\"\n\n    def __init__(self, scaling_policies: Dict[AgentType, ScalingPolicy]):\n        self.policies = scaling_policies\n        self.metrics_analyzer = ScalingMetricsAnalyzer()\n        self.predictive_scaler = PredictiveScaler()\n        self.scaling_history: List[ScalingEvent] = []\n\n    async def evaluate_scaling_needs(self) -&gt; List[ScalingDecision]:\n        \"\"\"Evaluate scaling needs for all pools\"\"\"\n        decisions = []\n\n        for agent_type, policy in self.policies.items():\n            current_metrics = await self.metrics_analyzer.get_current_metrics(agent_type)\n            decision = await self._evaluate_pool_scaling(agent_type, policy, current_metrics)\n\n            if decision.action != ScalingAction.NO_ACTION:\n                decisions.append(decision)\n\n        return decisions\n\n    async def _evaluate_pool_scaling(\n        self, \n        agent_type: AgentType, \n        policy: ScalingPolicy,\n        metrics: PoolMetrics\n    ) -&gt; ScalingDecision:\n        \"\"\"Evaluate scaling for a specific pool\"\"\"\n\n        # Current state analysis\n        utilization = metrics.utilization\n        wait_time = metrics.average_wait_time\n        queue_depth = metrics.queue_depth\n        current_size = metrics.pool_size\n\n        # Predictive analysis\n        future_demand = await self.predictive_scaler.predict_demand(\n            agent_type, look_ahead_minutes=30\n        )\n\n        # Decision logic\n        if (utilization &gt; policy.scale_up_threshold and \n            wait_time &gt; policy.max_acceptable_wait_time and\n            current_size &lt; policy.max_size):\n\n            # Calculate scale-up amount\n            target_size = await self._calculate_optimal_scale_up(\n                agent_type, current_size, metrics, future_demand\n            )\n\n            return ScalingDecision(\n                agent_type=agent_type,\n                action=ScalingAction.SCALE_UP,\n                current_size=current_size,\n                target_size=target_size,\n                reason=f\"High utilization ({utilization:.2f}) and wait time ({wait_time:.1f}s)\",\n                confidence=await self._calculate_scaling_confidence(metrics, future_demand)\n            )\n\n        elif (utilization &lt; policy.scale_down_threshold and \n              wait_time &lt; policy.min_useful_wait_time and\n              current_size &gt; policy.min_size and\n              await self._can_safely_scale_down(agent_type)):\n\n            target_size = await self._calculate_optimal_scale_down(\n                agent_type, current_size, metrics, future_demand\n            )\n\n            return ScalingDecision(\n                agent_type=agent_type,\n                action=ScalingAction.SCALE_DOWN,\n                current_size=current_size,\n                target_size=target_size,\n                reason=f\"Low utilization ({utilization:.2f}) and short wait times\",\n                confidence=await self._calculate_scaling_confidence(metrics, future_demand)\n            )\n\n        return ScalingDecision(\n            agent_type=agent_type,\n            action=ScalingAction.NO_ACTION,\n            current_size=current_size,\n            target_size=current_size,\n            reason=\"Metrics within acceptable range\"\n        )\n\n    async def _calculate_optimal_scale_up(\n        self,\n        agent_type: AgentType,\n        current_size: int,\n        metrics: PoolMetrics,\n        future_demand: DemandPrediction\n    ) -&gt; int:\n        \"\"\"Calculate optimal scale-up target\"\"\"\n\n        # Base calculation using Little's Law\n        # Target pool size = arrival rate \u00d7 service time / target utilization\n        arrival_rate = metrics.request_rate_per_minute\n        service_time_minutes = metrics.average_service_time.total_seconds() / 60\n        target_utilization = 0.75  # Target 75% utilization\n\n        base_target = math.ceil((arrival_rate * service_time_minutes) / target_utilization)\n\n        # Adjust for predicted demand changes\n        demand_multiplier = future_demand.peak_demand_ratio\n        adjusted_target = math.ceil(base_target * demand_multiplier)\n\n        # Apply policy constraints\n        policy = self.policies[agent_type]\n        max_increase = math.ceil(current_size * policy.max_scale_up_ratio)\n        target_size = min(adjusted_target, current_size + max_increase, policy.max_size)\n\n        return max(target_size, current_size + 1)  # Scale up by at least 1\n\nclass PredictiveScaler:\n    \"\"\"ML-based predictive scaling\"\"\"\n\n    def __init__(self):\n        self.demand_model = DemandPredictionModel()\n        self.seasonal_analyzer = SeasonalPatternAnalyzer()\n        self.event_detector = WorkloadEventDetector()\n\n    async def predict_demand(\n        self, \n        agent_type: AgentType, \n        look_ahead_minutes: int\n    ) -&gt; DemandPrediction:\n        \"\"\"Predict future demand for agent type\"\"\"\n\n        # Historical pattern analysis\n        historical_pattern = await self.seasonal_analyzer.get_pattern(\n            agent_type, look_ahead_minutes\n        )\n\n        # Event-based prediction (e.g., large story batches)\n        event_impact = await self.event_detector.predict_events(\n            agent_type, look_ahead_minutes\n        )\n\n        # ML model prediction\n        ml_prediction = await self.demand_model.predict(\n            agent_type, look_ahead_minutes\n        )\n\n        # Combine predictions\n        base_demand = ml_prediction.base_demand\n        seasonal_multiplier = historical_pattern.seasonal_multiplier\n        event_multiplier = event_impact.impact_multiplier\n\n        predicted_demand = base_demand * seasonal_multiplier * event_multiplier\n\n        return DemandPrediction(\n            agent_type=agent_type,\n            time_horizon_minutes=look_ahead_minutes,\n            predicted_demand=predicted_demand,\n            base_demand=base_demand,\n            seasonal_multiplier=seasonal_multiplier,\n            event_multiplier=event_multiplier,\n            confidence=min(ml_prediction.confidence, \n                          historical_pattern.confidence, \n                          event_impact.confidence),\n            peak_demand_ratio=max(seasonal_multiplier, event_multiplier)\n        )\n</code></pre>"},{"location":"architecture/parallel-agent-pool-management/#resource-allocation-system","title":"Resource Allocation System","text":""},{"location":"architecture/parallel-agent-pool-management/#1-multi-resource-allocation","title":"1. Multi-Resource Allocation","text":"<pre><code>class ResourceAllocator:\n    \"\"\"Sophisticated resource allocation across multiple dimensions\"\"\"\n\n    def __init__(self, limits: ResourceLimits):\n        self.limits = limits\n        self.allocations: Dict[str, ResourceAllocation] = {}  # cycle_id -&gt; allocation\n        self.global_usage = GlobalResourceUsage()\n        self.allocation_optimizer = AllocationOptimizer()\n\n    async def allocate(\n        self, \n        agent: AgentInstance, \n        cycle_id: str,\n        requirements: AgentRequirements\n    ) -&gt; ResourceAllocation:\n        \"\"\"Allocate resources for agent in cycle\"\"\"\n\n        # Check if allocation is feasible\n        feasibility = await self._check_allocation_feasibility(requirements)\n        if not feasibility.feasible:\n            raise ResourceAllocationError(feasibility.reason)\n\n        # Optimize allocation within constraints\n        optimized_allocation = await self.allocation_optimizer.optimize(\n            requirements, self.global_usage, self.limits\n        )\n\n        # Reserve resources\n        allocation = ResourceAllocation(\n            cycle_id=cycle_id,\n            agent_id=agent.id,\n            memory_mb=optimized_allocation.memory_mb,\n            cpu_cores=optimized_allocation.cpu_cores,\n            token_budget=optimized_allocation.token_budget,\n            disk_space_mb=optimized_allocation.disk_space_mb,\n            network_bandwidth_mbps=optimized_allocation.network_bandwidth,\n            allocated_at=datetime.now(),\n            expires_at=datetime.now() + timedelta(hours=4)  # Default 4-hour allocation\n        )\n\n        # Update global usage\n        await self.global_usage.reserve(allocation)\n        self.allocations[cycle_id] = allocation\n\n        # Configure agent with allocation\n        await agent.configure_resources(allocation)\n\n        return allocation\n\n    async def _check_allocation_feasibility(\n        self, \n        requirements: AgentRequirements\n    ) -&gt; AllocationFeasibility:\n        \"\"\"Check if requested allocation is feasible\"\"\"\n\n        # Check individual resource limits\n        if requirements.memory_mb &gt; self.limits.max_memory_per_agent:\n            return AllocationFeasibility(\n                feasible=False, \n                reason=f\"Memory request {requirements.memory_mb}MB exceeds limit {self.limits.max_memory_per_agent}MB\"\n            )\n\n        if requirements.cpu_cores &gt; self.limits.max_cpu_per_agent:\n            return AllocationFeasibility(\n                feasible=False,\n                reason=f\"CPU request {requirements.cpu_cores} exceeds limit {self.limits.max_cpu_per_agent}\"\n            )\n\n        # Check global resource availability\n        available_memory = self.limits.total_memory_mb - self.global_usage.used_memory_mb\n        if requirements.memory_mb &gt; available_memory:\n            return AllocationFeasibility(\n                feasible=False,\n                reason=f\"Insufficient memory: need {requirements.memory_mb}MB, available {available_memory}MB\"\n            )\n\n        available_cpu = self.limits.total_cpu_cores - self.global_usage.used_cpu_cores\n        if requirements.cpu_cores &gt; available_cpu:\n            return AllocationFeasibility(\n                feasible=False,\n                reason=f\"Insufficient CPU: need {requirements.cpu_cores}, available {available_cpu}\"\n            )\n\n        return AllocationFeasibility(feasible=True)\n\nclass AllocationOptimizer:\n    \"\"\"Optimize resource allocations for efficiency\"\"\"\n\n    async def optimize(\n        self,\n        requirements: AgentRequirements,\n        current_usage: GlobalResourceUsage,\n        limits: ResourceLimits\n    ) -&gt; OptimizedAllocation:\n        \"\"\"Optimize allocation within constraints\"\"\"\n\n        # Start with requested amounts\n        allocation = OptimizedAllocation(\n            memory_mb=requirements.memory_mb,\n            cpu_cores=requirements.cpu_cores,\n            token_budget=requirements.token_budget,\n            disk_space_mb=requirements.disk_space_mb,\n            network_bandwidth=10.0  # Default bandwidth\n        )\n\n        # Apply memory optimization\n        allocation.memory_mb = await self._optimize_memory_allocation(\n            requirements.memory_mb, current_usage, limits\n        )\n\n        # Apply CPU optimization  \n        allocation.cpu_cores = await self._optimize_cpu_allocation(\n            requirements.cpu_cores, current_usage, limits\n        )\n\n        # Apply token budget optimization\n        allocation.token_budget = await self._optimize_token_allocation(\n            requirements.token_budget, current_usage, limits\n        )\n\n        return allocation\n\n    async def _optimize_memory_allocation(\n        self,\n        requested_mb: int,\n        current_usage: GlobalResourceUsage,\n        limits: ResourceLimits\n    ) -&gt; int:\n        \"\"\"Optimize memory allocation\"\"\"\n\n        # Calculate available memory\n        available_mb = limits.total_memory_mb - current_usage.used_memory_mb\n\n        # If we have plenty of memory, potentially give more than requested\n        memory_utilization = current_usage.used_memory_mb / limits.total_memory_mb\n\n        if memory_utilization &lt; 0.6:  # Low utilization\n            # Give up to 50% more memory for better performance\n            optimized_mb = min(\n                int(requested_mb * 1.5),\n                available_mb,\n                limits.max_memory_per_agent\n            )\n        elif memory_utilization &lt; 0.8:  # Medium utilization\n            # Give exactly what was requested\n            optimized_mb = min(requested_mb, available_mb)\n        else:  # High utilization\n            # Try to reduce allocation if possible\n            optimized_mb = min(\n                max(int(requested_mb * 0.8), limits.min_memory_per_agent),\n                available_mb\n            )\n\n        return optimized_mb\n</code></pre>"},{"location":"architecture/parallel-agent-pool-management/#2-dynamic-resource-rebalancing","title":"2. Dynamic Resource Rebalancing","text":"<pre><code>class ResourceRebalancer:\n    \"\"\"Dynamic rebalancing of resources across active cycles\"\"\"\n\n    def __init__(self, allocator: ResourceAllocator):\n        self.allocator = allocator\n        self.usage_monitor = ResourceUsageMonitor()\n        self.rebalancing_history: List[RebalancingEvent] = []\n\n    async def rebalance_resources(self) -&gt; RebalancingResult:\n        \"\"\"Rebalance resources across all active allocations\"\"\"\n\n        # Analyze current usage patterns\n        usage_analysis = await self.usage_monitor.analyze_current_usage()\n\n        # Identify rebalancing opportunities\n        opportunities = await self._identify_rebalancing_opportunities(usage_analysis)\n\n        if not opportunities:\n            return RebalancingResult(\n                rebalanced=False,\n                reason=\"No beneficial rebalancing opportunities found\"\n            )\n\n        # Execute rebalancing\n        results = []\n        for opportunity in opportunities:\n            result = await self._execute_rebalancing(opportunity)\n            results.append(result)\n\n        return RebalancingResult(\n            rebalanced=True,\n            opportunities_found=len(opportunities),\n            successful_rebalances=sum(1 for r in results if r.success),\n            total_resources_freed=sum(r.resources_freed for r in results),\n            estimated_performance_improvement=await self._calculate_improvement(results)\n        )\n\n    async def _identify_rebalancing_opportunities(\n        self, \n        usage_analysis: UsageAnalysis\n    ) -&gt; List[RebalancingOpportunity]:\n        \"\"\"Identify opportunities for resource rebalancing\"\"\"\n        opportunities = []\n\n        # Find over-allocated cycles (using much less than allocated)\n        for cycle_id, usage in usage_analysis.cycle_usage.items():\n            allocation = self.allocator.allocations.get(cycle_id)\n            if not allocation:\n                continue\n\n            # Memory over-allocation\n            if usage.memory_utilization &lt; 0.3:  # Using less than 30% of allocated memory\n                memory_to_free = int(allocation.memory_mb * 0.4)  # Free 40% of allocation\n                opportunities.append(RebalancingOpportunity(\n                    type=RebalancingType.MEMORY_REDUCTION,\n                    cycle_id=cycle_id,\n                    current_allocation=allocation.memory_mb,\n                    suggested_allocation=allocation.memory_mb - memory_to_free,\n                    freed_amount=memory_to_free,\n                    confidence=0.8\n                ))\n\n            # CPU over-allocation\n            if usage.cpu_utilization &lt; 0.25:  # Using less than 25% of allocated CPU\n                cpu_to_free = allocation.cpu_cores * 0.3\n                opportunities.append(RebalancingOpportunity(\n                    type=RebalancingType.CPU_REDUCTION,\n                    cycle_id=cycle_id,\n                    current_allocation=allocation.cpu_cores,\n                    suggested_allocation=allocation.cpu_cores - cpu_to_free,\n                    freed_amount=cpu_to_free,\n                    confidence=0.7\n                ))\n\n        # Find under-allocated cycles (need more resources)\n        for cycle_id, usage in usage_analysis.cycle_usage.items():\n            if usage.memory_pressure &gt; 0.9:  # Memory pressure\n                additional_memory = int(usage.current_memory_mb * 0.5)\n                opportunities.append(RebalancingOpportunity(\n                    type=RebalancingType.MEMORY_INCREASE,\n                    cycle_id=cycle_id,\n                    current_allocation=usage.current_memory_mb,\n                    suggested_allocation=usage.current_memory_mb + additional_memory,\n                    needed_amount=additional_memory,\n                    confidence=0.9\n                ))\n\n        return sorted(opportunities, key=lambda o: o.confidence, reverse=True)\n</code></pre>"},{"location":"architecture/parallel-agent-pool-management/#performance-monitoring-and-optimization","title":"Performance Monitoring and Optimization","text":""},{"location":"architecture/parallel-agent-pool-management/#1-comprehensive-pool-metrics","title":"1. Comprehensive Pool Metrics","text":"<pre><code>class PoolMetricsCollector:\n    \"\"\"Collect comprehensive metrics for agent pools\"\"\"\n\n    def __init__(self):\n        self.metrics_store = TimeSeriesMetricsStore()\n        self.realtime_metrics: Dict[AgentType, PoolMetrics] = {}\n        self.collection_interval = 30  # seconds\n\n    async def collect_pool_metrics(self, agent_type: AgentType) -&gt; PoolMetrics:\n        \"\"\"Collect current metrics for a pool\"\"\"\n        pool = self._get_pool(agent_type)\n\n        metrics = PoolMetrics(\n            agent_type=agent_type,\n            timestamp=datetime.now(),\n\n            # Pool size metrics\n            total_agents=pool.total_agent_count(),\n            available_agents=pool.available_agent_count(),\n            busy_agents=pool.busy_agent_count(),\n            standby_agents=pool.standby_agent_count(),\n\n            # Utilization metrics\n            utilization=pool.busy_agent_count() / max(pool.total_agent_count(), 1),\n            queue_depth=pool.queue_depth(),\n            average_wait_time=await pool.calculate_average_wait_time(),\n\n            # Performance metrics\n            request_rate_per_minute=await self._calculate_request_rate(agent_type),\n            completion_rate_per_minute=await self._calculate_completion_rate(agent_type),\n            average_service_time=await self._calculate_average_service_time(agent_type),\n\n            # Quality metrics\n            success_rate=await self._calculate_success_rate(agent_type),\n            error_rate=await self._calculate_error_rate(agent_type),\n            timeout_rate=await self._calculate_timeout_rate(agent_type),\n\n            # Resource metrics\n            total_memory_allocated=await self._calculate_memory_usage(agent_type),\n            total_cpu_allocated=await self._calculate_cpu_usage(agent_type),\n            total_tokens_allocated=await self._calculate_token_usage(agent_type),\n\n            # Efficiency metrics\n            resource_efficiency=await self._calculate_resource_efficiency(agent_type),\n            throughput_per_agent=await self._calculate_throughput_per_agent(agent_type)\n        )\n\n        # Store metrics\n        await self.metrics_store.store(metrics)\n        self.realtime_metrics[agent_type] = metrics\n\n        return metrics\n\n    async def _calculate_resource_efficiency(self, agent_type: AgentType) -&gt; float:\n        \"\"\"Calculate how efficiently resources are being used\"\"\"\n        recent_allocations = await self._get_recent_allocations(agent_type, minutes=60)\n\n        if not recent_allocations:\n            return 0.0\n\n        total_efficiency = 0.0\n        for allocation in recent_allocations:\n            # Calculate efficiency as actual usage / allocated resources\n            actual_usage = await self._get_actual_resource_usage(allocation)\n\n            memory_efficiency = actual_usage.memory_used / allocation.memory_mb\n            cpu_efficiency = actual_usage.cpu_used / allocation.cpu_cores\n            token_efficiency = actual_usage.tokens_used / allocation.token_budget\n\n            # Weight different resource types\n            allocation_efficiency = (\n                memory_efficiency * 0.4 +\n                cpu_efficiency * 0.4 +\n                token_efficiency * 0.2\n            )\n\n            total_efficiency += allocation_efficiency\n\n        return total_efficiency / len(recent_allocations)\n\nclass PerformanceOptimizer:\n    \"\"\"Optimize pool performance based on metrics\"\"\"\n\n    def __init__(self):\n        self.optimization_strategies = {\n            PerformanceIssue.HIGH_WAIT_TIMES: self._optimize_wait_times,\n            PerformanceIssue.LOW_UTILIZATION: self._optimize_utilization,\n            PerformanceIssue.RESOURCE_WASTE: self._optimize_resource_usage,\n            PerformanceIssue.POOR_THROUGHPUT: self._optimize_throughput\n        }\n\n    async def optimize_performance(\n        self, \n        agent_type: AgentType, \n        metrics: PoolMetrics\n    ) -&gt; OptimizationResult:\n        \"\"\"Optimize pool performance based on current metrics\"\"\"\n\n        # Identify performance issues\n        issues = await self._identify_performance_issues(metrics)\n\n        optimizations_applied = []\n        for issue in issues:\n            strategy = self.optimization_strategies.get(issue.type)\n            if strategy:\n                result = await strategy(agent_type, issue, metrics)\n                optimizations_applied.append(result)\n\n        return OptimizationResult(\n            agent_type=agent_type,\n            issues_identified=issues,\n            optimizations_applied=optimizations_applied,\n            expected_improvement=await self._calculate_expected_improvement(\n                optimizations_applied\n            )\n        )\n\n    async def _optimize_wait_times(\n        self, \n        agent_type: AgentType, \n        issue: PerformanceIssue,\n        metrics: PoolMetrics\n    ) -&gt; OptimizationAction:\n        \"\"\"Optimize for reduced wait times\"\"\"\n\n        if metrics.utilization &gt; 0.8:\n            # High utilization causing wait times - scale up\n            recommended_increase = math.ceil(metrics.total_agents * 0.2)\n            return OptimizationAction(\n                type=ActionType.SCALE_UP,\n                details=f\"Increase pool size by {recommended_increase} to reduce wait times\",\n                expected_impact=\"Reduce wait times by ~40%\",\n                resource_cost=await self._calculate_scaling_cost(\n                    agent_type, recommended_increase\n                )\n            )\n        else:\n            # Low utilization but still wait times - agent performance issue\n            return OptimizationAction(\n                type=ActionType.AGENT_TUNING,\n                details=\"Optimize agent performance settings\",\n                expected_impact=\"Reduce wait times by ~20%\"\n            )\n</code></pre>"},{"location":"architecture/parallel-agent-pool-management/#security-and-isolation","title":"Security and Isolation","text":""},{"location":"architecture/parallel-agent-pool-management/#1-agent-security-boundaries","title":"1. Agent Security Boundaries","text":"<pre><code>class AgentSecurityManager:\n    \"\"\"Manage security boundaries for agent pools\"\"\"\n\n    def __init__(self):\n        self.security_profiles = {\n            AgentType.DESIGN: SecurityProfile(\n                allowed_tools=[\"read\", \"write_docs\", \"web_fetch\"],\n                network_access=NetworkAccess.LIMITED,\n                file_access=FileAccess.READ_ONLY,\n                resource_limits=ResourceLimits(memory_mb=1024, cpu_cores=1.0)\n            ),\n            AgentType.QA: SecurityProfile(\n                allowed_tools=[\"read\", \"test_execution\", \"coverage_analysis\"],\n                network_access=NetworkAccess.TEST_ONLY,\n                file_access=FileAccess.READ_WRITE_TESTS,\n                resource_limits=ResourceLimits(memory_mb=2048, cpu_cores=2.0)\n            ),\n            AgentType.CODE: SecurityProfile(\n                allowed_tools=[\"read\", \"write\", \"git\", \"test_execution\"],\n                network_access=NetworkAccess.LIMITED,\n                file_access=FileAccess.READ_WRITE_SOURCE,\n                resource_limits=ResourceLimits(memory_mb=4096, cpu_cores=2.0)\n            )\n        }\n\n    async def enforce_security_boundaries(\n        self, \n        agent: AgentInstance, \n        allocation: ResourceAllocation\n    ) -&gt; SecurityEnforcement:\n        \"\"\"Enforce security boundaries for agent\"\"\"\n\n        profile = self.security_profiles[agent.agent_type]\n\n        # Apply tool restrictions\n        await agent.restrict_tools(profile.allowed_tools)\n\n        # Apply network restrictions\n        await agent.configure_network_access(profile.network_access)\n\n        # Apply file access restrictions\n        await agent.configure_file_access(profile.file_access)\n\n        # Apply resource limits\n        await agent.enforce_resource_limits(profile.resource_limits)\n\n        # Set up monitoring\n        monitor = await self._setup_security_monitoring(agent, profile)\n\n        return SecurityEnforcement(\n            agent_id=agent.id,\n            profile=profile,\n            monitor=monitor,\n            enforced_at=datetime.now()\n        )\n</code></pre>"},{"location":"architecture/parallel-agent-pool-management/#2-resource-isolation","title":"2. Resource Isolation","text":"<pre><code>class ResourceIsolationManager:\n    \"\"\"Manage resource isolation between agent pools\"\"\"\n\n    def __init__(self):\n        self.isolation_strategies = {\n            IsolationType.PROCESS: ProcessIsolation(),\n            IsolationType.CONTAINER: ContainerIsolation(),\n            IsolationType.VIRTUAL_MACHINE: VMIsolation()\n        }\n\n    async def create_isolated_environment(\n        self, \n        agent_type: AgentType,\n        requirements: AgentRequirements\n    ) -&gt; IsolatedEnvironment:\n        \"\"\"Create isolated environment for agent\"\"\"\n\n        isolation_type = requirements.isolation_level\n        strategy = self.isolation_strategies[isolation_type]\n\n        environment = await strategy.create_environment(\n            agent_type=agent_type,\n            memory_limit=requirements.memory_mb,\n            cpu_limit=requirements.cpu_cores,\n            disk_limit=requirements.disk_space_mb,\n            network_policy=requirements.network_policy\n        )\n\n        # Set up monitoring and cleanup\n        await environment.setup_monitoring()\n        await environment.setup_auto_cleanup(timeout=timedelta(hours=6))\n\n        return environment\n</code></pre> <p>This comprehensive agent pool management system provides sophisticated resource allocation, dynamic scaling, intelligent load balancing, and strong security boundaries while maintaining optimal performance across parallel TDD execution cycles.</p>"},{"location":"architecture/parallel-conflict-algorithms/","title":"Parallel TDD Conflict Resolution Algorithms","text":""},{"location":"architecture/parallel-conflict-algorithms/#executive-summary","title":"Executive Summary","text":"<p>This document specifies the algorithms and strategies for detecting, analyzing, and resolving conflicts in parallel TDD execution. The system employs a multi-layered approach combining proactive detection, intelligent auto-resolution, and human-assisted resolution for complex cases.</p>"},{"location":"architecture/parallel-conflict-algorithms/#conflict-detection-framework","title":"Conflict Detection Framework","text":""},{"location":"architecture/parallel-conflict-algorithms/#1-static-analysis-detection","title":"1. Static Analysis Detection","text":"<pre><code>class StaticConflictAnalyzer:\n    \"\"\"Analyzes conflicts before execution starts\"\"\"\n\n    def __init__(self):\n        self.dependency_analyzer = DependencyAnalyzer()\n        self.code_analyzer = CodeStructureAnalyzer()\n        self.test_analyzer = TestAnalyzer()\n\n    async def analyze_potential_conflicts(\n        self, \n        stories: List[Story]\n    ) -&gt; List[PotentialConflict]:\n        \"\"\"Analyze potential conflicts between stories\"\"\"\n        conflicts = []\n\n        for i, story1 in enumerate(stories):\n            for j, story2 in enumerate(stories[i+1:], i+1):\n                # File overlap analysis\n                file_conflicts = await self._analyze_file_overlap(story1, story2)\n                conflicts.extend(file_conflicts)\n\n                # Dependency conflicts\n                dep_conflicts = await self._analyze_dependencies(story1, story2)\n                conflicts.extend(dep_conflicts)\n\n                # Semantic conflicts\n                semantic_conflicts = await self._analyze_semantic_conflicts(story1, story2)\n                conflicts.extend(semantic_conflicts)\n\n        return self._rank_by_severity(conflicts)\n\n    async def _analyze_file_overlap(self, story1: Story, story2: Story) -&gt; List[PotentialConflict]:\n        \"\"\"Detect file-level conflicts between stories\"\"\"\n        # Get affected files using AST analysis and import tracking\n        files1 = await self._get_affected_files(story1)\n        files2 = await self._get_affected_files(story2)\n\n        overlapping_files = files1 &amp; files2\n        conflicts = []\n\n        for file_path in overlapping_files:\n            # Analyze modification patterns\n            mod_pattern1 = await self._analyze_modification_pattern(story1, file_path)\n            mod_pattern2 = await self._analyze_modification_pattern(story2, file_path)\n\n            severity = self._calculate_overlap_severity(mod_pattern1, mod_pattern2)\n\n            conflicts.append(PotentialConflict(\n                type=ConflictType.FILE_OVERLAP,\n                severity=severity,\n                stories=[story1.id, story2.id],\n                resource=file_path,\n                probability=self._calculate_conflict_probability(mod_pattern1, mod_pattern2),\n                auto_resolvable=self._can_auto_resolve_overlap(mod_pattern1, mod_pattern2)\n            ))\n\n        return conflicts\n\n    async def _get_affected_files(self, story: Story) -&gt; Set[str]:\n        \"\"\"Get all files that might be affected by a story\"\"\"\n        affected_files = set()\n\n        # Direct file references in story\n        affected_files.update(story.files or [])\n\n        # Analyze imports and dependencies\n        for file_path in story.files or []:\n            if os.path.exists(file_path):\n                deps = await self.dependency_analyzer.get_dependencies(file_path)\n                affected_files.update(deps)\n\n                # Get reverse dependencies (files that import this)\n                reverse_deps = await self.dependency_analyzer.get_reverse_dependencies(file_path)\n                affected_files.update(reverse_deps)\n\n        # Analyze test files\n        for file_path in affected_files.copy():\n            test_files = await self.test_analyzer.find_test_files_for(file_path)\n            affected_files.update(test_files)\n\n        return affected_files\n</code></pre>"},{"location":"architecture/parallel-conflict-algorithms/#2-runtime-conflict-detection","title":"2. Runtime Conflict Detection","text":"<pre><code>class RuntimeConflictDetector:\n    \"\"\"Detects conflicts during parallel execution\"\"\"\n\n    def __init__(self):\n        self.file_monitors: Dict[str, FileMonitor] = {}\n        self.access_patterns: Dict[str, List[FileAccess]] = defaultdict(list)\n        self.lock_manager = LockManager()\n\n    async def monitor_file_access(self, cycle_id: str, file_path: str, access_type: str):\n        \"\"\"Monitor file access patterns for conflict detection\"\"\"\n        access = FileAccess(\n            cycle_id=cycle_id,\n            file_path=file_path,\n            access_type=access_type,\n            timestamp=datetime.now(),\n            content_hash=await self._get_file_hash(file_path) if access_type == 'read' else None\n        )\n\n        self.access_patterns[file_path].append(access)\n\n        # Check for potential conflicts\n        if access_type in ['write', 'modify']:\n            conflicts = await self._detect_write_conflicts(file_path, cycle_id)\n            if conflicts:\n                await self._notify_conflicts(conflicts)\n\n    async def _detect_write_conflicts(self, file_path: str, writing_cycle: str) -&gt; List[ActiveConflict]:\n        \"\"\"Detect conflicts when a cycle wants to write to a file\"\"\"\n        conflicts = []\n        recent_accesses = self._get_recent_accesses(file_path, minutes=30)\n\n        for access in recent_accesses:\n            if access.cycle_id != writing_cycle:\n                # Check if other cycle is still active and accessing this file\n                if await self._is_cycle_active(access.cycle_id):\n                    # Determine conflict severity based on access patterns\n                    severity = await self._calculate_runtime_severity(\n                        file_path, writing_cycle, access.cycle_id\n                    )\n\n                    conflicts.append(ActiveConflict(\n                        type=ConflictType.CONCURRENT_WRITE,\n                        severity=severity,\n                        cycles=[writing_cycle, access.cycle_id],\n                        resource=file_path,\n                        detected_at=datetime.now()\n                    ))\n\n        return conflicts\n\n    async def _calculate_runtime_severity(\n        self, \n        file_path: str, \n        cycle1: str, \n        cycle2: str\n    ) -&gt; ConflictSeverity:\n        \"\"\"Calculate conflict severity based on runtime analysis\"\"\"\n        # Get current locks\n        lock1 = await self.lock_manager.get_lock_info(file_path, cycle1)\n        lock2 = await self.lock_manager.get_lock_info(file_path, cycle2)\n\n        # If both have exclusive locks, it's critical\n        if (lock1 and lock1.lock_type == LockType.EXCLUSIVE and \n            lock2 and lock2.lock_type == LockType.EXCLUSIVE):\n            return ConflictSeverity.CRITICAL\n\n        # Analyze modification patterns\n        mod1 = await self._get_planned_modifications(cycle1, file_path)\n        mod2 = await self._get_planned_modifications(cycle2, file_path)\n\n        if self._modifications_overlap(mod1, mod2):\n            return ConflictSeverity.HIGH\n        elif self._modifications_might_interfere(mod1, mod2):\n            return ConflictSeverity.MEDIUM\n        else:\n            return ConflictSeverity.LOW\n</code></pre>"},{"location":"architecture/parallel-conflict-algorithms/#3-predictive-conflict-analysis","title":"3. Predictive Conflict Analysis","text":"<pre><code>class PredictiveConflictAnalyzer:\n    \"\"\"ML-based conflict prediction\"\"\"\n\n    def __init__(self):\n        self.model = self._load_conflict_prediction_model()\n        self.feature_extractor = ConflictFeatureExtractor()\n        self.historical_data = ConflictHistoryDatabase()\n\n    async def predict_conflict_probability(\n        self, \n        story1: Story, \n        story2: Story\n    ) -&gt; ConflictPrediction:\n        \"\"\"Predict probability and type of conflicts\"\"\"\n        features = await self.feature_extractor.extract_features(story1, story2)\n\n        # Multiple model predictions\n        file_conflict_prob = self.model.file_conflict.predict_proba([features])[0][1]\n        test_conflict_prob = self.model.test_conflict.predict_proba([features])[0][1]\n        semantic_conflict_prob = self.model.semantic_conflict.predict_proba([features])[0][1]\n\n        return ConflictPrediction(\n            overall_probability=max(file_conflict_prob, test_conflict_prob, semantic_conflict_prob),\n            file_conflict_probability=file_conflict_prob,\n            test_conflict_probability=test_conflict_prob,\n            semantic_conflict_probability=semantic_conflict_prob,\n            confidence=await self._calculate_prediction_confidence(features),\n            recommendation=await self._generate_recommendation(\n                file_conflict_prob, test_conflict_prob, semantic_conflict_prob\n            )\n        )\n\n    async def learn_from_conflicts(self, resolved_conflicts: List[ResolvedConflict]):\n        \"\"\"Learn from resolved conflicts to improve predictions\"\"\"\n        training_data = []\n\n        for conflict in resolved_conflicts:\n            # Extract features that led to this conflict\n            features = await self.feature_extractor.extract_historical_features(conflict)\n\n            # Create training sample\n            training_data.append({\n                'features': features,\n                'conflict_type': conflict.type,\n                'severity': conflict.severity,\n                'resolution_success': conflict.resolution_result.success,\n                'resolution_time': conflict.resolution_time\n            })\n\n        # Retrain models with new data\n        await self._retrain_models(training_data)\n\nclass ConflictFeatureExtractor:\n    \"\"\"Extract features for ML conflict prediction\"\"\"\n\n    async def extract_features(self, story1: Story, story2: Story) -&gt; np.ndarray:\n        \"\"\"Extract feature vector for conflict prediction\"\"\"\n        features = []\n\n        # File overlap features\n        files1 = set(await self._get_story_files(story1))\n        files2 = set(await self._get_story_files(story2))\n        features.extend([\n            len(files1 &amp; files2),  # Overlapping files count\n            len(files1 | files2),  # Total unique files\n            jaccard_similarity(files1, files2),  # Jaccard similarity\n            len(files1), len(files2)  # Individual file counts\n        ])\n\n        # Code complexity features\n        complexity1 = await self._calculate_story_complexity(story1)\n        complexity2 = await self._calculate_story_complexity(story2)\n        features.extend([\n            complexity1.cyclomatic,\n            complexity2.cyclomatic,\n            abs(complexity1.cyclomatic - complexity2.cyclomatic),\n            complexity1.lines_of_code,\n            complexity2.lines_of_code\n        ])\n\n        # Semantic similarity features\n        story_similarity = await self._calculate_semantic_similarity(\n            story1.description, story2.description\n        )\n        features.append(story_similarity)\n\n        # Historical conflict features\n        historical_rate = await self._get_historical_conflict_rate(\n            story1.epic_id, story2.epic_id\n        )\n        features.append(historical_rate)\n\n        # Team/developer features\n        features.extend([\n            1 if story1.assignee == story2.assignee else 0,\n            story1.priority,\n            story2.priority,\n            abs(story1.priority - story2.priority)\n        ])\n\n        # Temporal features\n        time_diff = abs((story1.created_at - story2.created_at).total_seconds())\n        features.append(min(time_diff / 86400, 30))  # Days difference, capped at 30\n\n        return np.array(features)\n</code></pre>"},{"location":"architecture/parallel-conflict-algorithms/#conflict-resolution-strategies","title":"Conflict Resolution Strategies","text":""},{"location":"architecture/parallel-conflict-algorithms/#1-automatic-merge-resolution","title":"1. Automatic Merge Resolution","text":"<pre><code>class AutoMergeResolver:\n    \"\"\"Automatically resolve conflicts through intelligent merging\"\"\"\n\n    def __init__(self):\n        self.merge_strategies = {\n            ConflictType.FILE_OVERLAP: [\n                self._try_ast_merge,\n                self._try_line_based_merge,\n                self._try_function_level_merge\n            ],\n            ConflictType.TEST_COLLISION: [\n                self._try_test_namespace_merge,\n                self._try_test_file_split\n            ],\n            ConflictType.IMPORT_CONFLICTS: [\n                self._try_import_resolution,\n                self._try_namespace_isolation\n            ]\n        }\n\n    async def resolve_conflict(self, conflict: Conflict) -&gt; ResolutionResult:\n        \"\"\"Attempt automatic conflict resolution\"\"\"\n        strategies = self.merge_strategies.get(conflict.type, [])\n\n        for strategy in strategies:\n            try:\n                result = await strategy(conflict)\n                if result.success:\n                    # Validate merge result\n                    if await self._validate_merge(result):\n                        return result\n                    else:\n                        # Merge succeeded but validation failed\n                        continue\n            except Exception as e:\n                logger.warning(f\"Merge strategy {strategy.__name__} failed: {e}\")\n                continue\n\n        return ResolutionResult(\n            success=False,\n            reason=\"All automatic merge strategies failed\",\n            requires_manual_resolution=True\n        )\n\n    async def _try_ast_merge(self, conflict: Conflict) -&gt; ResolutionResult:\n        \"\"\"Try AST-based intelligent merge\"\"\"\n        file_path = conflict.resource\n\n        # Get both versions of the file\n        version1 = await self._get_cycle_file_version(conflict.cycles[0], file_path)\n        version2 = await self._get_cycle_file_version(conflict.cycles[1], file_path)\n        base_version = await self._get_base_file_version(file_path)\n\n        try:\n            # Parse ASTs\n            ast1 = ast.parse(version1.content)\n            ast2 = ast.parse(version2.content)\n            ast_base = ast.parse(base_version.content)\n\n            # Perform semantic merge\n            merged_ast = await self._merge_asts(ast1, ast2, ast_base)\n            merged_code = astor.to_source(merged_ast)\n\n            # Verify syntax and semantics\n            if await self._verify_merged_code(merged_code):\n                return ResolutionResult(\n                    success=True,\n                    merged_content=merged_code,\n                    merge_method=\"ast_merge\",\n                    confidence=0.9\n                )\n\n        except SyntaxError as e:\n            return ResolutionResult(success=False, reason=f\"Syntax error in merge: {e}\")\n        except Exception as e:\n            return ResolutionResult(success=False, reason=f\"AST merge failed: {e}\")\n\n    async def _merge_asts(self, ast1: ast.AST, ast2: ast.AST, ast_base: ast.AST) -&gt; ast.AST:\n        \"\"\"Merge two ASTs using base version as reference\"\"\"\n        merger = ASTMerger()\n\n        # Extract changes from base\n        changes1 = merger.extract_changes(ast_base, ast1)\n        changes2 = merger.extract_changes(ast_base, ast2)\n\n        # Check for conflicting changes\n        conflicting_changes = merger.find_conflicting_changes(changes1, changes2)\n\n        if conflicting_changes:\n            # Try to resolve conflicts intelligently\n            resolved_changes = await merger.resolve_conflicts(conflicting_changes)\n            if not resolved_changes:\n                raise ConflictResolutionError(\"Cannot resolve AST conflicts\")\n\n        # Apply changes to base AST\n        merged_ast = merger.apply_changes(ast_base, changes1 + changes2)\n        return merged_ast\n\nclass ASTMerger:\n    \"\"\"Sophisticated AST merging with conflict resolution\"\"\"\n\n    def extract_changes(self, base_ast: ast.AST, modified_ast: ast.AST) -&gt; List[ASTChange]:\n        \"\"\"Extract changes between base and modified AST\"\"\"\n        changes = []\n\n        # Compare function definitions\n        base_functions = self._extract_functions(base_ast)\n        modified_functions = self._extract_functions(modified_ast)\n\n        for func_name, modified_func in modified_functions.items():\n            if func_name in base_functions:\n                base_func = base_functions[func_name]\n                if not self._functions_equal(base_func, modified_func):\n                    changes.append(ASTChange(\n                        type=ChangeType.FUNCTION_MODIFIED,\n                        target=func_name,\n                        old_node=base_func,\n                        new_node=modified_func\n                    ))\n            else:\n                changes.append(ASTChange(\n                    type=ChangeType.FUNCTION_ADDED,\n                    target=func_name,\n                    new_node=modified_func\n                ))\n\n        # Check for deleted functions\n        for func_name, base_func in base_functions.items():\n            if func_name not in modified_functions:\n                changes.append(ASTChange(\n                    type=ChangeType.FUNCTION_DELETED,\n                    target=func_name,\n                    old_node=base_func\n                ))\n\n        # Compare class definitions\n        # Compare imports\n        # Compare global variables\n        # etc.\n\n        return changes\n\n    async def resolve_conflicts(self, conflicts: List[ConflictingChange]) -&gt; List[ASTChange]:\n        \"\"\"Resolve conflicts between AST changes\"\"\"\n        resolved = []\n\n        for conflict in conflicts:\n            if conflict.type == ConflictType.FUNCTION_MODIFICATION:\n                # Try to merge function bodies\n                merged_function = await self._merge_function_bodies(\n                    conflict.change1.new_node,\n                    conflict.change2.new_node\n                )\n                if merged_function:\n                    resolved.append(ASTChange(\n                        type=ChangeType.FUNCTION_MODIFIED,\n                        target=conflict.target,\n                        new_node=merged_function\n                    ))\n                else:\n                    raise ConflictResolutionError(f\"Cannot merge function {conflict.target}\")\n\n            elif conflict.type == ConflictType.IMPORT_CONFLICT:\n                # Merge import statements\n                merged_imports = self._merge_imports(\n                    conflict.change1.new_node,\n                    conflict.change2.new_node\n                )\n                resolved.extend(merged_imports)\n\n        return resolved\n</code></pre>"},{"location":"architecture/parallel-conflict-algorithms/#2-sequential-execution-resolution","title":"2. Sequential Execution Resolution","text":"<pre><code>class SequentialResolver:\n    \"\"\"Resolve conflicts by executing cycles sequentially\"\"\"\n\n    async def resolve_by_sequencing(self, conflict: Conflict) -&gt; ResolutionResult:\n        \"\"\"Resolve conflict by determining optimal execution order\"\"\"\n        cycles = conflict.cycles\n\n        # Analyze dependencies to determine order\n        order = await self._determine_optimal_order(cycles, conflict.resource)\n\n        # Pause later cycles and let first one complete\n        primary_cycle = order[0]\n        dependent_cycles = order[1:]\n\n        for cycle_id in dependent_cycles:\n            await self._pause_cycle(cycle_id, reason=f\"Waiting for {primary_cycle}\")\n\n        # Set up dependency chain\n        for i, cycle_id in enumerate(dependent_cycles):\n            depends_on = primary_cycle if i == 0 else dependent_cycles[i-1]\n            await self._set_dependency(cycle_id, depends_on)\n\n        return ResolutionResult(\n            success=True,\n            resolution_method=\"sequential_execution\",\n            execution_order=order,\n            estimated_delay=await self._estimate_sequential_delay(order)\n        )\n\n    async def _determine_optimal_order(\n        self, \n        cycle_ids: List[str], \n        resource: str\n    ) -&gt; List[str]:\n        \"\"\"Determine optimal execution order to minimize total time\"\"\"\n        cycle_info = []\n\n        for cycle_id in cycle_ids:\n            cycle = await self._get_cycle(cycle_id)\n            info = CycleOrderInfo(\n                cycle_id=cycle_id,\n                priority=cycle.execution_priority,\n                estimated_time=await self._estimate_cycle_time(cycle),\n                dependencies=await self._analyze_cycle_dependencies(cycle),\n                complexity=await self._calculate_cycle_complexity(cycle)\n            )\n            cycle_info.append(info)\n\n        # Use weighted scoring for ordering\n        def score_function(info: CycleOrderInfo) -&gt; float:\n            return (\n                info.priority * 0.4 +          # Higher priority first\n                (1.0 / info.estimated_time) * 0.3 +  # Shorter cycles first\n                (1.0 / info.complexity) * 0.2 +      # Simpler cycles first\n                (1.0 / len(info.dependencies)) * 0.1  # Fewer deps first\n            )\n\n        sorted_info = sorted(cycle_info, key=score_function, reverse=True)\n        return [info.cycle_id for info in sorted_info]\n</code></pre>"},{"location":"architecture/parallel-conflict-algorithms/#3-human-assisted-resolution","title":"3. Human-Assisted Resolution","text":"<pre><code>class HumanAssistedResolver:\n    \"\"\"Handle conflicts requiring human intervention\"\"\"\n\n    def __init__(self):\n        self.approval_queue = ConflictApprovalQueue()\n        self.context_provider = ConflictContextProvider()\n\n    async def request_human_resolution(self, conflict: Conflict) -&gt; ResolutionResult:\n        \"\"\"Request human intervention for complex conflict\"\"\"\n        # Prepare comprehensive context\n        context = await self.context_provider.prepare_context(conflict)\n\n        # Create approval request\n        request = ConflictResolutionRequest(\n            conflict_id=conflict.id,\n            priority=self._calculate_human_priority(conflict),\n            context=context,\n            suggested_strategies=await self._suggest_resolution_strategies(conflict),\n            timeout=timedelta(hours=4),  # 4 hour timeout\n            fallback_action=FallbackAction.PAUSE_CONFLICTING_CYCLES\n        )\n\n        # Queue for human review\n        await self.approval_queue.add_request(request)\n\n        # Wait for human response or timeout\n        try:\n            response = await asyncio.wait_for(\n                self.approval_queue.wait_for_response(request.id),\n                timeout=request.timeout.total_seconds()\n            )\n\n            return await self._apply_human_resolution(conflict, response)\n\n        except asyncio.TimeoutError:\n            # Handle timeout\n            return await self._handle_resolution_timeout(conflict, request)\n\n    async def _suggest_resolution_strategies(self, conflict: Conflict) -&gt; List[ResolutionSuggestion]:\n        \"\"\"Generate resolution suggestions for human review\"\"\"\n        suggestions = []\n\n        if conflict.type == ConflictType.FILE_OVERLAP:\n            # Analyze conflict in detail\n            analysis = await self._analyze_file_conflict(conflict)\n\n            if analysis.changes_are_disjoint:\n                suggestions.append(ResolutionSuggestion(\n                    strategy=ResolutionStrategy.AUTO_MERGE,\n                    confidence=0.8,\n                    description=\"Changes appear to be in different parts of the file\",\n                    risk=RiskLevel.LOW\n                ))\n\n            suggestions.append(ResolutionSuggestion(\n                strategy=ResolutionStrategy.SEQUENTIAL,\n                confidence=0.9,\n                description=f\"Execute {conflict.cycles[0]} first, then rebase {conflict.cycles[1]}\",\n                risk=RiskLevel.LOW,\n                estimated_delay=await self._estimate_sequential_delay(conflict.cycles)\n            ))\n\n            if analysis.semantic_conflict_likely:\n                suggestions.append(ResolutionSuggestion(\n                    strategy=ResolutionStrategy.MANUAL,\n                    confidence=0.6,\n                    description=\"Semantic conflict detected - manual code review required\",\n                    risk=RiskLevel.MEDIUM\n                ))\n\n        return sorted(suggestions, key=lambda s: s.confidence, reverse=True)\n\nclass ConflictContextProvider:\n    \"\"\"Provide rich context for human conflict resolution\"\"\"\n\n    async def prepare_context(self, conflict: Conflict) -&gt; ConflictContext:\n        \"\"\"Prepare comprehensive context for human resolver\"\"\"\n        context = ConflictContext(conflict_id=conflict.id)\n\n        # Get cycle information\n        for cycle_id in conflict.cycles:\n            cycle = await self._get_cycle(cycle_id)\n            cycle_context = await self._prepare_cycle_context(cycle)\n            context.cycles[cycle_id] = cycle_context\n\n        # Analyze the conflicting resource\n        if conflict.resource:\n            resource_context = await self._analyze_resource_conflict(\n                conflict.resource, conflict.cycles\n            )\n            context.resource_analysis = resource_context\n\n        # Provide diff visualization\n        if conflict.type == ConflictType.FILE_OVERLAP:\n            context.diff_visualization = await self._create_diff_visualization(conflict)\n\n        # Historical conflict information\n        context.similar_conflicts = await self._find_similar_historical_conflicts(conflict)\n\n        # Impact analysis\n        context.impact_analysis = await self._analyze_conflict_impact(conflict)\n\n        return context\n\n    async def _create_diff_visualization(self, conflict: Conflict) -&gt; DiffVisualization:\n        \"\"\"Create visual diff for human review\"\"\"\n        file_path = conflict.resource\n\n        # Get all versions\n        base_version = await self._get_base_version(file_path)\n        versions = {}\n        for cycle_id in conflict.cycles:\n            versions[cycle_id] = await self._get_cycle_version(cycle_id, file_path)\n\n        # Create side-by-side diff\n        diff_viz = DiffVisualization(\n            base_content=base_version.content,\n            versions=versions,\n            highlighted_conflicts=await self._highlight_conflict_regions(versions),\n            suggested_resolution=await self._suggest_merge_resolution(versions)\n        )\n\n        return diff_viz\n</code></pre>"},{"location":"architecture/parallel-conflict-algorithms/#conflict-prevention-strategies","title":"Conflict Prevention Strategies","text":""},{"location":"architecture/parallel-conflict-algorithms/#1-proactive-scheduling","title":"1. Proactive Scheduling","text":"<pre><code>class ConflictAwareScheduler:\n    \"\"\"Schedule cycles to minimize conflicts\"\"\"\n\n    async def create_conflict_minimal_schedule(\n        self, \n        stories: List[Story]\n    ) -&gt; ConflictMinimalSchedule:\n        \"\"\"Create schedule that minimizes potential conflicts\"\"\"\n\n        # Build conflict probability matrix\n        conflict_matrix = await self._build_conflict_matrix(stories)\n\n        # Use graph coloring algorithm to group non-conflicting stories\n        conflict_graph = self._build_conflict_graph(stories, conflict_matrix)\n        schedule_groups = await self._color_graph(conflict_graph)\n\n        # Optimize within groups for resource utilization\n        optimized_schedule = await self._optimize_schedule_groups(schedule_groups)\n\n        return ConflictMinimalSchedule(\n            schedule_groups=optimized_schedule,\n            predicted_conflicts=await self._predict_remaining_conflicts(optimized_schedule),\n            resource_utilization=await self._calculate_resource_utilization(optimized_schedule)\n        )\n\n    async def _build_conflict_matrix(self, stories: List[Story]) -&gt; np.ndarray:\n        \"\"\"Build matrix of conflict probabilities between stories\"\"\"\n        n = len(stories)\n        matrix = np.zeros((n, n))\n\n        predictor = PredictiveConflictAnalyzer()\n\n        for i in range(n):\n            for j in range(i+1, n):\n                prediction = await predictor.predict_conflict_probability(\n                    stories[i], stories[j]\n                )\n                matrix[i][j] = matrix[j][i] = prediction.overall_probability\n\n        return matrix\n\n    def _build_conflict_graph(self, stories: List[Story], matrix: np.ndarray) -&gt; nx.Graph:\n        \"\"\"Build graph where edges represent potential conflicts\"\"\"\n        graph = nx.Graph()\n\n        for i, story in enumerate(stories):\n            graph.add_node(i, story=story)\n\n        # Add edges for high-conflict pairs\n        threshold = 0.3  # Configurable conflict threshold\n        for i in range(len(stories)):\n            for j in range(i+1, len(stories)):\n                if matrix[i][j] &gt; threshold:\n                    graph.add_edge(i, j, weight=matrix[i][j])\n\n        return graph\n\n    async def _color_graph(self, graph: nx.Graph) -&gt; List[List[Story]]:\n        \"\"\"Use graph coloring to group non-conflicting stories\"\"\"\n        # Use greedy coloring algorithm with priority ordering\n        coloring = nx.greedy_color(graph, strategy='largest_first')\n\n        # Group stories by color\n        groups = defaultdict(list)\n        for node, color in coloring.items():\n            story = graph.nodes[node]['story']\n            groups[color].append(story)\n\n        return list(groups.values())\n</code></pre>"},{"location":"architecture/parallel-conflict-algorithms/#2-resource-partitioning","title":"2. Resource Partitioning","text":"<pre><code>class ResourcePartitioner:\n    \"\"\"Partition resources to prevent conflicts\"\"\"\n\n    async def create_resource_partitions(\n        self, \n        cycles: List[ParallelTDDCycle]\n    ) -&gt; ResourcePartitionPlan:\n        \"\"\"Create non-overlapping resource partitions\"\"\"\n\n        # Analyze resource requirements\n        resource_map = await self._analyze_resource_requirements(cycles)\n\n        # Create partitions using set cover algorithm\n        partitions = await self._partition_resources(resource_map)\n\n        # Assign cycles to partitions\n        assignments = await self._assign_cycles_to_partitions(cycles, partitions)\n\n        return ResourcePartitionPlan(\n            partitions=partitions,\n            assignments=assignments,\n            conflict_elimination_rate=await self._calculate_elimination_rate(assignments)\n        )\n\n    async def _partition_resources(\n        self, \n        resource_map: Dict[str, Set[str]]\n    ) -&gt; List[ResourcePartition]:\n        \"\"\"Partition resources to minimize overlap\"\"\"\n\n        # Use clustering algorithm to group similar resource sets\n        resource_vectors = await self._vectorize_resource_sets(resource_map)\n        clusters = await self._cluster_resources(resource_vectors)\n\n        partitions = []\n        for cluster in clusters:\n            partition = ResourcePartition(\n                partition_id=f\"partition_{len(partitions)}\",\n                file_paths=self._get_cluster_files(cluster),\n                test_paths=self._get_cluster_tests(cluster),\n                max_concurrent_cycles=await self._calculate_partition_capacity(cluster)\n            )\n            partitions.append(partition)\n\n        return partitions\n</code></pre>"},{"location":"architecture/parallel-conflict-algorithms/#performance-optimization","title":"Performance Optimization","text":""},{"location":"architecture/parallel-conflict-algorithms/#1-conflict-resolution-caching","title":"1. Conflict Resolution Caching","text":"<pre><code>class ConflictResolutionCache:\n    \"\"\"Cache conflict resolutions for similar patterns\"\"\"\n\n    def __init__(self):\n        self.resolution_cache: Dict[str, CachedResolution] = {}\n        self.pattern_matcher = ConflictPatternMatcher()\n\n    async def get_cached_resolution(self, conflict: Conflict) -&gt; Optional[ResolutionResult]:\n        \"\"\"Check if similar conflict has been resolved before\"\"\"\n        pattern_signature = await self.pattern_matcher.get_signature(conflict)\n\n        cached = self.resolution_cache.get(pattern_signature)\n        if cached and await self._is_applicable(cached, conflict):\n            # Adapt cached resolution to current context\n            adapted_resolution = await self._adapt_resolution(cached.resolution, conflict)\n            return adapted_resolution\n\n        return None\n\n    async def cache_resolution(self, conflict: Conflict, resolution: ResolutionResult):\n        \"\"\"Cache successful resolution for future use\"\"\"\n        if resolution.success and resolution.confidence &gt; 0.8:\n            pattern_signature = await self.pattern_matcher.get_signature(conflict)\n\n            cached = CachedResolution(\n                pattern_signature=pattern_signature,\n                resolution=resolution,\n                conflict_pattern=await self._extract_pattern(conflict),\n                success_rate=1.0,\n                usage_count=1,\n                cached_at=datetime.now()\n            )\n\n            self.resolution_cache[pattern_signature] = cached\n</code></pre>"},{"location":"architecture/parallel-conflict-algorithms/#2-parallel-conflict-detection","title":"2. Parallel Conflict Detection","text":"<pre><code>class ParallelConflictDetector:\n    \"\"\"Detect conflicts in parallel for better performance\"\"\"\n\n    async def detect_all_conflicts(\n        self, \n        cycles: List[ParallelTDDCycle]\n    ) -&gt; List[Conflict]:\n        \"\"\"Detect all conflicts between cycles in parallel\"\"\"\n\n        # Create detection tasks for all pairs\n        detection_tasks = []\n        for i, cycle1 in enumerate(cycles):\n            for cycle2 in cycles[i+1:]:\n                task = asyncio.create_task(\n                    self._detect_pair_conflicts(cycle1, cycle2)\n                )\n                detection_tasks.append(task)\n\n        # Run all detections in parallel\n        results = await asyncio.gather(*detection_tasks)\n\n        # Flatten and deduplicate conflicts\n        all_conflicts = []\n        for conflict_list in results:\n            all_conflicts.extend(conflict_list)\n\n        return self._deduplicate_conflicts(all_conflicts)\n\n    async def _detect_pair_conflicts(\n        self, \n        cycle1: ParallelTDDCycle, \n        cycle2: ParallelTDDCycle\n    ) -&gt; List[Conflict]:\n        \"\"\"Detect conflicts between a specific pair of cycles\"\"\"\n        conflicts = []\n\n        # Run different conflict detection methods in parallel\n        detection_methods = [\n            self._detect_file_conflicts(cycle1, cycle2),\n            self._detect_test_conflicts(cycle1, cycle2),\n            self._detect_dependency_conflicts(cycle1, cycle2)\n        ]\n\n        method_results = await asyncio.gather(*detection_methods)\n\n        for method_conflicts in method_results:\n            conflicts.extend(method_conflicts)\n\n        return conflicts\n</code></pre>"},{"location":"architecture/parallel-conflict-algorithms/#monitoring-and-metrics","title":"Monitoring and Metrics","text":""},{"location":"architecture/parallel-conflict-algorithms/#1-conflict-resolution-metrics","title":"1. Conflict Resolution Metrics","text":"<pre><code>@dataclass\nclass ConflictMetrics:\n    \"\"\"Metrics for conflict detection and resolution\"\"\"\n\n    # Detection metrics\n    total_conflicts_detected: int = 0\n    conflicts_by_type: Dict[ConflictType, int] = field(default_factory=dict)\n    detection_accuracy: float = 0.0  # True positives / (TP + FP)\n    detection_latency_ms: float = 0.0\n\n    # Resolution metrics\n    auto_resolution_rate: float = 0.0  # Automatically resolved / total\n    manual_resolution_rate: float = 0.0\n    average_resolution_time: timedelta = timedelta()\n    resolution_success_rate: float = 0.0\n\n    # Impact metrics\n    cycles_delayed: int = 0\n    total_delay_time: timedelta = timedelta()\n    rollbacks_required: int = 0\n    quality_impact: float = 0.0  # Test pass rate change\n\n    def calculate_efficiency_score(self) -&gt; float:\n        \"\"\"Calculate overall conflict resolution efficiency\"\"\"\n        return (\n            self.auto_resolution_rate * 0.4 +\n            self.resolution_success_rate * 0.3 +\n            (1.0 - self.rollbacks_required / max(self.total_conflicts_detected, 1)) * 0.2 +\n            min(self.detection_accuracy, 1.0) * 0.1\n        )\n</code></pre> <p>This comprehensive conflict resolution system provides multiple layers of detection and resolution strategies, ensuring that parallel TDD execution can handle conflicts efficiently while maintaining code quality and system reliability.</p>"},{"location":"architecture/parallel-context-integration/","title":"Parallel Context Management Integration","text":""},{"location":"architecture/parallel-context-integration/#executive-summary","title":"Executive Summary","text":"<p>This document specifies the integration of the Context Management System (CMS) with parallel TDD execution. The system provides intelligent context isolation, optimized token distribution, and sophisticated context sharing mechanisms that enable efficient parallel development while maintaining context quality and relevance.</p>"},{"location":"architecture/parallel-context-integration/#parallel-context-architecture","title":"Parallel Context Architecture","text":""},{"location":"architecture/parallel-context-integration/#1-multi-context-coordination","title":"1. Multi-Context Coordination","text":"<pre><code>class ParallelContextManager:\n    \"\"\"Central coordinator for context across parallel TDD cycles\"\"\"\n\n    def __init__(self, base_context_manager: ContextManager):\n        self.base_context = base_context_manager\n        self.isolated_contexts: Dict[str, IsolatedCycleContext] = {}\n        self.shared_knowledge_base = SharedKnowledgeBase()\n        self.token_budget_manager = ParallelTokenBudgetManager()\n        self.context_optimizer = ParallelContextOptimizer()\n        self.dependency_tracker = ContextDependencyTracker()\n\n    async def create_cycle_context(\n        self, \n        cycle_id: str, \n        story: Story,\n        parallel_group: ParallelGroup\n    ) -&gt; IsolatedCycleContext:\n        \"\"\"Create optimally isolated context for a TDD cycle\"\"\"\n\n        # Calculate optimal token allocation\n        token_allocation = await self.token_budget_manager.allocate_for_cycle(\n            cycle_id, parallel_group\n        )\n\n        # Determine context scope based on story analysis\n        context_scope = await self._analyze_context_scope(story, parallel_group)\n\n        # Create isolated context\n        context = IsolatedCycleContext(\n            cycle_id=cycle_id,\n            story_id=story.id,\n            token_budget=token_allocation,\n            scope=context_scope,\n            shared_knowledge=self.shared_knowledge_base.get_readonly_view()\n        )\n\n        # Populate with story-specific context\n        await self._populate_story_context(context, story)\n\n        # Apply parallel-specific optimizations\n        await self.context_optimizer.optimize_for_parallel(context, parallel_group)\n\n        # Set up dependency tracking\n        await self.dependency_tracker.track_context_dependencies(context, parallel_group)\n\n        self.isolated_contexts[cycle_id] = context\n        return context\n\n    async def _analyze_context_scope(\n        self, \n        story: Story, \n        parallel_group: ParallelGroup\n    ) -&gt; ContextScope:\n        \"\"\"Analyze optimal context scope to minimize conflicts and maximize relevance\"\"\"\n\n        # Base scope from story requirements\n        base_files = await self._get_story_files(story)\n        base_dependencies = await self._analyze_dependencies(base_files)\n\n        # Expand scope based on parallel execution needs\n        parallel_considerations = await self._analyze_parallel_scope_needs(\n            story, parallel_group\n        )\n\n        # Calculate conflict boundaries with other cycles\n        conflict_boundaries = await self._calculate_conflict_boundaries(\n            story, parallel_group\n        )\n\n        # Optimize scope to balance completeness vs isolation\n        optimized_scope = await self._optimize_context_scope(\n            base_files, base_dependencies, parallel_considerations, conflict_boundaries\n        )\n\n        return ContextScope(\n            core_files=optimized_scope.core_files,\n            dependency_files=optimized_scope.dependency_files,\n            test_files=optimized_scope.test_files,\n            documentation_files=optimized_scope.documentation_files,\n            exclusion_patterns=optimized_scope.exclusions,\n            max_file_count=min(optimized_scope.file_count, 200),  # Parallel limit\n            isolation_level=optimized_scope.isolation_level\n        )\n\n    async def _optimize_context_scope(\n        self,\n        base_files: Set[str],\n        dependencies: Set[str], \n        parallel_needs: ParallelScopeAnalysis,\n        boundaries: ConflictBoundaries\n    ) -&gt; OptimizedScope:\n        \"\"\"Optimize context scope for parallel execution\"\"\"\n\n        # Start with base files\n        core_files = base_files.copy()\n\n        # Add critical dependencies\n        critical_deps = dependencies &amp; parallel_needs.critical_dependencies\n        core_files.update(critical_deps)\n\n        # Remove files that would cause conflicts\n        conflicting_files = core_files &amp; boundaries.conflicting_files\n        if conflicting_files:\n            # Try to find alternative context for conflicting files\n            alternatives = await self._find_alternative_context(conflicting_files)\n            core_files = (core_files - conflicting_files) | alternatives\n\n        # Add parallel-specific requirements\n        if parallel_needs.requires_shared_state:\n            shared_state_files = await self._get_shared_state_files(parallel_needs)\n            core_files.update(shared_state_files)\n\n        # Limit scope to fit token budget\n        if len(core_files) &gt; parallel_needs.max_files_for_budget:\n            core_files = await self._prioritize_files_for_budget(\n                core_files, parallel_needs.max_files_for_budget\n            )\n\n        return OptimizedScope(\n            core_files=core_files,\n            dependency_files=dependencies - core_files,\n            test_files=await self._get_test_files_for_scope(core_files),\n            documentation_files=await self._get_docs_for_scope(core_files),\n            exclusions=boundaries.exclusion_patterns,\n            file_count=len(core_files),\n            isolation_level=parallel_needs.recommended_isolation\n        )\n\nclass IsolatedCycleContext:\n    \"\"\"Context isolated for a specific TDD cycle with parallel optimization\"\"\"\n\n    def __init__(\n        self, \n        cycle_id: str, \n        story_id: str,\n        token_budget: int,\n        scope: ContextScope,\n        shared_knowledge: ReadOnlyKnowledgeView\n    ):\n        self.cycle_id = cycle_id\n        self.story_id = story_id\n        self.token_budget = token_budget\n        self.tokens_used = 0\n        self.scope = scope\n        self.shared_knowledge = shared_knowledge\n\n        # Context caches for performance\n        self.file_content_cache: Dict[str, str] = {}\n        self.compressed_content_cache: Dict[str, str] = {}\n        self.relevance_scores: Dict[str, float] = {}\n\n        # Parallel-specific features\n        self.context_updates: List[ContextUpdate] = []\n        self.dependency_changes: List[DependencyChange] = []\n        self.shared_context_keys: Set[str] = set()\n\n    async def get_context_for_agent(\n        self, \n        agent_type: AgentType, \n        task: TDDTask\n    ) -&gt; AgentContext:\n        \"\"\"Get optimized context for specific agent and task\"\"\"\n\n        # Calculate agent-specific context needs\n        context_needs = await self._analyze_agent_context_needs(agent_type, task)\n\n        # Get relevant files within scope\n        relevant_files = await self._get_relevant_files(context_needs)\n\n        # Apply context compression to fit token budget\n        compressed_context = await self._compress_context_for_agent(\n            relevant_files, agent_type, context_needs\n        )\n\n        # Add shared knowledge relevant to task\n        shared_context = await self._get_relevant_shared_knowledge(\n            agent_type, task, context_needs\n        )\n\n        # Combine into agent context\n        agent_context = AgentContext(\n            cycle_id=self.cycle_id,\n            agent_type=agent_type,\n            task_id=task.id,\n            files=compressed_context.files,\n            shared_knowledge=shared_context,\n            metadata=compressed_context.metadata,\n            token_count=compressed_context.token_count,\n            relevance_score=compressed_context.overall_relevance\n        )\n\n        # Update usage tracking\n        self.tokens_used += agent_context.token_count\n\n        return agent_context\n\n    async def _compress_context_for_agent(\n        self,\n        relevant_files: List[RelevantFile],\n        agent_type: AgentType,\n        context_needs: ContextNeeds\n    ) -&gt; CompressedContext:\n        \"\"\"Apply intelligent compression for agent type and parallel constraints\"\"\"\n\n        # Calculate available token budget\n        remaining_budget = self.token_budget - self.tokens_used\n        agent_budget = min(remaining_budget, context_needs.preferred_token_count)\n\n        # Apply agent-specific compression strategies\n        compression_strategy = self._get_compression_strategy(agent_type)\n\n        compressed_files = []\n        total_tokens = 0\n\n        # Process files in order of relevance\n        sorted_files = sorted(relevant_files, key=lambda f: f.relevance_score, reverse=True)\n\n        for file_info in sorted_files:\n            if total_tokens &gt;= agent_budget * 0.9:  # Leave 10% buffer\n                break\n\n            # Apply compression based on file type and agent needs\n            if file_info.file_path in self.compressed_content_cache:\n                compressed_content = self.compressed_content_cache[file_info.file_path]\n            else:\n                compressed_content = await compression_strategy.compress_file(\n                    file_info, context_needs\n                )\n                self.compressed_content_cache[file_info.file_path] = compressed_content\n\n            file_tokens = await self._estimate_tokens(compressed_content)\n\n            if total_tokens + file_tokens &lt;= agent_budget:\n                compressed_files.append(CompressedFile(\n                    path=file_info.file_path,\n                    content=compressed_content,\n                    original_size=len(file_info.content),\n                    compressed_size=len(compressed_content),\n                    compression_ratio=len(compressed_content) / len(file_info.content),\n                    relevance=file_info.relevance_score,\n                    tokens=file_tokens\n                ))\n                total_tokens += file_tokens\n\n        return CompressedContext(\n            files=compressed_files,\n            metadata=self._create_context_metadata(compressed_files),\n            token_count=total_tokens,\n            compression_stats=self._calculate_compression_stats(compressed_files),\n            overall_relevance=sum(f.relevance for f in compressed_files) / len(compressed_files)\n        )\n</code></pre>"},{"location":"architecture/parallel-context-integration/#2-token-budget-management-for-parallel-execution","title":"2. Token Budget Management for Parallel Execution","text":"<pre><code>class ParallelTokenBudgetManager:\n    \"\"\"Intelligent token budget allocation across parallel cycles\"\"\"\n\n    def __init__(self, total_budget: int = 200000):\n        self.total_budget = total_budget\n        self.system_reserve = int(total_budget * 0.1)  # 10% system reserve\n        self.available_budget = total_budget - self.system_reserve\n\n        self.allocations: Dict[str, TokenAllocation] = {}\n        self.usage_history: Dict[str, List[TokenUsage]] = defaultdict(list)\n        self.predictive_model = TokenUsagePredictionModel()\n\n    async def allocate_for_cycle(\n        self, \n        cycle_id: str, \n        parallel_group: ParallelGroup\n    ) -&gt; TokenAllocation:\n        \"\"\"Allocate optimal token budget for a cycle in parallel group\"\"\"\n\n        # Analyze current allocations\n        current_allocations = [a for a in self.allocations.values() if a.is_active()]\n        active_cycles = len(current_allocations)\n\n        # Predict usage for this cycle\n        predicted_usage = await self.predictive_model.predict_cycle_usage(\n            cycle_id, parallel_group\n        )\n\n        # Calculate base allocation\n        base_allocation = self._calculate_base_allocation(\n            active_cycles + 1, predicted_usage\n        )\n\n        # Apply intelligent adjustments\n        adjusted_allocation = await self._apply_intelligent_adjustments(\n            base_allocation, cycle_id, parallel_group, predicted_usage\n        )\n\n        # Ensure we don't exceed available budget\n        final_allocation = await self._ensure_budget_compliance(\n            adjusted_allocation, current_allocations\n        )\n\n        allocation = TokenAllocation(\n            cycle_id=cycle_id,\n            allocated_tokens=final_allocation.tokens,\n            priority_multiplier=final_allocation.priority_multiplier,\n            phase_adjustments=final_allocation.phase_adjustments,\n            sharing_permissions=final_allocation.sharing_permissions,\n            allocated_at=datetime.now(),\n            expires_at=datetime.now() + timedelta(hours=6)\n        )\n\n        self.allocations[cycle_id] = allocation\n        return allocation\n\n    async def _apply_intelligent_adjustments(\n        self,\n        base_allocation: BaseAllocation,\n        cycle_id: str,\n        parallel_group: ParallelGroup,\n        predicted_usage: PredictedUsage\n    ) -&gt; AdjustedAllocation:\n        \"\"\"Apply intelligent adjustments based on multiple factors\"\"\"\n\n        adjustments = AdjustedAllocation(\n            tokens=base_allocation.tokens,\n            priority_multiplier=1.0,\n            phase_adjustments={},\n            sharing_permissions=set()\n        )\n\n        # Story complexity adjustment\n        story_complexity = await self._analyze_story_complexity(cycle_id)\n        if story_complexity.complexity_score &gt; 0.8:\n            adjustments.tokens = int(adjustments.tokens * 1.3)  # 30% more for complex stories\n        elif story_complexity.complexity_score &lt; 0.3:\n            adjustments.tokens = int(adjustments.tokens * 0.8)  # 20% less for simple stories\n\n        # TDD phase adjustments\n        adjustments.phase_adjustments = {\n            TDDState.DESIGN: 1.2,      # Design needs more context\n            TDDState.TEST_RED: 1.0,    # Standard allocation\n            TDDState.CODE_GREEN: 1.1,  # Implementation needs good context\n            TDDState.REFACTOR: 0.9,    # Refactoring needs less new context\n            TDDState.COMMIT: 0.7       # Minimal context for commits\n        }\n\n        # Parallel coordination adjustments\n        coordination_needs = await self._analyze_coordination_needs(\n            cycle_id, parallel_group\n        )\n\n        if coordination_needs.requires_shared_context:\n            adjustments.sharing_permissions.add('shared_state')\n            adjustments.tokens = int(adjustments.tokens * 0.9)  # 10% less for individual use\n\n        if coordination_needs.high_conflict_risk:\n            adjustments.tokens = int(adjustments.tokens * 1.1)  # 10% more for conflict resolution\n\n        # Historical usage adjustment\n        historical_efficiency = await self._get_historical_efficiency(cycle_id)\n        if historical_efficiency &gt; 0.9:  # Very efficient usage\n            adjustments.tokens = int(adjustments.tokens * 0.95)  # Slightly reduce\n        elif historical_efficiency &lt; 0.6:  # Inefficient usage\n            adjustments.tokens = int(adjustments.tokens * 1.05)  # Slightly increase\n\n        return adjustments\n\n    async def rebalance_budgets(self) -&gt; RebalancingResult:\n        \"\"\"Dynamically rebalance token budgets across active cycles\"\"\"\n\n        # Analyze current usage patterns\n        usage_analysis = await self._analyze_current_usage()\n\n        # Identify rebalancing opportunities\n        opportunities = await self._identify_rebalancing_opportunities(usage_analysis)\n\n        if not opportunities:\n            return RebalancingResult(rebalanced=False, reason=\"No opportunities found\")\n\n        # Execute rebalancing\n        rebalancing_plan = await self._create_rebalancing_plan(opportunities)\n        results = await self._execute_rebalancing(rebalancing_plan)\n\n        return RebalancingResult(\n            rebalanced=True,\n            cycles_adjusted=len(results),\n            tokens_redistributed=sum(r.tokens_moved for r in results),\n            efficiency_improvement=await self._calculate_efficiency_improvement(results)\n        )\n\n    async def _identify_rebalancing_opportunities(\n        self, \n        usage_analysis: UsageAnalysis\n    ) -&gt; List[RebalancingOpportunity]:\n        \"\"\"Identify token budget rebalancing opportunities\"\"\"\n        opportunities = []\n\n        for cycle_id, usage in usage_analysis.cycle_usage.items():\n            allocation = self.allocations.get(cycle_id)\n            if not allocation:\n                continue\n\n            # Over-allocated cycles (using much less than allocated)\n            if usage.efficiency &lt; 0.4:  # Using less than 40% efficiently\n                tokens_to_free = int(allocation.allocated_tokens * 0.3)\n                opportunities.append(RebalancingOpportunity(\n                    cycle_id=cycle_id,\n                    type=RebalancingType.REDUCE_ALLOCATION,\n                    tokens_available=tokens_to_free,\n                    confidence=0.8,\n                    reason=f\"Low efficiency: {usage.efficiency:.2f}\"\n                ))\n\n            # Under-allocated cycles (running out of tokens)\n            elif usage.utilization &gt; 0.9:  # Using more than 90% of allocation\n                tokens_needed = int(allocation.allocated_tokens * 0.4)\n                opportunities.append(RebalancingOpportunity(\n                    cycle_id=cycle_id,\n                    type=RebalancingType.INCREASE_ALLOCATION,\n                    tokens_needed=tokens_needed,\n                    confidence=0.9,\n                    reason=f\"High utilization: {usage.utilization:.2f}\"\n                ))\n\n        return opportunities\n\nclass TokenUsagePredictionModel:\n    \"\"\"ML-based prediction of token usage for cycles\"\"\"\n\n    def __init__(self):\n        self.usage_model = self._load_usage_model()\n        self.feature_extractor = TokenUsageFeatureExtractor()\n\n    async def predict_cycle_usage(\n        self, \n        cycle_id: str, \n        parallel_group: ParallelGroup\n    ) -&gt; PredictedUsage:\n        \"\"\"Predict token usage for a cycle\"\"\"\n\n        # Extract features for prediction\n        features = await self.feature_extractor.extract_features(\n            cycle_id, parallel_group\n        )\n\n        # Predict different aspects of usage\n        total_usage = self.usage_model.total_usage.predict([features])[0]\n        peak_usage = self.usage_model.peak_usage.predict([features])[0]\n        phase_distribution = self.usage_model.phase_distribution.predict([features])[0]\n\n        return PredictedUsage(\n            total_tokens=int(total_usage),\n            peak_tokens_per_hour=int(peak_usage),\n            phase_distribution=dict(zip(\n                [s.value for s in TDDState], \n                phase_distribution\n            )),\n            confidence=self.usage_model.confidence_score([features])[0]\n        )\n\nclass TokenUsageFeatureExtractor:\n    \"\"\"Extract features for token usage prediction\"\"\"\n\n    async def extract_features(\n        self, \n        cycle_id: str, \n        parallel_group: ParallelGroup\n    ) -&gt; np.ndarray:\n        \"\"\"Extract feature vector for usage prediction\"\"\"\n        features = []\n\n        # Story characteristics\n        story = await self._get_story_for_cycle(cycle_id)\n        features.extend([\n            len(story.description),\n            len(story.acceptance_criteria),\n            story.story_points or 3,  # Default to 3 if not set\n            len(story.files or []),\n            story.priority\n        ])\n\n        # Code complexity features\n        if story.files:\n            complexity = await self._analyze_code_complexity(story.files)\n            features.extend([\n                complexity.cyclomatic_complexity,\n                complexity.lines_of_code,\n                complexity.function_count,\n                complexity.class_count\n            ])\n        else:\n            features.extend([0, 0, 0, 0])  # Default values\n\n        # Parallel context features\n        features.extend([\n            len(parallel_group.cycles),\n            parallel_group.conflict_risk_score,\n            1 if parallel_group.requires_coordination else 0,\n            parallel_group.shared_file_count\n        ])\n\n        # Historical features\n        historical_usage = await self._get_historical_usage(cycle_id)\n        features.extend([\n            historical_usage.average_total_usage,\n            historical_usage.average_efficiency,\n            historical_usage.completion_rate\n        ])\n\n        # Temporal features\n        features.extend([\n            datetime.now().hour,  # Time of day\n            datetime.now().weekday(),  # Day of week\n            1 if self._is_peak_usage_time() else 0\n        ])\n\n        return np.array(features)\n</code></pre>"},{"location":"architecture/parallel-context-integration/#3-context-sharing-and-coordination","title":"3. Context Sharing and Coordination","text":"<pre><code>class ContextSharingCoordinator:\n    \"\"\"Coordinate context sharing between parallel cycles\"\"\"\n\n    def __init__(self):\n        self.shared_contexts: Dict[str, SharedContext] = {}\n        self.sharing_policies = ContextSharingPolicies()\n        self.conflict_detector = ContextConflictDetector()\n\n    async def share_context(\n        self,\n        from_cycle: str,\n        to_cycle: str,\n        context_keys: List[str],\n        sharing_mode: SharingMode = SharingMode.READ_ONLY\n    ) -&gt; ContextSharingResult:\n        \"\"\"Share specific context between cycles\"\"\"\n\n        # Validate sharing is allowed\n        validation = await self._validate_sharing(from_cycle, to_cycle, context_keys)\n        if not validation.allowed:\n            return ContextSharingResult(\n                success=False,\n                reason=validation.reason\n            )\n\n        # Check for conflicts\n        conflicts = await self.conflict_detector.detect_sharing_conflicts(\n            from_cycle, to_cycle, context_keys\n        )\n\n        if conflicts:\n            return await self._handle_sharing_conflicts(conflicts, sharing_mode)\n\n        # Execute sharing\n        shared_context = await self._create_shared_context(\n            from_cycle, to_cycle, context_keys, sharing_mode\n        )\n\n        # Update both cycles\n        await self._update_cycle_with_shared_context(to_cycle, shared_context)\n        await self._track_context_dependency(from_cycle, to_cycle, shared_context)\n\n        return ContextSharingResult(\n            success=True,\n            shared_context_id=shared_context.id,\n            token_cost=shared_context.token_cost,\n            sharing_mode=sharing_mode\n        )\n\n    async def _create_shared_context(\n        self,\n        from_cycle: str,\n        to_cycle: str,\n        context_keys: List[str],\n        sharing_mode: SharingMode\n    ) -&gt; SharedContext:\n        \"\"\"Create shared context between cycles\"\"\"\n\n        source_context = await self._get_cycle_context(from_cycle)\n        target_context = await self._get_cycle_context(to_cycle)\n\n        # Extract requested context elements\n        shared_elements = {}\n        for key in context_keys:\n            if key in source_context.elements:\n                element = source_context.elements[key]\n\n                # Apply sharing transformations\n                if sharing_mode == SharingMode.READ_ONLY:\n                    shared_element = await self._create_readonly_copy(element)\n                elif sharing_mode == SharingMode.SYNCHRONIZED:\n                    shared_element = await self._create_synchronized_element(element)\n                else:  # COPY\n                    shared_element = await self._create_deep_copy(element)\n\n                shared_elements[key] = shared_element\n\n        # Create shared context\n        shared_context = SharedContext(\n            id=f\"shared_{from_cycle}_{to_cycle}_{uuid.uuid4().hex[:8]}\",\n            from_cycle=from_cycle,\n            to_cycle=to_cycle,\n            elements=shared_elements,\n            sharing_mode=sharing_mode,\n            created_at=datetime.now(),\n            token_cost=await self._calculate_sharing_token_cost(shared_elements)\n        )\n\n        self.shared_contexts[shared_context.id] = shared_context\n        return shared_context\n\nclass ContextConflictDetector:\n    \"\"\"Detect conflicts in context sharing\"\"\"\n\n    async def detect_sharing_conflicts(\n        self,\n        from_cycle: str,\n        to_cycle: str,\n        context_keys: List[str]\n    ) -&gt; List[ContextConflict]:\n        \"\"\"Detect potential conflicts from context sharing\"\"\"\n        conflicts = []\n\n        source_context = await self._get_cycle_context(from_cycle)\n        target_context = await self._get_cycle_context(to_cycle)\n\n        for key in context_keys:\n            # Check for key conflicts\n            if key in target_context.elements:\n                existing_element = target_context.elements[key]\n                shared_element = source_context.elements[key]\n\n                if await self._elements_conflict(existing_element, shared_element):\n                    conflicts.append(ContextConflict(\n                        type=ConflictType.KEY_COLLISION,\n                        key=key,\n                        from_cycle=from_cycle,\n                        to_cycle=to_cycle,\n                        severity=await self._calculate_conflict_severity(\n                            existing_element, shared_element\n                        )\n                    ))\n\n            # Check for semantic conflicts\n            semantic_conflicts = await self._detect_semantic_conflicts(\n                key, source_context, target_context\n            )\n            conflicts.extend(semantic_conflicts)\n\n        return conflicts\n\n    async def _elements_conflict(\n        self, \n        element1: ContextElement, \n        element2: ContextElement\n    ) -&gt; bool:\n        \"\"\"Check if two context elements conflict\"\"\"\n\n        # Type conflicts\n        if element1.element_type != element2.element_type:\n            return True\n\n        # Content conflicts (for file content)\n        if element1.element_type == ElementType.FILE_CONTENT:\n            return await self._file_contents_conflict(element1.content, element2.content)\n\n        # Version conflicts\n        if hasattr(element1, 'version') and hasattr(element2, 'version'):\n            return element1.version != element2.version\n\n        return False\n\n    async def _file_contents_conflict(self, content1: str, content2: str) -&gt; bool:\n        \"\"\"Check if file contents conflict\"\"\"\n        # Use AST comparison for code files\n        if self._is_code_file(content1):\n            try:\n                ast1 = ast.parse(content1)\n                ast2 = ast.parse(content2)\n                return not self._asts_compatible(ast1, ast2)\n            except SyntaxError:\n                # Fall back to text comparison\n                return content1 != content2\n        else:\n            # Text comparison for non-code files\n            return content1 != content2\n</code></pre>"},{"location":"architecture/parallel-context-integration/#4-context-optimization-for-parallel-execution","title":"4. Context Optimization for Parallel Execution","text":"<pre><code>class ParallelContextOptimizer:\n    \"\"\"Optimize context for parallel execution efficiency\"\"\"\n\n    def __init__(self):\n        self.compression_strategies = {\n            AgentType.DESIGN: DesignContextCompressor(),\n            AgentType.QA: QAContextCompressor(),\n            AgentType.CODE: CodeContextCompressor(),\n            AgentType.DATA: DataContextCompressor()\n        }\n        self.deduplication_engine = ContextDeduplicationEngine()\n        self.prefetch_predictor = ContextPrefetchPredictor()\n\n    async def optimize_for_parallel(\n        self, \n        context: IsolatedCycleContext,\n        parallel_group: ParallelGroup\n    ) -&gt; OptimizationResult:\n        \"\"\"Optimize context for parallel execution\"\"\"\n\n        optimizations = []\n\n        # Cross-cycle deduplication\n        dedup_result = await self.deduplication_engine.deduplicate_across_cycles(\n            context, parallel_group\n        )\n        if dedup_result.tokens_saved &gt; 0:\n            optimizations.append(dedup_result)\n\n        # Predictive prefetching\n        prefetch_result = await self.prefetch_predictor.prefetch_likely_context(\n            context, parallel_group\n        )\n        if prefetch_result.items_prefetched &gt; 0:\n            optimizations.append(prefetch_result)\n\n        # Compression optimization\n        compression_result = await self._optimize_compression(context, parallel_group)\n        if compression_result.compression_improvement &gt; 0:\n            optimizations.append(compression_result)\n\n        return OptimizationResult(\n            context_id=context.cycle_id,\n            optimizations=optimizations,\n            total_tokens_saved=sum(opt.tokens_saved for opt in optimizations),\n            performance_improvement=await self._calculate_performance_improvement(\n                optimizations\n            )\n        )\n\n    async def _optimize_compression(\n        self, \n        context: IsolatedCycleContext,\n        parallel_group: ParallelGroup\n    ) -&gt; CompressionOptimization:\n        \"\"\"Optimize compression strategies for parallel context\"\"\"\n\n        # Analyze context usage patterns across the group\n        usage_patterns = await self._analyze_group_usage_patterns(parallel_group)\n\n        # Identify commonly used context elements\n        common_elements = usage_patterns.common_elements\n        unique_elements = usage_patterns.unique_elements\n\n        compression_improvements = []\n\n        # Apply aggressive compression to unique elements\n        for element_key in unique_elements:\n            if element_key in context.scope.core_files:\n                current_compression = await self._get_current_compression_ratio(element_key)\n\n                # Try more aggressive compression\n                aggressive_compression = await self._apply_aggressive_compression(\n                    element_key, context\n                )\n\n                if aggressive_compression.ratio &gt; current_compression * 1.2:\n                    compression_improvements.append(aggressive_compression)\n\n        # Apply lighter compression to common elements (for sharing)\n        for element_key in common_elements:\n            if element_key in context.scope.core_files:\n                sharing_optimized = await self._optimize_for_sharing(\n                    element_key, context, parallel_group\n                )\n                compression_improvements.append(sharing_optimized)\n\n        return CompressionOptimization(\n            improvements=compression_improvements,\n            compression_improvement=sum(\n                imp.improvement_ratio for imp in compression_improvements\n            ),\n            tokens_saved=sum(imp.tokens_saved for imp in compression_improvements)\n        )\n\nclass ContextDeduplicationEngine:\n    \"\"\"Deduplicate context across parallel cycles\"\"\"\n\n    async def deduplicate_across_cycles(\n        self, \n        context: IsolatedCycleContext,\n        parallel_group: ParallelGroup\n    ) -&gt; DeduplicationResult:\n        \"\"\"Remove duplicate context across parallel cycles\"\"\"\n\n        # Analyze context overlap across cycles\n        overlap_analysis = await self._analyze_context_overlap(\n            context, parallel_group\n        )\n\n        deduplication_actions = []\n\n        # Identify exact duplicates\n        exact_duplicates = overlap_analysis.exact_matches\n        for duplicate_key, cycles in exact_duplicates.items():\n            if len(cycles) &gt; 1:  # Duplicate across multiple cycles\n                # Move to shared context\n                sharing_action = await self._move_to_shared_context(\n                    duplicate_key, cycles, context\n                )\n                deduplication_actions.append(sharing_action)\n\n        # Identify near-duplicates that can be merged\n        near_duplicates = overlap_analysis.near_matches\n        for near_duplicate_group in near_duplicates:\n            if len(near_duplicate_group.keys) &gt; 1:\n                merge_action = await self._merge_near_duplicates(\n                    near_duplicate_group, context\n                )\n                deduplication_actions.append(merge_action)\n\n        return DeduplicationResult(\n            actions=deduplication_actions,\n            tokens_saved=sum(action.tokens_saved for action in deduplication_actions),\n            files_deduplicated=len(deduplication_actions)\n        )\n\n    async def _move_to_shared_context(\n        self,\n        context_key: str,\n        involved_cycles: List[str],\n        source_context: IsolatedCycleContext\n    ) -&gt; DeduplicationAction:\n        \"\"\"Move duplicate context to shared space\"\"\"\n\n        # Create shared context entry\n        shared_entry = await self._create_shared_entry(context_key, source_context)\n\n        # Calculate token savings\n        individual_cost = await self._calculate_individual_context_cost(context_key)\n        shared_cost = await self._calculate_shared_context_cost(context_key)\n        tokens_saved = (individual_cost * len(involved_cycles)) - shared_cost\n\n        return DeduplicationAction(\n            type=DeduplicationType.MOVE_TO_SHARED,\n            context_key=context_key,\n            involved_cycles=involved_cycles,\n            shared_entry_id=shared_entry.id,\n            tokens_saved=tokens_saved\n        )\n\nclass ContextPrefetchPredictor:\n    \"\"\"Predict and prefetch likely needed context\"\"\"\n\n    def __init__(self):\n        self.usage_patterns = ContextUsagePatterns()\n        self.dependency_analyzer = ContextDependencyAnalyzer()\n\n    async def prefetch_likely_context(\n        self,\n        context: IsolatedCycleContext,\n        parallel_group: ParallelGroup\n    ) -&gt; PrefetchResult:\n        \"\"\"Prefetch context likely to be needed\"\"\"\n\n        # Analyze current context usage\n        current_files = set(context.scope.core_files)\n\n        # Predict likely next files based on patterns\n        likely_files = await self._predict_likely_files(\n            current_files, context.story_id\n        )\n\n        # Analyze dependencies that might be needed\n        dependency_predictions = await self.dependency_analyzer.predict_dependencies(\n            current_files, context\n        )\n\n        # Combine predictions\n        prefetch_candidates = (likely_files | dependency_predictions.likely_dependencies)\n\n        # Filter candidates that fit in remaining token budget\n        remaining_budget = context.token_budget - context.tokens_used\n        feasible_candidates = await self._filter_by_token_budget(\n            prefetch_candidates, remaining_budget * 0.2  # Use max 20% for prefetch\n        )\n\n        # Execute prefetching\n        prefetch_actions = []\n        for candidate in feasible_candidates:\n            action = await self._prefetch_context_item(candidate, context)\n            prefetch_actions.append(action)\n\n        return PrefetchResult(\n            items_prefetched=len(prefetch_actions),\n            tokens_used=sum(action.tokens_used for action in prefetch_actions),\n            predicted_time_savings=await self._calculate_time_savings(prefetch_actions)\n        )\n</code></pre>"},{"location":"architecture/parallel-context-integration/#5-performance-monitoring-and-metrics","title":"5. Performance Monitoring and Metrics","text":"<pre><code>class ParallelContextMetrics:\n    \"\"\"Monitor context performance in parallel execution\"\"\"\n\n    def __init__(self):\n        self.metrics_collector = ContextMetricsCollector()\n        self.performance_analyzer = ContextPerformanceAnalyzer()\n\n    async def collect_parallel_metrics(\n        self, \n        parallel_group: ParallelGroup\n    ) -&gt; ParallelContextMetrics:\n        \"\"\"Collect comprehensive context metrics for parallel group\"\"\"\n\n        metrics = ParallelContextMetrics(\n            group_id=parallel_group.id,\n            timestamp=datetime.now(),\n\n            # Token usage metrics\n            total_tokens_allocated=sum(\n                ctx.token_budget for ctx in parallel_group.contexts\n            ),\n            total_tokens_used=sum(\n                ctx.tokens_used for ctx in parallel_group.contexts\n            ),\n            token_efficiency=self._calculate_token_efficiency(parallel_group),\n\n            # Context sharing metrics\n            shared_contexts_count=len(parallel_group.shared_contexts),\n            sharing_efficiency=await self._calculate_sharing_efficiency(parallel_group),\n            deduplication_savings=await self._calculate_deduplication_savings(parallel_group),\n\n            # Performance metrics\n            average_context_prep_time=await self._calculate_avg_prep_time(parallel_group),\n            context_cache_hit_rate=await self._calculate_cache_hit_rate(parallel_group),\n            compression_efficiency=await self._calculate_compression_efficiency(parallel_group),\n\n            # Quality metrics\n            context_relevance_score=await self._calculate_relevance_score(parallel_group),\n            context_completeness_score=await self._calculate_completeness_score(parallel_group),\n            cross_cycle_consistency=await self._calculate_consistency_score(parallel_group)\n        )\n\n        await self.metrics_collector.store_metrics(metrics)\n        return metrics\n\n    async def _calculate_token_efficiency(self, parallel_group: ParallelGroup) -&gt; float:\n        \"\"\"Calculate overall token usage efficiency\"\"\"\n        total_allocated = sum(ctx.token_budget for ctx in parallel_group.contexts)\n        total_used = sum(ctx.tokens_used for ctx in parallel_group.contexts)\n\n        if total_allocated == 0:\n            return 0.0\n\n        return total_used / total_allocated\n\n    async def analyze_performance_bottlenecks(\n        self, \n        parallel_group: ParallelGroup\n    ) -&gt; List[PerformanceBottleneck]:\n        \"\"\"Identify context-related performance bottlenecks\"\"\"\n\n        bottlenecks = []\n\n        # Token allocation bottlenecks\n        token_analysis = await self._analyze_token_bottlenecks(parallel_group)\n        bottlenecks.extend(token_analysis.bottlenecks)\n\n        # Context preparation bottlenecks\n        prep_analysis = await self._analyze_preparation_bottlenecks(parallel_group)\n        bottlenecks.extend(prep_analysis.bottlenecks)\n\n        # Sharing inefficiencies\n        sharing_analysis = await self._analyze_sharing_bottlenecks(parallel_group)\n        bottlenecks.extend(sharing_analysis.bottlenecks)\n\n        return sorted(bottlenecks, key=lambda b: b.impact_score, reverse=True)\n</code></pre> <p>This comprehensive parallel context integration system ensures that the Context Management System works optimally with parallel TDD execution, providing intelligent token distribution, efficient context sharing, and sophisticated optimization while maintaining context quality and agent performance.</p>"},{"location":"architecture/parallel-tdd-architecture/","title":"Parallel TDD Execution Architecture","text":""},{"location":"architecture/parallel-tdd-architecture/#executive-summary","title":"Executive Summary","text":"<p>The Parallel TDD Execution Architecture enables concurrent execution of multiple TDD cycles while maintaining code quality, preventing conflicts, and optimizing resource utilization. This architecture builds on the proven sequential TDD foundation and integrates with the Context Management System to enable 2-3x faster story completion through intelligent parallelization.</p>"},{"location":"architecture/parallel-tdd-architecture/#system-overview","title":"System Overview","text":""},{"location":"architecture/parallel-tdd-architecture/#core-capabilities","title":"Core Capabilities","text":"<ul> <li>Concurrent TDD Cycles: Run 2-5 TDD cycles in parallel with intelligent scheduling</li> <li>Conflict Prevention: Proactive detection and resolution of code conflicts</li> <li>Resource Optimization: Dynamic agent pool management with efficient allocation</li> <li>Context Isolation: Parallel-aware context management with shared knowledge</li> <li>Quality Preservation: Maintain TDD integrity and test coverage across parallel execution</li> </ul>"},{"location":"architecture/parallel-tdd-architecture/#architecture-principles","title":"Architecture Principles","text":"<ol> <li>Sequential Foundation: Preserve sequential mode as default, parallel as opt-in enhancement</li> <li>Graceful Degradation: Automatic fallback to sequential on conflict or failure</li> <li>Zero Data Corruption: Transactional state management with rollback capability</li> <li>Progressive Enhancement: Phased rollout from 2 parallel cycles to 5+</li> </ol>"},{"location":"architecture/parallel-tdd-architecture/#high-level-architecture","title":"High-Level Architecture","text":"<pre><code>graph TB\n    subgraph \"Orchestration Layer\"\n        O[Orchestrator]\n        PS[Parallel Scheduler]\n        CR[Conflict Resolver]\n    end\n\n    subgraph \"Parallel Coordination\"\n        PC[Parallel Coordinator]\n        AP[Agent Pool Manager]\n        CS[Cycle Synchronizer]\n        CD[Conflict Detector]\n    end\n\n    subgraph \"TDD Execution Engines\"\n        TE1[TDD Engine 1]\n        TE2[TDD Engine 2]\n        TE3[TDD Engine 3]\n        TEn[TDD Engine N]\n    end\n\n    subgraph \"Agent Pools\"\n        DAP[Design Agent Pool]\n        QAP[QA Agent Pool]\n        CAP[Code Agent Pool]\n        RAP[Refactor Agent Pool]\n    end\n\n    subgraph \"Context Management\"\n        CMS[Context Manager]\n        PCI[Parallel Context Isolator]\n        SCK[Shared Context Knowledge]\n        TB[Token Budget Allocator]\n    end\n\n    subgraph \"Storage &amp; State\"\n        PSS[Parallel State Store]\n        LS[Lock Service]\n        TS[Transaction Log]\n        BS[Backup Service]\n    end\n\n    O --&gt; PS\n    PS --&gt; PC\n    PC --&gt; AP\n    PC --&gt; CS\n    PC --&gt; CD\n\n    PC --&gt; TE1\n    PC --&gt; TE2\n    PC --&gt; TE3\n    PC --&gt; TEn\n\n    AP --&gt; DAP\n    AP --&gt; QAP\n    AP --&gt; CAP\n    AP --&gt; RAP\n\n    TE1 --&gt; CMS\n    TE2 --&gt; CMS\n    TE3 --&gt; CMS\n    TEn --&gt; CMS\n\n    CMS --&gt; PCI\n    CMS --&gt; SCK\n    CMS --&gt; TB\n\n    CS --&gt; PSS\n    CD --&gt; LS\n    PC --&gt; TS\n    PSS --&gt; BS</code></pre>"},{"location":"architecture/parallel-tdd-architecture/#core-components","title":"Core Components","text":""},{"location":"architecture/parallel-tdd-architecture/#1-parallel-coordinator-central-brain","title":"1. Parallel Coordinator (Central Brain)","text":"<p>Responsibilities: - Orchestrate multiple TDD cycles concurrently - Manage cycle lifecycle and state transitions - Coordinate resource allocation and scheduling - Handle conflict detection and resolution</p> <p>Key Interfaces: <pre><code>class ParallelCoordinator:\n    async def start_parallel_cycle(self, story_id: str, priority: int) -&gt; TDDCycle\n    async def schedule_cycles(self, pending_stories: List[Story]) -&gt; List[TDDCycle]\n    async def detect_conflicts(self, cycle1: TDDCycle, cycle2: TDDCycle) -&gt; List[Conflict]\n    async def resolve_conflicts(self, conflicts: List[Conflict]) -&gt; ResolutionStrategy\n    async def monitor_parallel_execution(self) -&gt; ParallelStatus\n</code></pre></p>"},{"location":"architecture/parallel-tdd-architecture/#2-agent-pool-manager","title":"2. Agent Pool Manager","text":"<p>Responsibilities: - Maintain pools of specialized agents - Dynamic scaling based on workload - Efficient agent allocation across cycles - Health monitoring and recovery</p> <p>Agent Pool Strategy: <pre><code>@dataclass\nclass AgentPoolConfig:\n    agent_type: AgentType\n    min_instances: int = 1\n    max_instances: int = 5\n    idle_timeout: int = 300  # seconds\n    scaling_policy: ScalingPolicy = ScalingPolicy.DYNAMIC\n\nclass AgentPool:\n    def __init__(self, config: AgentPoolConfig):\n        self.available_agents: Queue[Agent] = Queue()\n        self.busy_agents: Dict[str, Agent] = {}\n        self.config = config\n\n    async def acquire_agent(self, timeout: int = 30) -&gt; Agent:\n        \"\"\"Acquire agent from pool with timeout\"\"\"\n\n    async def release_agent(self, agent: Agent) -&gt; None:\n        \"\"\"Return agent to pool for reuse\"\"\"\n\n    async def scale_pool(self, demand: int) -&gt; None:\n        \"\"\"Scale pool size based on demand\"\"\"\n</code></pre></p>"},{"location":"architecture/parallel-tdd-architecture/#3-cycle-synchronizer","title":"3. Cycle Synchronizer","text":"<p>Responsibilities: - Synchronize state across parallel cycles - Manage shared resources and locks - Coordinate phase transitions - Handle cycle dependencies</p> <p>Synchronization Patterns: <pre><code>class CycleSynchronizer:\n    async def acquire_file_lock(self, file_path: str, cycle_id: str) -&gt; FileLock\n    async def wait_for_dependency(self, cycle_id: str, depends_on: str) -&gt; None\n    async def broadcast_phase_transition(self, cycle_id: str, new_phase: TDDState) -&gt; None\n    async def coordinate_test_execution(self, cycles: List[TDDCycle]) -&gt; TestSchedule\n</code></pre></p>"},{"location":"architecture/parallel-tdd-architecture/#4-conflict-detector","title":"4. Conflict Detector","text":"<p>Responsibilities: - Proactive conflict detection before they occur - Static analysis of code dependencies - Runtime monitoring of file access patterns - Predictive conflict analysis using ML</p> <p>Conflict Detection Strategy: <pre><code>@dataclass\nclass Conflict:\n    type: ConflictType  # FILE_OVERLAP, TEST_COLLISION, DEPENDENCY_CONFLICT\n    severity: Severity  # LOW, MEDIUM, HIGH, CRITICAL\n    cycles: List[str]   # Affected cycle IDs\n    resources: List[str]  # Conflicting resources\n    suggested_resolution: ResolutionStrategy\n\nclass ConflictDetector:\n    async def analyze_static_conflicts(self, cycle1: TDDCycle, cycle2: TDDCycle) -&gt; List[Conflict]\n    async def monitor_runtime_conflicts(self) -&gt; AsyncIterator[Conflict]\n    async def predict_future_conflicts(self, scheduled_cycles: List[TDDCycle]) -&gt; List[Conflict]\n</code></pre></p>"},{"location":"architecture/parallel-tdd-architecture/#5-parallel-context-isolator","title":"5. Parallel Context Isolator","text":"<p>Responsibilities: - Isolate context between parallel cycles - Share common project knowledge efficiently - Manage token budget across parallel agents - Prevent context contamination</p> <p>Context Isolation Model: <pre><code>class ParallelContextIsolator:\n    def __init__(self, base_context: ProjectContext):\n        self.shared_context = base_context  # Read-only shared knowledge\n        self.cycle_contexts: Dict[str, CycleContext] = {}\n\n    async def create_isolated_context(self, cycle_id: str) -&gt; CycleContext:\n        \"\"\"Create isolated context for a TDD cycle\"\"\"\n        context = CycleContext(\n            cycle_id=cycle_id,\n            shared_knowledge=self.shared_context.get_readonly_view(),\n            token_budget=self.calculate_token_allocation(cycle_id),\n            file_scope=self.determine_file_scope(cycle_id)\n        )\n        return context\n\n    async def merge_context_changes(self, cycle_id: str) -&gt; None:\n        \"\"\"Merge cycle context changes back to shared knowledge\"\"\"\n</code></pre></p>"},{"location":"architecture/parallel-tdd-architecture/#concurrency-architecture","title":"Concurrency Architecture","text":""},{"location":"architecture/parallel-tdd-architecture/#execution-models","title":"Execution Models","text":""},{"location":"architecture/parallel-tdd-architecture/#1-work-stealing-model","title":"1. Work-Stealing Model","text":"<pre><code>class WorkStealingScheduler:\n    \"\"\"Agents steal work from other queues when idle\"\"\"\n    def __init__(self, worker_count: int):\n        self.work_queues = [deque() for _ in range(worker_count)]\n        self.workers = [Worker(i, self.work_queues) for i in range(worker_count)]\n\n    async def schedule_task(self, task: TDDTask) -&gt; None:\n        # Find least loaded queue\n        min_queue = min(self.work_queues, key=len)\n        min_queue.append(task)\n\n    async def steal_work(self, worker_id: int) -&gt; Optional[TDDTask]:\n        # Steal from longest queue\n        max_queue = max(self.work_queues, key=len)\n        if len(max_queue) &gt; 1:\n            return max_queue.popleft()\n</code></pre>"},{"location":"architecture/parallel-tdd-architecture/#2-pipeline-model","title":"2. Pipeline Model","text":"<pre><code>class PipelineScheduler:\n    \"\"\"Pipeline TDD phases across multiple cycles\"\"\"\n    def __init__(self):\n        self.phase_queues = {\n            TDDState.DESIGN: asyncio.Queue(),\n            TDDState.TEST_RED: asyncio.Queue(),\n            TDDState.CODE_GREEN: asyncio.Queue(),\n            TDDState.REFACTOR: asyncio.Queue()\n        }\n\n    async def schedule_phase(self, cycle: TDDCycle) -&gt; None:\n        current_phase = cycle.current_state\n        await self.phase_queues[current_phase].put(cycle)\n</code></pre>"},{"location":"architecture/parallel-tdd-architecture/#conflict-resolution-strategies","title":"Conflict Resolution Strategies","text":""},{"location":"architecture/parallel-tdd-architecture/#1-file-level-locking","title":"1. File-Level Locking","text":"<pre><code>class FileLockManager:\n    def __init__(self):\n        self.file_locks: Dict[str, FileLock] = {}\n\n    async def acquire_files(self, file_paths: List[str], cycle_id: str) -&gt; List[FileLock]:\n        \"\"\"Acquire locks for multiple files atomically\"\"\"\n        locks = []\n        try:\n            for path in sorted(file_paths):  # Sort to prevent deadlock\n                lock = await self.acquire_file(path, cycle_id)\n                locks.append(lock)\n            return locks\n        except LockTimeout:\n            # Release all acquired locks on failure\n            for lock in locks:\n                await lock.release()\n            raise\n</code></pre>"},{"location":"architecture/parallel-tdd-architecture/#2-optimistic-concurrency-control","title":"2. Optimistic Concurrency Control","text":"<pre><code>class OptimisticConcurrencyManager:\n    async def validate_changes(self, cycle_id: str, changes: Dict[str, FileChange]) -&gt; bool:\n        \"\"\"Validate changes haven't conflicted with other cycles\"\"\"\n        for file_path, change in changes.items():\n            current_version = await self.get_file_version(file_path)\n            if current_version != change.base_version:\n                # Conflict detected - attempt auto-merge\n                if await self.can_auto_merge(change, current_version):\n                    await self.auto_merge(change, current_version)\n                else:\n                    return False  # Manual resolution required\n        return True\n</code></pre>"},{"location":"architecture/parallel-tdd-architecture/#3-dependency-based-scheduling","title":"3. Dependency-Based Scheduling","text":"<pre><code>class DependencyScheduler:\n    def __init__(self):\n        self.dependency_graph = nx.DiGraph()\n\n    async def add_cycle_dependencies(self, cycle: TDDCycle) -&gt; None:\n        \"\"\"Add cycle to dependency graph\"\"\"\n        self.dependency_graph.add_node(cycle.id, cycle=cycle)\n\n        # Add edges for dependencies\n        for dep_story_id in cycle.depends_on:\n            dep_cycle = await self.get_cycle_for_story(dep_story_id)\n            if dep_cycle:\n                self.dependency_graph.add_edge(dep_cycle.id, cycle.id)\n\n    async def get_schedulable_cycles(self) -&gt; List[TDDCycle]:\n        \"\"\"Get cycles that can be scheduled (no pending dependencies)\"\"\"\n        schedulable = []\n        for node in self.dependency_graph.nodes():\n            if self.dependency_graph.in_degree(node) == 0:\n                cycle = self.dependency_graph.nodes[node]['cycle']\n                if cycle.current_state != TDDState.COMMIT:\n                    schedulable.append(cycle)\n        return schedulable\n</code></pre>"},{"location":"architecture/parallel-tdd-architecture/#resource-management","title":"Resource Management","text":""},{"location":"architecture/parallel-tdd-architecture/#agent-pool-scaling","title":"Agent Pool Scaling","text":"<pre><code>class DynamicAgentScaler:\n    def __init__(self, metrics_provider: MetricsProvider):\n        self.metrics = metrics_provider\n        self.scaling_decisions = []\n\n    async def calculate_optimal_pool_size(self, agent_type: AgentType) -&gt; int:\n        \"\"\"Calculate optimal pool size based on metrics\"\"\"\n        current_size = await self.get_current_pool_size(agent_type)\n        pending_tasks = await self.metrics.get_pending_tasks(agent_type)\n        avg_task_duration = await self.metrics.get_avg_task_duration(agent_type)\n        current_utilization = await self.metrics.get_utilization(agent_type)\n\n        # Scaling algorithm\n        if current_utilization &gt; 0.8 and pending_tasks &gt; current_size:\n            # Scale up\n            return min(current_size + 1, MAX_POOL_SIZE)\n        elif current_utilization &lt; 0.3 and current_size &gt; MIN_POOL_SIZE:\n            # Scale down\n            return current_size - 1\n        else:\n            return current_size\n\n    async def apply_scaling_decision(self, agent_type: AgentType, target_size: int) -&gt; None:\n        \"\"\"Apply scaling decision with gradual rollout\"\"\"\n        current_size = await self.get_current_pool_size(agent_type)\n\n        if target_size &gt; current_size:\n            # Scale up gradually\n            for _ in range(target_size - current_size):\n                await self.add_agent_to_pool(agent_type)\n                await asyncio.sleep(5)  # Gradual rollout\n        elif target_size &lt; current_size:\n            # Scale down gracefully\n            await self.mark_agents_for_removal(agent_type, current_size - target_size)\n</code></pre>"},{"location":"architecture/parallel-tdd-architecture/#token-budget-distribution","title":"Token Budget Distribution","text":"<pre><code>class ParallelTokenBudgetManager:\n    def __init__(self, total_budget: int = 200000):\n        self.total_budget = total_budget\n        self.allocated_budgets: Dict[str, int] = {}\n        self.usage_history: Dict[str, List[int]] = defaultdict(list)\n\n    async def allocate_budget(self, cycle_ids: List[str]) -&gt; Dict[str, int]:\n        \"\"\"Allocate token budget across parallel cycles\"\"\"\n        num_cycles = len(cycle_ids)\n\n        # Base allocation strategy\n        base_allocation = self.total_budget // (num_cycles + 1)  # +1 for buffer\n\n        # Adjust based on historical usage\n        allocations = {}\n        for cycle_id in cycle_ids:\n            cycle_history = self.usage_history.get(cycle_id, [])\n            if cycle_history:\n                # Use 95th percentile of historical usage\n                historical_need = np.percentile(cycle_history, 95)\n                allocations[cycle_id] = min(\n                    int(historical_need * 1.1),  # 10% buffer\n                    base_allocation * 1.5  # Max 50% above base\n                )\n            else:\n                allocations[cycle_id] = base_allocation\n\n        # Ensure we don't exceed total budget\n        total_allocated = sum(allocations.values())\n        if total_allocated &gt; self.total_budget * 0.9:  # Keep 10% buffer\n            # Scale down proportionally\n            scale_factor = (self.total_budget * 0.9) / total_allocated\n            for cycle_id in allocations:\n                allocations[cycle_id] = int(allocations[cycle_id] * scale_factor)\n\n        return allocations\n</code></pre>"},{"location":"architecture/parallel-tdd-architecture/#test-execution-coordination","title":"Test Execution Coordination","text":""},{"location":"architecture/parallel-tdd-architecture/#parallel-test-runner","title":"Parallel Test Runner","text":"<pre><code>class ParallelTestCoordinator:\n    def __init__(self, max_parallel_suites: int = 3):\n        self.max_parallel = max_parallel_suites\n        self.test_environments = TestEnvironmentPool(max_parallel)\n\n    async def run_parallel_test_suites(self, test_suites: List[TestSuite]) -&gt; TestResults:\n        \"\"\"Run multiple test suites in parallel with isolation\"\"\"\n        results = []\n\n        # Group test suites by potential conflicts\n        suite_groups = self.group_by_conflicts(test_suites)\n\n        for group in suite_groups:\n            if len(group) == 1:\n                # No conflicts - run directly\n                env = await self.test_environments.acquire()\n                result = await self.run_suite_isolated(group[0], env)\n                results.append(result)\n                await self.test_environments.release(env)\n            else:\n                # Potential conflicts - run sequentially within group\n                for suite in group:\n                    env = await self.test_environments.acquire()\n                    result = await self.run_suite_isolated(suite, env)\n                    results.append(result)\n                    await self.test_environments.release(env)\n\n        return TestResults.merge(results)\n\n    async def run_suite_isolated(self, suite: TestSuite, env: TestEnvironment) -&gt; TestResult:\n        \"\"\"Run test suite in isolated environment\"\"\"\n        # Set up isolated database\n        test_db = await env.create_test_database()\n\n        # Set up isolated file system\n        test_fs = await env.create_test_filesystem()\n\n        try:\n            # Run tests with isolation\n            result = await suite.run(\n                database=test_db,\n                filesystem=test_fs,\n                network_isolation=True\n            )\n            return result\n        finally:\n            # Clean up\n            await env.cleanup()\n</code></pre>"},{"location":"architecture/parallel-tdd-architecture/#test-fixture-management","title":"Test Fixture Management","text":"<pre><code>class ParallelFixtureManager:\n    def __init__(self):\n        self.shared_fixtures: Dict[str, Any] = {}\n        self.fixture_locks: Dict[str, asyncio.Lock] = {}\n\n    async def get_fixture(self, fixture_name: str, cycle_id: str) -&gt; Any:\n        \"\"\"Get test fixture with copy-on-write semantics\"\"\"\n        if fixture_name in self.shared_fixtures:\n            # Return deep copy for isolation\n            return deepcopy(self.shared_fixtures[fixture_name])\n        else:\n            # Create fixture if not exists\n            async with self.get_fixture_lock(fixture_name):\n                if fixture_name not in self.shared_fixtures:\n                    self.shared_fixtures[fixture_name] = await self.create_fixture(fixture_name)\n                return deepcopy(self.shared_fixtures[fixture_name])\n</code></pre>"},{"location":"architecture/parallel-tdd-architecture/#human-in-the-loop-coordination","title":"Human-in-the-Loop Coordination","text":""},{"location":"architecture/parallel-tdd-architecture/#parallel-approval-queue","title":"Parallel Approval Queue","text":"<pre><code>class ParallelApprovalQueue:\n    def __init__(self):\n        self.pending_approvals: PriorityQueue = PriorityQueue()\n        self.approval_contexts: Dict[str, ApprovalContext] = {}\n\n    async def request_approval(self, cycle_id: str, phase: TDDState, priority: int) -&gt; None:\n        \"\"\"Request human approval with priority\"\"\"\n        context = ApprovalContext(\n            cycle_id=cycle_id,\n            phase=phase,\n            priority=priority,\n            requested_at=datetime.now(),\n            timeout=timedelta(hours=2),\n            fallback_action=FallbackAction.PAUSE_CYCLE\n        )\n\n        self.approval_contexts[cycle_id] = context\n        await self.pending_approvals.put((-priority, cycle_id))  # Negative for max heap\n\n    async def get_next_approval(self) -&gt; Optional[ApprovalContext]:\n        \"\"\"Get highest priority approval request\"\"\"\n        if self.pending_approvals.empty():\n            return None\n\n        _, cycle_id = await self.pending_approvals.get()\n        return self.approval_contexts.get(cycle_id)\n\n    async def handle_approval_timeout(self, cycle_id: str) -&gt; None:\n        \"\"\"Handle approval timeout with fallback action\"\"\"\n        context = self.approval_contexts.get(cycle_id)\n        if context and context.is_expired():\n            if context.fallback_action == FallbackAction.PAUSE_CYCLE:\n                await self.pause_cycle(cycle_id)\n            elif context.fallback_action == FallbackAction.AUTO_APPROVE:\n                await self.auto_approve_with_restrictions(cycle_id)\n</code></pre>"},{"location":"architecture/parallel-tdd-architecture/#parallel-progress-dashboard","title":"Parallel Progress Dashboard","text":"<pre><code>class ParallelProgressMonitor:\n    def __init__(self):\n        self.cycle_metrics: Dict[str, CycleMetrics] = {}\n\n    async def get_dashboard_data(self) -&gt; Dict[str, Any]:\n        \"\"\"Get real-time dashboard data for all parallel cycles\"\"\"\n        active_cycles = await self.get_active_cycles()\n\n        dashboard = {\n            \"summary\": {\n                \"active_cycles\": len(active_cycles),\n                \"total_throughput\": sum(m.tasks_per_hour for m in self.cycle_metrics.values()),\n                \"average_cycle_time\": self.calculate_avg_cycle_time(),\n                \"conflict_rate\": self.calculate_conflict_rate(),\n                \"resource_utilization\": await self.get_resource_utilization()\n            },\n            \"cycles\": []\n        }\n\n        for cycle in active_cycles:\n            metrics = self.cycle_metrics.get(cycle.id, CycleMetrics())\n            dashboard[\"cycles\"].append({\n                \"id\": cycle.id,\n                \"story\": cycle.story_id,\n                \"phase\": cycle.current_state.value,\n                \"progress\": metrics.progress_percentage,\n                \"eta\": metrics.estimated_completion,\n                \"blockers\": metrics.current_blockers,\n                \"agent\": metrics.current_agent_type\n            })\n\n        return dashboard\n</code></pre>"},{"location":"architecture/parallel-tdd-architecture/#implementation-strategy","title":"Implementation Strategy","text":""},{"location":"architecture/parallel-tdd-architecture/#phase-1-basic-parallel-execution-weeks-1-2","title":"Phase 1: Basic Parallel Execution (Weeks 1-2)","text":"<ol> <li>Dual Cycle Support: Enable 2 concurrent TDD cycles</li> <li>Simple Conflict Detection: File-level locking only</li> <li>Static Agent Allocation: Fixed agent pools</li> <li>Manual Conflict Resolution: Human intervention required</li> </ol>"},{"location":"architecture/parallel-tdd-architecture/#phase-2-intelligent-scheduling-weeks-3-4","title":"Phase 2: Intelligent Scheduling (Weeks 3-4)","text":"<ol> <li>Dependency-Based Scheduling: Honor story dependencies</li> <li>Dynamic Agent Pools: Scale based on demand</li> <li>Automated Conflict Resolution: Simple auto-merge</li> <li>Parallel Test Execution: Isolated test environments</li> </ol>"},{"location":"architecture/parallel-tdd-architecture/#phase-3-advanced-parallelism-weeks-5-6","title":"Phase 3: Advanced Parallelism (Weeks 5-6)","text":"<ol> <li>5+ Concurrent Cycles: Scale to more parallel execution</li> <li>Predictive Conflict Avoidance: ML-based prediction</li> <li>Optimistic Concurrency: Reduce locking overhead</li> <li>Context Optimization: Parallel-aware context management</li> </ol>"},{"location":"architecture/parallel-tdd-architecture/#phase-4-production-optimization-weeks-7-8","title":"Phase 4: Production Optimization (Weeks 7-8)","text":"<ol> <li>Performance Tuning: Optimize for throughput</li> <li>Advanced Monitoring: Real-time analytics</li> <li>Cross-Project Parallelism: Coordinate across projects</li> <li>Automated Scaling: Self-tuning system</li> </ol>"},{"location":"architecture/parallel-tdd-architecture/#performance-targets","title":"Performance Targets","text":""},{"location":"architecture/parallel-tdd-architecture/#throughput-metrics","title":"Throughput Metrics","text":"<ul> <li>2 Parallel Cycles: 1.8x throughput improvement</li> <li>3 Parallel Cycles: 2.5x throughput improvement</li> <li>5 Parallel Cycles: 3.5x throughput improvement</li> <li>Overhead: &lt;10% coordination overhead</li> </ul>"},{"location":"architecture/parallel-tdd-architecture/#quality-metrics","title":"Quality Metrics","text":"<ul> <li>Test Coverage: Maintain &gt;95% coverage</li> <li>Conflict Rate: &lt;5% of cycles experience conflicts</li> <li>Auto-Resolution: &gt;80% of conflicts resolved automatically</li> <li>Zero Defects: No quality degradation from parallelism</li> </ul>"},{"location":"architecture/parallel-tdd-architecture/#resource-metrics","title":"Resource Metrics","text":"<ul> <li>CPU Utilization: 70-85% optimal range</li> <li>Memory Usage: &lt;2GB per TDD cycle</li> <li>Agent Efficiency: &gt;80% agent utilization</li> <li>Context Size: &lt;100k tokens per cycle</li> </ul>"},{"location":"architecture/parallel-tdd-architecture/#risk-mitigation","title":"Risk Mitigation","text":""},{"location":"architecture/parallel-tdd-architecture/#technical-risks","title":"Technical Risks","text":"<ol> <li>Data Corruption: Transactional state with automatic rollback</li> <li>Deadlocks: Timeout-based deadlock detection and recovery</li> <li>Resource Exhaustion: Hard limits and circuit breakers</li> <li>Quality Degradation: Continuous quality monitoring</li> </ol>"},{"location":"architecture/parallel-tdd-architecture/#operational-risks","title":"Operational Risks","text":"<ol> <li>Complexity: Progressive rollout with feature flags</li> <li>Debugging: Comprehensive distributed tracing</li> <li>Recovery: Automatic fallback to sequential mode</li> <li>Monitoring: Real-time alerting and dashboards</li> </ol>"},{"location":"architecture/parallel-tdd-architecture/#testing-strategy","title":"Testing Strategy","text":""},{"location":"architecture/parallel-tdd-architecture/#unit-testing","title":"Unit Testing","text":"<pre><code>class TestParallelCoordinator:\n    async def test_conflict_detection(self):\n        \"\"\"Test conflict detection between cycles\"\"\"\n        cycle1 = create_test_cycle(files=[\"user.py\", \"auth.py\"])\n        cycle2 = create_test_cycle(files=[\"auth.py\", \"db.py\"])\n\n        conflicts = await coordinator.detect_conflicts(cycle1, cycle2)\n        assert len(conflicts) == 1\n        assert conflicts[0].resources == [\"auth.py\"]\n\n    async def test_deadlock_prevention(self):\n        \"\"\"Test deadlock prevention in file locking\"\"\"\n        # Create circular dependency scenario\n        cycle1 = create_test_cycle(files=[\"a.py\", \"b.py\"])\n        cycle2 = create_test_cycle(files=[\"b.py\", \"a.py\"])\n\n        # Should not deadlock\n        result = await coordinator.schedule_cycles([cycle1, cycle2])\n        assert result.success\n</code></pre>"},{"location":"architecture/parallel-tdd-architecture/#integration-testing","title":"Integration Testing","text":"<pre><code>class TestParallelIntegration:\n    async def test_full_parallel_execution(self):\n        \"\"\"Test complete parallel TDD execution\"\"\"\n        stories = [\n            create_story(\"feature_a\", files=[\"feature_a.py\"]),\n            create_story(\"feature_b\", files=[\"feature_b.py\"]),\n            create_story(\"feature_c\", files=[\"feature_c.py\"])\n        ]\n\n        result = await orchestrator.execute_parallel_tdd(stories)\n\n        assert all(s.status == \"completed\" for s in result.stories)\n        assert result.total_time &lt; sequential_baseline * 0.5  # 2x speedup\n</code></pre>"},{"location":"architecture/parallel-tdd-architecture/#stress-testing","title":"Stress Testing","text":"<pre><code>class TestParallelStress:\n    async def test_high_concurrency(self):\n        \"\"\"Test system under high parallel load\"\"\"\n        num_cycles = 10\n        cycles = [create_test_cycle(f\"cycle_{i}\") for i in range(num_cycles)]\n\n        start_time = time.time()\n        results = await coordinator.execute_parallel(cycles, max_parallel=5)\n        duration = time.time() - start_time\n\n        assert all(r.success for r in results)\n        assert duration &lt; sequential_estimate * 0.3  # 3x+ speedup\n</code></pre>"},{"location":"architecture/parallel-tdd-architecture/#monitoring-and-observability","title":"Monitoring and Observability","text":""},{"location":"architecture/parallel-tdd-architecture/#key-metrics","title":"Key Metrics","text":"<pre><code>@dataclass\nclass ParallelMetrics:\n    # Throughput metrics\n    cycles_per_hour: float\n    tasks_completed_per_hour: float\n    average_cycle_duration: timedelta\n\n    # Conflict metrics\n    conflicts_detected: int\n    conflicts_auto_resolved: int\n    conflicts_manual_resolved: int\n    conflict_resolution_time: timedelta\n\n    # Resource metrics\n    agent_utilization: Dict[AgentType, float]\n    pool_scaling_events: int\n    token_budget_efficiency: float\n\n    # Quality metrics\n    test_pass_rate: float\n    code_coverage: float\n    refactoring_impact: float\n</code></pre>"},{"location":"architecture/parallel-tdd-architecture/#distributed-tracing","title":"Distributed Tracing","text":"<pre><code>class ParallelTracer:\n    async def trace_cycle_execution(self, cycle_id: str) -&gt; TraceData:\n        \"\"\"Trace complete cycle execution across parallel system\"\"\"\n        trace = TraceData(cycle_id=cycle_id)\n\n        # Trace agent interactions\n        trace.add_span(\"agent_acquisition\", \n                      duration=agent_acquire_time,\n                      metadata={\"agent_type\": agent_type, \"pool_size\": pool_size})\n\n        # Trace conflict detection\n        trace.add_span(\"conflict_detection\",\n                      duration=conflict_check_time,\n                      metadata={\"conflicts_found\": num_conflicts})\n\n        # Trace context preparation\n        trace.add_span(\"context_preparation\",\n                      duration=context_prep_time,\n                      metadata={\"token_count\": tokens_used})\n\n        return trace\n</code></pre>"},{"location":"architecture/parallel-tdd-architecture/#future-enhancements","title":"Future Enhancements","text":""},{"location":"architecture/parallel-tdd-architecture/#machine-learning-integration","title":"Machine Learning Integration","text":"<ul> <li>Conflict Prediction: ML model to predict conflicts before they occur</li> <li>Optimal Scheduling: Learn optimal scheduling patterns</li> <li>Resource Prediction: Predict resource needs based on story analysis</li> <li>Quality Prediction: Predict quality issues from parallel execution</li> </ul>"},{"location":"architecture/parallel-tdd-architecture/#advanced-features","title":"Advanced Features","text":"<ul> <li>Cross-Project Coordination: Coordinate parallel execution across projects</li> <li>Distributed Execution: Distribute cycles across multiple machines</li> <li>Real-time Collaboration: Multiple humans coordinating parallel cycles</li> <li>Adaptive Parallelism: Self-adjusting parallelism level</li> </ul> <p>This parallel TDD architecture provides a robust foundation for scaling TDD execution while maintaining quality and preventing conflicts. The phased implementation approach ensures gradual rollout with minimal risk.</p>"},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/","title":"Parallel TDD Comprehensive Implementation Plan","text":""},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#executive-summary","title":"Executive Summary","text":"<p>This document provides a comprehensive implementation plan for the Parallel TDD Execution system, building on the existing sequential TDD foundation and integrating all designed components: conflict resolution, agent pool management, context integration, and monitoring systems. The plan emphasizes incremental delivery, risk mitigation, and production readiness.</p>"},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#implementation-foundation-assessment","title":"Implementation Foundation Assessment","text":""},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#current-assets-available","title":"Current Assets Available","text":""},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#1-sequential-tdd-system-100-complete","title":"1. Sequential TDD System (100% Complete)","text":"<ul> <li>TDD State Machine: Fully implemented with comprehensive state transitions</li> <li>TDD Models: Complete data models for cycles, tasks, test files, and results</li> <li>Agent Security System: Production-ready agent restrictions and tool access control</li> <li>Storage &amp; Persistence: Robust state management and data persistence</li> <li>Testing Framework: Comprehensive test suite with &gt;90% coverage</li> </ul>"},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#2-context-management-system-design-complete","title":"2. Context Management System (Design Complete)","text":"<ul> <li>System Architecture: Complete design with all components specified</li> <li>API Specifications: Detailed interface definitions for all components</li> <li>Implementation Plan: 8-week phased implementation strategy</li> <li>Algorithm Documentation: Detailed relevance scoring and compression algorithms</li> <li>Evaluation Framework: Comprehensive success metrics and validation</li> </ul>"},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#3-parallel-architecture-design-complete","title":"3. Parallel Architecture (Design Complete)","text":"<ul> <li>Concurrency Architecture: Complete parallel coordination patterns</li> <li>Conflict Resolution: Advanced algorithms for detection and resolution</li> <li>Agent Pool Management: Sophisticated resource allocation and scaling</li> <li>Context Integration: Parallel-aware context management</li> <li>Technical Specifications: Complete API and protocol definitions</li> </ul>"},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#implementation-readiness-score-85","title":"Implementation Readiness Score: 85%","text":""},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#comprehensive-implementation-strategy","title":"Comprehensive Implementation Strategy","text":""},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#phase-1-foundation-integration-weeks-1-3","title":"Phase 1: Foundation Integration (Weeks 1-3)","text":""},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#week-1-core-infrastructure-setup","title":"Week 1: Core Infrastructure Setup","text":"<p>Objective: Establish basic parallel coordination infrastructure</p> <p>Day 1-2: Parallel Coordinator Foundation <pre><code># Primary Implementation Tasks\n1. lib/parallel/parallel_coordinator.py\n   - Basic ParallelCoordinator with 2-cycle support\n   - Simple file-level conflict detection\n   - Integration with existing TDD state machine\n\n2. lib/parallel/parallel_models.py\n   - Extend existing TDD models for parallel execution\n   - Add ParallelTDDCycle, Conflict, FileLock classes\n   - Ensure backward compatibility with sequential models\n\n3. tests/unit/test_parallel_coordinator.py\n   - Comprehensive unit tests for coordinator\n   - Mock integrations with existing systems\n   - Conflict detection validation tests\n</code></pre></p> <p>Day 3-4: Agent Pool Infrastructure <pre><code># Primary Implementation Tasks\n1. lib/parallel/agent_pool.py\n   - BasicAgentPool implementation\n   - Integration with existing agent security system\n   - Resource allocation tracking\n\n2. lib/parallel/resource_allocator.py\n   - Multi-resource allocation system\n   - Integration with existing project storage\n   - Resource usage monitoring\n\n3. tests/unit/test_agent_pool.py\n   - Agent acquisition and release tests\n   - Resource allocation validation\n   - Security boundary verification\n</code></pre></p> <p>Day 5: Storage Integration <pre><code># Primary Implementation Tasks\n1. lib/project_storage.py (extend existing)\n   - Add parallel execution state storage\n   - Implement atomic state transitions\n   - Add conflict state persistence\n\n2. .orch-state/parallel/ directory structure\n   - Create parallel execution storage schema\n   - Implement data migration from sequential format\n   - Add state validation and recovery\n\n3. tests/integration/test_parallel_storage.py\n   - State persistence tests\n   - Data migration validation\n   - Recovery mechanism tests\n</code></pre></p>"},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#week-2-context-management-integration","title":"Week 2: Context Management Integration","text":"<p>Objective: Integrate Context Management System with parallel execution</p> <p>Day 1-3: Context Management Core Implementation <pre><code># Build on Phase 7 Context Management Design\n1. lib/context/parallel_context_manager.py\n   - Implement ParallelContextManager\n   - Token budget allocation across cycles\n   - Context isolation and sharing\n\n2. lib/context/context_compressor.py\n   - Implement intelligent compression strategies\n   - Agent-type specific compression\n   - Parallel-aware optimization\n\n3. lib/context/context_optimizer.py\n   - Cross-cycle deduplication\n   - Predictive prefetching\n   - Performance optimization\n</code></pre></p> <p>Day 4-5: Context Integration Testing <pre><code># Comprehensive context integration tests\n1. tests/unit/test_parallel_context.py\n   - Context isolation verification\n   - Token budget allocation tests\n   - Compression efficiency validation\n\n2. tests/integration/test_context_sharing.py\n   - Cross-cycle context sharing\n   - Conflict detection in context\n   - Performance benchmarking\n</code></pre></p>"},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#week-3-basic-conflict-resolution","title":"Week 3: Basic Conflict Resolution","text":"<p>Objective: Implement foundational conflict detection and resolution</p> <p>Day 1-3: Conflict Detection System <pre><code>1. lib/parallel/conflict_detector.py\n   - Static conflict analysis\n   - Runtime conflict detection\n   - ML-based conflict prediction (basic version)\n\n2. lib/parallel/conflict_resolver.py\n   - Auto-merge resolver (AST-based)\n   - Sequential execution resolver\n   - Human-assisted resolution queue\n\n3. lib/parallel/lock_manager.py\n   - Distributed file locking\n   - Deadlock detection and prevention\n   - Lock timeout and recovery\n</code></pre></p> <p>Day 4-5: Integration and Validation <pre><code>1. tests/integration/test_parallel_basic.py\n   - Two independent cycles execution\n   - Basic conflict detection and resolution\n   - End-to-end parallel workflow\n\n2. Performance baseline establishment\n   - Sequential vs parallel performance metrics\n   - Resource utilization measurement\n   - Quality assurance validation\n</code></pre></p>"},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#phase-2-advanced-features-weeks-4-6","title":"Phase 2: Advanced Features (Weeks 4-6)","text":""},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#week-4-intelligent-scheduling","title":"Week 4: Intelligent Scheduling","text":"<p>Objective: Implement dependency-aware scheduling and dynamic scaling</p> <p>Day 1-2: Dependency Analysis <pre><code>1. lib/parallel/dependency_scheduler.py\n   - Story dependency analysis\n   - Implicit dependency detection (shared files)\n   - Optimal execution ordering\n\n2. lib/parallel/ml_conflict_predictor.py\n   - Feature extraction for conflict prediction\n   - Basic ML model training\n   - Conflict probability scoring\n</code></pre></p> <p>Day 3-4: Dynamic Agent Scaling <pre><code>1. lib/parallel/dynamic_agent_pool.py\n   - Auto-scaling based on demand\n   - Agent pool metrics collection\n   - Performance-based scaling decisions\n\n2. lib/parallel/workload_balancer.py\n   - Intelligent agent assignment\n   - Workload-aware balancing\n   - Historical performance consideration\n</code></pre></p> <p>Day 5: Advanced Testing <pre><code>1. tests/integration/test_intelligent_scheduling.py\n   - Dependency-aware execution\n   - Scaling behavior validation\n   - Performance optimization verification\n</code></pre></p>"},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#week-5-production-features","title":"Week 5: Production Features","text":"<p>Objective: Implement production-ready monitoring and optimization</p> <p>Day 1-2: Comprehensive Monitoring <pre><code>1. lib/parallel/parallel_monitor.py\n   - Real-time metrics collection\n   - Performance bottleneck detection\n   - Resource utilization tracking\n\n2. lib/parallel/dashboard.py\n   - Real-time dashboard for parallel execution\n   - Conflict resolution status\n   - Agent pool utilization display\n</code></pre></p> <p>Day 3-4: Auto-Optimization <pre><code>1. lib/parallel/performance_optimizer.py\n   - Automatic performance tuning\n   - Resource rebalancing\n   - Conflict pattern learning\n\n2. lib/parallel/self_tuning_system.py\n   - ML-based parameter optimization\n   - Continuous improvement mechanisms\n   - Adaptive system behavior\n</code></pre></p> <p>Day 5: Production Hardening <pre><code>1. Error handling and recovery\n   - Graceful degradation to sequential mode\n   - State corruption recovery\n   - Circuit breaker patterns\n\n2. Security hardening\n   - Enhanced isolation verification\n   - Security boundary enforcement\n   - Audit trail implementation\n</code></pre></p>"},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#week-6-scale-up-and-optimization","title":"Week 6: Scale-Up and Optimization","text":"<p>Objective: Scale to 5+ parallel cycles with advanced optimization</p> <p>Day 1-2: Advanced Parallel Support <pre><code>1. Scale coordinator to support 5+ cycles\n2. Implement optimistic concurrency control\n3. Advanced conflict resolution strategies\n4. Cross-project coordination foundation\n</code></pre></p> <p>Day 3-4: Performance Optimization <pre><code>1. Memory and CPU optimization\n2. Context preparation optimization\n3. Agent efficiency improvements\n4. Token budget optimization\n</code></pre></p> <p>Day 5: Advanced Testing <pre><code>1. Stress testing with 5+ parallel cycles\n2. Performance regression testing\n3. Quality assurance validation\n4. Security penetration testing\n</code></pre></p>"},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#phase-3-production-deployment-weeks-7-8","title":"Phase 3: Production Deployment (Weeks 7-8)","text":""},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#week-7-pre-production-validation","title":"Week 7: Pre-Production Validation","text":"<p>Objective: Comprehensive validation and production preparation</p> <p>Day 1-2: Comprehensive Testing <pre><code>1. End-to-end integration testing\n2. Performance benchmarking\n3. Load testing and stress testing\n4. Failover and recovery testing\n</code></pre></p> <p>Day 3-4: Documentation and Training <pre><code>1. Complete API documentation\n2. Operations runbook\n3. Troubleshooting guide\n4. User training materials\n</code></pre></p> <p>Day 5: Security and Compliance <pre><code>1. Security audit and penetration testing\n2. Compliance verification\n3. Data protection validation\n4. Access control verification\n</code></pre></p>"},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#week-8-production-rollout","title":"Week 8: Production Rollout","text":"<p>Objective: Gradual production rollout with monitoring</p> <p>Day 1-2: Canary Deployment <pre><code>1. Deploy to 5% of users\n2. Monitor metrics and performance\n3. Validate success criteria\n4. Adjust based on feedback\n</code></pre></p> <p>Day 3-4: Graduated Rollout <pre><code>1. Scale to 20% of users\n2. Continue monitoring\n3. Optimize based on real usage\n4. Prepare for full rollout\n</code></pre></p> <p>Day 5: Full Production <pre><code>1. Complete rollout to all users\n2. Monitor for issues\n3. Provide support and documentation\n4. Plan for future enhancements\n</code></pre></p>"},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#implementation-architecture","title":"Implementation Architecture","text":""},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#1-module-integration-strategy","title":"1. Module Integration Strategy","text":"<pre><code># Integration with existing system\nlib/\n\u251c\u2500\u2500 agents/                    # Existing agent system\n\u2502   \u251c\u2500\u2500 __init__.py           # Extend with parallel capabilities\n\u2502   \u251c\u2500\u2500 base_agent.py         # Add parallel coordination methods\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 parallel/                 # New parallel execution system\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 parallel_coordinator.py\n\u2502   \u251c\u2500\u2500 agent_pool.py\n\u2502   \u251c\u2500\u2500 conflict_detector.py\n\u2502   \u251c\u2500\u2500 conflict_resolver.py\n\u2502   \u251c\u2500\u2500 lock_manager.py\n\u2502   \u251c\u2500\u2500 resource_allocator.py\n\u2502   \u251c\u2500\u2500 parallel_monitor.py\n\u2502   \u2514\u2500\u2500 performance_optimizer.py\n\u251c\u2500\u2500 context/                  # New context management system\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 parallel_context_manager.py\n\u2502   \u251c\u2500\u2500 context_compressor.py\n\u2502   \u251c\u2500\u2500 context_optimizer.py\n\u2502   \u251c\u2500\u2500 token_budget_manager.py\n\u2502   \u2514\u2500\u2500 context_sharing.py\n\u251c\u2500\u2500 tdd_state_machine.py      # Extend for parallel support\n\u251c\u2500\u2500 tdd_models.py            # Extend with parallel models\n\u2514\u2500\u2500 project_storage.py       # Extend with parallel storage\n</code></pre>"},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#2-database-schema-extensions","title":"2. Database Schema Extensions","text":"<pre><code>-- Extend existing .orch-state storage\nCREATE TABLE parallel_executions (\n    id TEXT PRIMARY KEY,\n    project_id TEXT,\n    started_at TIMESTAMP,\n    completed_at TIMESTAMP,\n    status TEXT,\n    config JSON,\n    metrics JSON\n);\n\nCREATE TABLE parallel_cycles (\n    id TEXT PRIMARY KEY,\n    execution_id TEXT,\n    story_id TEXT,\n    current_state TEXT,\n    priority INTEGER,\n    started_at TIMESTAMP,\n    completed_at TIMESTAMP,\n    resource_allocation JSON,\n    FOREIGN KEY (execution_id) REFERENCES parallel_executions(id)\n);\n\nCREATE TABLE conflicts (\n    id TEXT PRIMARY KEY,\n    execution_id TEXT,\n    type TEXT,\n    severity TEXT,\n    cycles JSON,\n    resources JSON,\n    detected_at TIMESTAMP,\n    resolved_at TIMESTAMP,\n    resolution_strategy TEXT,\n    resolution_result JSON,\n    FOREIGN KEY (execution_id) REFERENCES parallel_executions(id)\n);\n</code></pre>"},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#3-configuration-schema","title":"3. Configuration Schema","text":"<pre><code># Add to existing project configuration\nparallel_tdd:\n  enabled: false  # Start disabled, enable via feature flag\n  max_parallel_cycles: 2  # Start conservative\n\n  agent_pools:\n    design:\n      min_size: 1\n      max_size: 3\n      scaling_policy: \"conservative\"\n    qa:\n      min_size: 1\n      max_size: 3\n      scaling_policy: \"conservative\"\n    code:\n      min_size: 2\n      max_size: 5\n      scaling_policy: \"aggressive\"\n\n  conflict_resolution:\n    auto_merge_enabled: true\n    ml_prediction_enabled: false  # Enable in Phase 2\n    human_timeout_hours: 4\n    fallback_strategy: \"sequential\"\n\n  context_management:\n    token_budget_total: 200000\n    token_budget_reserve_percent: 10\n    compression_enabled: true\n    sharing_enabled: true\n    deduplication_enabled: true\n\n  monitoring:\n    metrics_collection_interval: 30  # seconds\n    performance_alerts_enabled: true\n    dashboard_enabled: true\n</code></pre>"},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#risk-mitigation-strategy","title":"Risk Mitigation Strategy","text":""},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#1-technical-risk-mitigation","title":"1. Technical Risk Mitigation","text":"Risk Probability Impact Mitigation Strategy Data Corruption Low High Transactional storage, atomic operations, comprehensive backups Performance Degradation Medium Medium Continuous monitoring, auto-scaling, fallback mechanisms Context Quality Issues Medium Medium Relevance scoring validation, human feedback loops Agent Pool Exhaustion Medium Medium Auto-scaling, resource quotas, circuit breakers Conflict Storm Low High ML prediction, conflict rate limiting, sequential fallback"},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#2-implementation-risk-mitigation","title":"2. Implementation Risk Mitigation","text":"Risk Probability Impact Mitigation Strategy Integration Complexity High Medium Incremental integration, comprehensive testing Schedule Delays Medium Medium Phased delivery, MVP focus, feature flags Resource Requirements Medium Low Cloud auto-scaling, resource monitoring Team Coordination Low Medium Clear interfaces, documentation, communication"},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#3-operational-risk-mitigation","title":"3. Operational Risk Mitigation","text":"Risk Probability Impact Mitigation Strategy Production Issues Medium High Gradual rollout, monitoring, quick rollback User Adoption Low Medium Training, documentation, support Maintenance Complexity Medium Medium Clear documentation, monitoring tools"},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#success-metrics-and-validation","title":"Success Metrics and Validation","text":""},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#1-performance-targets","title":"1. Performance Targets","text":"Metric Baseline (Sequential) Phase 1 Target Phase 2 Target Phase 3 Target Story Completion Rate 100% 180% (2 cycles) 250% (3 cycles) 350% (5 cycles) Resource Utilization 60% 70% 80% 85% Conflict Rate 0% &lt;5% &lt;3% &lt;2% Auto-Resolution Rate N/A 60% 80% 90% Context Relevance 95% 90% 93% 95%"},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#2-quality-targets","title":"2. Quality Targets","text":"Metric Target Measurement Method Test Coverage &gt;95% Automated coverage reports Code Quality No degradation Static analysis, code review Security Compliance 100% Security audit, penetration testing Documentation Coverage &gt;90% Documentation review"},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#3-operational-targets","title":"3. Operational Targets","text":"Metric Target Measurement Method System Availability &gt;99.5% Uptime monitoring Error Rate &lt;1% Error tracking, logging Response Time &lt;2s Performance monitoring Recovery Time &lt;5min Incident response testing"},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#testing-strategy","title":"Testing Strategy","text":""},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#1-unit-testing-ongoing","title":"1. Unit Testing (Ongoing)","text":"<pre><code># Test coverage targets\n- Parallel Coordinator: &gt;95%\n- Conflict Resolution: &gt;90%\n- Agent Pool Management: &gt;95%\n- Context Management: &gt;90%\n- Integration Points: &gt;85%\n</code></pre>"},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#2-integration-testing-weekly","title":"2. Integration Testing (Weekly)","text":"<pre><code># Integration test scenarios\n- End-to-end parallel execution\n- Conflict detection and resolution\n- Context sharing and optimization\n- Agent pool scaling and management\n- Performance under load\n</code></pre>"},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#3-performance-testing-bi-weekly","title":"3. Performance Testing (Bi-weekly)","text":"<pre><code># Performance test scenarios\n- Throughput measurement (stories/hour)\n- Resource utilization optimization\n- Scalability testing (2, 3, 5+ cycles)\n- Memory and CPU profiling\n- Token usage efficiency\n</code></pre>"},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#4-security-testing-monthly","title":"4. Security Testing (Monthly)","text":"<pre><code># Security test scenarios\n- Agent isolation verification\n- Resource access control\n- Context sharing security\n- Data protection validation\n- Audit trail verification\n</code></pre>"},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#deployment-strategy","title":"Deployment Strategy","text":""},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#1-feature-flag-implementation","title":"1. Feature Flag Implementation","text":"<pre><code>class ParallelTDDFeatureFlags:\n    def __init__(self):\n        self.flags = {\n            'parallel_execution_enabled': False,\n            'max_parallel_cycles': 2,\n            'conflict_prediction_enabled': False,\n            'auto_scaling_enabled': False,\n            'context_sharing_enabled': False\n        }\n\n    def enable_for_percentage(self, flag: str, percentage: int):\n        # Gradual rollout implementation\n        pass\n</code></pre>"},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#2-rollout-phases","title":"2. Rollout Phases","text":"<ol> <li>Developer Testing (Week 7): Internal testing with development team</li> <li>Alpha Testing (Week 8, Days 1-2): 5% of power users</li> <li>Beta Testing (Week 8, Days 3-4): 20% of active users</li> <li>Production (Week 8, Day 5): 100% rollout</li> </ol>"},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#3-monitoring-and-alerting","title":"3. Monitoring and Alerting","text":"<pre><code># Key monitoring metrics\n- Parallel execution success rate\n- Conflict resolution effectiveness\n- Agent pool utilization\n- Context management efficiency\n- Performance degradation alerts\n- Error rate monitoring\n</code></pre>"},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#post-implementation-roadmap","title":"Post-Implementation Roadmap","text":""},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#month-1-optimization-and-tuning","title":"Month 1: Optimization and Tuning","text":"<ul> <li>Performance optimization based on real usage</li> <li>ML model training with production data</li> <li>User feedback integration</li> <li>Bug fixes and stability improvements</li> </ul>"},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#month-2-3-advanced-features","title":"Month 2-3: Advanced Features","text":"<ul> <li>Cross-project parallel coordination</li> <li>Advanced ML-based conflict prediction</li> <li>Sophisticated auto-scaling algorithms</li> <li>Enhanced monitoring and analytics</li> </ul>"},{"location":"architecture/parallel-tdd-comprehensive-implementation-plan/#month-4-6-scale-and-innovation","title":"Month 4-6: Scale and Innovation","text":"<ul> <li>Support for 10+ parallel cycles</li> <li>Distributed execution across multiple machines</li> <li>Advanced context management features</li> <li>Integration with external CI/CD systems</li> </ul> <p>This comprehensive implementation plan provides a clear path from the current sequential TDD system to a production-ready parallel execution system, building on all the architectural designs and ensuring incremental delivery with minimal risk.</p>"},{"location":"architecture/parallel-tdd-implementation-strategy/","title":"Parallel TDD Implementation Strategy","text":""},{"location":"architecture/parallel-tdd-implementation-strategy/#executive-summary","title":"Executive Summary","text":"<p>This document outlines a comprehensive 4-phase implementation strategy for the Parallel TDD Execution system. The strategy emphasizes incremental delivery, risk mitigation, and maintaining backward compatibility with the existing sequential TDD system.</p>"},{"location":"architecture/parallel-tdd-implementation-strategy/#implementation-timeline","title":"Implementation Timeline","text":""},{"location":"architecture/parallel-tdd-implementation-strategy/#overview","title":"Overview","text":"<ul> <li>Total Duration: 8 weeks</li> <li>Phase 1: Basic Parallel (Weeks 1-2)</li> <li>Phase 2: Intelligent Scheduling (Weeks 3-4)</li> <li>Phase 3: Advanced Parallelism (Weeks 5-6)</li> <li>Phase 4: Production Optimization (Weeks 7-8)</li> </ul>"},{"location":"architecture/parallel-tdd-implementation-strategy/#phase-1-basic-parallel-execution-weeks-1-2","title":"Phase 1: Basic Parallel Execution (Weeks 1-2)","text":""},{"location":"architecture/parallel-tdd-implementation-strategy/#goals","title":"Goals","text":"<ul> <li>Enable 2 concurrent TDD cycles with basic coordination</li> <li>Implement file-level conflict detection</li> <li>Create static agent pools</li> <li>Establish monitoring foundation</li> </ul>"},{"location":"architecture/parallel-tdd-implementation-strategy/#week-1-core-infrastructure","title":"Week 1: Core Infrastructure","text":""},{"location":"architecture/parallel-tdd-implementation-strategy/#day-1-2-parallel-coordinator","title":"Day 1-2: Parallel Coordinator","text":"<pre><code># lib/parallel/parallel_coordinator.py\nclass ParallelCoordinator:\n    def __init__(self, max_parallel: int = 2):\n        self.max_parallel = max_parallel\n        self.active_cycles: Dict[str, TDDCycle] = {}\n        self.cycle_locks: Dict[str, asyncio.Lock] = {}\n        self.file_locks: Dict[str, str] = {}  # file_path -&gt; cycle_id\n\n    async def can_start_cycle(self, story: Story) -&gt; Tuple[bool, Optional[str]]:\n        \"\"\"Check if a new cycle can be started\"\"\"\n        if len(self.active_cycles) &gt;= self.max_parallel:\n            return False, \"Max parallel cycles reached\"\n\n        # Check for file conflicts\n        story_files = self.analyze_story_files(story)\n        for file_path in story_files:\n            if file_path in self.file_locks:\n                blocking_cycle = self.file_locks[file_path]\n                return False, f\"File {file_path} locked by cycle {blocking_cycle}\"\n\n        return True, None\n</code></pre>"},{"location":"architecture/parallel-tdd-implementation-strategy/#day-3-4-basic-agent-pool","title":"Day 3-4: Basic Agent Pool","text":"<pre><code># lib/parallel/agent_pool.py\nclass BasicAgentPool:\n    def __init__(self, agent_type: AgentType, pool_size: int = 2):\n        self.agent_type = agent_type\n        self.pool = Queue(maxsize=pool_size)\n        self.active_agents: Dict[str, Agent] = {}\n\n        # Pre-create agents\n        for i in range(pool_size):\n            agent = self.create_agent(f\"{agent_type.value}_{i}\")\n            self.pool.put_nowait(agent)\n\n    async def acquire(self, cycle_id: str, timeout: int = 30) -&gt; Agent:\n        \"\"\"Acquire agent from pool\"\"\"\n        try:\n            agent = await asyncio.wait_for(self.pool.get(), timeout=timeout)\n            self.active_agents[cycle_id] = agent\n            return agent\n        except asyncio.TimeoutError:\n            raise AgentPoolExhausted(f\"No {self.agent_type} agents available\")\n</code></pre>"},{"location":"architecture/parallel-tdd-implementation-strategy/#day-5-file-lock-manager","title":"Day 5: File Lock Manager","text":"<pre><code># lib/parallel/lock_manager.py\nclass FileLockManager:\n    def __init__(self):\n        self.locks: Dict[str, FileLock] = {}\n        self.lock_holders: Dict[str, str] = {}  # file -&gt; cycle_id\n\n    async def acquire_files(self, files: List[str], cycle_id: str) -&gt; bool:\n        \"\"\"Acquire locks for multiple files atomically\"\"\"\n        sorted_files = sorted(files)  # Prevent deadlock\n        acquired = []\n\n        try:\n            for file_path in sorted_files:\n                if file_path in self.lock_holders:\n                    # Conflict - rollback\n                    raise FileAlreadyLocked(file_path, self.lock_holders[file_path])\n\n                lock = FileLock(file_path, cycle_id)\n                self.locks[file_path] = lock\n                self.lock_holders[file_path] = cycle_id\n                acquired.append(file_path)\n\n            return True\n\n        except FileAlreadyLocked:\n            # Rollback acquired locks\n            for file_path in acquired:\n                del self.locks[file_path]\n                del self.lock_holders[file_path]\n            return False\n</code></pre>"},{"location":"architecture/parallel-tdd-implementation-strategy/#week-2-integration-and-testing","title":"Week 2: Integration and Testing","text":""},{"location":"architecture/parallel-tdd-implementation-strategy/#day-1-2-state-synchronization","title":"Day 1-2: State Synchronization","text":"<pre><code># lib/parallel/state_synchronizer.py\nclass ParallelStateSynchronizer:\n    def __init__(self, storage: ProjectStorage):\n        self.storage = storage\n        self.state_locks: Dict[str, asyncio.Lock] = {}\n\n    async def update_cycle_state(self, cycle_id: str, updates: Dict[str, Any]) -&gt; None:\n        \"\"\"Thread-safe state updates\"\"\"\n        async with self.get_state_lock(cycle_id):\n            cycle = await self.storage.load_tdd_cycle(cycle_id)\n\n            # Apply updates\n            for key, value in updates.items():\n                setattr(cycle, key, value)\n\n            # Save atomically\n            await self.storage.save_tdd_cycle(cycle)\n\n    async def transition_phase(self, cycle_id: str, new_phase: TDDState) -&gt; None:\n        \"\"\"Coordinate phase transitions\"\"\"\n        async with self.get_state_lock(cycle_id):\n            # Notify other components\n            await self.broadcast_transition(cycle_id, new_phase)\n</code></pre>"},{"location":"architecture/parallel-tdd-implementation-strategy/#day-3-4-basic-monitoring","title":"Day 3-4: Basic Monitoring","text":"<pre><code># lib/parallel/parallel_monitor.py\nclass ParallelExecutionMonitor:\n    def __init__(self):\n        self.metrics = ParallelMetrics()\n        self.events: List[ParallelEvent] = []\n\n    async def record_cycle_start(self, cycle_id: str) -&gt; None:\n        self.events.append(ParallelEvent(\n            type=EventType.CYCLE_START,\n            cycle_id=cycle_id,\n            timestamp=datetime.now()\n        ))\n        self.metrics.active_cycles += 1\n\n    async def record_conflict(self, cycle1: str, cycle2: str, conflict: Conflict) -&gt; None:\n        self.events.append(ParallelEvent(\n            type=EventType.CONFLICT_DETECTED,\n            cycle_id=cycle1,\n            related_cycle=cycle2,\n            conflict=conflict,\n            timestamp=datetime.now()\n        ))\n        self.metrics.conflicts_detected += 1\n\n    def get_dashboard_data(self) -&gt; Dict[str, Any]:\n        return {\n            \"active_cycles\": self.metrics.active_cycles,\n            \"total_cycles_completed\": self.metrics.cycles_completed,\n            \"conflicts_detected\": self.metrics.conflicts_detected,\n            \"average_cycle_time\": self.metrics.get_average_cycle_time()\n        }\n</code></pre>"},{"location":"architecture/parallel-tdd-implementation-strategy/#day-5-integration-tests","title":"Day 5: Integration Tests","text":"<pre><code># tests/integration/test_parallel_basic.py\nclass TestBasicParallelExecution:\n    async def test_two_independent_cycles(self):\n        \"\"\"Test two cycles with no conflicts\"\"\"\n        coordinator = ParallelCoordinator(max_parallel=2)\n\n        story1 = create_story(\"feature_a\", files=[\"feature_a.py\"])\n        story2 = create_story(\"feature_b\", files=[\"feature_b.py\"])\n\n        # Start both cycles\n        cycle1 = await coordinator.start_cycle(story1)\n        cycle2 = await coordinator.start_cycle(story2)\n\n        assert len(coordinator.active_cycles) == 2\n        assert cycle1.id != cycle2.id\n\n        # Execute both in parallel\n        results = await asyncio.gather(\n            coordinator.execute_cycle(cycle1),\n            coordinator.execute_cycle(cycle2)\n        )\n\n        assert all(r.success for r in results)\n</code></pre>"},{"location":"architecture/parallel-tdd-implementation-strategy/#deliverables","title":"Deliverables","text":"<ol> <li>Basic ParallelCoordinator with 2-cycle support</li> <li>Static agent pools for each agent type</li> <li>File-level locking mechanism</li> <li>Basic monitoring dashboard</li> <li>Integration test suite</li> </ol>"},{"location":"architecture/parallel-tdd-implementation-strategy/#phase-2-intelligent-scheduling-weeks-3-4","title":"Phase 2: Intelligent Scheduling (Weeks 3-4)","text":""},{"location":"architecture/parallel-tdd-implementation-strategy/#goals_1","title":"Goals","text":"<ul> <li>Implement dependency-aware scheduling</li> <li>Add dynamic agent pool scaling</li> <li>Enable simple auto-merge for conflicts</li> <li>Create isolated test environments</li> </ul>"},{"location":"architecture/parallel-tdd-implementation-strategy/#week-3-advanced-scheduling","title":"Week 3: Advanced Scheduling","text":""},{"location":"architecture/parallel-tdd-implementation-strategy/#day-1-2-dependency-graph","title":"Day 1-2: Dependency Graph","text":"<pre><code># lib/parallel/dependency_scheduler.py\nclass DependencyAwareScheduler:\n    def __init__(self):\n        self.dependency_graph = nx.DiGraph()\n        self.execution_order: List[str] = []\n\n    async def analyze_dependencies(self, stories: List[Story]) -&gt; nx.DiGraph:\n        \"\"\"Build dependency graph from stories\"\"\"\n        for story in stories:\n            self.dependency_graph.add_node(story.id, story=story)\n\n            # Add explicit dependencies\n            for dep_id in story.depends_on:\n                self.dependency_graph.add_edge(dep_id, story.id)\n\n            # Add implicit dependencies (shared files)\n            for other_story in stories:\n                if other_story.id != story.id:\n                    shared_files = set(story.files) &amp; set(other_story.files)\n                    if shared_files:\n                        # Earlier story ID gets priority\n                        if story.id &lt; other_story.id:\n                            self.dependency_graph.add_edge(story.id, other_story.id)\n                        else:\n                            self.dependency_graph.add_edge(other_story.id, story.id)\n\n        return self.dependency_graph\n\n    async def get_next_schedulable(self) -&gt; List[str]:\n        \"\"\"Get stories that can be scheduled now\"\"\"\n        schedulable = []\n        for node in nx.topological_sort(self.dependency_graph):\n            if self.can_schedule_now(node):\n                schedulable.append(node)\n        return schedulable\n</code></pre>"},{"location":"architecture/parallel-tdd-implementation-strategy/#day-3-4-dynamic-agent-scaling","title":"Day 3-4: Dynamic Agent Scaling","text":"<pre><code># lib/parallel/dynamic_agent_pool.py\nclass DynamicAgentPool(BasicAgentPool):\n    def __init__(self, agent_type: AgentType, min_size: int = 1, max_size: int = 5):\n        super().__init__(agent_type, min_size)\n        self.min_size = min_size\n        self.max_size = max_size\n        self.scaling_metrics = ScalingMetrics()\n\n    async def auto_scale(self) -&gt; None:\n        \"\"\"Auto-scale pool based on demand\"\"\"\n        current_size = self.pool.qsize() + len(self.active_agents)\n        wait_time = self.scaling_metrics.average_wait_time\n        utilization = len(self.active_agents) / current_size\n\n        if utilization &gt; 0.8 and wait_time &gt; 5.0 and current_size &lt; self.max_size:\n            # Scale up\n            await self.add_agent()\n            logger.info(f\"Scaled up {self.agent_type} pool to {current_size + 1}\")\n\n        elif utilization &lt; 0.3 and current_size &gt; self.min_size:\n            # Scale down\n            await self.remove_agent()\n            logger.info(f\"Scaled down {self.agent_type} pool to {current_size - 1}\")\n\n    async def add_agent(self) -&gt; None:\n        \"\"\"Add new agent to pool\"\"\"\n        agent_id = f\"{self.agent_type.value}_{uuid.uuid4().hex[:8]}\"\n        agent = self.create_agent(agent_id)\n        await self.pool.put(agent)\n\n    async def remove_agent(self) -&gt; None:\n        \"\"\"Remove idle agent from pool\"\"\"\n        try:\n            agent = await asyncio.wait_for(self.pool.get(), timeout=0.1)\n            await agent.shutdown()\n        except asyncio.TimeoutError:\n            pass  # No idle agents\n</code></pre>"},{"location":"architecture/parallel-tdd-implementation-strategy/#day-5-auto-merge-capability","title":"Day 5: Auto-merge Capability","text":"<pre><code># lib/parallel/conflict_resolver.py\nclass AutoMergeResolver:\n    def __init__(self):\n        self.merge_strategies = {\n            MergeType.APPEND_ONLY: self.merge_append_only,\n            MergeType.NON_OVERLAPPING: self.merge_non_overlapping,\n            MergeType.IMPORT_ADDITIONS: self.merge_imports\n        }\n\n    async def can_auto_merge(self, conflict: Conflict) -&gt; bool:\n        \"\"\"Determine if conflict can be auto-merged\"\"\"\n        if conflict.type == ConflictType.NEW_FILE:\n            return False  # Can't auto-merge new file conflicts\n\n        if conflict.type == ConflictType.FILE_MODIFICATION:\n            # Analyze changes\n            changes1 = await self.get_changes(conflict.cycle1, conflict.file_path)\n            changes2 = await self.get_changes(conflict.cycle2, conflict.file_path)\n\n            # Check if changes are in different sections\n            if self.changes_are_independent(changes1, changes2):\n                return True\n\n        return False\n\n    async def auto_merge(self, conflict: Conflict) -&gt; MergeResult:\n        \"\"\"Attempt automatic merge\"\"\"\n        merge_type = self.determine_merge_type(conflict)\n        merge_strategy = self.merge_strategies.get(merge_type)\n\n        if merge_strategy:\n            return await merge_strategy(conflict)\n        else:\n            return MergeResult(success=False, reason=\"No suitable merge strategy\")\n</code></pre>"},{"location":"architecture/parallel-tdd-implementation-strategy/#week-4-test-isolation-and-integration","title":"Week 4: Test Isolation and Integration","text":""},{"location":"architecture/parallel-tdd-implementation-strategy/#day-1-2-test-environment-manager","title":"Day 1-2: Test Environment Manager","text":"<pre><code># lib/parallel/test_environment.py\nclass TestEnvironmentManager:\n    def __init__(self, max_environments: int = 3):\n        self.environments = Queue(maxsize=max_environments)\n        self.active_envs: Dict[str, TestEnvironment] = {}\n\n        # Pre-create environments\n        for i in range(max_environments):\n            env = self.create_environment(f\"test_env_{i}\")\n            self.environments.put_nowait(env)\n\n    async def acquire_environment(self, cycle_id: str) -&gt; TestEnvironment:\n        \"\"\"Acquire isolated test environment\"\"\"\n        env = await self.environments.get()\n        self.active_envs[cycle_id] = env\n\n        # Set up isolation\n        await env.setup_isolation()\n        return env\n\n    async def release_environment(self, cycle_id: str) -&gt; None:\n        \"\"\"Release and clean environment\"\"\"\n        env = self.active_envs.pop(cycle_id, None)\n        if env:\n            await env.cleanup()\n            await self.environments.put(env)\n\nclass TestEnvironment:\n    def __init__(self, env_id: str):\n        self.env_id = env_id\n        self.test_db = None\n        self.temp_dir = None\n        self.container = None\n\n    async def setup_isolation(self) -&gt; None:\n        \"\"\"Set up isolated environment\"\"\"\n        # Create temporary database\n        self.test_db = await self.create_test_database()\n\n        # Create isolated file system\n        self.temp_dir = tempfile.mkdtemp(prefix=f\"tdd_test_{self.env_id}_\")\n\n        # Optional: Create Docker container for full isolation\n        if USE_CONTAINERS:\n            self.container = await self.create_test_container()\n</code></pre>"},{"location":"architecture/parallel-tdd-implementation-strategy/#day-3-4-parallel-test-runner","title":"Day 3-4: Parallel Test Runner","text":"<pre><code># lib/parallel/parallel_test_runner.py\nclass ParallelTestRunner:\n    def __init__(self, env_manager: TestEnvironmentManager):\n        self.env_manager = env_manager\n        self.test_results: Dict[str, TestResult] = {}\n\n    async def run_tests_parallel(self, test_suites: List[TestSuite]) -&gt; Dict[str, TestResult]:\n        \"\"\"Run multiple test suites in parallel\"\"\"\n        tasks = []\n\n        for suite in test_suites:\n            task = asyncio.create_task(self.run_suite_isolated(suite))\n            tasks.append(task)\n\n        results = await asyncio.gather(*tasks, return_exceptions=True)\n\n        # Process results\n        for suite, result in zip(test_suites, results):\n            if isinstance(result, Exception):\n                self.test_results[suite.cycle_id] = TestResult(\n                    success=False,\n                    error=str(result)\n                )\n            else:\n                self.test_results[suite.cycle_id] = result\n\n        return self.test_results\n\n    async def run_suite_isolated(self, suite: TestSuite) -&gt; TestResult:\n        \"\"\"Run test suite in isolated environment\"\"\"\n        env = await self.env_manager.acquire_environment(suite.cycle_id)\n\n        try:\n            # Configure test runner for isolation\n            test_config = TestConfig(\n                database_url=env.test_db.url,\n                working_dir=env.temp_dir,\n                isolation_level=IsolationLevel.FULL\n            )\n\n            # Run tests\n            result = await suite.run(test_config)\n            return result\n\n        finally:\n            await self.env_manager.release_environment(suite.cycle_id)\n</code></pre>"},{"location":"architecture/parallel-tdd-implementation-strategy/#day-5-phase-2-integration","title":"Day 5: Phase 2 Integration","text":"<pre><code># lib/parallel/phase2_orchestrator.py\nclass Phase2ParallelOrchestrator(ParallelCoordinator):\n    def __init__(self):\n        super().__init__(max_parallel=3)  # Increase to 3\n        self.scheduler = DependencyAwareScheduler()\n        self.agent_pools = {\n            AgentType.DESIGN: DynamicAgentPool(AgentType.DESIGN),\n            AgentType.QA: DynamicAgentPool(AgentType.QA),\n            AgentType.CODE: DynamicAgentPool(AgentType.CODE),\n        }\n        self.conflict_resolver = AutoMergeResolver()\n        self.test_runner = ParallelTestRunner()\n\n    async def execute_stories_parallel(self, stories: List[Story]) -&gt; ExecutionResult:\n        \"\"\"Execute stories with intelligent scheduling\"\"\"\n        # Build dependency graph\n        await self.scheduler.analyze_dependencies(stories)\n\n        # Execute with dependency awareness\n        completed = []\n        while len(completed) &lt; len(stories):\n            # Get next schedulable stories\n            schedulable = await self.scheduler.get_next_schedulable()\n\n            # Filter by available capacity\n            to_execute = schedulable[:self.max_parallel - len(self.active_cycles)]\n\n            # Start cycles\n            tasks = []\n            for story_id in to_execute:\n                story = self.get_story(story_id)\n                task = asyncio.create_task(self.execute_story_with_retry(story))\n                tasks.append(task)\n\n            # Wait for completion\n            results = await asyncio.gather(*tasks)\n            completed.extend([r.story_id for r in results if r.success])\n\n        return ExecutionResult(stories=completed)\n</code></pre>"},{"location":"architecture/parallel-tdd-implementation-strategy/#deliverables_1","title":"Deliverables","text":"<ol> <li>Dependency-aware scheduling system</li> <li>Dynamic agent pool with auto-scaling</li> <li>Basic auto-merge for simple conflicts</li> <li>Isolated test environment system</li> <li>3 parallel cycles support</li> </ol>"},{"location":"architecture/parallel-tdd-implementation-strategy/#phase-3-advanced-parallelism-weeks-5-6","title":"Phase 3: Advanced Parallelism (Weeks 5-6)","text":""},{"location":"architecture/parallel-tdd-implementation-strategy/#goals_2","title":"Goals","text":"<ul> <li>Scale to 5+ concurrent cycles</li> <li>Implement ML-based conflict prediction</li> <li>Add optimistic concurrency control</li> <li>Integrate parallel-aware context management</li> </ul>"},{"location":"architecture/parallel-tdd-implementation-strategy/#week-5-advanced-conflict-management","title":"Week 5: Advanced Conflict Management","text":""},{"location":"architecture/parallel-tdd-implementation-strategy/#day-1-2-ml-conflict-predictor","title":"Day 1-2: ML Conflict Predictor","text":"<pre><code># lib/parallel/ml_conflict_predictor.py\nclass MLConflictPredictor:\n    def __init__(self):\n        self.model = self.load_or_train_model()\n        self.feature_extractor = ConflictFeatureExtractor()\n\n    def predict_conflict_probability(self, story1: Story, story2: Story) -&gt; float:\n        \"\"\"Predict probability of conflict between two stories\"\"\"\n        features = self.feature_extractor.extract(story1, story2)\n        probability = self.model.predict_proba([features])[0][1]\n        return probability\n\n    def extract_features(self, story1: Story, story2: Story) -&gt; np.ndarray:\n        \"\"\"Extract features for ML model\"\"\"\n        features = []\n\n        # File overlap features\n        files1 = set(self.analyze_affected_files(story1))\n        files2 = set(self.analyze_affected_files(story2))\n\n        features.append(len(files1 &amp; files2))  # Shared files\n        features.append(len(files1 | files2))  # Total files\n        features.append(jaccard_similarity(files1, files2))\n\n        # Code similarity features\n        features.append(self.code_similarity_score(story1, story2))\n\n        # Historical conflict rate\n        features.append(self.get_historical_conflict_rate(\n            story1.epic_id, story2.epic_id\n        ))\n\n        # Developer features\n        features.append(1 if story1.assignee == story2.assignee else 0)\n\n        return np.array(features)\n\n    async def rank_by_conflict_risk(self, stories: List[Story]) -&gt; List[Tuple[Story, float]]:\n        \"\"\"Rank stories by conflict risk\"\"\"\n        risk_scores = []\n\n        for i, story1 in enumerate(stories):\n            max_risk = 0.0\n            for j, story2 in enumerate(stories):\n                if i != j:\n                    risk = self.predict_conflict_probability(story1, story2)\n                    max_risk = max(max_risk, risk)\n\n            risk_scores.append((story1, max_risk))\n\n        return sorted(risk_scores, key=lambda x: x[1])\n</code></pre>"},{"location":"architecture/parallel-tdd-implementation-strategy/#day-3-4-optimistic-concurrency","title":"Day 3-4: Optimistic Concurrency","text":"<pre><code># lib/parallel/optimistic_concurrency.py\nclass OptimisticConcurrencyController:\n    def __init__(self):\n        self.file_versions: Dict[str, FileVersion] = {}\n        self.change_log: List[FileChange] = []\n\n    async def start_transaction(self, cycle_id: str, files: List[str]) -&gt; Transaction:\n        \"\"\"Start optimistic transaction\"\"\"\n        transaction = Transaction(cycle_id=cycle_id)\n\n        for file_path in files:\n            version = await self.get_file_version(file_path)\n            transaction.add_file(file_path, version)\n\n        return transaction\n\n    async def validate_and_commit(self, transaction: Transaction) -&gt; CommitResult:\n        \"\"\"Validate transaction and commit if valid\"\"\"\n        conflicts = []\n\n        for file_path, original_version in transaction.files.items():\n            current_version = await self.get_file_version(file_path)\n\n            if current_version != original_version:\n                # Version conflict - check if we can merge\n                if await self.can_merge_changes(\n                    transaction.changes[file_path],\n                    self.get_changes_since(file_path, original_version)\n                ):\n                    # Auto-merge possible\n                    merged = await self.merge_changes(\n                        transaction.changes[file_path],\n                        self.get_changes_since(file_path, original_version)\n                    )\n                    transaction.changes[file_path] = merged\n                else:\n                    conflicts.append(FileConflict(\n                        file_path=file_path,\n                        cycle_id=transaction.cycle_id,\n                        original_version=original_version,\n                        current_version=current_version\n                    ))\n\n        if conflicts:\n            return CommitResult(success=False, conflicts=conflicts)\n\n        # Commit changes\n        for file_path, changes in transaction.changes.items():\n            await self.apply_changes(file_path, changes)\n            self.file_versions[file_path] = FileVersion(\n                version=self.file_versions[file_path].version + 1,\n                modified_by=transaction.cycle_id,\n                timestamp=datetime.now()\n            )\n\n        return CommitResult(success=True)\n</code></pre>"},{"location":"architecture/parallel-tdd-implementation-strategy/#day-5-advanced-scheduling","title":"Day 5: Advanced Scheduling","text":"<pre><code># lib/parallel/advanced_scheduler.py\nclass AdvancedParallelScheduler:\n    def __init__(self, max_parallel: int = 5):\n        self.max_parallel = max_parallel\n        self.ml_predictor = MLConflictPredictor()\n        self.resource_predictor = ResourcePredictor()\n\n    async def optimize_schedule(self, stories: List[Story]) -&gt; Schedule:\n        \"\"\"Create optimal schedule minimizing conflicts and maximizing throughput\"\"\"\n        # Rank by conflict risk\n        ranked_stories = await self.ml_predictor.rank_by_conflict_risk(stories)\n\n        # Create time slots\n        schedule = Schedule()\n        current_slot = 0\n\n        while ranked_stories:\n            slot_stories = []\n            slot_resources = ResourceRequirements()\n\n            # Fill current time slot\n            for story, risk in list(ranked_stories):\n                # Check if we can add this story to current slot\n                if len(slot_stories) &gt;= self.max_parallel:\n                    break\n\n                # Predict resource needs\n                story_resources = await self.resource_predictor.predict(story)\n\n                # Check resource availability\n                if slot_resources.can_accommodate(story_resources):\n                    # Check conflict risk with stories in slot\n                    max_risk = 0.0\n                    for scheduled_story in slot_stories:\n                        conflict_risk = self.ml_predictor.predict_conflict_probability(\n                            story, scheduled_story\n                        )\n                        max_risk = max(max_risk, conflict_risk)\n\n                    if max_risk &lt; 0.3:  # Acceptable risk threshold\n                        slot_stories.append(story)\n                        slot_resources.add(story_resources)\n                        ranked_stories.remove((story, risk))\n\n            # Add slot to schedule\n            if slot_stories:\n                schedule.add_slot(current_slot, slot_stories)\n                current_slot += 1\n            else:\n                # Couldn't schedule any more stories\n                break\n\n        return schedule\n</code></pre>"},{"location":"architecture/parallel-tdd-implementation-strategy/#week-6-context-integration-and-optimization","title":"Week 6: Context Integration and Optimization","text":""},{"location":"architecture/parallel-tdd-implementation-strategy/#day-1-2-parallel-context-manager","title":"Day 1-2: Parallel Context Manager","text":"<pre><code># lib/parallel/parallel_context_manager.py\nclass ParallelContextManager:\n    def __init__(self, base_context_manager: ContextManager):\n        self.base_manager = base_context_manager\n        self.cycle_contexts: Dict[str, IsolatedContext] = {}\n        self.shared_knowledge = SharedKnowledgeBase()\n        self.token_allocator = ParallelTokenAllocator()\n\n    async def create_cycle_context(self, cycle_id: str, story: Story) -&gt; IsolatedContext:\n        \"\"\"Create isolated context for a cycle\"\"\"\n        # Calculate token budget\n        active_cycles = len(self.cycle_contexts)\n        token_budget = await self.token_allocator.allocate_for_cycle(\n            cycle_id, active_cycles + 1\n        )\n\n        # Create isolated context\n        context = IsolatedContext(\n            cycle_id=cycle_id,\n            story_id=story.id,\n            token_budget=token_budget,\n            shared_knowledge=self.shared_knowledge.get_readonly_view()\n        )\n\n        # Add story-specific context\n        await self.add_story_context(context, story)\n\n        self.cycle_contexts[cycle_id] = context\n        return context\n\n    async def optimize_parallel_contexts(self) -&gt; None:\n        \"\"\"Optimize context distribution across cycles\"\"\"\n        total_token_usage = sum(\n            ctx.get_token_usage() for ctx in self.cycle_contexts.values()\n        )\n\n        if total_token_usage &gt; TOKEN_LIMIT * 0.9:\n            # Need to optimize\n            await self.compress_contexts()\n            await self.redistribute_tokens()\n\n    async def merge_cycle_knowledge(self, cycle_id: str) -&gt; None:\n        \"\"\"Merge cycle's learned knowledge back to shared\"\"\"\n        context = self.cycle_contexts.get(cycle_id)\n        if context:\n            knowledge_updates = context.get_knowledge_updates()\n            await self.shared_knowledge.merge_updates(knowledge_updates)\n\nclass ParallelTokenAllocator:\n    def __init__(self, total_budget: int = 200000):\n        self.total_budget = total_budget\n        self.reserved_budget = int(total_budget * 0.1)  # 10% reserve\n        self.available_budget = total_budget - self.reserved_budget\n\n    async def allocate_for_cycle(self, cycle_id: str, active_cycles: int) -&gt; int:\n        \"\"\"Allocate tokens for a new cycle\"\"\"\n        # Base allocation\n        base_allocation = self.available_budget // (active_cycles + 1)\n\n        # Adjust based on cycle phase\n        phase_multipliers = {\n            TDDState.DESIGN: 1.2,      # More context needed\n            TDDState.TEST_RED: 1.0,\n            TDDState.CODE_GREEN: 1.1,\n            TDDState.REFACTOR: 0.9,\n            TDDState.COMMIT: 0.8\n        }\n\n        # Get cycle phase (default to DESIGN for new cycles)\n        phase = await self.get_cycle_phase(cycle_id)\n        multiplier = phase_multipliers.get(phase, 1.0)\n\n        return int(base_allocation * multiplier)\n</code></pre>"},{"location":"architecture/parallel-tdd-implementation-strategy/#day-3-4-performance-optimization","title":"Day 3-4: Performance Optimization","text":"<pre><code># lib/parallel/performance_optimizer.py\nclass ParallelPerformanceOptimizer:\n    def __init__(self):\n        self.metrics_collector = MetricsCollector()\n        self.bottleneck_analyzer = BottleneckAnalyzer()\n        self.optimization_strategies = {\n            Bottleneck.AGENT_POOL: self.optimize_agent_pool,\n            Bottleneck.FILE_LOCKS: self.optimize_file_locks,\n            Bottleneck.CONTEXT_PREP: self.optimize_context_prep,\n            Bottleneck.TEST_EXECUTION: self.optimize_test_execution\n        }\n\n    async def analyze_and_optimize(self) -&gt; OptimizationResult:\n        \"\"\"Analyze performance and apply optimizations\"\"\"\n        metrics = await self.metrics_collector.collect_current_metrics()\n        bottlenecks = await self.bottleneck_analyzer.identify_bottlenecks(metrics)\n\n        optimizations_applied = []\n        for bottleneck in bottlenecks:\n            strategy = self.optimization_strategies.get(bottleneck.type)\n            if strategy:\n                result = await strategy(bottleneck)\n                optimizations_applied.append(result)\n\n        return OptimizationResult(\n            bottlenecks_found=bottlenecks,\n            optimizations_applied=optimizations_applied,\n            performance_improvement=self.calculate_improvement(metrics)\n        )\n\n    async def optimize_agent_pool(self, bottleneck: Bottleneck) -&gt; OptimizationAction:\n        \"\"\"Optimize agent pool configuration\"\"\"\n        pool_type = bottleneck.resource\n        current_size = await self.get_pool_size(pool_type)\n        wait_times = bottleneck.metrics['average_wait_time']\n\n        if wait_times &gt; 10.0:  # 10 second threshold\n            # Increase pool size\n            new_size = min(current_size + 2, MAX_POOL_SIZE)\n            await self.resize_pool(pool_type, new_size)\n\n            return OptimizationAction(\n                type=\"resize_pool\",\n                details=f\"Increased {pool_type} pool from {current_size} to {new_size}\"\n            )\n</code></pre>"},{"location":"architecture/parallel-tdd-implementation-strategy/#day-5-phase-3-integration","title":"Day 5: Phase 3 Integration","text":"<pre><code># lib/parallel/phase3_orchestrator.py\nclass Phase3ParallelOrchestrator(Phase2ParallelOrchestrator):\n    def __init__(self):\n        super().__init__()\n        self.max_parallel = 5  # Increase to 5\n        self.ml_predictor = MLConflictPredictor()\n        self.occ_controller = OptimisticConcurrencyController()\n        self.parallel_context = ParallelContextManager()\n        self.performance_optimizer = ParallelPerformanceOptimizer()\n        self.advanced_scheduler = AdvancedParallelScheduler()\n\n    async def execute_stories_intelligent(self, stories: List[Story]) -&gt; ExecutionResult:\n        \"\"\"Execute stories with ML-based optimization\"\"\"\n        # Create optimal schedule\n        schedule = await self.advanced_scheduler.optimize_schedule(stories)\n\n        results = []\n        for time_slot in schedule.slots:\n            # Execute slot stories in parallel\n            slot_tasks = []\n\n            for story in time_slot.stories:\n                # Create optimistic transaction\n                transaction = await self.occ_controller.start_transaction(\n                    story.id, \n                    self.analyze_affected_files(story)\n                )\n\n                # Create isolated context\n                context = await self.parallel_context.create_cycle_context(\n                    story.id, story\n                )\n\n                # Execute with optimistic concurrency\n                task = asyncio.create_task(\n                    self.execute_story_optimistic(story, transaction, context)\n                )\n                slot_tasks.append(task)\n\n            # Wait for slot completion\n            slot_results = await asyncio.gather(*slot_tasks)\n            results.extend(slot_results)\n\n            # Optimize after each slot\n            await self.performance_optimizer.analyze_and_optimize()\n\n        return ExecutionResult(stories=results)\n</code></pre>"},{"location":"architecture/parallel-tdd-implementation-strategy/#deliverables_2","title":"Deliverables","text":"<ol> <li>ML-based conflict prediction system</li> <li>Optimistic concurrency control</li> <li>5+ parallel cycles support</li> <li>Parallel-aware context management</li> <li>Performance optimization system</li> </ol>"},{"location":"architecture/parallel-tdd-implementation-strategy/#phase-4-production-optimization-weeks-7-8","title":"Phase 4: Production Optimization (Weeks 7-8)","text":""},{"location":"architecture/parallel-tdd-implementation-strategy/#goals_3","title":"Goals","text":"<ul> <li>Fine-tune for production performance</li> <li>Add comprehensive monitoring</li> <li>Enable cross-project coordination</li> <li>Implement self-tuning capabilities</li> </ul>"},{"location":"architecture/parallel-tdd-implementation-strategy/#week-7-production-hardening","title":"Week 7: Production Hardening","text":""},{"location":"architecture/parallel-tdd-implementation-strategy/#day-1-2-advanced-monitoring","title":"Day 1-2: Advanced Monitoring","text":"<pre><code># lib/parallel/production_monitor.py\nclass ProductionMonitor:\n    def __init__(self):\n        self.metrics_store = TimeSeriesMetricsStore()\n        self.alert_manager = AlertManager()\n        self.dashboard = RealTimeDashboard()\n\n    async def collect_comprehensive_metrics(self) -&gt; None:\n        \"\"\"Collect all production metrics\"\"\"\n        while True:\n            metrics = ParallelProductionMetrics(\n                timestamp=datetime.now(),\n\n                # Throughput metrics\n                cycles_per_hour=await self.calculate_throughput(),\n                stories_completed=await self.count_completed_stories(),\n                average_cycle_time=await self.calculate_avg_cycle_time(),\n\n                # Resource metrics\n                cpu_usage=psutil.cpu_percent(),\n                memory_usage=psutil.virtual_memory().percent,\n                agent_utilization=await self.calculate_agent_utilization(),\n\n                # Quality metrics\n                test_pass_rate=await self.calculate_test_pass_rate(),\n                conflict_rate=await self.calculate_conflict_rate(),\n                auto_merge_success_rate=await self.calculate_merge_rate(),\n\n                # Cost metrics\n                token_usage=await self.calculate_token_usage(),\n                compute_cost=await self.estimate_compute_cost()\n            )\n\n            await self.metrics_store.store(metrics)\n            await self.check_alerts(metrics)\n            await self.update_dashboard(metrics)\n\n            await asyncio.sleep(60)  # Collect every minute\n</code></pre>"},{"location":"architecture/parallel-tdd-implementation-strategy/#day-3-4-cross-project-coordination","title":"Day 3-4: Cross-Project Coordination","text":"<pre><code># lib/parallel/cross_project_coordinator.py\nclass CrossProjectCoordinator:\n    def __init__(self):\n        self.project_coordinators: Dict[str, ParallelCoordinator] = {}\n        self.global_resource_manager = GlobalResourceManager()\n        self.project_priorities: Dict[str, int] = {}\n\n    async def register_project(self, project_id: str, priority: int = 5) -&gt; None:\n        \"\"\"Register project for cross-project coordination\"\"\"\n        coordinator = ParallelCoordinator(\n            max_parallel=self.calculate_project_allocation(priority)\n        )\n        self.project_coordinators[project_id] = coordinator\n        self.project_priorities[project_id] = priority\n\n    async def allocate_global_resources(self) -&gt; None:\n        \"\"\"Allocate resources across all projects\"\"\"\n        total_demand = await self.calculate_total_demand()\n        available_resources = await self.global_resource_manager.get_available()\n\n        # Allocate based on priority\n        allocations = {}\n        for project_id, priority in sorted(\n            self.project_priorities.items(), \n            key=lambda x: x[1], \n            reverse=True\n        ):\n            project_demand = await self.get_project_demand(project_id)\n            project_allocation = self.calculate_fair_share(\n                project_demand, \n                priority, \n                available_resources, \n                total_demand\n            )\n            allocations[project_id] = project_allocation\n\n        # Apply allocations\n        for project_id, allocation in allocations.items():\n            coordinator = self.project_coordinators[project_id]\n            await coordinator.update_resource_limits(allocation)\n</code></pre>"},{"location":"architecture/parallel-tdd-implementation-strategy/#day-5-self-tuning-system","title":"Day 5: Self-Tuning System","text":"<pre><code># lib/parallel/self_tuning_system.py\nclass SelfTuningSystem:\n    def __init__(self):\n        self.performance_history = PerformanceHistory()\n        self.tuning_parameters = TuningParameters()\n        self.ml_tuner = MLBasedTuner()\n\n    async def auto_tune(self) -&gt; TuningResult:\n        \"\"\"Automatically tune system parameters\"\"\"\n        # Collect recent performance data\n        recent_metrics = await self.performance_history.get_recent(hours=24)\n\n        # Identify optimization opportunities\n        opportunities = await self.identify_opportunities(recent_metrics)\n\n        # Apply ML-based tuning\n        for opportunity in opportunities:\n            if opportunity.confidence &gt; 0.8:\n                new_value = await self.ml_tuner.suggest_value(\n                    parameter=opportunity.parameter,\n                    current_value=opportunity.current_value,\n                    metrics=recent_metrics\n                )\n\n                # Apply with gradual rollout\n                await self.apply_tuning(\n                    parameter=opportunity.parameter,\n                    new_value=new_value,\n                    rollout_percentage=20  # Start with 20%\n                )\n\n        return TuningResult(\n            parameters_tuned=len(opportunities),\n            expected_improvement=self.calculate_expected_improvement(opportunities)\n        )\n\n    async def apply_tuning(self, parameter: str, new_value: Any, rollout_percentage: int):\n        \"\"\"Apply tuning with gradual rollout\"\"\"\n        if parameter == \"max_parallel_cycles\":\n            # Gradually increase parallelism\n            current = self.tuning_parameters.max_parallel_cycles\n            target = new_value\n            step = max(1, int((target - current) * rollout_percentage / 100))\n            self.tuning_parameters.max_parallel_cycles = current + step\n\n        elif parameter == \"conflict_threshold\":\n            # Adjust conflict threshold\n            self.tuning_parameters.conflict_threshold = new_value\n\n        # Monitor impact\n        await self.monitor_tuning_impact(parameter, new_value)\n</code></pre>"},{"location":"architecture/parallel-tdd-implementation-strategy/#week-8-final-integration-and-testing","title":"Week 8: Final Integration and Testing","text":""},{"location":"architecture/parallel-tdd-implementation-strategy/#day-1-2-production-test-suite","title":"Day 1-2: Production Test Suite","text":"<pre><code># tests/production/test_parallel_production.py\nclass TestProductionParallel:\n    async def test_sustained_load(self):\n        \"\"\"Test system under sustained production load\"\"\"\n        orchestrator = ProductionParallelOrchestrator()\n\n        # Generate realistic workload\n        stories = generate_production_workload(\n            num_stories=50,\n            complexity_distribution=\"normal\",\n            conflict_rate=0.1\n        )\n\n        # Run for extended period\n        start_time = time.time()\n        results = await orchestrator.execute_production_workload(\n            stories,\n            duration_hours=2\n        )\n\n        # Verify performance\n        assert results.average_throughput &gt; 10  # stories/hour\n        assert results.conflict_resolution_rate &gt; 0.8\n        assert results.test_pass_rate &gt; 0.95\n        assert results.resource_efficiency &gt; 0.7\n\n    async def test_failure_recovery(self):\n        \"\"\"Test system recovery from various failures\"\"\"\n        orchestrator = ProductionParallelOrchestrator()\n\n        # Test agent failure recovery\n        await self.simulate_agent_failure(orchestrator, AgentType.CODE)\n        assert await orchestrator.is_healthy()\n\n        # Test conflict storm recovery\n        await self.simulate_conflict_storm(orchestrator)\n        assert await orchestrator.is_healthy()\n</code></pre>"},{"location":"architecture/parallel-tdd-implementation-strategy/#day-3-4-documentation-and-training","title":"Day 3-4: Documentation and Training","text":"<pre><code># Create comprehensive documentation\n# - Architecture documentation\n# - Operations runbook  \n# - Troubleshooting guide\n# - Performance tuning guide\n# - API reference\n</code></pre>"},{"location":"architecture/parallel-tdd-implementation-strategy/#day-5-production-rollout-plan","title":"Day 5: Production Rollout Plan","text":"<pre><code># lib/parallel/rollout_manager.py\nclass ProductionRolloutManager:\n    def __init__(self):\n        self.feature_flags = FeatureFlagManager()\n        self.rollout_stages = [\n            RolloutStage(\"canary\", percentage=5, duration_hours=24),\n            RolloutStage(\"early_adopters\", percentage=20, duration_hours=48),\n            RolloutStage(\"broad\", percentage=50, duration_hours=72),\n            RolloutStage(\"general\", percentage=100, duration_hours=None)\n        ]\n\n    async def execute_rollout(self) -&gt; RolloutResult:\n        \"\"\"Execute phased production rollout\"\"\"\n        for stage in self.rollout_stages:\n            # Enable for percentage of users\n            await self.feature_flags.enable_for_percentage(\n                \"parallel_tdd_execution\",\n                stage.percentage\n            )\n\n            # Monitor metrics\n            metrics = await self.monitor_stage(stage)\n\n            # Check success criteria\n            if not self.meets_criteria(metrics):\n                # Rollback\n                await self.rollback(stage)\n                return RolloutResult(\n                    success=False,\n                    stopped_at_stage=stage.name,\n                    reason=self.get_failure_reason(metrics)\n                )\n\n            # Wait before next stage\n            if stage.duration_hours:\n                await asyncio.sleep(stage.duration_hours * 3600)\n\n        return RolloutResult(success=True)\n</code></pre>"},{"location":"architecture/parallel-tdd-implementation-strategy/#deliverables_3","title":"Deliverables","text":"<ol> <li>Production-ready monitoring system</li> <li>Cross-project coordination capability</li> <li>Self-tuning optimization system</li> <li>Comprehensive test suite</li> <li>Production rollout plan</li> </ol>"},{"location":"architecture/parallel-tdd-implementation-strategy/#risk-mitigation-matrix","title":"Risk Mitigation Matrix","text":"Risk Likelihood Impact Mitigation Strategy Data corruption Low High Transactional storage, automatic backups Deadlocks Medium High Timeout detection, ordered locking Performance degradation Medium Medium Continuous monitoring, auto-scaling Conflict storms Low High Circuit breakers, fallback to sequential Resource exhaustion Medium Medium Resource limits, quotas"},{"location":"architecture/parallel-tdd-implementation-strategy/#success-metrics","title":"Success Metrics","text":""},{"location":"architecture/parallel-tdd-implementation-strategy/#phase-1-basic-parallel","title":"Phase 1 (Basic Parallel)","text":"<ul> <li>\u2713 2 concurrent cycles working</li> <li>\u2713 &lt;5% conflict rate</li> <li>\u2713 1.5x throughput improvement</li> <li>\u2713 Zero data corruption</li> </ul>"},{"location":"architecture/parallel-tdd-implementation-strategy/#phase-2-intelligent-scheduling","title":"Phase 2 (Intelligent Scheduling)","text":"<ul> <li>\u2713 3 concurrent cycles</li> <li>\u2713 Dependency awareness working</li> <li>\u2713 50% conflicts auto-resolved</li> <li>\u2713 2x throughput improvement</li> </ul>"},{"location":"architecture/parallel-tdd-implementation-strategy/#phase-3-advanced-parallelism","title":"Phase 3 (Advanced Parallelism)","text":"<ul> <li>\u2713 5+ concurrent cycles</li> <li>\u2713 ML predictions &gt;80% accurate</li> <li>\u2713 80% conflicts auto-resolved</li> <li>\u2713 3x throughput improvement</li> </ul>"},{"location":"architecture/parallel-tdd-implementation-strategy/#phase-4-production-optimization","title":"Phase 4 (Production Optimization)","text":"<ul> <li>\u2713 Self-tuning active</li> <li>\u2713 &lt;2% manual intervention</li> <li>\u2713 &gt;90% resource efficiency</li> <li>\u2713 3.5x sustained throughput</li> </ul>"},{"location":"architecture/parallel-tdd-implementation-strategy/#conclusion","title":"Conclusion","text":"<p>This implementation strategy provides a clear path from basic parallel execution to a sophisticated, self-tuning system. The phased approach minimizes risk while delivering value incrementally. Each phase builds on the previous, ensuring a solid foundation for production-scale parallel TDD execution.</p>"},{"location":"architecture/parallel-tdd-technical-specification/","title":"Parallel TDD Technical Specification","text":""},{"location":"architecture/parallel-tdd-technical-specification/#overview","title":"Overview","text":"<p>This technical specification defines the APIs, data models, protocols, and integration points for the Parallel TDD Execution system. It serves as the authoritative reference for implementation teams.</p>"},{"location":"architecture/parallel-tdd-technical-specification/#data-models","title":"Data Models","text":""},{"location":"architecture/parallel-tdd-technical-specification/#core-entities","title":"Core Entities","text":""},{"location":"architecture/parallel-tdd-technical-specification/#paralleltddcycle","title":"ParallelTDDCycle","text":"<pre><code>@dataclass\nclass ParallelTDDCycle(TDDCycle):\n    \"\"\"Extended TDD cycle for parallel execution\"\"\"\n    # Inherited from TDDCycle\n    id: str\n    story_id: str\n    current_state: TDDState\n    tasks: List[TDDTask]\n\n    # Parallel-specific fields\n    parallel_group_id: str = \"\"  # Group of cycles running together\n    execution_priority: int = 5  # 1-10, higher = more priority\n    resource_allocation: ResourceAllocation = field(default_factory=ResourceAllocation)\n    conflict_status: ConflictStatus = ConflictStatus.NONE\n    dependencies: List[str] = field(default_factory=list)  # Other cycle IDs\n    lock_holdings: List[FileLock] = field(default_factory=list)\n    context_id: str = \"\"  # Isolated context identifier\n    transaction_id: str = \"\"  # Optimistic concurrency transaction\n\n    # Metrics\n    wait_time_seconds: float = 0.0\n    execution_time_seconds: float = 0.0\n    conflict_resolution_time: float = 0.0\n    token_usage: int = 0\n</code></pre>"},{"location":"architecture/parallel-tdd-technical-specification/#resourceallocation","title":"ResourceAllocation","text":"<pre><code>@dataclass\nclass ResourceAllocation:\n    \"\"\"Resource allocation for a parallel cycle\"\"\"\n    agent_assignments: Dict[AgentType, str] = field(default_factory=dict)  # type -&gt; agent_id\n    token_budget: int = 50000\n    test_environment_id: Optional[str] = None\n    cpu_cores: float = 1.0\n    memory_mb: int = 1024\n\n    def to_dict(self) -&gt; Dict[str, Any]:\n        return {\n            \"agent_assignments\": self.agent_assignments,\n            \"token_budget\": self.token_budget,\n            \"test_environment_id\": self.test_environment_id,\n            \"cpu_cores\": self.cpu_cores,\n            \"memory_mb\": self.memory_mb\n        }\n</code></pre>"},{"location":"architecture/parallel-tdd-technical-specification/#conflict","title":"Conflict","text":"<pre><code>@dataclass\nclass Conflict:\n    \"\"\"Represents a conflict between parallel cycles\"\"\"\n    id: str = field(default_factory=lambda: f\"conflict_{uuid.uuid4().hex[:8]}\")\n    type: ConflictType = ConflictType.FILE_OVERLAP\n    severity: ConflictSeverity = ConflictSeverity.MEDIUM\n    cycle_ids: List[str] = field(default_factory=list)\n    resources: List[str] = field(default_factory=list)  # Files, tests, etc.\n    detected_at: datetime = field(default_factory=datetime.now)\n    resolution_strategy: Optional[ResolutionStrategy] = None\n    resolved_at: Optional[datetime] = None\n    resolution_result: Optional[ResolutionResult] = None\n\n    def can_auto_resolve(self) -&gt; bool:\n        return self.severity in [ConflictSeverity.LOW, ConflictSeverity.MEDIUM]\n</code></pre>"},{"location":"architecture/parallel-tdd-technical-specification/#filelock","title":"FileLock","text":"<pre><code>@dataclass\nclass FileLock:\n    \"\"\"Distributed file lock for parallel execution\"\"\"\n    file_path: str\n    lock_id: str = field(default_factory=lambda: uuid.uuid4().hex)\n    owner_cycle_id: str = \"\"\n    lock_type: LockType = LockType.EXCLUSIVE\n    acquired_at: datetime = field(default_factory=datetime.now)\n    expires_at: Optional[datetime] = None\n    version: int = 0  # For optimistic concurrency\n\n    def is_expired(self) -&gt; bool:\n        if not self.expires_at:\n            return False\n        return datetime.now() &gt; self.expires_at\n</code></pre>"},{"location":"architecture/parallel-tdd-technical-specification/#enumerations","title":"Enumerations","text":"<pre><code>class ConflictType(Enum):\n    FILE_OVERLAP = \"file_overlap\"           # Same file modified\n    TEST_COLLISION = \"test_collision\"       # Same test files\n    DEPENDENCY_CONFLICT = \"dependency\"      # Dependency not ready\n    RESOURCE_CONTENTION = \"resource\"        # Agent/env not available\n    SEMANTIC_CONFLICT = \"semantic\"          # Code logic conflicts\n\nclass ConflictSeverity(Enum):\n    LOW = 1      # Can be auto-resolved easily\n    MEDIUM = 2   # May require smart merging\n    HIGH = 3     # Requires careful resolution\n    CRITICAL = 4 # Blocks execution\n\nclass ResolutionStrategy(Enum):\n    AUTO_MERGE = \"auto_merge\"\n    SEQUENTIAL = \"sequential\"  # Run one after another\n    REBASE = \"rebase\"         # Rebase one on top of other\n    MANUAL = \"manual\"         # Human intervention\n    ABORT = \"abort\"           # Cancel one cycle\n\nclass LockType(Enum):\n    SHARED = \"shared\"       # Multiple readers\n    EXCLUSIVE = \"exclusive\" # Single writer\n\nclass ConflictStatus(Enum):\n    NONE = \"none\"\n    POTENTIAL = \"potential\"   # Predicted but not occurred\n    ACTIVE = \"active\"        # Currently in conflict\n    RESOLVING = \"resolving\"  # Resolution in progress\n    RESOLVED = \"resolved\"    # Successfully resolved\n</code></pre>"},{"location":"architecture/parallel-tdd-technical-specification/#api-specifications","title":"API Specifications","text":""},{"location":"architecture/parallel-tdd-technical-specification/#parallel-coordinator-api","title":"Parallel Coordinator API","text":"<pre><code>class ParallelCoordinatorAPI:\n    \"\"\"Main API for parallel TDD coordination\"\"\"\n\n    async def start_parallel_execution(\n        self,\n        stories: List[Story],\n        config: ParallelConfig\n    ) -&gt; ParallelExecutionHandle:\n        \"\"\"\n        Start parallel execution of multiple stories\n\n        Args:\n            stories: List of stories to execute\n            config: Parallel execution configuration\n\n        Returns:\n            Handle for monitoring and controlling execution\n\n        Raises:\n            ResourceExhausted: If insufficient resources\n            InvalidConfiguration: If config is invalid\n        \"\"\"\n\n    async def schedule_cycle(\n        self,\n        story: Story,\n        priority: int = 5,\n        dependencies: List[str] = None\n    ) -&gt; ParallelTDDCycle:\n        \"\"\"\n        Schedule a single cycle for execution\n\n        Args:\n            story: Story to execute\n            priority: Execution priority (1-10)\n            dependencies: List of cycle IDs this depends on\n\n        Returns:\n            Scheduled cycle object\n\n        Raises:\n            SchedulingConflict: If cycle cannot be scheduled\n            DependencyError: If dependencies cannot be satisfied\n        \"\"\"\n\n    async def detect_conflicts(\n        self,\n        cycle1_id: str,\n        cycle2_id: str\n    ) -&gt; List[Conflict]:\n        \"\"\"\n        Detect conflicts between two cycles\n\n        Args:\n            cycle1_id: First cycle ID\n            cycle2_id: Second cycle ID\n\n        Returns:\n            List of detected conflicts\n        \"\"\"\n\n    async def resolve_conflict(\n        self,\n        conflict: Conflict,\n        strategy: ResolutionStrategy = ResolutionStrategy.AUTO_MERGE\n    ) -&gt; ResolutionResult:\n        \"\"\"\n        Resolve a conflict between cycles\n\n        Args:\n            conflict: Conflict to resolve\n            strategy: Resolution strategy to use\n\n        Returns:\n            Resolution result with success status\n\n        Raises:\n            ResolutionFailed: If conflict cannot be resolved\n        \"\"\"\n\n    async def get_execution_status(\n        self,\n        handle: ParallelExecutionHandle\n    ) -&gt; ParallelExecutionStatus:\n        \"\"\"\n        Get current status of parallel execution\n\n        Args:\n            handle: Execution handle from start_parallel_execution\n\n        Returns:\n            Current execution status with metrics\n        \"\"\"\n\n    async def abort_cycle(\n        self,\n        cycle_id: str,\n        reason: str\n    ) -&gt; None:\n        \"\"\"\n        Abort a running cycle\n\n        Args:\n            cycle_id: Cycle to abort\n            reason: Reason for abortion\n\n        Raises:\n            CycleNotFound: If cycle doesn't exist\n        \"\"\"\n</code></pre>"},{"location":"architecture/parallel-tdd-technical-specification/#agent-pool-api","title":"Agent Pool API","text":"<pre><code>class AgentPoolAPI:\n    \"\"\"API for managing agent pools\"\"\"\n\n    async def acquire_agent(\n        self,\n        agent_type: AgentType,\n        cycle_id: str,\n        timeout: int = 30\n    ) -&gt; Agent:\n        \"\"\"\n        Acquire an agent from the pool\n\n        Args:\n            agent_type: Type of agent needed\n            cycle_id: Cycle requesting the agent\n            timeout: Max seconds to wait\n\n        Returns:\n            Acquired agent instance\n\n        Raises:\n            AgentPoolExhausted: If no agents available\n            TimeoutError: If timeout exceeded\n        \"\"\"\n\n    async def release_agent(\n        self,\n        agent: Agent,\n        cycle_id: str\n    ) -&gt; None:\n        \"\"\"\n        Release agent back to pool\n\n        Args:\n            agent: Agent to release\n            cycle_id: Cycle releasing the agent\n        \"\"\"\n\n    async def scale_pool(\n        self,\n        agent_type: AgentType,\n        target_size: int\n    ) -&gt; None:\n        \"\"\"\n        Scale agent pool to target size\n\n        Args:\n            agent_type: Type of agent pool\n            target_size: Desired pool size\n\n        Raises:\n            ScalingError: If scaling fails\n            InvalidSize: If size outside allowed range\n        \"\"\"\n\n    async def get_pool_metrics(\n        self,\n        agent_type: AgentType\n    ) -&gt; PoolMetrics:\n        \"\"\"\n        Get metrics for an agent pool\n\n        Args:\n            agent_type: Type of agent pool\n\n        Returns:\n            Pool metrics including utilization\n        \"\"\"\n</code></pre>"},{"location":"architecture/parallel-tdd-technical-specification/#lock-manager-api","title":"Lock Manager API","text":"<pre><code>class LockManagerAPI:\n    \"\"\"API for distributed lock management\"\"\"\n\n    async def acquire_locks(\n        self,\n        cycle_id: str,\n        file_paths: List[str],\n        lock_type: LockType = LockType.EXCLUSIVE,\n        timeout: int = 10\n    ) -&gt; List[FileLock]:\n        \"\"\"\n        Acquire locks for multiple files atomically\n\n        Args:\n            cycle_id: Cycle requesting locks\n            file_paths: Files to lock\n            lock_type: Type of lock needed\n            timeout: Max seconds to wait\n\n        Returns:\n            List of acquired locks\n\n        Raises:\n            LockTimeout: If locks cannot be acquired\n            DeadlockDetected: If deadlock detected\n        \"\"\"\n\n    async def release_locks(\n        self,\n        locks: List[FileLock]\n    ) -&gt; None:\n        \"\"\"\n        Release multiple locks\n\n        Args:\n            locks: Locks to release\n        \"\"\"\n\n    async def extend_lock(\n        self,\n        lock: FileLock,\n        duration: timedelta\n    ) -&gt; FileLock:\n        \"\"\"\n        Extend lock duration\n\n        Args:\n            lock: Lock to extend\n            duration: Additional duration\n\n        Returns:\n            Updated lock with new expiry\n\n        Raises:\n            LockExpired: If lock already expired\n            LockNotOwned: If cycle doesn't own lock\n        \"\"\"\n\n    async def get_lock_info(\n        self,\n        file_path: str\n    ) -&gt; Optional[FileLock]:\n        \"\"\"\n        Get current lock info for a file\n\n        Args:\n            file_path: File to check\n\n        Returns:\n            Lock info if locked, None otherwise\n        \"\"\"\n</code></pre>"},{"location":"architecture/parallel-tdd-technical-specification/#context-manager-api","title":"Context Manager API","text":"<pre><code>class ParallelContextAPI:\n    \"\"\"API for parallel context management\"\"\"\n\n    async def create_isolated_context(\n        self,\n        cycle_id: str,\n        story: Story,\n        token_budget: int\n    ) -&gt; IsolatedContext:\n        \"\"\"\n        Create isolated context for a cycle\n\n        Args:\n            cycle_id: Cycle needing context\n            story: Story being executed\n            token_budget: Token allocation\n\n        Returns:\n            Isolated context object\n\n        Raises:\n            InsufficientTokens: If budget too low\n        \"\"\"\n\n    async def share_context(\n        self,\n        from_cycle: str,\n        to_cycle: str,\n        context_keys: List[str]\n    ) -&gt; None:\n        \"\"\"\n        Share specific context between cycles\n\n        Args:\n            from_cycle: Source cycle ID\n            to_cycle: Destination cycle ID\n            context_keys: Keys to share\n\n        Raises:\n            ContextNotFound: If context doesn't exist\n            SharingViolation: If sharing not allowed\n        \"\"\"\n\n    async def optimize_contexts(\n        self,\n        cycle_ids: List[str]\n    ) -&gt; ContextOptimizationResult:\n        \"\"\"\n        Optimize context distribution across cycles\n\n        Args:\n            cycle_ids: Cycles to optimize\n\n        Returns:\n            Optimization results with metrics\n        \"\"\"\n</code></pre>"},{"location":"architecture/parallel-tdd-technical-specification/#integration-protocols","title":"Integration Protocols","text":""},{"location":"architecture/parallel-tdd-technical-specification/#agent-communication-protocol","title":"Agent Communication Protocol","text":"<pre><code># Agent request format\nagent_request:\n  version: \"1.0\"\n  cycle_id: \"cycle_123\"\n  agent_type: \"code\"\n  task:\n    id: \"task_456\"\n    command: \"implement_minimal_solution\"\n    context:\n      story_id: \"story_789\"\n      test_files: [\"test_feature.py\"]\n      token_budget: 50000\n  metadata:\n    priority: 7\n    timeout: 300\n\n# Agent response format\nagent_response:\n  version: \"1.0\"\n  cycle_id: \"cycle_123\"\n  task_id: \"task_456\"\n  result:\n    success: true\n    output: \"Implementation complete\"\n    artifacts:\n      \"src/feature.py\": \"...\"\n    metrics:\n      execution_time: 45.2\n      tokens_used: 35000\n</code></pre>"},{"location":"architecture/parallel-tdd-technical-specification/#conflict-detection-protocol","title":"Conflict Detection Protocol","text":"<pre><code># Conflict check request\nconflict_check:\n  version: \"1.0\"\n  requester: \"cycle_123\"\n  target_resources:\n    files: [\"user.py\", \"auth.py\"]\n    tests: [\"test_user.py\"]\n  operation: \"write\"\n\n# Conflict check response  \nconflict_response:\n  version: \"1.0\"\n  conflicts:\n    - type: \"file_overlap\"\n      severity: \"medium\"\n      conflicting_cycle: \"cycle_456\"\n      resources: [\"auth.py\"]\n      suggestion: \"auto_merge\"\n</code></pre>"},{"location":"architecture/parallel-tdd-technical-specification/#lock-acquisition-protocol","title":"Lock Acquisition Protocol","text":"<pre><code># Lock request\nlock_request:\n  version: \"1.0\"\n  cycle_id: \"cycle_123\"\n  requests:\n    - file_path: \"src/user.py\"\n      lock_type: \"exclusive\"\n      duration: 300\n    - file_path: \"src/auth.py\"\n      lock_type: \"exclusive\"\n      duration: 300\n  atomic: true\n\n# Lock response\nlock_response:\n  version: \"1.0\"\n  success: true\n  locks:\n    - lock_id: \"lock_abc\"\n      file_path: \"src/user.py\"\n      expires_at: \"2024-01-01T12:30:00Z\"\n    - lock_id: \"lock_def\"\n      file_path: \"src/auth.py\"\n      expires_at: \"2024-01-01T12:30:00Z\"\n</code></pre>"},{"location":"architecture/parallel-tdd-technical-specification/#event-bus-specifications","title":"Event Bus Specifications","text":""},{"location":"architecture/parallel-tdd-technical-specification/#event-types","title":"Event Types","text":"<pre><code>@dataclass\nclass ParallelEvent:\n    \"\"\"Base class for parallel execution events\"\"\"\n    event_id: str = field(default_factory=lambda: uuid.uuid4().hex)\n    event_type: str = \"\"\n    cycle_id: str = \"\"\n    timestamp: datetime = field(default_factory=datetime.now)\n    metadata: Dict[str, Any] = field(default_factory=dict)\n\n# Cycle lifecycle events\nclass CycleStartedEvent(ParallelEvent):\n    event_type: str = \"cycle.started\"\n    story_id: str = \"\"\n    priority: int = 5\n\nclass CycleCompletedEvent(ParallelEvent):\n    event_type: str = \"cycle.completed\"\n    duration_seconds: float = 0.0\n    success: bool = True\n\n# Conflict events\nclass ConflictDetectedEvent(ParallelEvent):\n    event_type: str = \"conflict.detected\"\n    conflict: Conflict = None\n    affected_cycles: List[str] = field(default_factory=list)\n\nclass ConflictResolvedEvent(ParallelEvent):\n    event_type: str = \"conflict.resolved\"\n    conflict_id: str = \"\"\n    resolution_strategy: ResolutionStrategy = None\n\n# Resource events\nclass AgentAcquiredEvent(ParallelEvent):\n    event_type: str = \"agent.acquired\"\n    agent_type: AgentType = None\n    agent_id: str = \"\"\n\nclass ResourceExhaustedEvent(ParallelEvent):\n    event_type: str = \"resource.exhausted\"\n    resource_type: str = \"\"\n    waiting_cycles: List[str] = field(default_factory=list)\n</code></pre>"},{"location":"architecture/parallel-tdd-technical-specification/#event-subscriptions","title":"Event Subscriptions","text":"<pre><code>class EventSubscription:\n    \"\"\"Event subscription configuration\"\"\"\n\n    def __init__(\n        self,\n        event_patterns: List[str],\n        handler: Callable[[ParallelEvent], Awaitable[None]],\n        filter_predicate: Optional[Callable[[ParallelEvent], bool]] = None\n    ):\n        self.event_patterns = event_patterns  # e.g., [\"cycle.*\", \"conflict.detected\"]\n        self.handler = handler\n        self.filter_predicate = filter_predicate\n</code></pre>"},{"location":"architecture/parallel-tdd-technical-specification/#storage-specifications","title":"Storage Specifications","text":""},{"location":"architecture/parallel-tdd-technical-specification/#parallel-state-storage","title":"Parallel State Storage","text":"<pre><code>class ParallelStateStorage:\n    \"\"\"Storage interface for parallel execution state\"\"\"\n\n    async def save_parallel_state(\n        self,\n        state: ParallelExecutionState\n    ) -&gt; None:\n        \"\"\"Save complete parallel execution state\"\"\"\n\n    async def load_parallel_state(\n        self,\n        execution_id: str\n    ) -&gt; Optional[ParallelExecutionState]:\n        \"\"\"Load parallel execution state\"\"\"\n\n    async def save_cycle_checkpoint(\n        self,\n        cycle_id: str,\n        checkpoint: CycleCheckpoint\n    ) -&gt; None:\n        \"\"\"Save cycle checkpoint for recovery\"\"\"\n\n    async def list_active_executions(\n        self\n    ) -&gt; List[ParallelExecutionSummary]:\n        \"\"\"List all active parallel executions\"\"\"\n</code></pre>"},{"location":"architecture/parallel-tdd-technical-specification/#file-structure","title":"File Structure","text":"<pre><code>.orch-state/\n\u251c\u2500\u2500 parallel/\n\u2502   \u251c\u2500\u2500 executions/\n\u2502   \u2502   \u251c\u2500\u2500 {execution_id}/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 metadata.json\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 cycles/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 {cycle_id}.json\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 conflicts/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 {conflict_id}.json\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 metrics/\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 throughput.json\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 resource_usage.json\n\u2502   \u2502   \u2502       \u2514\u2500\u2500 conflicts.json\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u251c\u2500\u2500 locks/\n\u2502   \u2502   \u251c\u2500\u2500 {file_path_hash}.lock\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u251c\u2500\u2500 agent_pools/\n\u2502   \u2502   \u251c\u2500\u2500 design_pool.json\n\u2502   \u2502   \u251c\u2500\u2500 qa_pool.json\n\u2502   \u2502   \u251c\u2500\u2500 code_pool.json\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u2514\u2500\u2500 checkpoints/\n\u2502       \u251c\u2500\u2500 {cycle_id}/\n\u2502       \u2502   \u251c\u2500\u2500 {timestamp}.json\n\u2502       \u2502   \u2514\u2500\u2500 ...\n\u2502       \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"architecture/parallel-tdd-technical-specification/#performance-requirements","title":"Performance Requirements","text":""},{"location":"architecture/parallel-tdd-technical-specification/#latency-slas","title":"Latency SLAs","text":"Operation P50 P95 P99 Max Acquire Agent 100ms 500ms 1s 30s Acquire Lock 50ms 200ms 500ms 10s Conflict Detection 200ms 1s 2s 5s Context Creation 500ms 2s 5s 10s State Checkpoint 100ms 500ms 1s 5s"},{"location":"architecture/parallel-tdd-technical-specification/#throughput-requirements","title":"Throughput Requirements","text":"Metric Target Peak Concurrent Cycles 5 10 Cycles/Hour 20 50 Conflicts/Hour (resolved) 10 25 Agent Requests/Minute 100 250"},{"location":"architecture/parallel-tdd-technical-specification/#resource-limits","title":"Resource Limits","text":"Resource Per Cycle Total System Memory 2GB 20GB CPU Cores 1.0 10.0 Token Budget 50k 200k File Locks 20 200 Test Environments 1 5"},{"location":"architecture/parallel-tdd-technical-specification/#error-handling","title":"Error Handling","text":""},{"location":"architecture/parallel-tdd-technical-specification/#error-codes","title":"Error Codes","text":"<pre><code>class ParallelErrorCode(Enum):\n    # Resource errors (1xxx)\n    RESOURCE_EXHAUSTED = 1001\n    AGENT_POOL_EMPTY = 1002\n    TOKEN_BUDGET_EXCEEDED = 1003\n\n    # Lock errors (2xxx)\n    LOCK_TIMEOUT = 2001\n    DEADLOCK_DETECTED = 2002\n    LOCK_EXPIRED = 2003\n\n    # Conflict errors (3xxx)\n    CONFLICT_UNRESOLVABLE = 3001\n    MERGE_FAILED = 3002\n    DEPENDENCY_CYCLE = 3003\n\n    # System errors (4xxx)\n    CHECKPOINT_FAILED = 4001\n    STATE_CORRUPTED = 4002\n    COMMUNICATION_ERROR = 4003\n</code></pre>"},{"location":"architecture/parallel-tdd-technical-specification/#error-recovery","title":"Error Recovery","text":"<pre><code>@dataclass\nclass ErrorRecovery:\n    \"\"\"Error recovery configuration\"\"\"\n    error_code: ParallelErrorCode\n    max_retries: int = 3\n    backoff_strategy: BackoffStrategy = BackoffStrategy.EXPONENTIAL\n    fallback_action: FallbackAction = FallbackAction.ABORT_CYCLE\n    alert_threshold: int = 2  # Alert after N occurrences\n</code></pre>"},{"location":"architecture/parallel-tdd-technical-specification/#monitoring-metrics","title":"Monitoring Metrics","text":""},{"location":"architecture/parallel-tdd-technical-specification/#key-performance-indicators","title":"Key Performance Indicators","text":"<pre><code>@dataclass\nclass ParallelKPIs:\n    \"\"\"Key performance indicators for parallel execution\"\"\"\n\n    # Throughput metrics\n    cycles_started_per_hour: float\n    cycles_completed_per_hour: float\n    stories_completed_per_hour: float\n\n    # Efficiency metrics\n    average_parallelism: float  # Avg concurrent cycles\n    resource_utilization: float  # 0-1\n    conflict_rate: float  # Conflicts per cycle\n\n    # Quality metrics\n    auto_resolve_rate: float  # Auto-resolved conflicts\n    test_pass_rate: float\n    rollback_rate: float  # Cycles rolled back\n\n    # Performance metrics\n    average_cycle_time: timedelta\n    average_wait_time: timedelta\n    average_conflict_resolution_time: timedelta\n</code></pre>"},{"location":"architecture/parallel-tdd-technical-specification/#alerting-rules","title":"Alerting Rules","text":"<pre><code>alerts:\n  - name: \"High Conflict Rate\"\n    condition: \"conflict_rate &gt; 0.3\"\n    severity: \"warning\"\n    action: \"reduce_parallelism\"\n\n  - name: \"Resource Exhaustion\"\n    condition: \"resource_utilization &gt; 0.95\"\n    severity: \"critical\"\n    action: \"scale_resources\"\n\n  - name: \"Lock Timeout Storm\"\n    condition: \"lock_timeouts_per_minute &gt; 10\"\n    severity: \"critical\"\n    action: \"investigate_deadlock\"\n</code></pre>"},{"location":"architecture/parallel-tdd-technical-specification/#security-considerations","title":"Security Considerations","text":""},{"location":"architecture/parallel-tdd-technical-specification/#access-control","title":"Access Control","text":"<pre><code>class ParallelAccessControl:\n    \"\"\"Access control for parallel operations\"\"\"\n\n    async def can_start_cycle(\n        self,\n        user_id: str,\n        story: Story\n    ) -&gt; bool:\n        \"\"\"Check if user can start parallel cycle\"\"\"\n\n    async def can_resolve_conflict(\n        self,\n        user_id: str,\n        conflict: Conflict\n    ) -&gt; bool:\n        \"\"\"Check if user can resolve conflict\"\"\"\n\n    async def can_abort_cycle(\n        self,\n        user_id: str,\n        cycle_id: str\n    ) -&gt; bool:\n        \"\"\"Check if user can abort cycle\"\"\"\n</code></pre>"},{"location":"architecture/parallel-tdd-technical-specification/#audit-trail","title":"Audit Trail","text":"<pre><code>@dataclass\nclass ParallelAuditEntry:\n    \"\"\"Audit entry for parallel operations\"\"\"\n    timestamp: datetime\n    user_id: str\n    action: str  # \"start_cycle\", \"resolve_conflict\", etc.\n    cycle_id: Optional[str]\n    details: Dict[str, Any]\n    ip_address: str\n    success: bool\n</code></pre>"},{"location":"architecture/parallel-tdd-technical-specification/#migration-guide","title":"Migration Guide","text":""},{"location":"architecture/parallel-tdd-technical-specification/#from-sequential-to-parallel","title":"From Sequential to Parallel","text":"<ol> <li> <p>Enable Feature Flag <pre><code>config.features.parallel_tdd_enabled = True\nconfig.parallel.max_cycles = 2  # Start conservative\n</code></pre></p> </li> <li> <p>Configure Resource Pools <pre><code>config.agent_pools = {\n    AgentType.DESIGN: {\"min\": 1, \"max\": 3},\n    AgentType.QA: {\"min\": 1, \"max\": 3},\n    AgentType.CODE: {\"min\": 2, \"max\": 5}\n}\n</code></pre></p> </li> <li> <p>Set Conflict Policies <pre><code>config.conflict_resolution = {\n    ConflictType.FILE_OVERLAP: ResolutionStrategy.AUTO_MERGE,\n    ConflictType.TEST_COLLISION: ResolutionStrategy.SEQUENTIAL,\n    ConflictType.DEPENDENCY_CONFLICT: ResolutionStrategy.MANUAL\n}\n</code></pre></p> </li> <li> <p>Monitor and Tune</p> </li> <li>Monitor conflict rates</li> <li>Adjust parallelism level</li> <li>Tune resource allocation</li> <li>Enable advanced features gradually</li> </ol> <p>This technical specification provides the complete blueprint for implementing the Parallel TDD Execution system with all necessary APIs, protocols, and integration points defined.</p>"},{"location":"architecture/parallel-tdd-testing-strategy/","title":"Parallel TDD Comprehensive Testing Strategy","text":""},{"location":"architecture/parallel-tdd-testing-strategy/#executive-summary","title":"Executive Summary","text":"<p>This document outlines a comprehensive testing strategy for the Parallel TDD Execution system. The strategy encompasses unit testing, integration testing, performance testing, security testing, and chaos engineering to ensure the system meets quality, performance, and reliability requirements while maintaining the integrity of the TDD workflow.</p>"},{"location":"architecture/parallel-tdd-testing-strategy/#testing-framework-architecture","title":"Testing Framework Architecture","text":""},{"location":"architecture/parallel-tdd-testing-strategy/#1-test-pyramid-for-parallel-tdd","title":"1. Test Pyramid for Parallel TDD","text":"<pre><code>                 /\\\n                /  \\\n               /    \\\n              /      \\\n             /  E2E   \\\n            /  Tests   \\\n           /____________\\\n          /              \\\n         /   Integration  \\\n        /     Tests       \\\n       /__________________\\\n      /                    \\\n     /     Unit Tests       \\\n    /________________________\\\n</code></pre> <p>Distribution Target: - Unit Tests: 70% (Fast feedback, comprehensive coverage) - Integration Tests: 20% (Component interaction validation) - End-to-End Tests: 10% (Complete workflow validation)</p>"},{"location":"architecture/parallel-tdd-testing-strategy/#2-testing-infrastructure","title":"2. Testing Infrastructure","text":"<pre><code>class ParallelTDDTestFramework:\n    \"\"\"Comprehensive testing framework for parallel TDD system\"\"\"\n\n    def __init__(self):\n        self.test_environments = TestEnvironmentManager()\n        self.mock_factory = MockFactory()\n        self.data_factory = TestDataFactory()\n        self.performance_profiler = PerformanceProfiler()\n        self.chaos_engine = ChaosTestingEngine()\n\n    async def setup_test_environment(self, test_type: TestType) -&gt; TestEnvironment:\n        \"\"\"Set up isolated test environment\"\"\"\n        if test_type == TestType.UNIT:\n            return await self._setup_unit_test_env()\n        elif test_type == TestType.INTEGRATION:\n            return await self._setup_integration_test_env()\n        elif test_type == TestType.E2E:\n            return await self._setup_e2e_test_env()\n        elif test_type == TestType.PERFORMANCE:\n            return await self._setup_performance_test_env()\n\n    async def _setup_integration_test_env(self) -&gt; TestEnvironment:\n        \"\"\"Set up environment for integration testing\"\"\"\n        env = TestEnvironment(\n            test_type=TestType.INTEGRATION,\n            isolation_level=IsolationLevel.CONTAINER,\n            resource_limits=ResourceLimits(\n                memory_mb=4096,\n                cpu_cores=4.0,\n                disk_gb=10\n            )\n        )\n\n        # Set up test databases\n        await env.create_test_database()\n\n        # Set up mock external services\n        await env.setup_mock_services([\n            'discord_api',\n            'github_api', \n            'claude_code_cli'\n        ])\n\n        # Initialize test data\n        await self.data_factory.populate_test_data(env)\n\n        return env\n\nclass TestDataFactory:\n    \"\"\"Generate realistic test data for parallel TDD testing\"\"\"\n\n    async def create_parallel_test_scenario(\n        self,\n        num_cycles: int = 3,\n        conflict_probability: float = 0.2,\n        complexity_distribution: str = \"normal\"\n    ) -&gt; ParallelTestScenario:\n        \"\"\"Create realistic parallel execution test scenario\"\"\"\n\n        stories = []\n        for i in range(num_cycles):\n            story = await self._create_test_story(\n                story_id=f\"test_story_{i}\",\n                complexity=self._sample_complexity(complexity_distribution),\n                files=await self._generate_story_files(i, conflict_probability)\n            )\n            stories.append(story)\n\n        return ParallelTestScenario(\n            stories=stories,\n            expected_conflicts=await self._calculate_expected_conflicts(stories),\n            expected_duration=await self._estimate_execution_time(stories),\n            success_criteria=await self._define_success_criteria(stories)\n        )\n</code></pre>"},{"location":"architecture/parallel-tdd-testing-strategy/#unit-testing-strategy","title":"Unit Testing Strategy","text":""},{"location":"architecture/parallel-tdd-testing-strategy/#1-component-level-unit-tests","title":"1. Component-Level Unit Tests","text":"<pre><code>class TestParallelCoordinator:\n    \"\"\"Comprehensive unit tests for ParallelCoordinator\"\"\"\n\n    @pytest.fixture\n    async def coordinator(self):\n        \"\"\"Set up coordinator with mocked dependencies\"\"\"\n        mock_storage = Mock(spec=ProjectStorage)\n        mock_agent_pool = Mock(spec=AgentPoolManager)\n        mock_context_manager = Mock(spec=ParallelContextManager)\n\n        coordinator = ParallelCoordinator(\n            max_parallel=3,\n            storage=mock_storage,\n            agent_pool_manager=mock_agent_pool,\n            context_manager=mock_context_manager\n        )\n        return coordinator\n\n    async def test_can_start_cycle_with_available_resources(self, coordinator):\n        \"\"\"Test cycle can start when resources are available\"\"\"\n        # Arrange\n        story = TestDataFactory.create_simple_story()\n        coordinator.active_cycles = {}\n        coordinator.resource_allocator.check_availability.return_value = True\n\n        # Act\n        can_start, reason = await coordinator.can_start_cycle(story)\n\n        # Assert\n        assert can_start is True\n        assert reason is None\n\n    async def test_cannot_start_cycle_when_max_parallel_reached(self, coordinator):\n        \"\"\"Test cycle cannot start when max parallel limit reached\"\"\"\n        # Arrange\n        story = TestDataFactory.create_simple_story()\n        coordinator.active_cycles = {\n            'cycle1': Mock(),\n            'cycle2': Mock(), \n            'cycle3': Mock()\n        }\n\n        # Act\n        can_start, reason = await coordinator.can_start_cycle(story)\n\n        # Assert\n        assert can_start is False\n        assert \"Max parallel cycles reached\" in reason\n\n    async def test_conflict_detection_identifies_file_overlap(self, coordinator):\n        \"\"\"Test conflict detection identifies overlapping files\"\"\"\n        # Arrange\n        cycle1 = await TestDataFactory.create_test_cycle(files=[\"user.py\", \"auth.py\"])\n        cycle2 = await TestDataFactory.create_test_cycle(files=[\"auth.py\", \"db.py\"])\n\n        # Act\n        conflicts = await coordinator.detect_conflicts(cycle1.id, cycle2.id)\n\n        # Assert\n        assert len(conflicts) == 1\n        assert conflicts[0].type == ConflictType.FILE_OVERLAP\n        assert \"auth.py\" in conflicts[0].resources\n\n    async def test_graceful_degradation_on_agent_failure(self, coordinator):\n        \"\"\"Test system degrades gracefully when agents fail\"\"\"\n        # Arrange\n        story = TestDataFactory.create_simple_story()\n        coordinator.agent_pool_manager.acquire_agent.side_effect = AgentPoolExhausted()\n\n        # Act &amp; Assert\n        with pytest.raises(AgentPoolExhausted):\n            await coordinator.start_cycle(story)\n\n        # Verify fallback mechanisms triggered\n        assert coordinator.metrics.fallback_triggered is True\n\nclass TestConflictResolver:\n    \"\"\"Unit tests for conflict resolution algorithms\"\"\"\n\n    async def test_ast_merge_resolves_non_overlapping_changes(self):\n        \"\"\"Test AST merge successfully resolves non-overlapping changes\"\"\"\n        # Arrange\n        base_code = '''\ndef function_a():\n    pass\n\ndef function_b():\n    pass\n'''\n\n        version1 = '''\ndef function_a():\n    return \"modified_a\"\n\ndef function_b():\n    pass\n'''\n\n        version2 = '''\ndef function_a():\n    pass\n\ndef function_b():\n    return \"modified_b\"\n'''\n\n        conflict = Conflict(\n            type=ConflictType.FILE_OVERLAP,\n            resource=\"test_file.py\",\n            cycles=[\"cycle1\", \"cycle2\"]\n        )\n\n        resolver = AutoMergeResolver()\n\n        # Mock file versions\n        resolver._get_cycle_file_version = AsyncMock(side_effect=[\n            FileVersion(content=version1),\n            FileVersion(content=version2)\n        ])\n        resolver._get_base_file_version = AsyncMock(return_value=FileVersion(content=base_code))\n\n        # Act\n        result = await resolver._try_ast_merge(conflict)\n\n        # Assert\n        assert result.success is True\n        assert \"return \\\"modified_a\\\"\" in result.merged_content\n        assert \"return \\\"modified_b\\\"\" in result.merged_content\n\n    async def test_ast_merge_fails_on_conflicting_changes(self):\n        \"\"\"Test AST merge fails when changes conflict\"\"\"\n        # Arrange - both cycles modify the same function\n        base_code = '''\ndef function_a():\n    pass\n'''\n\n        version1 = '''\ndef function_a():\n    return \"version_1\"\n'''\n\n        version2 = '''\ndef function_a():\n    return \"version_2\"\n'''\n\n        conflict = Conflict(\n            type=ConflictType.FILE_OVERLAP,\n            resource=\"test_file.py\",\n            cycles=[\"cycle1\", \"cycle2\"]\n        )\n\n        resolver = AutoMergeResolver()\n        resolver._get_cycle_file_version = AsyncMock(side_effect=[\n            FileVersion(content=version1),\n            FileVersion(content=version2)\n        ])\n        resolver._get_base_file_version = AsyncMock(return_value=FileVersion(content=base_code))\n\n        # Act\n        result = await resolver._try_ast_merge(conflict)\n\n        # Assert\n        assert result.success is False\n        assert \"conflict\" in result.reason.lower()\n\nclass TestAgentPoolManager:\n    \"\"\"Unit tests for agent pool management\"\"\"\n\n    async def test_dynamic_scaling_increases_pool_on_high_demand(self):\n        \"\"\"Test pool scales up when demand is high\"\"\"\n        # Arrange\n        pool = DynamicAgentPool(AgentType.CODE, min_size=2, max_size=5)\n        pool.metrics.utilization = 0.9\n        pool.metrics.average_wait_time = timedelta(seconds=15)\n\n        # Act\n        await pool.auto_scale()\n\n        # Assert\n        assert pool.target_size &gt; pool.current_size\n\n    async def test_agent_allocation_respects_requirements(self):\n        \"\"\"Test agent allocation considers specific requirements\"\"\"\n        # Arrange\n        pool_manager = AgentPoolManager()\n        requirements = AgentRequirements(\n            memory_mb=2048,\n            cpu_cores=2.0,\n            special_tools=[\"advanced_testing\"]\n        )\n\n        # Mock agent pool\n        mock_pool = Mock()\n        suitable_agent = Mock()\n        suitable_agent.max_memory_mb = 4096\n        suitable_agent.max_cpu_cores = 4.0\n        suitable_agent.available_tools = [\"basic_tools\", \"advanced_testing\"]\n\n        mock_pool.acquire_with_requirements.return_value = suitable_agent\n        pool_manager.pools[AgentType.CODE] = mock_pool\n\n        # Act\n        allocation = await pool_manager.acquire_agent(\n            AgentType.CODE, \"test_cycle\", requirements\n        )\n\n        # Assert\n        assert allocation.agent == suitable_agent\n        mock_pool.acquire_with_requirements.assert_called_once_with(\"test_cycle\", requirements)\n\nclass TestContextManagement:\n    \"\"\"Unit tests for parallel context management\"\"\"\n\n    async def test_token_budget_allocation_across_cycles(self):\n        \"\"\"Test token budget is allocated optimally across cycles\"\"\"\n        # Arrange\n        budget_manager = ParallelTokenBudgetManager(total_budget=200000)\n        parallel_group = ParallelGroup(cycles=[\"cycle1\", \"cycle2\", \"cycle3\"])\n\n        # Act\n        allocation1 = await budget_manager.allocate_for_cycle(\"cycle1\", parallel_group)\n        allocation2 = await budget_manager.allocate_for_cycle(\"cycle2\", parallel_group)\n        allocation3 = await budget_manager.allocate_for_cycle(\"cycle3\", parallel_group)\n\n        # Assert\n        total_allocated = (allocation1.allocated_tokens + \n                          allocation2.allocated_tokens + \n                          allocation3.allocated_tokens)\n\n        # Should not exceed 90% of total budget (10% reserve)\n        assert total_allocated &lt;= 180000\n\n        # Each allocation should be reasonable\n        assert allocation1.allocated_tokens &gt;= 30000\n        assert allocation2.allocated_tokens &gt;= 30000\n        assert allocation3.allocated_tokens &gt;= 30000\n\n    async def test_context_compression_maintains_relevance(self):\n        \"\"\"Test context compression maintains relevance while reducing size\"\"\"\n        # Arrange\n        context = IsolatedCycleContext(\n            cycle_id=\"test_cycle\",\n            story_id=\"test_story\",\n            token_budget=50000,\n            scope=ContextScope(core_files=[\"large_file.py\"])\n        )\n\n        # Mock large file content\n        large_content = \"def function():\\n\" + \"    pass\\n\" * 1000  # Large file\n        context.file_content_cache[\"large_file.py\"] = large_content\n\n        compressor = ContextCompressor()\n\n        # Act\n        compressed_context = await context._compress_context_for_agent(\n            [RelevantFile(file_path=\"large_file.py\", content=large_content, relevance_score=0.9)],\n            AgentType.CODE,\n            ContextNeeds(preferred_token_count=40000)\n        )\n\n        # Assert\n        assert compressed_context.token_count &lt;= 40000\n        assert compressed_context.overall_relevance &gt;= 0.8\n        assert len(compressed_context.files) == 1\n        assert compressed_context.files[0].compression_ratio &lt; 1.0\n</code></pre>"},{"location":"architecture/parallel-tdd-testing-strategy/#integration-testing-strategy","title":"Integration Testing Strategy","text":""},{"location":"architecture/parallel-tdd-testing-strategy/#1-component-integration-tests","title":"1. Component Integration Tests","text":"<pre><code>class TestParallelExecutionIntegration:\n    \"\"\"Integration tests for complete parallel execution flow\"\"\"\n\n    @pytest.fixture\n    async def test_environment(self):\n        \"\"\"Set up complete test environment\"\"\"\n        env = await TestEnvironmentSetup.create_integration_environment()\n\n        # Initialize all components\n        await env.initialize_components([\n            'parallel_coordinator',\n            'agent_pool_manager', \n            'context_manager',\n            'conflict_resolver',\n            'storage_system'\n        ])\n\n        yield env\n\n        # Cleanup\n        await env.cleanup()\n\n    async def test_two_independent_parallel_cycles(self, test_environment):\n        \"\"\"Test two completely independent cycles run in parallel\"\"\"\n        # Arrange\n        story1 = await TestDataFactory.create_story(\n            \"feature_a\", \n            files=[\"feature_a.py\", \"test_feature_a.py\"]\n        )\n        story2 = await TestDataFactory.create_story(\n            \"feature_b\", \n            files=[\"feature_b.py\", \"test_feature_b.py\"]\n        )\n\n        coordinator = test_environment.get_component('parallel_coordinator')\n\n        # Act\n        start_time = time.time()\n\n        # Start both cycles\n        cycle1_task = asyncio.create_task(coordinator.execute_story(story1))\n        cycle2_task = asyncio.create_task(coordinator.execute_story(story2))\n\n        # Wait for completion\n        results = await asyncio.gather(cycle1_task, cycle2_task)\n\n        end_time = time.time()\n        execution_time = end_time - start_time\n\n        # Assert\n        assert all(result.success for result in results)\n        assert len(coordinator.active_cycles) == 0  # All cycles completed\n\n        # Performance assertion - should be faster than sequential\n        sequential_estimate = await self._estimate_sequential_time([story1, story2])\n        assert execution_time &lt; sequential_estimate * 0.7  # At least 30% faster\n\n    async def test_conflicting_cycles_resolution(self, test_environment):\n        \"\"\"Test conflicting cycles are properly resolved\"\"\"\n        # Arrange\n        shared_file = \"shared_module.py\"\n        story1 = await TestDataFactory.create_story(\n            \"feature_c\",\n            files=[shared_file, \"feature_c.py\"],\n            modifications={shared_file: \"add_function_c\"}\n        )\n        story2 = await TestDataFactory.create_story(\n            \"feature_d\", \n            files=[shared_file, \"feature_d.py\"],\n            modifications={shared_file: \"add_function_d\"}\n        )\n\n        coordinator = test_environment.get_component('parallel_coordinator')\n\n        # Act\n        cycle1_task = asyncio.create_task(coordinator.execute_story(story1))\n        cycle2_task = asyncio.create_task(coordinator.execute_story(story2))\n\n        results = await asyncio.gather(cycle1_task, cycle2_task)\n\n        # Assert\n        assert all(result.success for result in results)\n\n        # Verify conflict was detected and resolved\n        conflicts = await coordinator.get_resolved_conflicts()\n        assert len(conflicts) &gt;= 1\n        assert any(shared_file in c.resources for c in conflicts)\n\n        # Verify final state is consistent\n        final_file_content = await test_environment.read_file(shared_file)\n        assert \"add_function_c\" in final_file_content\n        assert \"add_function_d\" in final_file_content\n\n    async def test_agent_pool_scaling_under_load(self, test_environment):\n        \"\"\"Test agent pool scales appropriately under load\"\"\"\n        # Arrange\n        stories = [\n            await TestDataFactory.create_story(f\"story_{i}\")\n            for i in range(5)  # More stories than initial agent pool\n        ]\n\n        coordinator = test_environment.get_component('parallel_coordinator')\n        agent_pool_manager = test_environment.get_component('agent_pool_manager')\n\n        initial_pool_sizes = {\n            agent_type: pool.current_size \n            for agent_type, pool in agent_pool_manager.pools.items()\n        }\n\n        # Act\n        tasks = [\n            asyncio.create_task(coordinator.execute_story(story))\n            for story in stories\n        ]\n\n        # Monitor pool scaling during execution\n        scaling_events = []\n        async def monitor_scaling():\n            while any(not task.done() for task in tasks):\n                current_sizes = {\n                    agent_type: pool.current_size\n                    for agent_type, pool in agent_pool_manager.pools.items()\n                }\n                if current_sizes != initial_pool_sizes:\n                    scaling_events.append({\n                        'timestamp': time.time(),\n                        'pool_sizes': current_sizes\n                    })\n                await asyncio.sleep(1)\n\n        monitor_task = asyncio.create_task(monitor_scaling())\n\n        # Wait for execution completion\n        results = await asyncio.gather(*tasks)\n        monitor_task.cancel()\n\n        # Assert\n        assert all(result.success for result in results)\n\n        # Verify scaling occurred\n        assert len(scaling_events) &gt; 0\n\n        # Verify pools scaled back down after execution\n        final_pool_sizes = {\n            agent_type: pool.current_size\n            for agent_type, pool in agent_pool_manager.pools.items()\n        }\n\n        # Pool sizes should be close to initial sizes (may not be exact due to cooldown)\n        for agent_type, initial_size in initial_pool_sizes.items():\n            assert abs(final_pool_sizes[agent_type] - initial_size) &lt;= 1\n\nclass TestContextSharingIntegration:\n    \"\"\"Integration tests for context sharing between cycles\"\"\"\n\n    async def test_context_sharing_improves_efficiency(self, test_environment):\n        \"\"\"Test context sharing reduces token usage and improves efficiency\"\"\"\n        # Arrange\n        shared_files = [\"common_utils.py\", \"shared_models.py\"]\n\n        story1 = await TestDataFactory.create_story(\n            \"feature_e\",\n            files=shared_files + [\"feature_e.py\"]\n        )\n        story2 = await TestDataFactory.create_story(\n            \"feature_f\",\n            files=shared_files + [\"feature_f.py\"]\n        )\n\n        context_manager = test_environment.get_component('context_manager')\n\n        # Act - Execute with context sharing enabled\n        parallel_group = ParallelGroup(cycles=[\"cycle1\", \"cycle2\"])\n\n        context1 = await context_manager.create_cycle_context(\"cycle1\", story1, parallel_group)\n        context2 = await context_manager.create_cycle_context(\"cycle2\", story2, parallel_group)\n\n        # Enable context sharing for common files\n        await context_manager.share_context(\n            from_cycle=\"cycle1\",\n            to_cycle=\"cycle2\", \n            context_keys=shared_files,\n            sharing_mode=SharingMode.READ_ONLY\n        )\n\n        # Execute both cycles\n        coordinator = test_environment.get_component('parallel_coordinator')\n\n        results = await asyncio.gather(\n            coordinator.execute_story_with_context(story1, context1),\n            coordinator.execute_story_with_context(story2, context2)\n        )\n\n        # Assert\n        assert all(result.success for result in results)\n\n        # Verify token efficiency improvement\n        total_tokens_used = context1.tokens_used + context2.tokens_used\n        estimated_individual_usage = await self._estimate_individual_token_usage([story1, story2])\n\n        efficiency_improvement = (estimated_individual_usage - total_tokens_used) / estimated_individual_usage\n        assert efficiency_improvement &gt;= 0.1  # At least 10% improvement\n\n        # Verify shared context was actually used\n        shared_contexts = await context_manager.get_shared_contexts(parallel_group)\n        assert len(shared_contexts) &gt; 0\n        assert any(shared_file in sc.elements for sc in shared_contexts for shared_file in shared_files)\n</code></pre>"},{"location":"architecture/parallel-tdd-testing-strategy/#performance-testing-strategy","title":"Performance Testing Strategy","text":""},{"location":"architecture/parallel-tdd-testing-strategy/#1-load-testing","title":"1. Load Testing","text":"<pre><code>class PerformanceTestSuite:\n    \"\"\"Comprehensive performance testing for parallel TDD system\"\"\"\n\n    async def test_throughput_scaling(self):\n        \"\"\"Test throughput scaling with increasing parallel cycles\"\"\"\n        test_cases = [\n            {'parallel_cycles': 1, 'expected_throughput_multiplier': 1.0},\n            {'parallel_cycles': 2, 'expected_throughput_multiplier': 1.8},\n            {'parallel_cycles': 3, 'expected_throughput_multiplier': 2.5},\n            {'parallel_cycles': 5, 'expected_throughput_multiplier': 3.5}\n        ]\n\n        baseline_throughput = await self._measure_sequential_throughput()\n\n        for test_case in test_cases:\n            # Arrange\n            stories = await TestDataFactory.create_independent_stories(\n                count=test_case['parallel_cycles'] * 2  # 2x stories to keep system busy\n            )\n\n            # Act\n            start_time = time.time()\n            results = await self._execute_parallel_stories(\n                stories, \n                max_parallel=test_case['parallel_cycles']\n            )\n            end_time = time.time()\n\n            # Calculate throughput\n            execution_time = end_time - start_time\n            actual_throughput = len(stories) / execution_time\n            throughput_multiplier = actual_throughput / baseline_throughput\n\n            # Assert\n            expected_multiplier = test_case['expected_throughput_multiplier']\n            assert throughput_multiplier &gt;= expected_multiplier * 0.9  # 10% tolerance\n\n            # Verify quality wasn't compromised\n            assert all(result.success for result in results)\n            assert all(result.test_pass_rate &gt;= 0.95 for result in results)\n\n    async def test_resource_utilization_efficiency(self):\n        \"\"\"Test resource utilization remains efficient under load\"\"\"\n        # Arrange\n        stories = await TestDataFactory.create_mixed_complexity_stories(count=10)\n        resource_monitor = ResourceMonitor()\n\n        # Act\n        await resource_monitor.start_monitoring()\n\n        results = await self._execute_parallel_stories(stories, max_parallel=5)\n\n        resource_stats = await resource_monitor.stop_and_get_stats()\n\n        # Assert\n        assert resource_stats.cpu_utilization &gt;= 0.7  # Good CPU utilization\n        assert resource_stats.cpu_utilization &lt;= 0.9  # Not overloaded\n        assert resource_stats.memory_utilization &lt;= 0.8  # Reasonable memory usage\n        assert resource_stats.agent_utilization &gt;= 0.8  # Agents being used efficiently\n\n        # No resource exhaustion events\n        assert resource_stats.resource_exhaustion_events == 0\n\n    async def test_token_budget_efficiency(self):\n        \"\"\"Test token budget is used efficiently across parallel cycles\"\"\"\n        # Arrange\n        total_budget = 200000\n        stories = await TestDataFactory.create_context_heavy_stories(count=4)\n\n        # Act\n        context_manager = ParallelContextManager(total_budget=total_budget)\n\n        results = await self._execute_with_context_monitoring(\n            stories, context_manager, max_parallel=4\n        )\n\n        # Assert\n        total_tokens_used = sum(result.tokens_used for result in results)\n        token_efficiency = total_tokens_used / total_budget\n\n        assert token_efficiency &gt;= 0.8  # High token utilization\n        assert token_efficiency &lt;= 0.95  # Didn't exceed safe limits\n\n        # Context quality maintained\n        avg_relevance = sum(result.context_relevance for result in results) / len(results)\n        assert avg_relevance &gt;= 0.9\n\nclass StressTestSuite:\n    \"\"\"Stress testing for system limits and failure scenarios\"\"\"\n\n    async def test_high_conflict_scenario(self):\n        \"\"\"Test system behavior under high conflict rates\"\"\"\n        # Arrange - Create stories with high likelihood of conflicts\n        stories = await TestDataFactory.create_conflicting_stories(\n            count=8,\n            conflict_probability=0.7  # High conflict rate\n        )\n\n        coordinator = ParallelCoordinator(max_parallel=4)\n\n        # Act\n        start_time = time.time()\n        results = await coordinator.execute_stories(stories)\n        end_time = time.time()\n\n        # Assert\n        execution_time = end_time - start_time\n\n        # System should handle high conflicts gracefully\n        assert all(result.success for result in results)\n\n        # Conflict resolution metrics\n        conflicts = await coordinator.get_all_conflicts()\n        auto_resolved = sum(1 for c in conflicts if c.resolution_strategy != ResolutionStrategy.MANUAL)\n        auto_resolution_rate = auto_resolved / len(conflicts) if conflicts else 1.0\n\n        assert auto_resolution_rate &gt;= 0.6  # At least 60% auto-resolved\n\n        # Execution time should be reasonable despite conflicts\n        sequential_estimate = await self._estimate_sequential_time(stories)\n        assert execution_time &lt;= sequential_estimate * 1.5  # No more than 50% overhead\n\n    async def test_agent_failure_recovery(self):\n        \"\"\"Test system recovery from agent failures\"\"\"\n        # Arrange\n        stories = await TestDataFactory.create_standard_stories(count=6)\n\n        # Inject agent failures\n        failure_injector = AgentFailureInjector()\n        await failure_injector.configure_failures([\n            AgentFailure(agent_type=AgentType.CODE, failure_rate=0.3),\n            AgentFailure(agent_type=AgentType.QA, failure_rate=0.2)\n        ])\n\n        coordinator = ParallelCoordinator(max_parallel=3)\n\n        # Act\n        results = await coordinator.execute_stories(stories)\n\n        # Assert\n        assert all(result.success for result in results)\n\n        # Verify recovery mechanisms worked\n        recovery_events = await coordinator.get_recovery_events()\n        assert len(recovery_events) &gt; 0  # Failures occurred and were handled\n\n        # Verify no data corruption\n        for result in results:\n            assert await self._verify_result_integrity(result)\n\n    async def test_memory_pressure_handling(self):\n        \"\"\"Test system behavior under memory pressure\"\"\"\n        # Arrange\n        memory_pressure_injector = MemoryPressureInjector()\n\n        # Create memory-intensive scenarios\n        stories = await TestDataFactory.create_large_context_stories(count=5)\n\n        # Act\n        await memory_pressure_injector.start_pressure_simulation()\n\n        try:\n            results = await self._execute_parallel_stories(stories, max_parallel=3)\n\n            # Assert\n            assert all(result.success for result in results)\n\n            # Verify graceful degradation occurred\n            context_metrics = await self._get_context_metrics()\n            assert context_metrics.compression_rate &gt; 0.7  # High compression under pressure\n            assert context_metrics.cache_eviction_rate &gt; 0.1  # Active cache management\n\n        finally:\n            await memory_pressure_injector.stop_pressure_simulation()\n</code></pre>"},{"location":"architecture/parallel-tdd-testing-strategy/#security-testing-strategy","title":"Security Testing Strategy","text":""},{"location":"architecture/parallel-tdd-testing-strategy/#1-agent-isolation-testing","title":"1. Agent Isolation Testing","text":"<pre><code>class SecurityTestSuite:\n    \"\"\"Security testing for parallel TDD system\"\"\"\n\n    async def test_agent_security_boundaries(self):\n        \"\"\"Test agent security boundaries are maintained in parallel execution\"\"\"\n        # Arrange\n        stories = await TestDataFactory.create_security_test_stories()\n\n        # Create cycles with different security requirements\n        design_cycle = await self._create_cycle_with_agent(AgentType.DESIGN)\n        code_cycle = await self._create_cycle_with_agent(AgentType.CODE)\n        qa_cycle = await self._create_cycle_with_agent(AgentType.QA)\n\n        security_monitor = SecurityMonitor()\n\n        # Act\n        await security_monitor.start_monitoring()\n\n        # Execute cycles in parallel\n        results = await asyncio.gather(\n            self._execute_cycle_with_monitoring(design_cycle),\n            self._execute_cycle_with_monitoring(code_cycle),\n            self._execute_cycle_with_monitoring(qa_cycle)\n        )\n\n        violations = await security_monitor.get_security_violations()\n\n        # Assert\n        assert len(violations) == 0  # No security violations\n\n        # Verify each agent stayed within its boundaries\n        design_actions = await security_monitor.get_agent_actions(AgentType.DESIGN)\n        code_actions = await security_monitor.get_agent_actions(AgentType.CODE)\n        qa_actions = await security_monitor.get_agent_actions(AgentType.QA)\n\n        # Design agent should only read and create docs\n        assert all(action.type in ['read', 'write_docs'] for action in design_actions)\n\n        # Code agent should not push to remote\n        assert not any(action.type == 'git_push' for action in code_actions)\n\n        # QA agent should not modify source code\n        assert not any(action.type == 'write_source' for action in qa_actions)\n\n    async def test_context_isolation_security(self):\n        \"\"\"Test context is properly isolated between cycles\"\"\"\n        # Arrange\n        sensitive_story = await TestDataFactory.create_story_with_sensitive_data()\n        normal_story = await TestDataFactory.create_normal_story()\n\n        context_manager = ParallelContextManager()\n\n        # Act\n        sensitive_context = await context_manager.create_cycle_context(\n            \"sensitive_cycle\", sensitive_story, security_level=SecurityLevel.HIGH\n        )\n        normal_context = await context_manager.create_cycle_context(\n            \"normal_cycle\", normal_story, security_level=SecurityLevel.STANDARD\n        )\n\n        # Attempt to share context (should fail for sensitive data)\n        sharing_result = await context_manager.share_context(\n            from_cycle=\"sensitive_cycle\",\n            to_cycle=\"normal_cycle\",\n            context_keys=[\"sensitive_file.py\"]\n        )\n\n        # Assert\n        assert sharing_result.success is False\n        assert \"security\" in sharing_result.reason.lower()\n\n        # Verify isolation maintained\n        normal_context_files = await normal_context.get_available_files()\n        assert \"sensitive_file.py\" not in normal_context_files\n\n    async def test_resource_access_control(self):\n        \"\"\"Test resource access is properly controlled in parallel execution\"\"\"\n        # Arrange\n        resource_controller = ResourceAccessController()\n\n        # Create cycles with different resource requirements\n        limited_cycle = await self._create_resource_limited_cycle()\n        privileged_cycle = await self._create_privileged_cycle()\n\n        # Act\n        access_attempts = []\n\n        # Monitor resource access attempts\n        async def monitor_access():\n            async for attempt in resource_controller.monitor_access_attempts():\n                access_attempts.append(attempt)\n\n        monitor_task = asyncio.create_task(monitor_access())\n\n        # Execute cycles\n        await asyncio.gather(\n            self._execute_cycle(limited_cycle),\n            self._execute_cycle(privileged_cycle)\n        )\n\n        monitor_task.cancel()\n\n        # Assert\n        limited_attempts = [a for a in access_attempts if a.cycle_id == limited_cycle.id]\n        privileged_attempts = [a for a in access_attempts if a.cycle_id == privileged_cycle.id]\n\n        # Limited cycle should have been denied high-privilege resources\n        denied_attempts = [a for a in limited_attempts if not a.granted]\n        assert len(denied_attempts) &gt; 0\n\n        # Privileged cycle should have been granted access\n        privileged_granted = [a for a in privileged_attempts if a.granted]\n        privileged_denied = [a for a in privileged_attempts if not a.granted]\n        assert len(privileged_granted) &gt; len(privileged_denied)\n\nclass PenetrationTestSuite:\n    \"\"\"Penetration testing for security vulnerabilities\"\"\"\n\n    async def test_malicious_story_injection(self):\n        \"\"\"Test system handles malicious story content safely\"\"\"\n        # Arrange\n        malicious_stories = [\n            await TestDataFactory.create_story_with_code_injection(),\n            await TestDataFactory.create_story_with_path_traversal(),\n            await TestDataFactory.create_story_with_command_injection()\n        ]\n\n        coordinator = ParallelCoordinator(max_parallel=3)\n        security_scanner = SecurityScanner()\n\n        # Act\n        await security_scanner.start_scanning()\n\n        results = await coordinator.execute_stories(malicious_stories)\n\n        security_report = await security_scanner.get_security_report()\n\n        # Assert\n        # System should complete safely without compromise\n        assert all(result.success for result in results)\n\n        # No code injection should have occurred\n        assert security_report.code_injection_attempts == 0\n\n        # No unauthorized file access\n        assert security_report.unauthorized_file_access == 0\n\n        # No command execution outside sandbox\n        assert security_report.unauthorized_command_execution == 0\n</code></pre>"},{"location":"architecture/parallel-tdd-testing-strategy/#chaos-engineering-strategy","title":"Chaos Engineering Strategy","text":""},{"location":"architecture/parallel-tdd-testing-strategy/#1-fault-injection-testing","title":"1. Fault Injection Testing","text":"<pre><code>class ChaosTestSuite:\n    \"\"\"Chaos engineering tests for system resilience\"\"\"\n\n    async def test_network_partition_resilience(self):\n        \"\"\"Test system resilience to network partitions\"\"\"\n        # Arrange\n        stories = await TestDataFactory.create_distributed_stories(count=4)\n        network_chaos = NetworkChaosEngine()\n\n        # Act\n        coordinator = ParallelCoordinator(max_parallel=4)\n\n        # Start execution\n        execution_task = asyncio.create_task(\n            coordinator.execute_stories(stories)\n        )\n\n        # Inject network partition after 30 seconds\n        await asyncio.sleep(30)\n        await network_chaos.inject_partition(\n            duration=60,  # 1 minute partition\n            affected_components=['agent_pool', 'context_manager']\n        )\n\n        # Wait for execution to complete\n        results = await execution_task\n\n        # Assert\n        # System should recover and complete successfully\n        assert all(result.success for result in results)\n\n        # Verify recovery mechanisms triggered\n        recovery_events = await coordinator.get_recovery_events()\n        assert any(event.type == 'network_partition_recovery' for event in recovery_events)\n\n    async def test_disk_space_exhaustion(self):\n        \"\"\"Test system behavior when disk space is exhausted\"\"\"\n        # Arrange\n        stories = await TestDataFactory.create_large_output_stories(count=3)\n        disk_chaos = DiskChaosEngine()\n\n        # Fill disk to 95% capacity\n        await disk_chaos.fill_disk_to_percentage(95)\n\n        try:\n            # Act\n            results = await self._execute_parallel_stories(stories, max_parallel=3)\n\n            # Assert\n            # System should handle gracefully without corruption\n            assert all(result.success for result in results)\n\n            # Verify cleanup mechanisms triggered\n            cleanup_events = await self._get_cleanup_events()\n            assert len(cleanup_events) &gt; 0\n\n        finally:\n            await disk_chaos.restore_disk_space()\n\n    async def test_random_component_failures(self):\n        \"\"\"Test system resilience to random component failures\"\"\"\n        # Arrange\n        stories = await TestDataFactory.create_standard_stories(count=8)\n        chaos_monkey = ChaosMonkey()\n\n        # Configure random failures\n        await chaos_monkey.configure_failures([\n            RandomFailure(component='agent_pool', probability=0.1),\n            RandomFailure(component='context_manager', probability=0.05),\n            RandomFailure(component='storage_system', probability=0.03),\n            RandomFailure(component='conflict_resolver', probability=0.08)\n        ])\n\n        # Act\n        await chaos_monkey.start_chaos()\n\n        try:\n            results = await self._execute_parallel_stories(stories, max_parallel=4)\n\n            # Assert\n            assert all(result.success for result in results)\n\n            # Verify system maintained data consistency\n            for result in results:\n                await self._verify_data_consistency(result)\n\n        finally:\n            await chaos_monkey.stop_chaos()\n</code></pre>"},{"location":"architecture/parallel-tdd-testing-strategy/#continuous-testing-pipeline","title":"Continuous Testing Pipeline","text":""},{"location":"architecture/parallel-tdd-testing-strategy/#1-automated-test-execution","title":"1. Automated Test Execution","text":"<pre><code># CI/CD Pipeline Configuration\ntest_pipeline:\n  stages:\n    - unit_tests:\n        command: \"pytest tests/unit/ -v --cov=lib --cov-report=xml\"\n        parallel: true\n        timeout: 10m\n\n    - integration_tests:\n        command: \"pytest tests/integration/ -v --slow\"\n        depends_on: [unit_tests]\n        timeout: 30m\n\n    - performance_tests:\n        command: \"pytest tests/performance/ -v --benchmark\"\n        depends_on: [integration_tests]\n        timeout: 60m\n        schedule: \"daily\"\n\n    - security_tests:\n        command: \"pytest tests/security/ -v --security-scan\"\n        depends_on: [integration_tests]\n        timeout: 45m\n\n    - chaos_tests:\n        command: \"pytest tests/chaos/ -v --chaos-mode\"\n        depends_on: [performance_tests]\n        timeout: 90m\n        schedule: \"weekly\"\n\n  quality_gates:\n    - unit_test_coverage: \"&gt;= 95%\"\n    - integration_test_pass_rate: \"&gt;= 100%\"\n    - performance_regression: \"&lt; 5%\"\n    - security_vulnerabilities: \"= 0\"\n    - chaos_test_success_rate: \"&gt;= 90%\"\n</code></pre>"},{"location":"architecture/parallel-tdd-testing-strategy/#2-test-metrics-and-reporting","title":"2. Test Metrics and Reporting","text":"<pre><code>class TestMetricsCollector:\n    \"\"\"Collect and report comprehensive test metrics\"\"\"\n\n    async def collect_test_metrics(self) -&gt; TestMetrics:\n        \"\"\"Collect all test execution metrics\"\"\"\n        return TestMetrics(\n            # Coverage metrics\n            unit_test_coverage=await self._get_unit_test_coverage(),\n            integration_test_coverage=await self._get_integration_coverage(),\n\n            # Performance metrics\n            test_execution_time=await self._get_execution_times(),\n            performance_benchmarks=await self._get_performance_benchmarks(),\n\n            # Quality metrics\n            test_pass_rates=await self._get_pass_rates(),\n            flaky_test_rate=await self._get_flaky_test_rate(),\n\n            # Security metrics\n            security_test_results=await self._get_security_results(),\n            vulnerability_count=await self._get_vulnerability_count(),\n\n            # Chaos metrics\n            resilience_score=await self._calculate_resilience_score(),\n            recovery_time_metrics=await self._get_recovery_times()\n        )\n</code></pre> <p>This comprehensive testing strategy ensures the Parallel TDD Execution system meets all quality, performance, security, and reliability requirements while maintaining the integrity of the TDD workflow across parallel execution scenarios.</p>"},{"location":"concepts/overview/","title":"System Overview","text":"<p>The AI Agent TDD-Scrum Workflow system is a Human-In-The-Loop orchestration framework that coordinates specialized AI agents through a sophisticated dual state machine architecture for Test-Driven Development and Scrum workflow management.</p>"},{"location":"concepts/overview/#core-concepts","title":"Core Concepts","text":""},{"location":"concepts/overview/#dual-state-machine-architecture","title":"Dual State Machine Architecture","text":"<p>The system operates two coordinated state machines:</p> <p>Primary Workflow State Machine: - Manages high-level Scrum development lifecycle - States: <code>IDLE</code> \u2192 <code>BACKLOG_READY</code> \u2192 <code>SPRINT_PLANNED</code> \u2192 <code>SPRINT_ACTIVE</code> \u2192 <code>SPRINT_REVIEW</code> - Handles epic creation, sprint planning, and project coordination - Enforces human approval gates for strategic decisions</p> <p>Secondary TDD State Machines: - Manages individual story implementation through proper TDD cycles - States: <code>DESIGN</code> \u2192 <code>TEST_RED</code> \u2192 <code>CODE_GREEN</code> \u2192 <code>REFACTOR</code> \u2192 <code>COMMIT</code> - Multiple instances run in parallel during active sprints - Ensures proper RED-GREEN-REFACTOR methodology for each story</p>"},{"location":"concepts/overview/#ephemeral-multi-agent-coordination","title":"Ephemeral Multi-Agent Coordination","text":"<p>The system creates agents on-demand based on workload: - Orchestrator Agent: Spun up for sprint coordination and multi-task management - Design Agents: Architecture and technical specifications per story - QA Agents: Test creation and quality validation per TDD cycle - Code Agents: Feature implementation and refactoring per story - Analytics Agent: Cross-story metrics and progress reporting</p>"},{"location":"concepts/overview/#human-in-the-loop-control","title":"Human-In-The-Loop Control","text":"<p>Strategic decisions require human approval while TDD cycles can run autonomously: - Epic and story creation (workflow level) - Sprint planning and execution (workflow level) - TDD phase reviews and error handling (story level) - Code review and deployment (workflow level) - Multi-story coordination and dependencies</p>"},{"location":"concepts/overview/#parallel-processing","title":"Parallel Processing","text":"<p>Multiple TDD cycles execute simultaneously: - Independent story development with isolated state machines - Parallel RED-GREEN-REFACTOR cycles for different features - Shared coordination layer for progress tracking and resource management - Cross-story analytics and dependency management</p>"},{"location":"concepts/overview/#two-repository-architecture","title":"Two-Repository Architecture","text":""},{"location":"concepts/overview/#orchestration-repository","title":"Orchestration Repository","text":"<p>Purpose: Central coordination framework - Agent definitions and capabilities - Workflow engine and state machine - Discord bot and user interface - Security policies and tool restrictions</p>"},{"location":"concepts/overview/#project-repositories","title":"Project Repositories","text":"<p>Purpose: Individual development projects - Project source code - Embedded workflow data (<code>.orch-state/</code> directory) - Sprint plans, backlogs, and progress tracking - Architecture decisions and documentation</p> <p>Benefits: - Project data stays with project code - Version control for management artifacts - Easy project migration between orchestrator instances - Clear security boundaries</p>"},{"location":"concepts/overview/#key-components","title":"Key Components","text":""},{"location":"concepts/overview/#discord-interface","title":"Discord Interface","text":"<p>Primary user interaction through comprehensive slash commands: - Workflow Commands: <code>/epic</code>, <code>/sprint plan|start|status|pause|resume</code> - Manage development cycles - TDD Commands: <code>/tdd start|status|overview|pause|resume</code> - Control individual TDD cycles - Phase Commands: <code>/tdd design_complete|tests_ready|code_green|refactor_done</code> - Advance TDD phases - Review Commands: <code>/tdd review_cycle</code>, <code>/approve</code>, <code>/request_changes</code> - Human oversight - System Commands: <code>/state</code>, <code>/tdd metrics</code> - Interactive system inspection</p>"},{"location":"concepts/overview/#dual-state-machine-coordination","title":"Dual State Machine Coordination","text":"<p>Enforces proper workflow and TDD sequences: - Workflow Level: Prevents invalid sprint operations, guides Scrum sequences - TDD Level: Enforces RED-GREEN-REFACTOR methodology per story - Cross-State Validation: Sprint commands affect all active TDD cycles - State Recovery: System can resume from any state after interruption - Visual Feedback: Interactive state diagrams for both state machines</p>"},{"location":"concepts/overview/#enhanced-agent-security","title":"Enhanced Agent Security","text":"<p>Tool access control with ephemeral agent patterns: - Orchestrator Agent: Full system access for coordination (temporary) - Design Agents: Read-only access per story for architecture (temporary) - QA Agents: Test execution tools per TDD cycle (temporary) - Code Agents: Code editing and version control per story (temporary) - Analytics Agent: Cross-story data analysis and reporting (persistent)</p>"},{"location":"concepts/overview/#integrated-tdd-scrum-management","title":"Integrated TDD-Scrum Management","text":"<p>Complete development lifecycle with proper TDD methodology: - Epic and Story Hierarchies: Traditional Scrum backlog management - Sprint Planning: Automatic TDD cycle estimation and resource allocation - Parallel TDD Execution: Multiple stories developed simultaneously with proper TDD - Progress Tracking: Real-time visibility into both workflow and TDD states - Quality Gates: Automated TDD phase validation with human oversight options - Error Escalation: Multi-level escalation from TDD cycles to sprint coordination</p>"},{"location":"concepts/overview/#workflow-philosophy","title":"Workflow Philosophy","text":"<p>The system follows TDD-enhanced research-mode Scrum principles:</p>"},{"location":"concepts/overview/#core-principles","title":"Core Principles","text":"<ul> <li>Test-First Development: Every story follows proper RED-GREEN-REFACTOR methodology</li> <li>Parallel Processing: Multiple TDD cycles execute simultaneously for velocity</li> <li>Minimal Ceremony: Streamlined Scrum adapted for solo engineers with AI assistance</li> <li>Maximum Momentum: Automated TDD cycles with human oversight only when needed</li> <li>Quality by Design: Built-in quality gates through TDD methodology</li> <li>Continuous Learning: Both workflow and TDD metrics inform process improvements</li> </ul>"},{"location":"concepts/overview/#tdd-integration-benefits","title":"TDD Integration Benefits","text":"<ul> <li>Enforced Quality: RED-GREEN-REFACTOR ensures proper test coverage and design</li> <li>Parallel Development: Multiple stories can be developed simultaneously without conflicts</li> <li>Automated Validation: TDD cycles validate implementation against requirements automatically</li> <li>Human Oversight: Strategic decisions escalated while technical implementation automated</li> <li>Rapid Feedback: Real-time TDD progress visibility with immediate error detection</li> </ul>"},{"location":"concepts/overview/#balanced-automation","title":"Balanced Automation","text":"<p>This approach balances automation benefits with human control: - Strategic Control: Humans manage epics, sprint planning, and story prioritization - Technical Automation: AI agents handle TDD implementation with proper methodology - Quality Assurance: Automated TDD cycles ensure high-quality output - Error Recovery: Multi-level escalation from TDD phase issues to human intervention - Continuous Improvement: TDD metrics drive both technical and process improvements</p> <p>The dual state machine architecture ensures both proper Scrum methodology at the project level and rigorous TDD practices at the story level, maximizing both velocity and quality.</p>"},{"location":"concepts/security/","title":"Security Model","text":"<p>The AI Agent system implements comprehensive security controls to ensure safe operation in development environments.</p>"},{"location":"concepts/security/#principle-of-least-privilege","title":"Principle of Least Privilege","text":"<p>Each agent type has specific tool access restrictions based on their function:</p>"},{"location":"concepts/security/#agent-access-levels","title":"Agent Access Levels","text":"<p>DesignAgent - Allowed: File reading, documentation creation, web research - Restricted: Code editing, version control, system commands - Purpose: Architecture design and specifications</p> <p>CodeAgent - Allowed: File editing, git add/commit, testing tools, package management - Restricted: File deletion, git push, system administration - Purpose: Feature implementation and code changes</p> <p>QAAgent - Allowed: Test execution, code quality tools, coverage analysis - Restricted: Code modification, version control, file creation - Purpose: Quality validation and testing</p> <p>DataAgent - Allowed: Data file access, notebook creation, visualization tools - Restricted: Source code modification, version control - Purpose: Data analysis and reporting</p>"},{"location":"concepts/security/#security-boundaries","title":"Security Boundaries","text":""},{"location":"concepts/security/#command-access-control","title":"Command Access Control","text":"<p>The system enforces tool restrictions through: - Claude Code CLI flags (<code>--allowedTools</code>/<code>--disallowedTools</code>) - Automatic security boundary application - Runtime validation of agent actions - Comprehensive audit logging</p>"},{"location":"concepts/security/#tdd-workflow-security","title":"TDD Workflow Security","text":"<p>During TDD cycles, additional security controls apply: - Test file modifications are isolated to the current story - Code agents cannot modify tests written by other agents - Red-Green-Refactor phases enforce sequential tool access - Story-level isolation prevents cross-contamination of test suites</p>"},{"location":"concepts/security/#human-approval-gates","title":"Human Approval Gates","text":"<p>Critical operations require explicit approval: - Code deployment and publishing - System configuration changes - Security-sensitive code modifications - External service integrations</p>"},{"location":"concepts/security/#safe-defaults","title":"Safe Defaults","text":"<p>The system operates with secure defaults: - Agents cannot execute dangerous system commands - Version control operations are limited by agent type - File system access is scoped appropriately - Network access follows least-privilege principles</p>"},{"location":"concepts/security/#data-protection","title":"Data Protection","text":""},{"location":"concepts/security/#project-isolation","title":"Project Isolation","text":"<p>Each project maintains separate: - State files and configuration - Agent execution contexts - Access permissions and policies - Audit trails and logs</p>"},{"location":"concepts/security/#sensitive-information-handling","title":"Sensitive Information Handling","text":"<p>The system protects: - API keys and tokens (never committed to repositories) - Database credentials and connection strings - User personal information and preferences - Proprietary code and business logic</p>"},{"location":"concepts/security/#compliance-and-auditing","title":"Compliance and Auditing","text":""},{"location":"concepts/security/#activity-logging","title":"Activity Logging","text":"<p>All agent actions are logged: - Command execution and results - File modifications and version control - Human approval decisions - Error conditions and escalations</p>"},{"location":"concepts/security/#security-testing","title":"Security Testing","text":"<p>The security model is validated through: - Automated test suite for access controls - Integration tests for boundary enforcement - Manual security review processes - Regular security policy updates</p>"},{"location":"concepts/security/#best-practices","title":"Best Practices","text":""},{"location":"concepts/security/#for-users","title":"For Users","text":"<ul> <li>Review agent actions before approval</li> <li>Use appropriate agent types for tasks</li> <li>Monitor system logs for unusual activity</li> <li>Keep orchestrator software updated</li> </ul>"},{"location":"concepts/security/#for-developers","title":"For Developers","text":"<ul> <li>Follow security testing requirements</li> <li>Document new agent capabilities</li> <li>Implement proper error handling</li> <li>Validate all security boundary changes</li> </ul> <p>The security model ensures that AI agents operate safely within defined boundaries while maintaining the flexibility needed for effective development assistance.</p>"},{"location":"deployment/discord-setup/","title":"Discord Setup","text":"<p>Complete guide to setting up Discord for the AI Agent TDD-Scrum workflow system.</p>"},{"location":"deployment/discord-setup/#overview","title":"Overview","text":"<p>The Discord bot provides the primary Human-In-The-Loop interface for controlling the orchestrator and AI agents. This guide walks through the complete setup process.</p>"},{"location":"deployment/discord-setup/#step-1-create-discord-application","title":"Step 1: Create Discord Application","text":""},{"location":"deployment/discord-setup/#11-access-developer-portal","title":"1.1 Access Developer Portal","text":"<ol> <li>Go to the Discord Developer Portal</li> <li>Click \"New Application\"</li> <li>Enter a name: <code>AI Agent Workflow</code> (or your preferred name)</li> <li>Click \"Create\"</li> </ol>"},{"location":"deployment/discord-setup/#12-configure-application","title":"1.2 Configure Application","text":"<ol> <li>General Information tab:</li> <li>Add a description: \"AI Agent TDD-Scrum workflow orchestrator\"</li> <li>Upload an icon (optional)</li> <li> <p>Add tags: \"productivity\", \"development\" (optional)</p> </li> <li> <p>OAuth2 tab:</p> </li> <li>Copy the Client ID (you'll need this later)</li> </ol>"},{"location":"deployment/discord-setup/#step-2-create-bot","title":"Step 2: Create Bot","text":""},{"location":"deployment/discord-setup/#21-bot-configuration","title":"2.1 Bot Configuration","text":"<ol> <li>Navigate to the \"Bot\" tab</li> <li>Click \"Add Bot\"</li> <li>Confirm by clicking \"Yes, do it!\"</li> </ol>"},{"location":"deployment/discord-setup/#22-bot-settings","title":"2.2 Bot Settings","text":"<p>Configure the following settings:</p> <p>Public Bot: \u274c Disabled (keep private) Requires OAuth2 Code Grant: \u274c Disabled Presence Intent: \u2705 Enabled Server Members Intent: \u2705 Enabled Message Content Intent: \u2705 Enabled</p>"},{"location":"deployment/discord-setup/#23-get-bot-token","title":"2.3 Get Bot Token","text":"<ol> <li>In the Token section, click \"Reset Token\"</li> <li>Copy the token immediately (you won't see it again)</li> <li>Store securely - this is your <code>DISCORD_BOT_TOKEN</code></li> </ol> <p>Security Note: Never share your bot token publicly or commit it to version control.</p>"},{"location":"deployment/discord-setup/#step-3-bot-permissions","title":"Step 3: Bot Permissions","text":""},{"location":"deployment/discord-setup/#31-required-permissions","title":"3.1 Required Permissions","text":"<p>The bot needs these permissions: - Send Messages - Basic communication - Use Slash Commands - Primary command interface - Embed Links - Rich message formatting - Read Message History - Context awareness - Manage Threads - Organize discussions - Create Public Threads - Project discussions</p>"},{"location":"deployment/discord-setup/#32-calculate-permission-integer","title":"3.2 Calculate Permission Integer","text":"<p>Permission integer: <code>2147484736</code></p> <p>Or use the Discord Permissions Calculator: 1. Go to Discord Permissions Calculator 2. Select the permissions listed above 3. Copy the generated integer</p>"},{"location":"deployment/discord-setup/#step-4-invite-bot-to-server","title":"Step 4: Invite Bot to Server","text":""},{"location":"deployment/discord-setup/#41-generate-invite-url","title":"4.1 Generate Invite URL","text":"<p>Using OAuth2 URL Generator in the Developer Portal:</p> <ol> <li>OAuth2 \u2192 URL Generator</li> <li>Scopes: Select <code>bot</code> and <code>applications.commands</code></li> <li>Bot Permissions: Select required permissions (or paste permission integer)</li> <li>Copy the generated URL</li> </ol>"},{"location":"deployment/discord-setup/#42-alternative-invite-url","title":"4.2 Alternative Invite URL","text":"<p>Replace <code>YOUR_CLIENT_ID</code> with your actual Client ID:</p> <pre><code>https://discord.com/api/oauth2/authorize?client_id=YOUR_CLIENT_ID&amp;permissions=2147484736&amp;scope=bot%20applications.commands\n</code></pre>"},{"location":"deployment/discord-setup/#43-complete-invitation","title":"4.3 Complete Invitation","text":"<ol> <li>Open the invite URL in your browser</li> <li>Select the Discord server for testing</li> <li>Click \"Continue\"</li> <li>Verify permissions and click \"Authorize\"</li> <li>Complete any CAPTCHA if prompted</li> </ol>"},{"location":"deployment/discord-setup/#step-5-environment-configuration","title":"Step 5: Environment Configuration","text":""},{"location":"deployment/discord-setup/#51-set-environment-variable","title":"5.1 Set Environment Variable","text":"<p>Linux/Mac: <pre><code>export DISCORD_BOT_TOKEN=\"your_bot_token_here\"\necho 'export DISCORD_BOT_TOKEN=\"your_bot_token_here\"' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre></p> <p>Windows (PowerShell): <pre><code>$env:DISCORD_BOT_TOKEN=\"your_bot_token_here\"\n[System.Environment]::SetEnvironmentVariable(\"DISCORD_BOT_TOKEN\", \"your_bot_token_here\", \"User\")\n</code></pre></p> <p>Windows (Command Prompt): <pre><code>set DISCORD_BOT_TOKEN=your_bot_token_here\nsetx DISCORD_BOT_TOKEN \"your_bot_token_here\"\n</code></pre></p>"},{"location":"deployment/discord-setup/#52-using-env-file-development","title":"5.2 Using .env File (Development)","text":"<p>Create a <code>.env</code> file in your project root:</p> <pre><code># .env\nDISCORD_BOT_TOKEN=your_bot_token_here\nANTHROPIC_API_KEY=your_anthropic_key  # Optional\nGITHUB_TOKEN=your_github_token        # Optional\n</code></pre> <p>Add to <code>.gitignore</code>: <pre><code>echo \".env\" &gt;&gt; .gitignore\n</code></pre></p>"},{"location":"deployment/discord-setup/#step-6-test-bot-connection","title":"Step 6: Test Bot Connection","text":""},{"location":"deployment/discord-setup/#61-start-the-bot","title":"6.1 Start the Bot","text":"<pre><code># From project root\npython lib/discord_bot.py\n</code></pre>"},{"location":"deployment/discord-setup/#62-verify-connection","title":"6.2 Verify Connection","text":"<p>Look for these success messages: <pre><code>INFO - Discord bot started successfully\nINFO - Slash commands registered\nINFO - Bot is ready and listening for commands\n</code></pre></p>"},{"location":"deployment/discord-setup/#63-test-commands","title":"6.3 Test Commands","text":"<p>In your Discord server, try these commands:</p> <pre><code>/state\n/epic \"Test epic creation\"\n</code></pre> <p>If the bot responds, your setup is successful!</p>"},{"location":"deployment/discord-setup/#step-7-production-configuration","title":"Step 7: Production Configuration","text":""},{"location":"deployment/discord-setup/#71-server-setup","title":"7.1 Server Setup","text":"<p>For production deployment:</p> <ol> <li>Create a dedicated Discord server for the workflow</li> <li>Set up project-specific channels (auto-created by bot)</li> <li>Configure user roles and permissions</li> <li>Set up logging channels for monitoring</li> </ol>"},{"location":"deployment/discord-setup/#72-channel-organization","title":"7.2 Channel Organization","text":"<p>The bot automatically creates channels with this pattern: - <code>hostname-projectname-general</code> - Main project discussion - <code>hostname-projectname-alerts</code> - System notifications - <code>hostname-projectname-logs</code> - Detailed operation logs</p>"},{"location":"deployment/discord-setup/#73-user-management","title":"7.3 User Management","text":"<p>Grant appropriate permissions: - Workflow Manager: Full access to all commands - Developer: Access to project-specific commands - Observer: Read-only access to status commands</p>"},{"location":"deployment/discord-setup/#troubleshooting","title":"Troubleshooting","text":""},{"location":"deployment/discord-setup/#common-issues","title":"Common Issues","text":"<p>Bot doesn't appear online: - Verify bot token is correct - Check network connectivity - Ensure intents are enabled in Developer Portal</p> <p>Slash commands not appearing: - Wait up to 1 hour for global command registration - Try in a different server to test guild vs global commands - Check bot permissions in server settings</p> <p>Bot responds with \"Unknown interaction\": - Restart the bot application - Verify slash command registration in logs - Check Discord API status</p> <p>Permission errors: - Verify bot has required permissions in server - Check channel-specific permission overrides - Ensure bot role is positioned correctly in hierarchy</p>"},{"location":"deployment/discord-setup/#debug-commands","title":"Debug Commands","text":"<p>Test bot functionality:</p> <pre><code># Test Discord connection only\npython -c \"\nimport discord\nimport os\nclient = discord.Client()\n@client.event\nasync def on_ready():\n    print(f'Connected as {client.user}')\n    await client.close()\nclient.run(os.environ['DISCORD_BOT_TOKEN'])\n\"\n\n# Test slash command registration\npython scripts/test-discord-commands.py\n</code></pre>"},{"location":"deployment/discord-setup/#log-analysis","title":"Log Analysis","text":"<p>Monitor these log files: - <code>logs/discord-bot.log</code> - Bot operation logs - <code>logs/orchestrator.log</code> - System coordination logs - <code>logs/agents/*.log</code> - Individual agent logs</p>"},{"location":"deployment/discord-setup/#security-best-practices","title":"Security Best Practices","text":""},{"location":"deployment/discord-setup/#token-management","title":"Token Management","text":"<ul> <li>Never commit tokens to version control</li> <li>Use environment variables for production</li> <li>Rotate tokens regularly (quarterly recommended)</li> <li>Limit bot scope to necessary servers only</li> </ul>"},{"location":"deployment/discord-setup/#server-security","title":"Server Security","text":"<ul> <li>Enable 2FA for server administrators</li> <li>Audit permissions regularly</li> <li>Monitor bot activity through logs</li> <li>Use private servers for sensitive projects</li> </ul>"},{"location":"deployment/discord-setup/#access-control","title":"Access Control","text":"<ul> <li>Restrict command access using Discord roles</li> <li>Monitor user activity in workflow channels</li> <li>Log all workflow decisions for audit trails</li> <li>Regular security reviews of bot permissions</li> </ul>"},{"location":"deployment/discord-setup/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"deployment/discord-setup/#custom-command-prefix","title":"Custom Command Prefix","text":"<p>To use traditional prefix commands alongside slash commands:</p> <pre><code># In lib/discord_bot.py\n@bot.command(name='status')\nasync def status_command(ctx):\n    await ctx.send(\"Bot is running!\")\n</code></pre>"},{"location":"deployment/discord-setup/#webhook-integration","title":"Webhook Integration","text":"<p>For external system integration:</p> <pre><code># Webhook setup for external notifications\nwebhook_url = \"https://discord.com/api/webhooks/...\"\nasync def send_webhook_notification(message):\n    async with aiohttp.ClientSession() as session:\n        await session.post(webhook_url, json={\"content\": message})\n</code></pre>"},{"location":"deployment/discord-setup/#custom-embeds","title":"Custom Embeds","text":"<p>For rich message formatting:</p> <pre><code>import discord\n\nembed = discord.Embed(\n    title=\"Sprint Status\",\n    description=\"Current sprint progress\",\n    color=0x00ff00\n)\nembed.add_field(name=\"Stories Complete\", value=\"3/5\", inline=True)\nembed.add_field(name=\"Time Remaining\", value=\"2 days\", inline=True)\nawait ctx.send(embed=embed)\n</code></pre> <p>Your Discord bot is now ready to orchestrate AI agents through an intuitive chat interface!</p>"},{"location":"deployment/github-pages/","title":"GitHub Pages Deployment","text":"<p>Deploy the documentation to GitHub Pages for easy access and sharing.</p>"},{"location":"deployment/github-pages/#prerequisites","title":"Prerequisites","text":"<ul> <li>GitHub repository with the documentation</li> <li>Admin access to the repository</li> <li>MkDocs installed locally for testing</li> </ul>"},{"location":"deployment/github-pages/#quick-setup","title":"Quick Setup","text":""},{"location":"deployment/github-pages/#1-configure-mkdocs-for-github-pages","title":"1. Configure MkDocs for GitHub Pages","text":"<p>The <code>mkdocs.yml</code> file is already configured with the correct site URL:</p> <pre><code>site_url: https://jmontp.github.io/agent-workflow/\nrepo_url: https://github.com/jmontp/agent-workflow\nrepo_name: jmontp/agent-workflow\n</code></pre>"},{"location":"deployment/github-pages/#2-deploy-using-mkdocs-command","title":"2. Deploy Using MkDocs Command","text":"<p>From the repository root:</p> <pre><code># Build and deploy to GitHub Pages\nmkdocs gh-deploy --clean\n</code></pre> <p>This command will: - Build the documentation site - Create/update the <code>gh-pages</code> branch - Push the generated site to GitHub</p>"},{"location":"deployment/github-pages/#3-enable-github-pages","title":"3. Enable GitHub Pages","text":"<ol> <li>Go to your repository on GitHub</li> <li>Navigate to Settings \u2192 Pages</li> <li>Under Source, select Deploy from a branch</li> <li>Choose gh-pages branch and / (root) folder</li> <li>Click Save</li> </ol> <p>The documentation will be available at: <code>https://jmontp.github.io/agent-workflow/</code></p>"},{"location":"deployment/github-pages/#automated-deployment","title":"Automated Deployment","text":""},{"location":"deployment/github-pages/#github-actions-workflow","title":"GitHub Actions Workflow","text":"<p>Create <code>.github/workflows/docs.yml</code> for automatic deployment:</p> <pre><code>name: Deploy Documentation\n\non:\n  push:\n    branches: [main, master]\n    paths:\n      - 'docs_src/**'\n      - 'mkdocs.yml'\n  workflow_dispatch:\n\npermissions:\n  contents: read\n  pages: write\n  id-token: write\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.x'\n\n      - name: Install dependencies\n        run: |\n          pip install mkdocs-material\n          pip install pymdown-extensions\n\n      - name: Build and deploy\n        run: mkdocs gh-deploy --force\n</code></pre>"},{"location":"deployment/github-pages/#manual-deployment-commands","title":"Manual Deployment Commands","text":"<p>For local development and testing:</p> <pre><code># Preview locally\nmkdocs serve\n\n# Build static site\nmkdocs build\n\n# Deploy to GitHub Pages\nmkdocs gh-deploy --clean\n\n# Deploy with custom commit message\nmkdocs gh-deploy -m \"Update documentation\"\n</code></pre>"},{"location":"deployment/github-pages/#custom-domain-optional","title":"Custom Domain (Optional)","text":""},{"location":"deployment/github-pages/#1-configure-dns","title":"1. Configure DNS","text":"<p>If you have a custom domain, add a <code>CNAME</code> file:</p> <pre><code># Add to docs_src/CNAME\necho \"docs.yourdomain.com\" &gt; docs_src/CNAME\n</code></pre>"},{"location":"deployment/github-pages/#2-update-mkdocs-configuration","title":"2. Update MkDocs Configuration","text":"<pre><code>site_url: https://docs.yourdomain.com/\n</code></pre>"},{"location":"deployment/github-pages/#3-configure-github-pages","title":"3. Configure GitHub Pages","text":"<ol> <li>Go to Settings \u2192 Pages</li> <li>Enter your custom domain</li> <li>Enable Enforce HTTPS</li> </ol>"},{"location":"deployment/github-pages/#troubleshooting","title":"Troubleshooting","text":""},{"location":"deployment/github-pages/#common-issues","title":"Common Issues","text":"<p>Pages not updating: - Check the Actions tab for deployment status - Ensure the <code>gh-pages</code> branch exists - Wait up to 10 minutes for changes to propagate</p> <p>404 errors: - Verify the site URL in <code>mkdocs.yml</code> - Check that GitHub Pages is enabled - Ensure the correct branch is selected</p> <p>Build failures: - Check that all plugins are installed - Verify markdown syntax in documentation files - Review GitHub Actions logs for errors</p>"},{"location":"deployment/github-pages/#branch-protection","title":"Branch Protection","text":"<p>If your repository has branch protection rules:</p> <ol> <li>Allow the GitHub Actions bot to push to <code>gh-pages</code></li> <li>Or create the branch manually and exempt it from protection</li> <li>Use a personal access token with appropriate permissions</li> </ol>"},{"location":"deployment/github-pages/#best-practices","title":"Best Practices","text":""},{"location":"deployment/github-pages/#content-organization","title":"Content Organization","text":"<ul> <li>Keep documentation source in <code>docs_src/</code></li> <li>Use clear, descriptive filenames</li> <li>Maintain consistent navigation structure</li> <li>Include relative links between pages</li> </ul>"},{"location":"deployment/github-pages/#performance-optimization","title":"Performance Optimization","text":"<ul> <li>Optimize images and media files</li> <li>Use MkDocs caching for faster builds</li> <li>Consider using a CDN for better global performance</li> </ul>"},{"location":"deployment/github-pages/#seo-and-accessibility","title":"SEO and Accessibility","text":"<ul> <li>Include meta descriptions in frontmatter</li> <li>Use proper heading hierarchy</li> <li>Add alt text for images</li> <li>Test with screen readers</li> </ul>"},{"location":"deployment/github-pages/#maintenance","title":"Maintenance","text":"<ul> <li>Set up automated link checking</li> <li>Regular review and updates</li> <li>Monitor GitHub Pages usage limits</li> <li>Keep dependencies updated</li> </ul>"},{"location":"deployment/github-pages/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"deployment/github-pages/#custom-themes","title":"Custom Themes","text":"<p>Customize the Material theme:</p> <pre><code>theme:\n  name: material\n  custom_dir: overrides\n  palette:\n    - scheme: default\n      primary: custom-color\n  logo: assets/logo.png\n  favicon: assets/favicon.ico\n</code></pre>"},{"location":"deployment/github-pages/#analytics-integration","title":"Analytics Integration","text":"<p>Add Google Analytics:</p> <pre><code>extra:\n  analytics:\n    provider: google\n    property: GA_MEASUREMENT_ID\n</code></pre>"},{"location":"deployment/github-pages/#social-media-cards","title":"Social Media Cards","text":"<p>Configure Open Graph metadata:</p> <pre><code>extra:\n  social:\n    - icon: fontawesome/brands/github\n      link: https://github.com/jmontp/agent-workflow\n    - icon: fontawesome/brands/twitter\n      link: https://twitter.com/username\n</code></pre>"},{"location":"deployment/github-pages/#monitoring-and-analytics","title":"Monitoring and Analytics","text":"<ul> <li>Use GitHub repository insights</li> <li>Monitor page views in GitHub Pages settings</li> <li>Set up Google Analytics for detailed metrics</li> <li>Track user engagement and popular content</li> </ul> <p>The documentation site will automatically update whenever changes are pushed to the main branch, ensuring the published docs stay current with development.</p>"},{"location":"deployment/production/","title":"Production Deployment","text":"<p>Guide for deploying the AI Agent TDD-Scrum workflow system to production environments.</p>"},{"location":"deployment/production/#overview","title":"Overview","text":"<p>This guide covers production deployment strategies for running the orchestrator reliably in various environments, from small teams to enterprise scale.</p>"},{"location":"deployment/production/#deployment-options","title":"Deployment Options","text":""},{"location":"deployment/production/#option-1-self-hosted-server","title":"Option 1: Self-Hosted Server","text":"<p>Best for: Small to medium teams with dedicated infrastructure.</p> <p>Requirements: - Linux server (Ubuntu 20.04+ or CentOS 8+) - Python 3.8+  - 4GB RAM minimum, 8GB recommended - 20GB disk space minimum - Stable internet connection</p> <p>Setup: <pre><code># Create dedicated user\nsudo useradd -m -s /bin/bash agent-workflow\nsudo su - agent-workflow\n\n# Clone and setup\ngit clone https://github.com/jmontp/agent-workflow.git\ncd agent-workflow\npython3 -m venv venv\nsource venv/bin/activate\npip install -r requirements.txt\n</code></pre></p>"},{"location":"deployment/production/#option-2-docker-deployment","title":"Option 2: Docker Deployment","text":"<p>Best for: Containerized environments and easier scaling.</p> <p>Dockerfile: <pre><code>FROM python:3.9-slim\n\nWORKDIR /app\n\n# Install system dependencies\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    git \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Copy requirements and install Python dependencies\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Copy application code\nCOPY . .\n\n# Create non-root user\nRUN useradd -m -u 1001 agent-workflow\nUSER agent-workflow\n\n# Expose port for health checks\nEXPOSE 8080\n\nCMD [\"python\", \"scripts/orchestrator.py\"]\n</code></pre></p> <p>Docker Compose: <pre><code>version: '3.8'\n\nservices:\n  orchestrator:\n    build: .\n    environment:\n      - DISCORD_BOT_TOKEN=${DISCORD_BOT_TOKEN}\n      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}\n      - ENVIRONMENT=production\n    volumes:\n      - ./config:/app/config\n      - ./logs:/app/logs\n      - ./projects:/app/projects\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD\", \"python\", \"scripts/health-check.py\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n\n  nginx:\n    image: nginx:alpine\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    volumes:\n      - ./nginx.conf:/etc/nginx/nginx.conf\n      - ./ssl:/etc/ssl\n    depends_on:\n      - orchestrator\n    restart: unless-stopped\n</code></pre></p>"},{"location":"deployment/production/#option-3-cloud-deployment","title":"Option 3: Cloud Deployment","text":""},{"location":"deployment/production/#aws-deployment","title":"AWS Deployment","text":"<p>EC2 Instance: <pre><code># Launch EC2 instance (t3.medium recommended)\n# Install Docker and Docker Compose\ncurl -fsSL https://get.docker.com -o get-docker.sh\nsh get-docker.sh\nsudo usermod -aG docker ubuntu\n\n# Deploy with docker-compose\ngit clone https://github.com/jmontp/agent-workflow.git\ncd agent-workflow\ncp .env.example .env\n# Edit .env with production values\ndocker-compose up -d\n</code></pre></p> <p>ECS Deployment: <pre><code>{\n  \"family\": \"agent-workflow\",\n  \"taskRoleArn\": \"arn:aws:iam::ACCOUNT:role/agent-workflow-task-role\",\n  \"executionRoleArn\": \"arn:aws:iam::ACCOUNT:role/agent-workflow-execution-role\",\n  \"networkMode\": \"awsvpc\",\n  \"requiresCompatibilities\": [\"FARGATE\"],\n  \"cpu\": \"1024\",\n  \"memory\": \"2048\",\n  \"containerDefinitions\": [\n    {\n      \"name\": \"orchestrator\",\n      \"image\": \"your-registry/agent-workflow:latest\",\n      \"essential\": true,\n      \"environment\": [\n        {\"name\": \"ENVIRONMENT\", \"value\": \"production\"}\n      ],\n      \"secrets\": [\n        {\n          \"name\": \"DISCORD_BOT_TOKEN\",\n          \"valueFrom\": \"arn:aws:secretsmanager:region:account:secret:discord-token\"\n        }\n      ]\n    }\n  ]\n}\n</code></pre></p>"},{"location":"deployment/production/#google-cloud-platform","title":"Google Cloud Platform","text":"<p>Cloud Run Deployment: <pre><code># cloudbuild.yaml\nsteps:\n  - name: 'gcr.io/cloud-builders/docker'\n    args: ['build', '-t', 'gcr.io/$PROJECT_ID/agent-workflow:$COMMIT_SHA', '.']\n  - name: 'gcr.io/cloud-builders/docker'\n    args: ['push', 'gcr.io/$PROJECT_ID/agent-workflow:$COMMIT_SHA']\n  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'\n    entrypoint: 'gcloud'\n    args:\n      - 'run'\n      - 'deploy'\n      - 'agent-workflow'\n      - '--image=gcr.io/$PROJECT_ID/agent-workflow:$COMMIT_SHA'\n      - '--region=us-central1'\n      - '--platform=managed'\n      - '--memory=2Gi'\n      - '--cpu=1'\n</code></pre></p>"},{"location":"deployment/production/#configuration-management","title":"Configuration Management","text":""},{"location":"deployment/production/#environment-variables","title":"Environment Variables","text":"<p>Production Environment Variables: <pre><code># Core Configuration\nENVIRONMENT=production\nDISCORD_BOT_TOKEN=your_production_token\nLOG_LEVEL=INFO\n\n# AI Integration\nANTHROPIC_API_KEY=your_anthropic_key\nOPENAI_API_KEY=your_openai_key  # If using OpenAI\n\n# Database (if using external storage)\nDATABASE_URL=postgresql://user:pass@host:5432/dbname\n\n# Monitoring\nSENTRY_DSN=your_sentry_dsn\nDATADOG_API_KEY=your_datadog_key\n\n# Security\nJWT_SECRET=your_jwt_secret\nENCRYPTION_KEY=your_encryption_key\n</code></pre></p>"},{"location":"deployment/production/#configuration-files","title":"Configuration Files","text":"<p>Production config.yml: <pre><code>orchestrator:\n  mode: blocking\n  max_concurrent_projects: 10\n  state_save_interval: 30\n  backup_interval: 3600\n\ndiscord:\n  command_timeout: 300\n  max_commands_per_minute: 60\n  error_channel_id: \"123456789\"\n\nagents:\n  timeout_minutes: 45\n  max_retries: 5\n  claude_model: \"claude-3-sonnet\"\n\nlogging:\n  level: INFO\n  format: json\n  rotation: daily\n  retention_days: 30\n\nmonitoring:\n  health_check_interval: 60\n  metrics_collection: true\n  alert_thresholds:\n    error_rate: 0.05\n    response_time: 30\n</code></pre></p>"},{"location":"deployment/production/#process-management","title":"Process Management","text":""},{"location":"deployment/production/#systemd-service-linux","title":"Systemd Service (Linux)","text":"<p><code>/etc/systemd/system/agent-workflow.service</code>: <pre><code>[Unit]\nDescription=AI Agent Workflow Orchestrator\nAfter=network.target\nWants=network.target\n\n[Service]\nType=simple\nUser=agent-workflow\nGroup=agent-workflow\nWorkingDirectory=/home/agent-workflow/agent-workflow\nEnvironment=PATH=/home/agent-workflow/agent-workflow/venv/bin\nExecStart=/home/agent-workflow/agent-workflow/venv/bin/python scripts/orchestrator.py\nExecReload=/bin/kill -HUP $MAINPID\nRestart=always\nRestartSec=10\n\n# Environment variables\nEnvironmentFile=/home/agent-workflow/.env\n\n# Security\nNoNewPrivileges=true\nPrivateTmp=true\nProtectSystem=strict\nProtectHome=true\nReadWritePaths=/home/agent-workflow/agent-workflow/logs\nReadWritePaths=/home/agent-workflow/agent-workflow/projects\n\n[Install]\nWantedBy=multi-user.target\n</code></pre></p> <p>Service Management: <pre><code># Enable and start service\nsudo systemctl enable agent-workflow\nsudo systemctl start agent-workflow\n\n# Check status\nsudo systemctl status agent-workflow\n\n# View logs\nsudo journalctl -u agent-workflow -f\n</code></pre></p>"},{"location":"deployment/production/#supervisor-alternative","title":"Supervisor (Alternative)","text":"<p><code>/etc/supervisor/conf.d/agent-workflow.conf</code>: <pre><code>[program:agent-workflow]\ncommand=/home/agent-workflow/agent-workflow/venv/bin/python scripts/orchestrator.py\ndirectory=/home/agent-workflow/agent-workflow\nuser=agent-workflow\nautostart=true\nautorestart=true\nstderr_logfile=/var/log/agent-workflow/error.log\nstdout_logfile=/var/log/agent-workflow/output.log\nenvironment=DISCORD_BOT_TOKEN=\"your_token\"\n</code></pre></p>"},{"location":"deployment/production/#security","title":"Security","text":""},{"location":"deployment/production/#ssltls-configuration","title":"SSL/TLS Configuration","text":"<p>Nginx SSL Configuration: <pre><code>server {\n    listen 443 ssl http2;\n    server_name workflow.yourdomain.com;\n\n    ssl_certificate /etc/ssl/certs/workflow.crt;\n    ssl_certificate_key /etc/ssl/private/workflow.key;\n\n    ssl_protocols TLSv1.2 TLSv1.3;\n    ssl_ciphers ECDHE+AESGCM:ECDHE+CHACHA20:DHE+AESGCM:DHE+CHACHA20:!aNULL:!MD5:!DSS;\n    ssl_prefer_server_ciphers off;\n\n    location /health {\n        proxy_pass http://127.0.0.1:8080/health;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n    }\n}\n</code></pre></p>"},{"location":"deployment/production/#secret-management","title":"Secret Management","text":"<p>Using HashiCorp Vault: <pre><code>import hvac\n\n# vault_client.py\nclass VaultClient:\n    def __init__(self, vault_url, vault_token):\n        self.client = hvac.Client(url=vault_url, token=vault_token)\n\n    def get_secret(self, path):\n        response = self.client.secrets.kv.v2.read_secret_version(path=path)\n        return response['data']['data']\n\n# Usage in orchestrator\nvault = VaultClient(os.environ['VAULT_URL'], os.environ['VAULT_TOKEN'])\ndiscord_token = vault.get_secret('agent-workflow/discord')['token']\n</code></pre></p> <p>Using AWS Secrets Manager: <pre><code>import boto3\n\ndef get_secret(secret_name, region='us-east-1'):\n    session = boto3.session.Session()\n    client = session.client('secretsmanager', region_name=region)\n    response = client.get_secret_value(SecretId=secret_name)\n    return json.loads(response['SecretString'])\n</code></pre></p>"},{"location":"deployment/production/#firewall-configuration","title":"Firewall Configuration","text":"<p>UFW (Ubuntu): <pre><code># Basic firewall setup\nsudo ufw default deny incoming\nsudo ufw default allow outgoing\nsudo ufw allow ssh\nsudo ufw allow 80\nsudo ufw allow 443\nsudo ufw enable\n</code></pre></p> <p>Security Groups (AWS): <pre><code>{\n  \"GroupName\": \"agent-workflow-sg\",\n  \"Description\": \"Security group for Agent Workflow\",\n  \"IpPermissions\": [\n    {\n      \"IpProtocol\": \"tcp\",\n      \"FromPort\": 22,\n      \"ToPort\": 22,\n      \"IpRanges\": [{\"CidrIp\": \"your.office.ip/32\"}]\n    },\n    {\n      \"IpProtocol\": \"tcp\", \n      \"FromPort\": 443,\n      \"ToPort\": 443,\n      \"IpRanges\": [{\"CidrIp\": \"0.0.0.0/0\"}]\n    }\n  ]\n}\n</code></pre></p>"},{"location":"deployment/production/#monitoring","title":"Monitoring","text":""},{"location":"deployment/production/#health-checks","title":"Health Checks","text":"<p>Health Check Script: <pre><code>#!/usr/bin/env python3\n# scripts/health-check.py\n\nimport asyncio\nimport sys\nfrom lib.orchestrator import Orchestrator\n\nasync def health_check():\n    try:\n        orchestrator = Orchestrator()\n        state = await orchestrator.get_state()\n\n        # Check if orchestrator is responsive\n        if state is None:\n            return False\n\n        # Check Discord connection\n        if not orchestrator.discord_bot.is_ready():\n            return False\n\n        return True\n    except Exception as e:\n        print(f\"Health check failed: {e}\")\n        return False\n\nif __name__ == \"__main__\":\n    healthy = asyncio.run(health_check())\n    sys.exit(0 if healthy else 1)\n</code></pre></p>"},{"location":"deployment/production/#logging","title":"Logging","text":"<p>Structured Logging Configuration: <pre><code>import logging\nimport json\nfrom datetime import datetime\n\nclass JSONFormatter(logging.Formatter):\n    def format(self, record):\n        log_entry = {\n            'timestamp': datetime.utcnow().isoformat(),\n            'level': record.levelname,\n            'logger': record.name,\n            'message': record.getMessage(),\n            'module': record.module,\n            'function': record.funcName,\n            'line': record.lineno\n        }\n\n        if record.exc_info:\n            log_entry['exception'] = self.formatException(record.exc_info)\n\n        return json.dumps(log_entry)\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(message)s',\n    handlers=[\n        logging.FileHandler('/var/log/agent-workflow/app.log'),\n        logging.StreamHandler()\n    ]\n)\n\nfor handler in logging.root.handlers:\n    handler.setFormatter(JSONFormatter())\n</code></pre></p>"},{"location":"deployment/production/#metrics-collection","title":"Metrics Collection","text":"<p>Prometheus Metrics: <pre><code>from prometheus_client import Counter, Histogram, Gauge, start_http_server\n\n# Define metrics\ncommands_total = Counter('discord_commands_total', 'Total Discord commands processed', ['command', 'status'])\nagent_execution_duration = Histogram('agent_execution_seconds', 'Agent task execution time', ['agent_type'])\nactive_sprints = Gauge('active_sprints_total', 'Number of active sprints')\n\n# Usage in code\ncommands_total.labels(command='epic', status='success').inc()\nagent_execution_duration.labels(agent_type='CodeAgent').observe(task_duration)\nactive_sprints.set(len(active_sprint_list))\n\n# Start metrics server\nstart_http_server(8000)\n</code></pre></p>"},{"location":"deployment/production/#backup-and-recovery","title":"Backup and Recovery","text":""},{"location":"deployment/production/#data-backup","title":"Data Backup","text":"<p>Backup Script: <pre><code>#!/bin/bash\n# scripts/backup.sh\n\nBACKUP_DIR=\"/backup/agent-workflow\"\nDATE=$(date +%Y%m%d_%H%M%S)\nPROJECT_DIR=\"/home/agent-workflow/agent-workflow\"\n\n# Create backup directory\nmkdir -p $BACKUP_DIR/$DATE\n\n# Backup configuration\ncp -r $PROJECT_DIR/config $BACKUP_DIR/$DATE/\n\n# Backup project data\ncp -r $PROJECT_DIR/projects $BACKUP_DIR/$DATE/\n\n# Backup logs (last 7 days)\nfind $PROJECT_DIR/logs -mtime -7 -type f -exec cp {} $BACKUP_DIR/$DATE/logs/ \\;\n\n# Compress backup\ntar -czf $BACKUP_DIR/agent-workflow-$DATE.tar.gz -C $BACKUP_DIR $DATE\nrm -rf $BACKUP_DIR/$DATE\n\n# Clean old backups (keep 30 days)\nfind $BACKUP_DIR -name \"*.tar.gz\" -mtime +30 -delete\n\necho \"Backup completed: agent-workflow-$DATE.tar.gz\"\n</code></pre></p>"},{"location":"deployment/production/#database-backup-if-using-external-db","title":"Database Backup (if using external DB)","text":"<p>PostgreSQL Backup: <pre><code>#!/bin/bash\n# Automated database backup\npg_dump -h localhost -U agent_workflow -d agent_workflow_prod &gt; backup_$(date +%Y%m%d_%H%M%S).sql\n\n# Upload to S3\naws s3 cp backup_*.sql s3://your-backup-bucket/database/\n</code></pre></p>"},{"location":"deployment/production/#scaling","title":"Scaling","text":""},{"location":"deployment/production/#horizontal-scaling","title":"Horizontal Scaling","text":"<p>Multiple Orchestrator Instances: <pre><code># Load balancer configuration for multiple instances\n# Use Redis for shared state management\n\nimport redis\nimport json\n\nclass SharedStateManager:\n    def __init__(self, redis_url):\n        self.redis = redis.from_url(redis_url)\n\n    def save_state(self, project_id, state):\n        self.redis.set(f\"project:{project_id}:state\", json.dumps(state))\n\n    def load_state(self, project_id):\n        data = self.redis.get(f\"project:{project_id}:state\")\n        return json.loads(data) if data else None\n</code></pre></p>"},{"location":"deployment/production/#resource-optimization","title":"Resource Optimization","text":"<p>Memory and CPU Optimization: <pre><code># Optimize agent execution\nimport asyncio\nfrom concurrent.futures import ThreadPoolExecutor\n\nclass OptimizedOrchestrator:\n    def __init__(self, max_workers=4):\n        self.executor = ThreadPoolExecutor(max_workers=max_workers)\n        self.semaphore = asyncio.Semaphore(max_workers)\n\n    async def execute_agent_task(self, agent, task):\n        async with self.semaphore:\n            loop = asyncio.get_event_loop()\n            return await loop.run_in_executor(\n                self.executor, \n                agent.run, \n                task\n            )\n</code></pre></p>"},{"location":"deployment/production/#troubleshooting","title":"Troubleshooting","text":""},{"location":"deployment/production/#common-production-issues","title":"Common Production Issues","text":"<p>High Memory Usage: <pre><code># Monitor memory usage\nps aux | grep python | head -10\nfree -h\n\n# Tune Python garbage collection\nexport PYTHONGC=1  # Enable garbage collection debug\n</code></pre></p> <p>Discord Rate Limiting: <pre><code># Implement exponential backoff\nimport asyncio\nfrom discord.errors import HTTPException\n\nasync def send_with_retry(channel, message, max_retries=3):\n    for attempt in range(max_retries):\n        try:\n            return await channel.send(message)\n        except HTTPException as e:\n            if e.status == 429:  # Rate limited\n                retry_after = e.response.headers.get('Retry-After', 1)\n                await asyncio.sleep(float(retry_after))\n            else:\n                raise\n    raise Exception(\"Max retries exceeded\")\n</code></pre></p>"},{"location":"deployment/production/#log-analysis","title":"Log Analysis","text":"<p>Common Log Patterns: <pre><code># Find errors in last hour\ngrep -i error /var/log/agent-workflow/app.log | tail -100\n\n# Monitor agent failures\ngrep \"AgentExecutionError\" /var/log/agent-workflow/app.log\n\n# Check Discord connection issues\ngrep \"discord\" /var/log/agent-workflow/app.log | grep -i \"error\\|timeout\"\n</code></pre></p> <p>Your production deployment is now ready for reliable, scalable operation!</p>"},{"location":"development/api-reference/","title":"API Reference","text":"<p>Complete API reference for the AI Agent TDD-Scrum workflow system.</p>"},{"location":"development/api-reference/#core-classes","title":"Core Classes","text":""},{"location":"development/api-reference/#orchestrator","title":"Orchestrator","text":"<p>Main coordination engine for the workflow system.</p> <pre><code>from lib.orchestrator import Orchestrator\n\norchestrator = Orchestrator(config_path=\"config.yml\")\n</code></pre>"},{"location":"development/api-reference/#methods","title":"Methods","text":"<p><code>async create_epic(description: str, priority: str = \"medium\") -&gt; Epic</code></p> <p>Create a new epic with the given description.</p> <p>Parameters: - <code>description</code> (str): Human-readable description of the epic - <code>priority</code> (str, optional): Priority level (\"low\", \"medium\", \"high\"). Defaults to \"medium\"</p> <p>Returns: - <code>Epic</code>: The created epic instance</p> <p>Raises: - <code>ValueError</code>: If description is empty or invalid</p> <p>Example: <pre><code>epic = await orchestrator.create_epic(\"Build authentication system\", \"high\")\nprint(f\"Created epic: {epic.id}\")\n</code></pre></p> <p><code>async plan_sprint(story_ids: List[str]) -&gt; Sprint</code></p> <p>Plan a new sprint with the specified stories.</p> <p><code>async start_sprint() -&gt; bool</code></p> <p>Start the currently planned sprint.</p> <p><code>async get_state() -&gt; OrchestratorState</code></p> <p>Get the current orchestrator state.</p>"},{"location":"development/api-reference/#state-machine","title":"State Machine","text":"<p>Finite state machine managing workflow transitions.</p> <pre><code>from lib.state_machine import StateMachine, OrchestratorState\n\nstate_machine = StateMachine()\n</code></pre>"},{"location":"development/api-reference/#states","title":"States","text":"<ul> <li><code>IDLE</code>: Initial state, ready for epic creation</li> <li><code>BACKLOG_READY</code>: Epic created, ready for sprint planning</li> <li><code>SPRINT_PLANNED</code>: Sprint planned, ready to start</li> <li><code>SPRINT_ACTIVE</code>: Sprint in progress</li> <li><code>SPRINT_PAUSED</code>: Sprint temporarily paused</li> <li><code>SPRINT_REVIEW</code>: Sprint completed, awaiting review</li> <li><code>BLOCKED</code>: System blocked, requires intervention</li> </ul>"},{"location":"development/api-reference/#methods_1","title":"Methods","text":"<p><code>transition(current_state: OrchestratorState, command: str) -&gt; OrchestratorState</code></p> <p>Execute a state transition based on the current state and command.</p> <p><code>get_allowed_commands(state: OrchestratorState) -&gt; List[str]</code></p> <p>Get the list of commands allowed in the given state.</p>"},{"location":"development/api-reference/#data-models","title":"Data Models","text":""},{"location":"development/api-reference/#epic","title":"Epic","text":"<p>High-level initiative or feature area.</p> <pre><code>from lib.data_models import Epic\n\nepic = Epic(\n    id=\"AUTH-EPIC-001\",\n    description=\"Build comprehensive authentication system\",\n    priority=\"high\",\n    status=\"active\"\n)\n</code></pre>"},{"location":"development/api-reference/#attributes","title":"Attributes","text":"<ul> <li><code>id</code> (str): Unique identifier</li> <li><code>description</code> (str): Human-readable description</li> <li><code>priority</code> (str): Priority level (\"low\", \"medium\", \"high\")</li> <li><code>status</code> (str): Current status (\"pending\", \"active\", \"completed\")</li> <li><code>created_at</code> (datetime): Creation timestamp</li> <li><code>stories</code> (List[Story]): Associated stories</li> </ul>"},{"location":"development/api-reference/#methods_2","title":"Methods","text":"<p><code>add_story(story: Story) -&gt; None</code></p> <p>Add a story to this epic.</p> <p><code>to_dict() -&gt; dict</code></p> <p>Serialize epic to dictionary.</p> <p><code>from_dict(data: dict) -&gt; Epic</code> (classmethod)</p> <p>Create epic from dictionary.</p>"},{"location":"development/api-reference/#story","title":"Story","text":"<p>Specific, actionable task within an epic.</p> <pre><code>from lib.data_models import Story\n\nstory = Story(\n    id=\"AUTH-001\",\n    description=\"Create user registration form\",\n    epic_id=\"AUTH-EPIC-001\",\n    priority=\"high\"\n)\n</code></pre>"},{"location":"development/api-reference/#attributes_1","title":"Attributes","text":"<ul> <li><code>id</code> (str): Unique identifier</li> <li><code>description</code> (str): Detailed task description</li> <li><code>epic_id</code> (str): Parent epic identifier</li> <li><code>priority</code> (str): Priority level</li> <li><code>status</code> (str): Current status</li> <li><code>assigned_agent</code> (str, optional): Agent type assigned</li> <li><code>created_at</code> (datetime): Creation timestamp</li> </ul>"},{"location":"development/api-reference/#sprint","title":"Sprint","text":"<p>Time-boxed development iteration.</p> <pre><code>from lib.data_models import Sprint\n\nsprint = Sprint(\n    id=\"SPRINT-001\",\n    stories=[\"AUTH-001\", \"AUTH-002\"],\n    start_date=datetime.now(),\n    duration_days=7\n)\n</code></pre>"},{"location":"development/api-reference/#attributes_2","title":"Attributes","text":"<ul> <li><code>id</code> (str): Unique identifier</li> <li><code>stories</code> (List[str]): Story IDs included in sprint</li> <li><code>start_date</code> (datetime): Sprint start date</li> <li><code>duration_days</code> (int): Sprint length in days</li> <li><code>status</code> (str): Current status (\"planned\", \"active\", \"completed\")</li> </ul>"},{"location":"development/api-reference/#agent-system","title":"Agent System","text":""},{"location":"development/api-reference/#baseagent","title":"BaseAgent","text":"<p>Abstract base class for all agents.</p> <pre><code>from lib.agents.base_agent import BaseAgent\n\nclass CustomAgent(BaseAgent):\n    async def run(self, task: str, dry_run: bool = False) -&gt; str:\n        # Implementation\n        pass\n</code></pre>"},{"location":"development/api-reference/#methods_3","title":"Methods","text":"<p><code>async run(task: str, dry_run: bool = False) -&gt; str</code> (abstract)</p> <p>Execute the given task.</p> <p><code>get_capabilities() -&gt; List[str]</code></p> <p>Return list of agent capabilities.</p>"},{"location":"development/api-reference/#designagent","title":"DesignAgent","text":"<p>Specialized agent for architecture and design tasks.</p> <pre><code>from lib.agents.design_agent import DesignAgent\n\nagent = DesignAgent()\nresult = await agent.run(\"Create API specification for user authentication\")\n</code></pre>"},{"location":"development/api-reference/#capabilities","title":"Capabilities","text":"<ul> <li>System architecture design</li> <li>API specification creation</li> <li>Component interface design</li> <li>Technical documentation</li> <li>Design review and validation</li> </ul>"},{"location":"development/api-reference/#codeagent","title":"CodeAgent","text":"<p>Specialized agent for code implementation tasks.</p> <pre><code>from lib.agents.code_agent import CodeAgent\n\nagent = CodeAgent()\nresult = await agent.run(\"Implement user registration endpoint\")\n</code></pre>"},{"location":"development/api-reference/#capabilities_1","title":"Capabilities","text":"<ul> <li>Feature implementation</li> <li>Bug fixing and debugging</li> <li>Code refactoring</li> <li>Performance optimization</li> <li>Integration development</li> </ul>"},{"location":"development/api-reference/#qaagent","title":"QAAgent","text":"<p>Specialized agent for testing and quality assurance.</p> <pre><code>from lib.agents.qa_agent import QAAgent\n\nagent = QAAgent()\nresult = await agent.run(\"Create unit tests for authentication module\")\n</code></pre>"},{"location":"development/api-reference/#capabilities_2","title":"Capabilities","text":"<ul> <li>Test suite creation</li> <li>Quality validation</li> <li>Coverage analysis</li> <li>Performance testing</li> <li>Security testing</li> </ul>"},{"location":"development/api-reference/#dataagent","title":"DataAgent","text":"<p>Specialized agent for data analysis and visualization.</p> <pre><code>from lib.agents.data_agent import DataAgent\n\nagent = DataAgent()\nresult = await agent.run(\"Analyze user registration patterns\")\n</code></pre>"},{"location":"development/api-reference/#capabilities_3","title":"Capabilities","text":"<ul> <li>Data analysis and insights</li> <li>Pipeline creation</li> <li>Metrics reporting</li> <li>Visualization generation</li> <li>Statistical analysis</li> </ul>"},{"location":"development/api-reference/#discord-bot","title":"Discord Bot","text":"<p>Discord interface for Human-In-The-Loop control.</p> <pre><code>from lib.discord_bot import DiscordBot\n\nbot = DiscordBot(orchestrator=orchestrator)\n</code></pre>"},{"location":"development/api-reference/#commands","title":"Commands","text":"<p>All Discord commands are implemented as slash commands:</p> <ul> <li><code>/epic \"description\"</code> - Create new epic</li> <li><code>/approve [ID...]</code> - Approve pending items</li> <li><code>/sprint plan|start|status|pause|resume</code> - Sprint management</li> <li><code>/backlog view|add_story|prioritize</code> - Backlog operations</li> <li><code>/state</code> - Interactive state inspection</li> </ul>"},{"location":"development/api-reference/#storage-system","title":"Storage System","text":""},{"location":"development/api-reference/#projectstorage","title":"ProjectStorage","text":"<p>File-based persistence for project data.</p> <pre><code>from lib.project_storage import ProjectStorage\n\nstorage = ProjectStorage(project_path=\"/path/to/project\")\n</code></pre>"},{"location":"development/api-reference/#methods_4","title":"Methods","text":"<p><code>save_epic(epic: Epic) -&gt; None</code></p> <p>Persist epic to storage.</p> <p><code>load_epic(epic_id: str) -&gt; Epic</code></p> <p>Load epic from storage.</p> <p><code>save_sprint(sprint: Sprint) -&gt; None</code></p> <p>Persist sprint to storage.</p> <p><code>get_project_state() -&gt; dict</code></p> <p>Get complete project state.</p>"},{"location":"development/api-reference/#security-system","title":"Security System","text":""},{"location":"development/api-reference/#agent-tool-configuration","title":"Agent Tool Configuration","text":"<p>Security controls for agent capabilities.</p> <pre><code>from lib.agent_tool_config import get_agent_security_profile\n\nprofile = get_agent_security_profile(\"CodeAgent\")\nallowed_tools = profile[\"allowed_tools\"]\nblocked_tools = profile[\"blocked_tools\"]\n</code></pre>"},{"location":"development/api-reference/#security-profiles","title":"Security Profiles","text":"<p>Each agent type has specific tool restrictions:</p> <ul> <li>DesignAgent: Read-only access, documentation creation</li> <li>CodeAgent: Code editing, version control (limited)</li> <li>QAAgent: Testing tools only</li> <li>DataAgent: Data processing and visualization</li> </ul>"},{"location":"development/api-reference/#error-handling","title":"Error Handling","text":""},{"location":"development/api-reference/#custom-exceptions","title":"Custom Exceptions","text":"<pre><code>from lib.exceptions import (\n    InvalidStateTransitionError,\n    AgentExecutionError,\n    ConfigurationError\n)\n\ntry:\n    await orchestrator.start_sprint()\nexcept InvalidStateTransitionError as e:\n    print(f\"Invalid state transition: {e}\")\n</code></pre>"},{"location":"development/api-reference/#exception-types","title":"Exception Types","text":"<ul> <li><code>InvalidStateTransitionError</code>: Illegal state machine transition</li> <li><code>AgentExecutionError</code>: Agent task execution failure</li> <li><code>ConfigurationError</code>: Invalid configuration settings</li> <li><code>StorageError</code>: File system or data persistence error</li> </ul>"},{"location":"development/api-reference/#configuration","title":"Configuration","text":""},{"location":"development/api-reference/#config-schema","title":"Config Schema","text":"<pre><code>from lib.config import Config\n\nconfig = Config.from_file(\"config.yml\")\n</code></pre>"},{"location":"development/api-reference/#configuration-structure","title":"Configuration Structure","text":"<pre><code>orchestrator:\n  mode: \"blocking\"  # blocking, partial, autonomous\n  max_concurrent_projects: 3\n  state_save_interval: 60\n\ndiscord:\n  bot_token: \"your_token_here\"\n  command_prefix: \"/\"\n  max_commands_per_minute: 20\n\nagents:\n  timeout_minutes: 30\n  max_retries: 3\n\nprojects:\n  - name: \"web-app\"\n    path: \"/path/to/project\"\n    mode: \"partial\"\n</code></pre>"},{"location":"development/api-reference/#utilities","title":"Utilities","text":""},{"location":"development/api-reference/#logging","title":"Logging","text":"<pre><code>from lib.utils.logging import get_logger\n\nlogger = get_logger(__name__)\nlogger.info(\"Orchestrator started\")\n</code></pre>"},{"location":"development/api-reference/#async-helpers","title":"Async Helpers","text":"<pre><code>from lib.utils.async_helpers import run_with_timeout\n\nresult = await run_with_timeout(agent.run(task), timeout=300)\n</code></pre>"},{"location":"development/api-reference/#examples","title":"Examples","text":""},{"location":"development/api-reference/#complete-workflow-example","title":"Complete Workflow Example","text":"<pre><code>import asyncio\nfrom lib.orchestrator import Orchestrator\n\nasync def main():\n    # Initialize orchestrator\n    orchestrator = Orchestrator(\"config.yml\")\n\n    # Create epic\n    epic = await orchestrator.create_epic(\n        \"Build user authentication system\", \n        priority=\"high\"\n    )\n\n    # Plan sprint\n    sprint = await orchestrator.plan_sprint([\n        \"AUTH-001\", \"AUTH-002\", \"AUTH-003\"\n    ])\n\n    # Start sprint\n    success = await orchestrator.start_sprint()\n\n    if success:\n        print(\"Sprint started successfully!\")\n\n    # Monitor progress\n    while True:\n        state = await orchestrator.get_state()\n        if state == \"SPRINT_REVIEW\":\n            break\n        await asyncio.sleep(30)  # Check every 30 seconds\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"development/api-reference/#custom-agent-example","title":"Custom Agent Example","text":"<pre><code>from lib.agents.base_agent import BaseAgent\n\nclass DocumentationAgent(BaseAgent):\n    \"\"\"Agent specialized in creating and maintaining documentation.\"\"\"\n\n    def get_capabilities(self) -&gt; List[str]:\n        return [\n            \"markdown_generation\",\n            \"api_documentation\", \n            \"user_guide_creation\",\n            \"code_commenting\"\n        ]\n\n    async def run(self, task: str, dry_run: bool = False) -&gt; str:\n        if \"api documentation\" in task.lower():\n            return await self._generate_api_docs(task)\n        elif \"user guide\" in task.lower():\n            return await self._create_user_guide(task)\n        else:\n            return await self._general_documentation(task)\n\n    async def _generate_api_docs(self, task: str) -&gt; str:\n        # Implementation for API documentation\n        return \"Generated API documentation\"\n</code></pre>"},{"location":"development/api-reference/#tdd-system-apis","title":"TDD System APIs","text":""},{"location":"development/api-reference/#tddstatemachine","title":"TDDStateMachine","text":"<p>Finite state machine that enforces proper TDD command sequencing according to Test-Driven Development best practices.</p> <pre><code>from lib.tdd_state_machine import TDDStateMachine, TDDCommandResult\nfrom lib.tdd_models import TDDState, TDDCycle\n\nstate_machine = TDDStateMachine()\n</code></pre>"},{"location":"development/api-reference/#methods_5","title":"Methods","text":"<p><code>validate_command(command: str, cycle: Optional[TDDCycle] = None) -&gt; TDDCommandResult</code></p> <p>Validate if a TDD command is allowed in the current state.</p> <p>Parameters: - <code>command</code> (str): The TDD command to validate (e.g., \"/tdd test\", \"/tdd code\") - <code>cycle</code> (TDDCycle, optional): TDD cycle for context validation</p> <p>Returns: - <code>TDDCommandResult</code>: Validation outcome with success flag, new state, error message, and hints</p> <p>Example: <pre><code>result = state_machine.validate_command(\"/tdd code\", active_cycle)\nif result.success:\n    print(f\"Command allowed, new state: {result.new_state}\")\nelse:\n    print(f\"Error: {result.error_message}\")\n    print(f\"Hint: {result.hint}\")\n</code></pre></p> <p><code>transition(command: str, cycle: Optional[TDDCycle] = None) -&gt; TDDCommandResult</code></p> <p>Execute a TDD state transition if the command is valid.</p> <p><code>get_allowed_commands(cycle: Optional[TDDCycle] = None) -&gt; List[str]</code></p> <p>Get list of TDD commands allowed in current state.</p> <p><code>get_next_suggested_command(cycle: Optional[TDDCycle] = None) -&gt; Optional[str]</code></p> <p>Get the next suggested command based on current state and conditions.</p> <p><code>get_state_info(cycle: Optional[TDDCycle] = None) -&gt; Dict[str, Any]</code></p> <p>Get comprehensive TDD state information for debugging and visualization.</p> <p><code>can_auto_progress(cycle: Optional[TDDCycle] = None) -&gt; bool</code></p> <p>Check if state machine can automatically progress to next state.</p> <p><code>get_mermaid_diagram() -&gt; str</code></p> <p>Generate Mermaid state diagram for TDD workflow visualization.</p>"},{"location":"development/api-reference/#tdd-data-models","title":"TDD Data Models","text":""},{"location":"development/api-reference/#tddstate-enum","title":"TDDState Enum","text":"<p>TDD cycle states with their purposes:</p> <pre><code>from lib.tdd_models import TDDState\n\nclass TDDState(Enum):\n    DESIGN = \"design\"           # Create specifications and acceptance criteria\n    TEST_RED = \"test_red\"       # Write failing tests\n    CODE_GREEN = \"code_green\"   # Implement minimal code to pass tests\n    REFACTOR = \"refactor\"       # Improve code quality while keeping tests green\n    COMMIT = \"commit\"           # Save progress and mark task complete\n</code></pre>"},{"location":"development/api-reference/#tddcycle","title":"TDDCycle","text":"<p>TDD cycle linked to a story with task management and progress tracking.</p> <pre><code>from lib.tdd_models import TDDCycle, TDDTask\n\ncycle = TDDCycle(\n    id=\"tdd-cycle-abc123\",\n    story_id=\"AUTH-001\",\n    current_state=TDDState.DESIGN\n)\n</code></pre> <p>Attributes: - <code>id</code> (str): Unique identifier - <code>story_id</code> (str): Associated story identifier - <code>current_state</code> (TDDState): Current TDD phase - <code>current_task_id</code> (Optional[str]): Active task identifier - <code>tasks</code> (List[TDDTask]): All tasks in the cycle - <code>started_at</code> (str): Cycle start timestamp - <code>completed_at</code> (Optional[str]): Cycle completion timestamp - <code>total_test_runs</code> (int): Count of test executions - <code>total_refactors</code> (int): Count of refactor operations - <code>total_commits</code> (int): Count of commits made - <code>ci_status</code> (CIStatus): Overall CI status - <code>overall_test_coverage</code> (float): Average test coverage</p> <p>Methods:</p> <p><code>get_current_task() -&gt; Optional[TDDTask]</code></p> <p>Get the currently active task.</p> <p><code>add_task(task: TDDTask) -&gt; None</code></p> <p>Add a new task to the cycle.</p> <p><code>start_task(task_id: str) -&gt; bool</code></p> <p>Start a specific task (only one can be active).</p> <p><code>complete_current_task() -&gt; bool</code></p> <p>Mark current task as complete and advance cycle.</p> <p><code>get_progress_summary() -&gt; Dict[str, Any]</code></p> <p>Get detailed progress information including task counts and metrics.</p> <p><code>calculate_overall_coverage() -&gt; float</code></p> <p>Calculate overall test coverage for the entire cycle.</p>"},{"location":"development/api-reference/#tddtask","title":"TDDTask","text":"<p>Individual task within a TDD cycle with test management and state tracking.</p> <pre><code>from lib.tdd_models import TDDTask, TestFile, TestResult\n\ntask = TDDTask(\n    id=\"tdd-task-xyz789\",\n    cycle_id=\"tdd-cycle-abc123\",\n    description=\"Implement user authentication API\",\n    current_state=TDDState.DESIGN\n)\n</code></pre> <p>Attributes: - <code>id</code> (str): Unique identifier - <code>cycle_id</code> (str): Parent cycle identifier - <code>description</code> (str): Task description - <code>acceptance_criteria</code> (List[str]): Acceptance criteria list - <code>current_state</code> (TDDState): Current task state - <code>test_files</code> (List[str]): Test file paths - <code>test_file_objects</code> (List[TestFile]): TestFile objects with metadata - <code>source_files</code> (List[str]): Source file paths - <code>test_results</code> (List[TestResult]): Test execution results - <code>design_notes</code> (str): Design phase documentation - <code>implementation_notes</code> (str): Implementation notes - <code>refactor_notes</code> (str): Refactoring documentation - <code>ci_status</code> (CIStatus): CI pipeline status - <code>test_coverage</code> (float): Task-specific test coverage</p> <p>Methods:</p> <p><code>has_passing_tests() -&gt; bool</code></p> <p>Check if all tests are currently passing.</p> <p><code>has_failing_tests() -&gt; bool</code></p> <p>Check if any tests are currently failing.</p> <p><code>add_test_file(test_file: TestFile) -&gt; None</code></p> <p>Add a test file to this task.</p> <p><code>get_committed_test_files() -&gt; List[TestFile]</code></p> <p>Get all test files that have been committed to repository.</p> <p><code>can_commit_tests() -&gt; bool</code></p> <p>Check if tests are ready to be committed (RED state with failing tests).</p> <p><code>can_commit_code() -&gt; bool</code></p> <p>Check if code can be committed (tests passing with committed test files).</p> <p><code>can_commit_refactor() -&gt; bool</code></p> <p>Check if refactored code can be committed (tests still passing).</p>"},{"location":"development/api-reference/#testfile","title":"TestFile","text":"<p>Test file lifecycle management with CI integration.</p> <pre><code>from lib.tdd_models import TestFile, TestFileStatus, CIStatus\n\ntest_file = TestFile(\n    file_path=\"/path/to/test_auth.py\",\n    relative_path=\"tests/tdd/AUTH-001/test_auth.py\",\n    story_id=\"AUTH-001\",\n    status=TestFileStatus.DRAFT\n)\n</code></pre> <p>Attributes: - <code>id</code> (str): Unique identifier - <code>file_path</code> (str): Absolute file path - <code>relative_path</code> (str): Path relative to project root - <code>story_id</code> (str): Associated story identifier - <code>task_id</code> (str): Associated task identifier - <code>status</code> (TestFileStatus): File lifecycle status - <code>ci_status</code> (CIStatus): CI pipeline status - <code>test_count</code> (int): Total number of tests - <code>passing_tests</code> (int): Count of passing tests - <code>failing_tests</code> (int): Count of failing tests - <code>coverage_percentage</code> (float): Code coverage percentage</p> <p>Methods:</p> <p><code>exists() -&gt; bool</code></p> <p>Check if test file exists on filesystem.</p> <p><code>is_committed() -&gt; bool</code></p> <p>Check if test file has been committed to repository.</p> <p><code>is_passing() -&gt; bool</code></p> <p>Check if all tests in file are passing.</p> <p><code>get_permanent_location() -&gt; str</code></p> <p>Get the permanent test location after integration (tests/unit/ or tests/integration/).</p>"},{"location":"development/api-reference/#testresult","title":"TestResult","text":"<p>Individual test execution result with timing and output capture.</p> <pre><code>from lib.tdd_models import TestResult, TestStatus\n\nresult = TestResult(\n    test_file=\"test_auth.py\",\n    test_name=\"test_login_success\",\n    status=TestStatus.GREEN,\n    execution_time=0.045\n)\n</code></pre> <p>Attributes: - <code>id</code> (str): Unique identifier - <code>test_file</code> (str): Test file name - <code>test_name</code> (str): Specific test name - <code>status</code> (TestStatus): Execution status (RED, GREEN, ERROR) - <code>output</code> (str): Test output capture - <code>error_message</code> (Optional[str]): Error details if failed - <code>execution_time</code> (float): Test execution time in seconds - <code>timestamp</code> (str): Execution timestamp</p>"},{"location":"development/api-reference/#enhanced-agent-apis-for-tdd","title":"Enhanced Agent APIs for TDD","text":""},{"location":"development/api-reference/#designagent-tdd-mode","title":"DesignAgent (TDD Mode)","text":"<p>Extended capabilities for TDD design phase.</p> <pre><code>from lib.agents.design_agent import DesignAgent\n\nagent = DesignAgent()\nresult = await agent.run_tdd_design(\n    story=\"Implement user authentication\", \n    acceptance_criteria=[\"User can login\", \"Passwords are hashed\"]\n)\n</code></pre> <p>TDD-Specific Methods:</p> <p><code>async run_tdd_design(story: str, acceptance_criteria: List[str]) -&gt; TDDTask</code></p> <p>Create detailed technical specifications for TDD implementation.</p> <p><code>async create_acceptance_tests(task: TDDTask) -&gt; List[str]</code></p> <p>Generate acceptance test scenarios from design specifications.</p>"},{"location":"development/api-reference/#qaagent-tdd-mode","title":"QAAgent (TDD Mode)","text":"<p>Specialized for TDD test creation and validation.</p> <pre><code>from lib.agents.qa_agent import QAAgent\n\nagent = QAAgent()\nresult = await agent.run_tdd_test_creation(\n    task=tdd_task,\n    ensure_failures=True\n)\n</code></pre> <p>TDD-Specific Methods:</p> <p><code>async run_tdd_test_creation(task: TDDTask, ensure_failures: bool = True) -&gt; List[TestFile]</code></p> <p>Create comprehensive failing tests based on design specifications.</p> <p><code>async validate_test_red_state(task: TDDTask) -&gt; bool</code></p> <p>Verify that tests are properly failing before implementation.</p> <p><code>async run_tdd_test_validation(task: TDDTask) -&gt; List[TestResult]</code></p> <p>Execute tests and validate results against TDD requirements.</p>"},{"location":"development/api-reference/#codeagent-tdd-mode","title":"CodeAgent (TDD Mode)","text":"<p>Implementation with TDD constraints and refactoring support.</p> <pre><code>from lib.agents.code_agent import CodeAgent\n\nagent = CodeAgent()\nresult = await agent.run_tdd_implementation(\n    task=tdd_task,\n    minimal_implementation=True\n)\n</code></pre> <p>TDD-Specific Methods:</p> <p><code>async run_tdd_implementation(task: TDDTask, minimal_implementation: bool = True) -&gt; List[str]</code></p> <p>Implement minimal code to make tests pass in CODE_GREEN phase.</p> <p><code>async run_tdd_refactor(task: TDDTask, maintain_green: bool = True) -&gt; List[str]</code></p> <p>Improve code quality while ensuring all tests remain green.</p> <p><code>async validate_green_state(task: TDDTask) -&gt; bool</code></p> <p>Verify that all tests are passing after implementation.</p>"},{"location":"development/api-reference/#tdd-orchestration-apis","title":"TDD Orchestration APIs","text":""},{"location":"development/api-reference/#tddorchestrator","title":"TDDOrchestrator","text":"<p>Coordinates TDD cycles with the main Scrum workflow.</p> <pre><code>from lib.tdd_orchestrator import TDDOrchestrator\n\norchestrator = TDDOrchestrator()\n</code></pre> <p>Methods:</p> <p><code>async start_tdd_cycle(story_id: str, tasks: List[str]) -&gt; TDDCycle</code></p> <p>Start a new TDD cycle for a story with specified tasks.</p> <p><code>async progress_tdd_cycle(cycle_id: str, command: str) -&gt; TDDCommandResult</code></p> <p>Advance a TDD cycle through the next state based on command.</p> <p><code>async get_active_tdd_cycles() -&gt; List[TDDCycle]</code></p> <p>Get all currently active TDD cycles across all stories.</p> <p><code>async pause_tdd_cycle(cycle_id: str) -&gt; bool</code></p> <p>Temporarily pause a TDD cycle.</p> <p><code>async resume_tdd_cycle(cycle_id: str) -&gt; bool</code></p> <p>Resume a paused TDD cycle.</p> <p><code>async get_tdd_metrics(time_period: str = \"30d\") -&gt; Dict[str, Any]</code></p> <p>Get TDD performance metrics and analytics.</p>"},{"location":"development/api-reference/#tdd-integration-examples","title":"TDD Integration Examples","text":""},{"location":"development/api-reference/#complete-tdd-cycle-management","title":"Complete TDD Cycle Management","text":"<pre><code>import asyncio\nfrom lib.tdd_state_machine import TDDStateMachine\nfrom lib.tdd_models import TDDCycle, TDDTask\nfrom lib.agents.design_agent import DesignAgent\nfrom lib.agents.qa_agent import QAAgent\nfrom lib.agents.code_agent import CodeAgent\n\nasync def run_complete_tdd_cycle():\n    # Initialize TDD cycle\n    cycle = TDDCycle(story_id=\"AUTH-001\")\n    task = TDDTask(\n        description=\"Implement user login API\",\n        acceptance_criteria=[\"User can authenticate\", \"Invalid credentials rejected\"]\n    )\n    cycle.add_task(task)\n\n    # Initialize state machine\n    tdd_sm = TDDStateMachine()\n    tdd_sm.set_active_cycle(cycle)\n\n    # Phase 1: Design\n    design_agent = DesignAgent()\n    design_result = await design_agent.run_tdd_design(\n        story=task.description,\n        acceptance_criteria=task.acceptance_criteria\n    )\n\n    # Transition to TEST_RED\n    transition_result = tdd_sm.transition(\"/tdd test\", cycle)\n    if transition_result.success:\n        # Phase 2: Write failing tests\n        qa_agent = QAAgent()\n        test_files = await qa_agent.run_tdd_test_creation(task)\n\n        # Commit tests\n        commit_result = tdd_sm.transition(\"/tdd commit-tests\", cycle)\n        if commit_result.success:\n            # Phase 3: Implement code\n            code_agent = CodeAgent()\n            source_files = await code_agent.run_tdd_implementation(task)\n\n            # Validate green state\n            is_green = await code_agent.validate_green_state(task)\n            if is_green:\n                # Phase 4: Refactor\n                refactor_result = tdd_sm.transition(\"/tdd refactor\", cycle)\n                if refactor_result.success:\n                    refactored_files = await code_agent.run_tdd_refactor(task)\n\n                    # Final commit\n                    final_result = tdd_sm.transition(\"/tdd commit\", cycle)\n                    return final_result.success\n\n    return False\n\n# Usage\nsuccess = asyncio.run(run_complete_tdd_cycle())\n</code></pre>"},{"location":"development/api-reference/#tdd-metrics-and-monitoring","title":"TDD Metrics and Monitoring","text":"<pre><code>from lib.tdd_orchestrator import TDDOrchestrator\n\nasync def monitor_tdd_progress():\n    orchestrator = TDDOrchestrator()\n\n    # Get all active cycles\n    active_cycles = await orchestrator.get_active_tdd_cycles()\n\n    for cycle in active_cycles:\n        progress = cycle.get_progress_summary()\n        print(f\"Story {cycle.story_id}: {progress['current_state']} \"\n              f\"({progress['progress']} tasks complete)\")\n\n        current_task = cycle.get_current_task()\n        if current_task:\n            if current_task.has_failing_tests():\n                print(f\"  - RED: {len(current_task.test_results)} tests failing\")\n            elif current_task.has_passing_tests():\n                print(f\"  - GREEN: All tests passing, coverage: {current_task.test_coverage:.1f}%\")\n\n    # Get performance metrics\n    metrics = await orchestrator.get_tdd_metrics(\"7d\")\n    print(f\"Last 7 days: {metrics['total_cycles']} cycles, \"\n          f\"avg cycle time: {metrics['avg_cycle_time']} minutes\")\n\n# Usage\nasyncio.run(monitor_tdd_progress())\n</code></pre> <p>This API reference provides comprehensive coverage of the system's public interfaces and usage patterns.</p>"},{"location":"development/contributing/","title":"Contributing","text":"<p>Welcome to the AI Agent TDD-Scrum Workflow project! We appreciate your interest in contributing.</p>"},{"location":"development/contributing/#getting-started","title":"Getting Started","text":""},{"location":"development/contributing/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.8 or higher</li> <li>Git for version control</li> <li>Discord account for testing bot functionality</li> <li>Basic understanding of async Python programming</li> </ul>"},{"location":"development/contributing/#development-setup","title":"Development Setup","text":"<ol> <li> <p>Fork and clone the repository: <pre><code>git clone https://github.com/jmontp/agent-workflow.git\ncd agent-workflow\n</code></pre></p> </li> <li> <p>Create a virtual environment: <pre><code>python -m venv venv\nsource venv/bin/activate  # Linux/Mac\n# or\nvenv\\Scripts\\activate     # Windows\n</code></pre></p> </li> <li> <p>Install dependencies: <pre><code>pip install -r requirements.txt\npip install -r requirements-dev.txt  # Development dependencies\n</code></pre></p> </li> <li> <p>Set up environment variables: <pre><code>cp .env.example .env\n# Edit .env with your Discord bot token and other settings\n</code></pre></p> </li> </ol>"},{"location":"development/contributing/#development-workflow","title":"Development Workflow","text":""},{"location":"development/contributing/#branch-strategy","title":"Branch Strategy","text":"<ul> <li><code>main</code>: Production-ready code</li> <li><code>develop</code>: Integration branch for features</li> <li><code>feature/*</code>: Individual feature development</li> <li><code>hotfix/*</code>: Critical bug fixes</li> </ul>"},{"location":"development/contributing/#making-changes","title":"Making Changes","text":"<ol> <li> <p>Create a feature branch: <pre><code>git checkout -b feature/your-feature-name\n</code></pre></p> </li> <li> <p>Make your changes:</p> </li> <li>Follow existing code style and patterns</li> <li>Add tests for new functionality</li> <li> <p>Update documentation as needed</p> </li> <li> <p>Test your changes: <pre><code># Run the full test suite\npytest\n\n# Run specific test categories\npytest tests/unit/\npytest tests/integration/\npytest -m \"not slow\"\n</code></pre></p> </li> <li> <p>Commit your changes: <pre><code>git add .\ngit commit -m \"Add feature: description of your changes\"\n</code></pre></p> </li> <li> <p>Push and create a pull request: <pre><code>git push origin feature/your-feature-name\n</code></pre></p> </li> </ol>"},{"location":"development/contributing/#code-style-guidelines","title":"Code Style Guidelines","text":""},{"location":"development/contributing/#python-code-style","title":"Python Code Style","text":"<p>We follow PEP 8 with some modifications:</p> <ul> <li>Line length: 88 characters (Black formatter default)</li> <li>Import ordering: Use <code>isort</code> for consistent import organization</li> <li>Type hints: Required for public methods and complex functions</li> <li>Docstrings: Use Google-style docstrings</li> </ul>"},{"location":"development/contributing/#example-code-style","title":"Example Code Style","text":"<pre><code>from typing import List, Optional\nimport asyncio\n\nfrom lib.data_models import Epic, Story\n\n\nclass EpicManager:\n    \"\"\"Manages epic creation and lifecycle.\n\n    This class handles the creation, modification, and deletion of epics\n    within the workflow system.\n    \"\"\"\n\n    def __init__(self, storage_path: str) -&gt; None:\n        \"\"\"Initialize the epic manager.\n\n        Args:\n            storage_path: Path to the storage directory for epics.\n        \"\"\"\n        self.storage_path = storage_path\n\n    async def create_epic(\n        self, \n        description: str, \n        priority: str = \"medium\"\n    ) -&gt; Epic:\n        \"\"\"Create a new epic with the given description.\n\n        Args:\n            description: Human-readable description of the epic.\n            priority: Priority level (low, medium, high).\n\n        Returns:\n            The created Epic instance.\n\n        Raises:\n            ValueError: If description is empty or invalid.\n        \"\"\"\n        if not description.strip():\n            raise ValueError(\"Epic description cannot be empty\")\n\n        # Implementation here...\n</code></pre>"},{"location":"development/contributing/#testing-guidelines","title":"Testing Guidelines","text":""},{"location":"development/contributing/#test-organization","title":"Test Organization","text":"<ul> <li>Unit tests: <code>tests/unit/</code> - Test individual components in isolation</li> <li>Integration tests: <code>tests/integration/</code> - Test component interactions</li> <li>End-to-end tests: <code>tests/e2e/</code> - Test complete user workflows</li> </ul>"},{"location":"development/contributing/#test-patterns","title":"Test Patterns","text":"<pre><code>import pytest\nfrom unittest.mock import AsyncMock, patch\n\nfrom lib.orchestrator import Orchestrator\n\n\nclass TestOrchestrator:\n    \"\"\"Test suite for the Orchestrator class.\"\"\"\n\n    @pytest.fixture\n    def orchestrator(self):\n        \"\"\"Create a test orchestrator instance.\"\"\"\n        return Orchestrator(config_path=\"test_config.yml\")\n\n    @pytest.mark.asyncio\n    async def test_create_epic_success(self, orchestrator):\n        \"\"\"Test successful epic creation.\"\"\"\n        # Given\n        description = \"Build authentication system\"\n\n        # When\n        epic = await orchestrator.create_epic(description)\n\n        # Then\n        assert epic.description == description\n        assert epic.status == \"pending\"\n\n    @pytest.mark.asyncio\n    async def test_create_epic_with_empty_description_raises_error(self, orchestrator):\n        \"\"\"Test that empty description raises ValueError.\"\"\"\n        # Given\n        description = \"\"\n\n        # When/Then\n        with pytest.raises(ValueError, match=\"Epic description cannot be empty\"):\n            await orchestrator.create_epic(description)\n</code></pre>"},{"location":"development/contributing/#architecture-guidelines","title":"Architecture Guidelines","text":""},{"location":"development/contributing/#adding-new-agents","title":"Adding New Agents","text":"<p>When adding a new agent type:</p> <ol> <li> <p>Inherit from BaseAgent: <pre><code>from lib.agents.base_agent import BaseAgent\n\nclass NewAgent(BaseAgent):\n    async def run(self, task: str, dry_run: bool = False) -&gt; str:\n        # Implementation\n</code></pre></p> </li> <li> <p>Define security profile:    Add to <code>lib/agent_tool_config.py</code>:    <pre><code>\"NewAgent\": {\n    \"allowed_tools\": [\"read\", \"specific_tool\"],\n    \"blocked_tools\": [\"edit\", \"system\"]\n}\n</code></pre></p> </li> <li> <p>Add comprehensive tests:</p> </li> <li>Unit tests for agent logic</li> <li>Security boundary tests</li> <li>Integration tests with orchestrator</li> </ol>"},{"location":"development/contributing/#state-machine-extensions","title":"State Machine Extensions","text":"<p>When modifying the state machine:</p> <ol> <li>Update state definitions in <code>lib/state_machine.py</code></li> <li>Add transition logic with proper validation</li> <li>Update command mappings in the Discord bot</li> <li>Add comprehensive tests for all new transitions</li> </ol>"},{"location":"development/contributing/#documentation","title":"Documentation","text":""},{"location":"development/contributing/#documentation-requirements","title":"Documentation Requirements","text":"<ul> <li>API documentation: Update docstrings for any public methods</li> <li>User documentation: Update relevant user guides</li> <li>Architecture documentation: Update design docs for significant changes</li> </ul>"},{"location":"development/contributing/#building-documentation","title":"Building Documentation","text":"<pre><code># Install documentation dependencies\npip install mkdocs-material\n\n# Serve locally for development\nmkdocs serve\n\n# Build static site\nmkdocs build\n</code></pre>"},{"location":"development/contributing/#testing","title":"Testing","text":""},{"location":"development/contributing/#running-tests","title":"Running Tests","text":"<pre><code># Full test suite\npytest\n\n# With coverage report\npytest --cov=lib --cov-report=html\n\n# Specific test categories\npytest tests/unit/\npytest tests/integration/\npytest -m \"not slow\"\n\n# Security tests\npytest tests/unit/test_agent_tool_config.py\n\n# TDD-specific tests\npytest tests/unit/test_tdd_models.py\npytest tests/unit/test_tdd_state_machine.py\npytest test_tdd_e2e.py\n</code></pre>"},{"location":"development/contributing/#test-requirements","title":"Test Requirements","text":"<ul> <li>Coverage: Aim for &gt;90% code coverage</li> <li>Security tests: Required for any security-related changes</li> <li>Integration tests: Required for cross-component changes</li> <li>Performance tests: For changes affecting system performance</li> <li>TDD tests: Required for all TDD state machine and model changes</li> </ul>"},{"location":"development/contributing/#tdd-development-practices","title":"TDD Development Practices","text":""},{"location":"development/contributing/#working-with-tdd-features","title":"Working with TDD Features","text":"<p>The AI Agent TDD-Scrum system includes a comprehensive TDD workflow system. When contributing to TDD-related functionality, follow these practices:</p>"},{"location":"development/contributing/#tdd-state-machine-development","title":"TDD State Machine Development","text":"<p>State Transition Testing: <pre><code>def test_tdd_state_transition():\n    \"\"\"Test TDD state transitions follow RED-GREEN-REFACTOR cycle\"\"\"\n    machine = TDDStateMachine(TDDState.DESIGN)\n\n    # Test valid transition\n    result = machine.transition(\"/tdd test\")\n    assert result.success\n    assert result.new_state == TDDState.TEST_RED\n\n    # Test invalid transition\n    result = machine.transition(\"/tdd refactor\") \n    assert not result.success\n    assert \"Write failing tests first\" in result.hint\n</code></pre></p> <p>Condition Validation: <pre><code>def test_transition_conditions():\n    \"\"\"Test that transition conditions are properly validated\"\"\"\n    task = TDDTask(description=\"Test login API\")\n    task.test_results = [TestResult(status=TestStatus.RED)]\n\n    machine = TDDStateMachine()\n    cycle = TDDCycle(current_task_id=task.id)\n    cycle.add_task(task)\n\n    # Should allow transition when conditions are met\n    result = machine.validate_command(\"/tdd code\", cycle)\n    assert result.success\n</code></pre></p>"},{"location":"development/contributing/#tdd-model-development","title":"TDD Model Development","text":"<p>Data Model Changes: - All TDD models must include <code>to_dict()</code> and <code>from_dict()</code> methods - Ensure serialization compatibility for persistence - Add proper type hints and documentation</p> <pre><code>@dataclass\nclass TDDTask:\n    \"\"\"Individual task within a TDD cycle\"\"\"\n    id: str = field(default_factory=lambda: f\"tdd-task-{uuid.uuid4().hex[:8]}\")\n    # ... other fields\n\n    def to_dict(self) -&gt; Dict[str, Any]:\n        \"\"\"Serialize to dictionary for persistence\"\"\"\n        return {\n            \"id\": self.id,\n            # ... serialize all fields including nested objects\n        }\n</code></pre>"},{"location":"development/contributing/#test-preservation-workflow","title":"Test Preservation Workflow","text":"<p>When working on test preservation features:</p> <p>File Management: <pre><code>def test_test_file_lifecycle():\n    \"\"\"Test the complete test file lifecycle\"\"\"\n    test_file = TestFile(\n        file_path=\"/tests/tdd/story-123/test_login.py\",\n        story_id=\"story-123\",\n        status=TestFileStatus.DRAFT\n    )\n\n    # Test commit transition\n    test_file.committed_at = datetime.now().isoformat()\n    assert test_file.is_committed()\n\n    # Test integration\n    permanent_path = test_file.get_permanent_location()\n    assert \"tests/unit/\" in permanent_path\n</code></pre></p> <p>CI Integration: <pre><code>def test_ci_status_updates():\n    \"\"\"Test CI status tracking for TDD cycles\"\"\"\n    cycle = TDDCycle(story_id=\"story-123\")\n    cycle.update_ci_status(CIStatus.RUNNING)\n\n    assert cycle.ci_status == CIStatus.RUNNING\n    # Test status propagation to tasks\n</code></pre></p>"},{"location":"development/contributing/#tdd-code-style-guidelines","title":"TDD Code Style Guidelines","text":""},{"location":"development/contributing/#command-validation","title":"Command Validation","text":"<pre><code># Good: Clear error messages with helpful hints\nif command not in self.TRANSITIONS:\n    return TDDCommandResult(\n        success=False,\n        error_message=f\"Unknown TDD command: {command}\",\n        hint=\"Use /tdd status to see available commands\"\n    )\n\n# Bad: Generic error without guidance\nif command not in self.TRANSITIONS:\n    return TDDCommandResult(success=False)\n</code></pre>"},{"location":"development/contributing/#state-management","title":"State Management","text":"<pre><code># Good: Atomic state updates with logging\ndef transition(self, command: str) -&gt; TDDCommandResult:\n    result = self.validate_command(command)\n    if result.success:\n        old_state = self.current_state\n        self.current_state = result.new_state\n        logger.info(f\"TDD transition: {old_state} \u2192 {self.current_state}\")\n    return result\n\n# Bad: State changes without validation or logging\ndef transition(self, command: str):\n    self.current_state = new_state  # No validation\n</code></pre>"},{"location":"development/contributing/#error-handling","title":"Error Handling","text":"<pre><code># Good: Specific error handling with context\ntry:\n    test_results = self.run_tests(test_files)\nexcept TestExecutionError as e:\n    return TDDCommandResult(\n        success=False,\n        error_message=f\"Test execution failed: {e}\",\n        hint=\"Check test file syntax and dependencies\"\n    )\n\n# Bad: Silent failures or generic exceptions\ntry:\n    self.run_tests(test_files)\nexcept:\n    pass  # Silent failure\n</code></pre>"},{"location":"development/contributing/#tdd-testing-requirements","title":"TDD Testing Requirements","text":""},{"location":"development/contributing/#state-machine-tests","title":"State Machine Tests","text":"<ul> <li>Transition Matrix: Test all valid and invalid state transitions</li> <li>Command Validation: Verify command parsing and validation logic</li> <li>Condition Checking: Test all transition conditions and hints</li> <li>Error Scenarios: Test malformed commands and edge cases</li> </ul>"},{"location":"development/contributing/#model-tests","title":"Model Tests","text":"<ul> <li>Serialization: Test <code>to_dict()</code> and <code>from_dict()</code> for all models</li> <li>Lifecycle: Test complete object lifecycles (create \u2192 update \u2192 complete)</li> <li>Relationships: Test task-cycle-story relationships</li> <li>Business Logic: Test domain-specific methods and calculations</li> </ul>"},{"location":"development/contributing/#integration-tests","title":"Integration Tests","text":"<ul> <li>E2E Workflows: Test complete TDD cycles from start to finish</li> <li>Persistence: Test data persistence and recovery</li> <li>Agent Coordination: Test TDD workflow with multiple agents</li> <li>Error Recovery: Test recovery from failed states</li> </ul>"},{"location":"development/contributing/#example-test-structure","title":"Example Test Structure","text":"<pre><code>class TestTDDStateMachine:\n    \"\"\"Comprehensive test suite for TDD state machine\"\"\"\n\n    @pytest.fixture\n    def machine(self):\n        return TDDStateMachine(TDDState.DESIGN)\n\n    @pytest.fixture\n    def sample_cycle(self):\n        cycle = TDDCycle(story_id=\"test-story\")\n        task = TDDTask(description=\"Test task\")\n        cycle.add_task(task)\n        cycle.start_task(task.id)\n        return cycle\n\n    def test_valid_transitions(self, machine):\n        \"\"\"Test all valid state transitions\"\"\"\n        # Test each transition in TRANSITIONS matrix\n\n    def test_invalid_transitions(self, machine):\n        \"\"\"Test invalid transitions return helpful errors\"\"\"\n        # Test transitions not in matrix\n\n    def test_condition_validation(self, machine, sample_cycle):\n        \"\"\"Test transition conditions are properly checked\"\"\"\n        # Test each condition in TRANSITION_CONDITIONS\n\n    @pytest.mark.parametrize(\"command,state,expected_hint\", [\n        (\"/tdd code\", TDDState.DESIGN, \"Write failing tests first\"),\n        # ... more test cases\n    ])\n    def test_error_hints(self, machine, command, state, expected_hint):\n        \"\"\"Test that error hints are helpful and accurate\"\"\"\n        machine.current_state = state\n        result = machine.validate_command(command)\n        assert not result.success\n        assert expected_hint in result.hint\n</code></pre>"},{"location":"development/contributing/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>State Transitions: Should complete in &lt;1ms for local operations</li> <li>Model Serialization: Should handle cycles with 100+ tasks efficiently</li> <li>Test File Management: Should support 1000+ test files per cycle</li> <li>Memory Usage: Avoid memory leaks in long-running TDD cycles</li> </ul>"},{"location":"development/contributing/#review-process","title":"Review Process","text":""},{"location":"development/contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<ol> <li>Clear description: Explain what and why</li> <li>Link issues: Reference related GitHub issues</li> <li>Include tests: All changes must include appropriate tests</li> <li>Update documentation: Keep docs in sync with code changes</li> <li>Security review: Highlight any security implications</li> </ol>"},{"location":"development/contributing/#review-checklist","title":"Review Checklist","text":"<ul> <li> Code follows style guidelines</li> <li> Tests pass and coverage is maintained</li> <li> Documentation is updated</li> <li> Security implications are considered</li> <li> Breaking changes are documented</li> <li> Performance impact is assessed</li> </ul>"},{"location":"development/contributing/#getting-help","title":"Getting Help","text":""},{"location":"development/contributing/#resources","title":"Resources","text":"<ul> <li>GitHub Issues: Report bugs and request features</li> <li>GitHub Discussions: Ask questions and share ideas</li> <li>Discord: Join our development Discord server (link in README)</li> </ul>"},{"location":"development/contributing/#common-issues","title":"Common Issues","text":"<p>Tests failing locally: - Ensure all dependencies are installed - Check environment variable configuration - Run <code>pytest -v</code> for detailed error output</p> <p>Import errors: - Verify virtual environment is activated - Run <code>pip install -e .</code> to install in development mode</p> <p>Discord bot not responding: - Check bot token configuration - Verify bot permissions in test server - Review Discord API rate limits</p>"},{"location":"development/contributing/#release-process","title":"Release Process","text":""},{"location":"development/contributing/#version-management","title":"Version Management","text":"<p>We use semantic versioning (SemVer): - Major: Breaking changes - Minor: New features, backward compatible - Patch: Bug fixes, backward compatible</p>"},{"location":"development/contributing/#release-checklist","title":"Release Checklist","text":"<ol> <li>Update version numbers</li> <li>Update CHANGELOG.md</li> <li>Run full test suite</li> <li>Update documentation</li> <li>Create release PR</li> <li>Tag release after merge</li> <li>Deploy to production</li> </ol> <p>Thank you for contributing to the AI Agent TDD-Scrum Workflow project!</p>"},{"location":"getting-started/configuration/","title":"Configuration","text":"<p>Configure the AI Agent TDD-Scrum workflow system for your development environment.</p>"},{"location":"getting-started/configuration/#environment-variables","title":"Environment Variables","text":""},{"location":"getting-started/configuration/#required-configuration","title":"Required Configuration","text":"<p><code>DISCORD_BOT_TOKEN</code> Your Discord bot token for the HITL interface. <pre><code>export DISCORD_BOT_TOKEN=\"your_discord_bot_token_here\"\n</code></pre></p>"},{"location":"getting-started/configuration/#optional-configuration","title":"Optional Configuration","text":"<p><code>ANTHROPIC_API_KEY</code> (for Claude integration) <pre><code>export ANTHROPIC_API_KEY=\"your_anthropic_api_key\"\n</code></pre></p> <p><code>GITHUB_TOKEN</code> (for enhanced GitHub integration) <pre><code>export GITHUB_TOKEN=\"your_github_personal_access_token\"\n</code></pre></p>"},{"location":"getting-started/configuration/#project-configuration","title":"Project Configuration","text":""},{"location":"getting-started/configuration/#single-project-setup","title":"Single Project Setup","text":"<p>For managing a single project, create a simple configuration:</p> <pre><code># config.yml\norchestrator:\n  mode: blocking  # blocking, partial, or autonomous\n  project_path: \"/path/to/your/project\"\n  project_name: \"my-project\"\n</code></pre>"},{"location":"getting-started/configuration/#multi-project-setup","title":"Multi-Project Setup","text":"<p>For managing multiple projects simultaneously:</p> <pre><code># config.yml\norchestrator:\n  mode: blocking\n  projects:\n    - name: \"web-app\"\n      path: \"/path/to/web-app\"\n      mode: partial\n    - name: \"api-service\" \n      path: \"/path/to/api-service\"\n      mode: autonomous\n    - name: \"mobile-app\"\n      path: \"/path/to/mobile-app\"\n      mode: blocking\n</code></pre>"},{"location":"getting-started/configuration/#orchestration-modes","title":"Orchestration Modes","text":""},{"location":"getting-started/configuration/#blocking-mode","title":"Blocking Mode","text":"<ul> <li>Human approval required for all strategic decisions</li> <li>Safest option for critical projects</li> <li>Recommended for learning the system</li> </ul>"},{"location":"getting-started/configuration/#partial-mode","title":"Partial Mode","text":"<ul> <li>Agents execute with quarantined output for review</li> <li>Balanced automation with oversight</li> <li>Good for established workflows</li> </ul>"},{"location":"getting-started/configuration/#autonomous-mode","title":"Autonomous Mode","text":"<ul> <li>Full execution with monitoring and alerts</li> <li>Highest automation level</li> <li>Use only for well-tested processes</li> </ul>"},{"location":"getting-started/configuration/#discord-configuration","title":"Discord Configuration","text":""},{"location":"getting-started/configuration/#bot-setup","title":"Bot Setup","text":"<ol> <li>Create a Discord application at Discord Developer Portal</li> <li>Create a bot and copy the token</li> <li>Invite the bot to your server with these permissions:</li> <li>Use Slash Commands</li> <li>Send Messages</li> <li>Embed Links</li> <li>Read Message History</li> </ol>"},{"location":"getting-started/configuration/#channel-configuration","title":"Channel Configuration","text":"<p>The system automatically creates project-specific channels: - Format: <code>hostname-projectname</code> - Example: <code>macbook-web-app</code>, <code>ubuntu-api-service</code></p>"},{"location":"getting-started/configuration/#agent-configuration","title":"Agent Configuration","text":""},{"location":"getting-started/configuration/#ai-integration","title":"AI Integration","text":"<p>Claude Code Integration: <pre><code># Install Claude Code CLI\npip install claude-code\n\n# Verify installation\nclaude --version\n</code></pre></p> <p>Alternative AI Services: The system supports pluggable AI integrations. Implement the <code>BaseAgent</code> interface for custom AI services.</p>"},{"location":"getting-started/configuration/#security-settings","title":"Security Settings","text":"<p>Agent tool access is configured in <code>lib/agent_tool_config.py</code>:</p> <pre><code>AGENT_SECURITY_PROFILES = {\n    \"DesignAgent\": {\n        \"allowed_tools\": [\"read\", \"web_search\", \"documentation\"],\n        \"blocked_tools\": [\"edit\", \"git\", \"system\"]\n    },\n    \"CodeAgent\": {\n        \"allowed_tools\": [\"read\", \"edit\", \"git_add\", \"git_commit\", \"test\"],\n        \"blocked_tools\": [\"git_push\", \"system\", \"delete\"]\n    }\n    # ... other agents\n}\n</code></pre>"},{"location":"getting-started/configuration/#file-locations","title":"File Locations","text":""},{"location":"getting-started/configuration/#configuration-files","title":"Configuration Files","text":"<ul> <li>Main config: <code>config.yml</code> (repository root)</li> <li>User preferences: <code>~/.agent-workflow/preferences.yml</code></li> <li>Project state: <code>&lt;project&gt;/.orch-state/status.json</code></li> </ul>"},{"location":"getting-started/configuration/#log-files","title":"Log Files","text":"<ul> <li>System logs: <code>logs/orchestrator.log</code></li> <li>Agent logs: <code>logs/agents/&lt;agent-type&gt;.log</code></li> <li>Discord logs: <code>logs/discord-bot.log</code></li> </ul>"},{"location":"getting-started/configuration/#performance-tuning","title":"Performance Tuning","text":""},{"location":"getting-started/configuration/#resource-limits","title":"Resource Limits","text":"<pre><code>orchestrator:\n  max_concurrent_projects: 3\n  agent_timeout_minutes: 30\n  state_save_interval_seconds: 60\n</code></pre>"},{"location":"getting-started/configuration/#discord-rate-limiting","title":"Discord Rate Limiting","text":"<pre><code>discord:\n  max_commands_per_minute: 20\n  response_timeout_seconds: 30\n</code></pre>"},{"location":"getting-started/configuration/#troubleshooting-configuration","title":"Troubleshooting Configuration","text":""},{"location":"getting-started/configuration/#common-issues","title":"Common Issues","text":"<p>Environment variables not recognized: <pre><code># Check current environment\nenv | grep -E \"(DISCORD|ANTHROPIC|GITHUB)\"\n\n# Set in shell profile for persistence\necho 'export DISCORD_BOT_TOKEN=\"your_token\"' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre></p> <p>Configuration file not found: <pre><code># Create default configuration\ncp config.example.yml config.yml\n# Edit with your settings\n</code></pre></p> <p>Permission errors: <pre><code># Ensure proper file permissions\nchmod 600 config.yml  # Restrict access to config file\nchmod +x scripts/orchestrator.py  # Make scripts executable\n</code></pre></p>"},{"location":"getting-started/configuration/#validation","title":"Validation","text":"<p>Test your configuration: <pre><code># Validate configuration syntax\npython -c \"import yaml; yaml.safe_load(open('config.yml'))\"\n\n# Test Discord connection\npython scripts/test-discord.py\n\n# Test AI integration\npython scripts/test-agents.py\n</code></pre></p>"},{"location":"getting-started/configuration/#tdd-configuration","title":"TDD Configuration","text":""},{"location":"getting-started/configuration/#tdd-state-machine-settings","title":"TDD State Machine Settings","text":"<p>Configure TDD behavior in your project configuration:</p> <pre><code># config.yml\norchestrator:\n  mode: blocking\n  tdd:\n    enabled: true\n    auto_start_cycles: true  # Automatically start TDD for active stories\n    preserve_tests: true     # Enable test preservation workflow\n    parallel_execution: true # Allow multiple TDD cycles simultaneously\n\n    # State machine configuration\n    state_machine:\n      auto_transitions: true    # Enable /tdd next auto-advancement\n      require_conditions: true  # Enforce transition conditions\n      validation_mode: strict   # strict, relaxed, or disabled\n\n    # Test preservation settings\n    test_preservation:\n      base_directory: \"tests/tdd\"\n      structure_mode: \"story_based\"  # story_based or flat\n      integration_target: \"tests/unit\"  # Where to move tests after completion\n      backup_enabled: true\n      max_backup_age_days: 30\n</code></pre>"},{"location":"getting-started/configuration/#tdd-cycle-timeouts","title":"TDD Cycle Timeouts","text":"<p>Configure timeouts for different TDD phases:</p> <pre><code>tdd:\n  timeouts:\n    design_phase_minutes: 30      # Design Agent specification creation\n    test_red_phase_minutes: 45    # QA Agent test writing\n    code_green_phase_minutes: 60  # Code Agent implementation\n    refactor_phase_minutes: 30    # Code Agent refactoring\n    commit_phase_minutes: 15      # Final commit and cleanup\n\n    # Global timeout settings\n    max_cycle_hours: 4           # Maximum time for complete TDD cycle\n    stuck_detection_minutes: 15  # How long before marking phase as stuck\n    auto_recovery_enabled: true  # Enable automatic recovery attempts\n</code></pre>"},{"location":"getting-started/configuration/#test-execution-configuration","title":"Test Execution Configuration","text":"<p>Configure how tests are executed during TDD cycles:</p> <pre><code>tdd:\n  test_execution:\n    runner: \"pytest\"              # Test runner: pytest, unittest, nose2\n    parallel_jobs: 4              # Number of parallel test jobs\n    timeout_seconds: 300          # Individual test timeout\n    coverage_threshold: 90        # Minimum coverage percentage\n\n    # Test discovery\n    test_patterns:\n      - \"test_*.py\"\n      - \"*_test.py\"\n\n    # Coverage configuration\n    coverage:\n      enabled: true\n      fail_under: 90\n      exclude_patterns:\n        - \"*/migrations/*\"\n        - \"*/venv/*\"\n        - \"test_*\"\n\n    # CI integration\n    ci_integration:\n      enabled: true\n      provider: \"github_actions\"  # github_actions, gitlab_ci, jenkins\n      trigger_on_commit: true\n      require_passing_ci: true\n</code></pre>"},{"location":"getting-started/configuration/#agent-behavior-in-tdd","title":"Agent Behavior in TDD","text":"<p>Configure how agents behave during TDD cycles:</p> <pre><code>tdd:\n  agents:\n    design_agent:\n      max_specification_length: 2000\n      include_diagrams: true\n      detail_level: \"comprehensive\"  # minimal, standard, comprehensive\n\n    qa_agent:\n      test_types:\n        - \"unit\"\n        - \"integration\"\n        - \"acceptance\"\n      mock_external_services: true\n      generate_test_data: true\n\n    code_agent:\n      implementation_style: \"minimal\"  # minimal, complete, extensive\n      refactor_automatically: true\n      apply_best_practices: true\n\n    # Agent coordination\n    coordination:\n      exclusive_phases: true        # Only one agent active per phase\n      handoff_validation: true      # Validate work before handoff\n      conflict_resolution: \"human\"  # human, automatic, priority_based\n</code></pre>"},{"location":"getting-started/configuration/#tdd-quality-gates","title":"TDD Quality Gates","text":"<p>Configure quality requirements for TDD progression:</p> <pre><code>tdd:\n  quality_gates:\n    test_red_phase:\n      min_test_count: 3\n      require_failing_tests: true\n      max_test_errors: 0\n\n    code_green_phase:\n      require_all_tests_passing: true\n      max_complexity_score: 10\n      min_coverage_increase: 5  # Percentage points\n\n    refactor_phase:\n      maintain_test_coverage: true\n      max_complexity_regression: 0\n      code_quality_threshold: 8.0  # SonarQube-style rating\n\n    commit_phase:\n      require_commit_message: true\n      run_full_test_suite: true\n      validate_ci_config: true\n</code></pre>"},{"location":"getting-started/configuration/#tdd-metrics-and-monitoring","title":"TDD Metrics and Monitoring","text":"<p>Configure metrics collection and monitoring:</p> <pre><code>tdd:\n  metrics:\n    collection_enabled: true\n\n    # Cycle metrics\n    track_cycle_times: true\n    track_phase_durations: true\n    track_success_rates: true\n\n    # Quality metrics\n    track_test_coverage: true\n    track_code_complexity: true\n    track_refactor_frequency: true\n\n    # Export configuration\n    export:\n      format: \"json\"  # json, csv, prometheus\n      interval_minutes: 15\n      destination: \"logs/tdd_metrics.json\"\n\n    # Alerting\n    alerts:\n      stuck_cycle_threshold_minutes: 60\n      low_coverage_threshold: 80\n      high_complexity_threshold: 15\n      notification_webhook: \"https://hooks.slack.com/...\"\n</code></pre>"},{"location":"getting-started/configuration/#environment-specific-tdd-settings","title":"Environment-Specific TDD Settings","text":"<p>Configure TDD behavior for different environments:</p> <pre><code># Development environment\ndevelopment:\n  tdd:\n    timeouts:\n      design_phase_minutes: 15    # Faster for dev\n      test_red_phase_minutes: 20\n    quality_gates:\n      code_green_phase:\n        min_coverage_increase: 2  # Relaxed for dev\n    test_execution:\n      parallel_jobs: 2            # Lower resource usage\n\n# Production environment  \nproduction:\n  tdd:\n    timeouts:\n      design_phase_minutes: 60    # More thorough for prod\n      test_red_phase_minutes: 90\n    quality_gates:\n      code_green_phase:\n        min_coverage_increase: 10 # Stricter for prod\n    test_execution:\n      parallel_jobs: 8            # Full resource utilization\n</code></pre>"},{"location":"getting-started/configuration/#tdd-integration-settings","title":"TDD Integration Settings","text":"<p>Configure integration with external tools and services:</p> <pre><code>tdd:\n  integrations:\n    # Git integration\n    git:\n      auto_commit_tests: true\n      commit_message_template: \"TDD: {phase} for {story_id} - {description}\"\n      branch_strategy: \"feature\"  # feature, tdd_cycles, main\n\n    # CI/CD integration  \n    ci:\n      provider: \"github_actions\"\n      config_file: \".github/workflows/tdd.yml\"\n      trigger_events:\n        - \"test_commit\"\n        - \"code_commit\" \n        - \"refactor_commit\"\n\n    # Code quality tools\n    quality_tools:\n      sonarqube:\n        enabled: true\n        server_url: \"https://sonar.company.com\"\n        project_key: \"my-project\"\n\n      codecov:\n        enabled: true\n        token: \"${CODECOV_TOKEN}\"\n\n    # Notification services\n    notifications:\n      slack:\n        webhook_url: \"${SLACK_WEBHOOK}\"\n        channels:\n          - \"#tdd-cycles\"\n          - \"#development\"\n\n      email:\n        smtp_server: \"smtp.company.com\"\n        from_address: \"tdd-bot@company.com\"\n        recipients:\n          - \"team-lead@company.com\"\n</code></pre>"},{"location":"getting-started/configuration/#validating-tdd-configuration","title":"Validating TDD Configuration","text":"<p>Test your TDD configuration:</p> <pre><code># Validate TDD configuration syntax\npython -c \"import yaml; yaml.safe_load(open('config.yml'))\"\n\n# Test TDD state machine initialization\npython -c \"\nfrom lib.tdd_state_machine import TDDStateMachine\nmachine = TDDStateMachine()\nprint('TDD state machine initialized successfully')\n\"\n\n# Validate TDD directory structure\npython scripts/validate_tdd_config.py\n\n# Test TDD integration with main system\npython scripts/test_tdd_integration.py\n</code></pre>"},{"location":"getting-started/configuration/#common-tdd-configuration-issues","title":"Common TDD Configuration Issues","text":"<p>TDD cycles not starting automatically: <pre><code># Ensure auto_start_cycles is enabled\ntdd:\n  auto_start_cycles: true\n</code></pre></p> <p>Test preservation not working: <pre><code># Check directory permissions and paths\ntdd:\n  test_preservation:\n    base_directory: \"tests/tdd\"  # Must be writable\n    structure_mode: \"story_based\"\n</code></pre></p> <p>Agent coordination conflicts: <pre><code># Enable exclusive phases to prevent conflicts\ntdd:\n  agents:\n    coordination:\n      exclusive_phases: true\n      handoff_validation: true\n</code></pre></p> <p>Performance issues with large test suites: <pre><code># Optimize test execution\ntdd:\n  test_execution:\n    parallel_jobs: 8\n    timeout_seconds: 60  # Reduce if needed\n</code></pre></p>"},{"location":"getting-started/configuration/#next-steps","title":"Next Steps","text":"<p>After configuration: 1. Run the quick start guide 2. Set up your first project 3. Learn the HITL commands 4. Explore TDD workflows</p>"},{"location":"getting-started/installation/","title":"Installation Guide","text":"<p>This comprehensive guide will help you install and set up the AI Agent TDD-Scrum Workflow system with clear, step-by-step instructions.</p>"},{"location":"getting-started/installation/#prerequisites","title":"Prerequisites","text":""},{"location":"getting-started/installation/#system-requirements","title":"System Requirements","text":"<ul> <li>Operating System: Linux, macOS, or Windows (with WSL2 recommended)</li> <li>Python: Version 3.9 or higher</li> <li>Git: Version 2.20 or higher</li> <li>Memory: Minimum 4GB RAM, 8GB+ recommended for multi-project setups</li> <li>Storage: At least 2GB free space</li> </ul>"},{"location":"getting-started/installation/#required-accounts-tokens","title":"Required Accounts &amp; Tokens","text":"<p>You'll need these before starting:</p> <ol> <li>Discord Bot Token (REQUIRED)</li> <li>Create a Discord application at Discord Developer Portal</li> <li>Create a bot and copy the token</li> <li> <p>Invite bot to your server with permissions below</p> </li> <li> <p>Claude Code CLI (HIGHLY RECOMMENDED)</p> </li> <li>Sign up at claude.ai</li> <li> <p>Install Claude Code CLI from official docs</p> </li> <li> <p>GitHub Token (Optional)</p> </li> <li>Create at GitHub Settings &gt; Tokens</li> <li>Enables advanced git operations</li> </ol>"},{"location":"getting-started/installation/#quick-start-installation","title":"Quick Start Installation","text":""},{"location":"getting-started/installation/#one-command-setup","title":"\ud83d\ude80 One-Command Setup","text":"<pre><code>curl -sSL https://raw.githubusercontent.com/your-username/agent-workflow/main/install.sh | bash\n</code></pre>"},{"location":"getting-started/installation/#manual-installation-recommended","title":"\ud83d\udccb Manual Installation (Recommended)","text":""},{"location":"getting-started/installation/#step-1-clone-repository","title":"Step 1: Clone Repository","text":"<pre><code>git clone https://github.com/your-username/agent-workflow.git\ncd agent-workflow\n</code></pre>"},{"location":"getting-started/installation/#step-2-create-virtual-environment","title":"Step 2: Create Virtual Environment","text":"<pre><code># Create isolated Python environment\npython3 -m venv .venv\n\n# Activate environment\nsource .venv/bin/activate  # Linux/macOS\n# OR\n.venv\\Scripts\\activate     # Windows\n</code></pre>"},{"location":"getting-started/installation/#step-3-install-dependencies","title":"Step 3: Install Dependencies","text":"<pre><code># Core dependencies\npip install -r requirements.txt\n\n# Verify installation\npython -c \"import discord, yaml, websockets; print('\u2705 Core dependencies installed')\"\n</code></pre>"},{"location":"getting-started/installation/#step-4-configure-environment","title":"Step 4: Configure Environment","text":"<pre><code># Copy environment template\ncp .env.example .env\n\n# Edit with your tokens (use your preferred editor)\nnano .env\n</code></pre> <p>Required <code>.env</code> content: <pre><code># REQUIRED: Discord bot token\nDISCORD_BOT_TOKEN=your_discord_bot_token_here\n\n# RECOMMENDED: Claude API settings\nANTHROPIC_API_KEY=your_claude_api_key_here\nANTHROPIC_MODEL=claude-3-sonnet-20240229\n\n# OPTIONAL: GitHub integration\nGITHUB_TOKEN=your_github_token_here\n\n# SYSTEM: Basic configuration\nHOSTNAME=localhost\nLOG_LEVEL=INFO\nORCHESTRATOR_MODE=blocking\n</code></pre></p>"},{"location":"getting-started/installation/#step-5-initialize-system","title":"Step 5: Initialize System","text":"<pre><code># Initialize project structure\npython scripts/multi_project_orchestrator.py --setup\n\n# Run health check\npython scripts/multi_project_orchestrator.py --health-check\n</code></pre>"},{"location":"getting-started/installation/#step-6-verify-installation","title":"Step 6: Verify Installation","text":"<pre><code># Run test suite\npytest tests/ -v\n\n# Expected: All core tests pass\n# Note: Some integration tests may require additional setup\n</code></pre>"},{"location":"getting-started/installation/#detailed-installation-options","title":"Detailed Installation Options","text":""},{"location":"getting-started/installation/#option-a-production-installation","title":"Option A: Production Installation","text":"<p>For running the system in production:</p> <pre><code># 1. System dependencies (Ubuntu/Debian)\nsudo apt update &amp;&amp; sudo apt install -y python3 python3-pip python3-venv git curl\n\n# 2. Clone and setup\ngit clone https://github.com/your-username/agent-workflow.git\ncd agent-workflow\npython3 -m venv .venv\nsource .venv/bin/activate\n\n# 3. Install production dependencies\npip install --upgrade pip\npip install -r requirements.txt\npip install gunicorn supervisor  # For production deployment\n\n# 4. Configure for production\ncp config/production.env .env\n# Edit .env with production values\n</code></pre>"},{"location":"getting-started/installation/#option-b-development-installation","title":"Option B: Development Installation","text":"<p>For development and contribution:</p> <pre><code># 1. Clone with development branch\ngit clone -b develop https://github.com/your-username/agent-workflow.git\ncd agent-workflow\n\n# 2. Setup development environment\npython3 -m venv .venv\nsource .venv/bin/activate\n\n# 3. Install with development tools\npip install -e .\npip install -r requirements-dev.txt\n\n# 4. Setup pre-commit hooks\npre-commit install\n\n# 5. Run full test suite\npytest tests/ --cov=lib --cov-report=html\nopen htmlcov/index.html  # View coverage report\n</code></pre>"},{"location":"getting-started/installation/#option-c-docker-installation","title":"Option C: Docker Installation","text":"<p>For containerized deployment:</p> <pre><code># 1. Clone repository\ngit clone https://github.com/your-username/agent-workflow.git\ncd agent-workflow\n\n# 2. Copy environment\ncp .env.example .env\n# Edit .env with your tokens\n\n# 3. Build and run\ndocker-compose up -d\n\n# 4. Check status\ndocker-compose ps\ndocker-compose logs orchestrator\n</code></pre>"},{"location":"getting-started/installation/#discord-bot-setup","title":"Discord Bot Setup","text":""},{"location":"getting-started/installation/#step-1-create-discord-application","title":"Step 1: Create Discord Application","text":"<ol> <li>Visit Discord Developer Portal</li> <li>Click \"New Application\"</li> <li>Name your application (e.g., \"AI Agent Workflow\")</li> <li>Go to \"Bot\" section in sidebar</li> <li>Click \"Add Bot\" </li> <li>Copy the Bot Token</li> <li>Add token to your <code>.env</code> file</li> </ol>"},{"location":"getting-started/installation/#step-2-configure-bot-permissions","title":"Step 2: Configure Bot Permissions","text":"<p>Your bot needs these permissions:</p> <ul> <li>\u2705 Send Messages - Post command responses</li> <li>\u2705 Use Slash Commands - Enable <code>/epic</code>, <code>/sprint</code>, etc.</li> <li>\u2705 Create Public Threads - For threaded discussions</li> <li>\u2705 Embed Links - Rich message formatting</li> <li>\u2705 Attach Files - Share generated files</li> <li>\u2705 Read Message History - Context awareness</li> <li>\u2705 Manage Channels - Create project channels</li> </ul>"},{"location":"getting-started/installation/#step-3-invite-bot-to-server","title":"Step 3: Invite Bot to Server","text":"<p>Use this URL template (replace <code>YOUR_CLIENT_ID</code>):</p> <pre><code>https://discord.com/api/oauth2/authorize?client_id=YOUR_CLIENT_ID&amp;permissions=274877918208&amp;scope=bot%20applications.commands\n</code></pre> <p>Find your Client ID in the \"General Information\" tab.</p>"},{"location":"getting-started/installation/#platform-specific-instructions","title":"Platform-Specific Instructions","text":""},{"location":"getting-started/installation/#linux-ubuntudebian","title":"\ud83d\udc27 Linux (Ubuntu/Debian)","text":"<pre><code># Update system packages\nsudo apt update &amp;&amp; sudo apt upgrade -y\n\n# Install system dependencies\nsudo apt install -y python3 python3-pip python3-venv git curl build-essential\n\n# Install the workflow system\ngit clone https://github.com/your-username/agent-workflow.git\ncd agent-workflow\npython3 -m venv .venv\nsource .venv/bin/activate\npip install -r requirements.txt\n\n# Test installation\npython -c \"import lib.discord_bot; print('\u2705 Installation successful')\"\n</code></pre>"},{"location":"getting-started/installation/#macos","title":"\ud83c\udf4e macOS","text":"<pre><code># Install Homebrew (if not already installed)\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n\n# Install dependencies\nbrew install python@3.11 git\n\n# Install the workflow system\ngit clone https://github.com/your-username/agent-workflow.git\ncd agent-workflow\npython3 -m venv .venv\nsource .venv/bin/activate\npip install -r requirements.txt\n\n# Test installation\npython -c \"import lib.discord_bot; print('\u2705 Installation successful')\"\n</code></pre>"},{"location":"getting-started/installation/#windows-with-wsl2-recommended","title":"\ud83e\ude9f Windows (with WSL2 - Recommended)","text":"<pre><code># In PowerShell (as Administrator)\nwsl --install -d Ubuntu\nwsl --set-default-version 2\n\n# Restart computer, then in WSL2 terminal:\nsudo apt update &amp;&amp; sudo apt install -y python3 python3-pip python3-venv git\n\n# Install the workflow system\ngit clone https://github.com/your-username/agent-workflow.git\ncd agent-workflow\npython3 -m venv .venv\nsource .venv/bin/activate\npip install -r requirements.txt\n</code></pre>"},{"location":"getting-started/installation/#windows-native","title":"\ud83e\ude9f Windows (Native)","text":"<pre><code># Install Python 3.9+ from python.org\n# Install Git from git-scm.com\n\n# In Command Prompt or PowerShell:\ngit clone https://github.com/your-username/agent-workflow.git\ncd agent-workflow\npython -m venv .venv\n.venv\\Scripts\\activate\npip install -r requirements.txt\n</code></pre>"},{"location":"getting-started/installation/#verification-testing","title":"Verification &amp; Testing","text":""},{"location":"getting-started/installation/#installation-health-check","title":"\u2705 Installation Health Check","text":"<pre><code># Test 1: Import verification\npython -c \"\nimport lib.discord_bot\nimport lib.state_machine\nimport lib.data_models\nprint('\u2705 All core modules import successfully')\n\"\n\n# Test 2: Discord integration check\npython -c \"\nimport os\nif os.getenv('DISCORD_BOT_TOKEN'):\n    print('\u2705 Discord token configured')\nelse:\n    print('\u274c Discord token missing - check .env file')\n\"\n\n# Test 3: System health check  \npython scripts/multi_project_orchestrator.py --health-check\n</code></pre> <p>Expected output: <pre><code>\u2705 Configuration loaded\n\u2705 State machine initialized\n\u2705 Discord integration ready  \n\u2705 Claude integration available\n\u2705 System ready for operation\n</code></pre></p>"},{"location":"getting-started/installation/#test-suite-execution","title":"\ud83e\uddea Test Suite Execution","text":"<pre><code># Quick test - core functionality\npytest tests/unit/test_state_machine.py -v\npytest tests/unit/test_data_models.py -v\n\n# Integration tests (requires Discord token)\npytest tests/integration/ -v\n\n# Full test suite with coverage\npytest tests/ --cov=lib --cov-report=term-missing\n\n# Performance tests\npytest tests/performance/ -v --durations=10\n</code></pre>"},{"location":"getting-started/installation/#coverage-report","title":"\ud83d\udcca Coverage Report","text":"<pre><code># Generate detailed coverage report\npytest tests/ --cov=lib --cov-report=html\n\n# View in browser\nopen htmlcov/index.html  # macOS\nxdg-open htmlcov/index.html  # Linux\nstart htmlcov/index.html  # Windows\n</code></pre>"},{"location":"getting-started/installation/#documentation-setup-optional","title":"Documentation Setup (Optional)","text":""},{"location":"getting-started/installation/#local-documentation-server","title":"Local Documentation Server","text":"<pre><code># Install documentation dependencies\npip install mkdocs mkdocs-material mkdocs-mermaid2-plugin\n\n# Serve documentation locally\nmkdocs serve\n\n# Access at: http://localhost:8000\n</code></pre>"},{"location":"getting-started/installation/#build-static-documentation","title":"Build Static Documentation","text":"<pre><code># Build documentation\nmkdocs build\n\n# Deploy to GitHub Pages\nmkdocs gh-deploy\n</code></pre>"},{"location":"getting-started/installation/#configuration-files","title":"Configuration Files","text":"<p>The system expects certain configuration files:</p>"},{"location":"getting-started/installation/#project-configuration-optional","title":"Project Configuration (Optional)","text":"<p>Create <code>config/projects.yaml</code>: <pre><code>projects:\n  - name: \"my_project\"\n    path: \"/path/to/project\"\n    orchestration: \"blocking\"\n</code></pre></p>"},{"location":"getting-started/installation/#environment-variables","title":"Environment Variables","text":"<p>Required variables: <pre><code>export DISCORD_BOT_TOKEN=\"your_discord_bot_token\"\n</code></pre></p> <p>Optional variables: <pre><code>export HOSTNAME=\"your_hostname\"  # For Discord channel naming\nexport LOG_LEVEL=\"INFO\"          # Logging level\n</code></pre></p>"},{"location":"getting-started/installation/#platform-specific-notes","title":"Platform-Specific Notes","text":""},{"location":"getting-started/installation/#windows","title":"Windows","text":"<pre><code># Use Windows paths\nset DISCORD_BOT_TOKEN=your_token\n\n# Activate virtual environment\nvenv\\Scripts\\activate\n\n# Run with Python\npython lib/discord_bot.py\n</code></pre>"},{"location":"getting-started/installation/#macoslinux","title":"macOS/Linux","text":"<pre><code># Use Unix paths\nexport DISCORD_BOT_TOKEN=\"your_token\"\n\n# Activate virtual environment\nsource venv/bin/activate\n\n# Run with Make\nmake run\n</code></pre>"},{"location":"getting-started/installation/#wsl-windows-subsystem-for-linux","title":"WSL (Windows Subsystem for Linux)","text":"<p>The system is fully compatible with WSL. Follow Linux instructions above.</p>"},{"location":"getting-started/installation/#docker-installation-alternative","title":"Docker Installation (Alternative)","text":"<p>For containerized deployment:</p> <pre><code>FROM python:3.9-slim\n\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\n\nCOPY . .\nCMD [\"python\", \"lib/discord_bot.py\"]\n</code></pre> <pre><code># Build and run\ndocker build -t agent-workflow .\ndocker run -e DISCORD_BOT_TOKEN=\"your_token\" agent-workflow\n</code></pre>"},{"location":"getting-started/installation/#troubleshooting-installation","title":"Troubleshooting Installation","text":""},{"location":"getting-started/installation/#common-issues","title":"Common Issues","text":"<p>Permission Errors: <pre><code># Use user installation\npip install --user -r requirements.txt\n</code></pre></p> <p>Version Conflicts: <pre><code># Create clean virtual environment\npython -m venv fresh_venv\nsource fresh_venv/bin/activate\npip install -r requirements.txt\n</code></pre></p> <p>Discord.py Installation Issues: <pre><code># Update pip first\npip install --upgrade pip\n\n# Install with specific version\npip install discord.py==2.3.0\n</code></pre></p> <p>Import Errors: - Ensure virtual environment is activated - Check Python path includes project directory - Verify all dependencies installed correctly</p>"},{"location":"getting-started/installation/#dependency-issues","title":"Dependency Issues","text":"<p>If you encounter dependency conflicts:</p> <pre><code># Check installed packages\npip list\n\n# Create requirements lock file\npip freeze &gt; requirements-lock.txt\n\n# Clean install from lock file\npip install -r requirements-lock.txt\n</code></pre>"},{"location":"getting-started/installation/#performance-optimization","title":"Performance Optimization","text":"<p>For better performance:</p> <pre><code># Install with optimizations\npip install --upgrade pip setuptools wheel\n\n# Use faster package resolution\npip install --use-feature=fast-deps -r requirements.txt\n</code></pre>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<p>After successful installation:</p> <ol> <li>Configure Discord Bot</li> <li>Set up Project Configuration </li> <li>Try Quick Start Guide</li> <li>Read User Guide</li> </ol> <p>Installation Complete</p> <p>Your AI Agent TDD-Scrum Workflow system is now installed and ready for configuration!</p>"},{"location":"getting-started/quick-start/","title":"Quick Start Guide","text":"<p>Get the AI Agent TDD-Scrum Workflow system running in under 5 minutes.</p>"},{"location":"getting-started/quick-start/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.8+ installed</li> <li>Discord Bot Token (see Discord Setup)</li> <li>Git for cloning the repository</li> </ul>"},{"location":"getting-started/quick-start/#1-clone-and-install","title":"1. Clone and Install","text":"<pre><code># Clone the repository\ngit clone https://github.com/jmontp/agent-workflow.git\ncd agent-workflow\n\n# Install dependencies\nmake install\n</code></pre> <p>Or manually: <pre><code>pip install -r requirements.txt\n</code></pre></p>"},{"location":"getting-started/quick-start/#2-configure-environment","title":"2. Configure Environment","text":"<p>Set up your Discord bot token:</p> <pre><code>export DISCORD_BOT_TOKEN=\"your_discord_bot_token_here\"\n</code></pre> <p>Note: The system works without AI integration for testing. For full AI capabilities, you can integrate with Claude Code or other AI services.</p>"},{"location":"getting-started/quick-start/#3-run-the-system","title":"3. Run the System","text":""},{"location":"getting-started/quick-start/#option-a-discord-bot-recommended","title":"Option A: Discord Bot (Recommended)","text":"<pre><code>make run\n</code></pre> <p>This starts the Discord bot with the orchestrator backend.</p>"},{"location":"getting-started/quick-start/#option-b-orchestrator-only","title":"Option B: Orchestrator Only","text":"<pre><code>make orchestrator\n</code></pre> <p>This runs the orchestrator without Discord integration (useful for testing).</p>"},{"location":"getting-started/quick-start/#4-test-in-discord","title":"4. Test in Discord","text":"<ol> <li>Invite your bot to a Discord server</li> <li> <p>Try basic commands:    <pre><code>/state\n/epic \"Build a todo app\"\n/approve\n/sprint plan\n/sprint start\n</code></pre></p> </li> <li> <p>Monitor TDD workflow:    <pre><code>/tdd overview\n/tdd status TODO-1\n/sprint status\n</code></pre></p> </li> </ol>"},{"location":"getting-started/quick-start/#5-verify-installation","title":"5. Verify Installation","text":"<p>Run the test suite to ensure everything works:</p> <pre><code>make test\n</code></pre>"},{"location":"getting-started/quick-start/#example-tdd-workflow","title":"Example TDD Workflow","text":"<p>Once your system is running, try this complete TDD workflow:</p> <pre><code># 1. Create epic and stories\n/epic \"Build user authentication system\"\n/approve AUTH-1 AUTH-2\n\n# 2. Plan and start sprint\n/sprint plan AUTH-1 AUTH-2\n/sprint start\n\n# 3. Monitor TDD progress\n/tdd overview\n# Shows: AUTH-1 in DESIGN phase, AUTH-2 in DESIGN phase\n\n# 4. Check specific story progress\n/tdd status AUTH-1\n# Shows: \"AUTH-1 in TEST_RED phase - 12 failing tests written\"\n\n# 5. Review TDD cycle if needed\n/tdd review_cycle AUTH-1\n\n# 6. Monitor sprint completion\n/sprint status\n# Shows overall sprint progress with TDD cycle status\n</code></pre>"},{"location":"getting-started/quick-start/#next-steps","title":"Next Steps","text":"<ul> <li>Read the TDD Workflow Guide for complete TDD implementation</li> <li>Read the User Guide for complete command reference</li> <li>Configure Projects for multi-project setups</li> <li>Explore Workflows for common usage patterns</li> </ul>"},{"location":"getting-started/quick-start/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/quick-start/#common-issues","title":"Common Issues","text":"<p>Bot doesn't respond to commands: - Verify <code>DISCORD_BOT_TOKEN</code> is set correctly - Check bot permissions in Discord server - Ensure bot is invited with appropriate scopes</p> <p>Import errors: - Run <code>make install</code> to ensure all dependencies are installed - Check Python version is 3.8+</p> <p>Tests failing: - Some tests require Discord token for integration tests - Use <code>make test-unit</code> to run only unit tests</p>"},{"location":"getting-started/quick-start/#getting-help","title":"Getting Help","text":"<ul> <li>Check the <code>/state</code> command in Discord to see system status</li> <li>Review logs for error messages</li> <li>See Contributing Guide for support options</li> </ul> <p>Success! Your AI Agent TDD-Scrum Workflow system is now running. Start with <code>/epic \"Your first project\"</code> in Discord.</p>"},{"location":"user-guide/cli-reference/","title":"CLI Reference Manual","text":"<p>Complete command-line interface reference for the AI Agent TDD-Scrum workflow system, covering all scripts, tools, and operational commands.</p>"},{"location":"user-guide/cli-reference/#overview","title":"Overview","text":"<p>The system provides several CLI entry points for different operational modes:</p> <ul> <li><code>scripts/orchestrator.py</code> - Single-project orchestrator</li> <li><code>scripts/multi_project_orchestrator.py</code> - Multi-project management</li> <li><code>lib/discord_bot.py</code> - Discord bot interface</li> <li><code>visualizer/app.py</code> - Real-time state visualizer</li> <li>Management scripts - Various operational tools</li> </ul>"},{"location":"user-guide/cli-reference/#core-cli-commands","title":"Core CLI Commands","text":""},{"location":"user-guide/cli-reference/#primary-orchestrator","title":"Primary Orchestrator","text":""},{"location":"user-guide/cli-reference/#scriptsorchestratorpy","title":"<code>scripts/orchestrator.py</code>","text":"<p>Single-project orchestration with comprehensive options.</p> <pre><code>python scripts/orchestrator.py [OPTIONS]\n</code></pre> <p>Options: <pre><code>--config, -c FILE           Configuration file path [default: config.yml]\n--project-path, -p PATH     Project directory path [required]\n--mode, -m MODE            Orchestration mode [blocking|partial|autonomous]\n--verbose, -v              Enable verbose logging\n--debug, -d                Enable debug mode with detailed output\n--dry-run                  Simulate operations without making changes\n--log-file FILE            Log file path [default: logs/orchestrator.log]\n--log-level LEVEL          Logging level [DEBUG|INFO|WARNING|ERROR]\n--no-discord               Run without Discord integration\n--health-check             Run system health check and exit\n--validate-config          Validate configuration and exit\n--setup                    Initialize project structure\n--reset                    Reset project state (use with caution)\n</code></pre></p> <p>Examples: <pre><code># Basic usage\npython scripts/orchestrator.py --project-path /home/user/my-project\n\n# Development mode with verbose logging\npython scripts/orchestrator.py -p /path/to/project -v --debug\n\n# Production mode with custom config\npython scripts/orchestrator.py -c production.yml -m autonomous -p /opt/projects/app\n\n# Health check only\npython scripts/orchestrator.py --health-check\n\n# Setup new project\npython scripts/orchestrator.py --setup -p /new/project/path\n</code></pre></p>"},{"location":"user-guide/cli-reference/#multi-project-orchestrator","title":"Multi-Project Orchestrator","text":""},{"location":"user-guide/cli-reference/#scriptsmulti_project_orchestratorpy","title":"<code>scripts/multi_project_orchestrator.py</code>","text":"<p>Advanced multi-project management with enterprise features.</p> <pre><code>python scripts/multi_project_orchestrator.py [OPTIONS]\n</code></pre> <p>Options: <pre><code>--config, -c FILE           Multi-project configuration file\n--list-projects, -l         List all configured projects\n--project PROJECT           Target specific project for operations\n--start-all                 Start orchestration for all projects\n--stop-all                  Stop all active orchestrators\n--status                    Show status of all projects\n--logs PROJECT              Show logs for specific project\n--monitor                   Real-time monitoring mode\n--health-check              Comprehensive system health check\n--performance-test          Run performance benchmarks\n--backup                    Create backup of all project states\n--restore BACKUP_PATH       Restore from backup\n--cleanup                   Clean up old logs and temporary files\n--export-metrics FILE       Export performance metrics to file\n--import-config FILE        Import project configuration\n--validate                  Validate all project configurations\n</code></pre></p> <p>Examples: <pre><code># List all projects\npython scripts/multi_project_orchestrator.py --list-projects\n\n# Start specific project\npython scripts/multi_project_orchestrator.py --project web-app\n\n# Monitor all projects\npython scripts/multi_project_orchestrator.py --monitor\n\n# Health check with detailed output\npython scripts/multi_project_orchestrator.py --health-check --verbose\n\n# Performance testing\npython scripts/multi_project_orchestrator.py --performance-test\n\n# Backup and restore\npython scripts/multi_project_orchestrator.py --backup\npython scripts/multi_project_orchestrator.py --restore backups/2024-01-15_full.tar.gz\n</code></pre></p>"},{"location":"user-guide/cli-reference/#discord-bot-interface","title":"Discord Bot Interface","text":""},{"location":"user-guide/cli-reference/#libdiscord_botpy","title":"<code>lib/discord_bot.py</code>","text":"<p>Discord bot for Human-In-The-Loop control with advanced features.</p> <pre><code>python lib/discord_bot.py [OPTIONS]\n</code></pre> <p>Options: <pre><code>--token TOKEN               Discord bot token (or use DISCORD_BOT_TOKEN env)\n--config FILE               Bot configuration file\n--orchestrator-config FILE  Orchestrator configuration file\n--channel-prefix PREFIX     Channel naming prefix [default: hostname-]\n--command-prefix PREFIX     Command prefix [default: /]\n--sync-commands             Sync slash commands on startup\n--guild-only GUILD_ID       Restrict to specific guild (for testing)\n--status-message MESSAGE    Custom bot status message\n--activity-type TYPE        Activity type [playing|watching|listening]\n--no-auto-channels          Disable automatic channel creation\n--max-projects NUMBER       Maximum concurrent projects [default: 10]\n--debug-mode                Enable debug features and logging\n--metrics-port PORT         Metrics server port [default: 8000]\n</code></pre></p> <p>Examples: <pre><code># Basic bot startup\npython lib/discord_bot.py\n\n# Development mode with guild restriction\npython lib/discord_bot.py --guild-only 123456789 --debug-mode\n\n# Production with custom status\npython lib/discord_bot.py --status-message \"Managing 5 projects\" --activity-type watching\n\n# Sync commands for new bot\npython lib/discord_bot.py --sync-commands\n</code></pre></p>"},{"location":"user-guide/cli-reference/#state-visualizer","title":"State Visualizer","text":""},{"location":"user-guide/cli-reference/#visualizerapppy","title":"<code>visualizer/app.py</code>","text":"<p>Real-time workflow visualization with WebSocket interface.</p> <pre><code>cd visualizer &amp;&amp; python app.py [OPTIONS]\n</code></pre> <p>Options: <pre><code>--host HOST                 Host to bind to [default: localhost]\n--port PORT                 Port to bind to [default: 5000]\n--debug                     Enable Flask debug mode\n--websocket-host HOST       WebSocket server host [default: localhost]\n--websocket-port PORT       WebSocket server port [default: 8080]\n--auto-connect              Auto-connect to orchestrator on startup\n--theme THEME               UI theme [light|dark|auto]\n--update-interval MS        Update interval in milliseconds [default: 1000]\n--max-history NUMBER        Max state history to display [default: 100]\n</code></pre></p> <p>Examples: <pre><code># Basic visualizer\ncd visualizer &amp;&amp; python app.py\n\n# Production with external access\ncd visualizer &amp;&amp; python app.py --host 0.0.0.0 --port 8080\n\n# Development with auto-refresh\ncd visualizer &amp;&amp; python app.py --debug --update-interval 500\n</code></pre></p>"},{"location":"user-guide/cli-reference/#management-scripts","title":"Management Scripts","text":""},{"location":"user-guide/cli-reference/#database-operations","title":"Database Operations","text":""},{"location":"user-guide/cli-reference/#scriptsdb_managerpy","title":"<code>scripts/db_manager.py</code>","text":"<p>Database management and maintenance operations.</p> <pre><code>python scripts/db_manager.py [COMMAND] [OPTIONS]\n</code></pre> <p>Commands: <pre><code>init                        Initialize database schema\nmigrate                     Run database migrations\nbackup [--output FILE]     Create database backup\nrestore --input FILE       Restore from backup\nvacuum                      Vacuum and optimize database\nrepair                      Repair corrupted data\nexport --format FORMAT     Export data [json|csv|yaml]\nimport --file FILE          Import data from file\nstats                       Show database statistics\nclean --older-than DAYS     Clean old records\n</code></pre></p> <p>Examples: <pre><code># Initialize new database\npython scripts/db_manager.py init\n\n# Create backup\npython scripts/db_manager.py backup --output backups/db_$(date +%Y%m%d).sql\n\n# Clean old data\npython scripts/db_manager.py clean --older-than 30\n\n# Export metrics\npython scripts/db_manager.py export --format json &gt; metrics.json\n</code></pre></p>"},{"location":"user-guide/cli-reference/#configuration-management","title":"Configuration Management","text":""},{"location":"user-guide/cli-reference/#scriptsconfig_managerpy","title":"<code>scripts/config_manager.py</code>","text":"<p>Configuration file management and validation.</p> <pre><code>python scripts/config_manager.py [COMMAND] [OPTIONS]\n</code></pre> <p>Commands: <pre><code>validate FILE               Validate configuration file\ngenerate-template TYPE      Generate configuration template\nmerge FILE1 FILE2          Merge configuration files\ndiff FILE1 FILE2           Compare configuration files\nencrypt FILE                Encrypt sensitive configuration\ndecrypt FILE                Decrypt configuration file\nlint FILE                   Check configuration best practices\nconvert --from FORMAT       Convert between formats\n</code></pre></p> <p>Examples: <pre><code># Validate configuration\npython scripts/config_manager.py validate config/production.yml\n\n# Generate template\npython scripts/config_manager.py generate-template multi-project &gt; new-config.yml\n\n# Encrypt secrets\npython scripts/config_manager.py encrypt config/secrets.yml\n\n# Compare configs\npython scripts/config_manager.py diff config/dev.yml config/prod.yml\n</code></pre></p>"},{"location":"user-guide/cli-reference/#log-management","title":"Log Management","text":""},{"location":"user-guide/cli-reference/#scriptslog_managerpy","title":"<code>scripts/log_manager.py</code>","text":"<p>Log file management and analysis tools.</p> <pre><code>python scripts/log_manager.py [COMMAND] [OPTIONS]\n</code></pre> <p>Commands: <pre><code>analyze [FILE]              Analyze log files for patterns\nrotate                      Rotate log files\ncompress --older-than DAYS  Compress old log files\nsearch PATTERN              Search across all log files\ntail --follow               Follow live log output\nerrors --since TIME         Show errors since timestamp\nmetrics --interval MINUTES  Extract metrics from logs\nreport --format FORMAT      Generate log report\n</code></pre></p> <p>Examples: <pre><code># Analyze recent logs\npython scripts/log_manager.py analyze logs/orchestrator.log\n\n# Search for errors\npython scripts/log_manager.py search \"ERROR|CRITICAL\"\n\n# Follow live logs\npython scripts/log_manager.py tail --follow\n\n# Generate daily report\npython scripts/log_manager.py report --format html &gt; daily_report.html\n</code></pre></p>"},{"location":"user-guide/cli-reference/#testing-utilities","title":"Testing Utilities","text":""},{"location":"user-guide/cli-reference/#scriptstest_runnerpy","title":"<code>scripts/test_runner.py</code>","text":"<p>Advanced test execution and management.</p> <pre><code>python scripts/test_runner.py [COMMAND] [OPTIONS]\n</code></pre> <p>Commands: <pre><code>run [PATTERN]               Run tests matching pattern\ncoverage                    Run tests with coverage\nperformance                 Run performance tests\nintegration                 Run integration tests only\nsecurity                    Run security tests\nregression                  Run regression test suite\nsmoke                       Run smoke tests\nreport --format FORMAT     Generate test report\n</code></pre></p> <p>Options: <pre><code>--parallel WORKERS          Number of parallel workers\n--verbose, -v               Verbose output\n--fail-fast                 Stop on first failure\n--retry-failures            Retry failed tests\n--timeout SECONDS           Test timeout\n--markers MARKERS           Run tests with specific markers\n--output-file FILE          Output results to file\n--junit-xml FILE            Generate JUnit XML report\n</code></pre></p> <p>Examples: <pre><code># Run all tests with coverage\npython scripts/test_runner.py coverage --parallel 4\n\n# Run specific test pattern\npython scripts/test_runner.py run \"test_tdd_*\" --verbose\n\n# Performance testing\npython scripts/test_runner.py performance --timeout 300\n\n# Generate comprehensive report\npython scripts/test_runner.py report --format html --output-file test_report.html\n</code></pre></p>"},{"location":"user-guide/cli-reference/#tdd-specific-cli-tools","title":"TDD-Specific CLI Tools","text":""},{"location":"user-guide/cli-reference/#tdd-cycle-manager","title":"TDD Cycle Manager","text":""},{"location":"user-guide/cli-reference/#scriptstdd_managerpy","title":"<code>scripts/tdd_manager.py</code>","text":"<p>TDD cycle management and analysis tools.</p> <pre><code>python scripts/tdd_manager.py [COMMAND] [OPTIONS]\n</code></pre> <p>Commands: <pre><code>list-cycles [PROJECT]       List active TDD cycles\nstatus CYCLE_ID             Get detailed cycle status\nstart STORY_ID              Start new TDD cycle\npause CYCLE_ID              Pause TDD cycle\nresume CYCLE_ID             Resume paused cycle\nabort CYCLE_ID              Abort TDD cycle\nreset CYCLE_ID --to-state   Reset cycle to specific state\nvalidate CYCLE_ID           Validate cycle integrity\nmetrics [--period DAYS]     Show TDD metrics\nexport CYCLE_ID             Export cycle data\nimport FILE                 Import cycle data\n</code></pre></p> <p>Examples: <pre><code># List all active cycles\npython scripts/tdd_manager.py list-cycles\n\n# Get detailed status\npython scripts/tdd_manager.py status tdd-cycle-abc123\n\n# Start new cycle\npython scripts/tdd_manager.py start AUTH-001\n\n# Get weekly metrics\npython scripts/tdd_manager.py metrics --period 7\n</code></pre></p>"},{"location":"user-guide/cli-reference/#test-preservation-manager","title":"Test Preservation Manager","text":""},{"location":"user-guide/cli-reference/#scriptstest_preservationpy","title":"<code>scripts/test_preservation.py</code>","text":"<p>Test file preservation and integration management.</p> <pre><code>python scripts/test_preservation.py [COMMAND] [OPTIONS]\n</code></pre> <p>Commands: <pre><code>preserve STORY_ID           Preserve test files for story\nintegrate STORY_ID          Integrate tests into main suite\nvalidate-structure          Validate test directory structure\ncleanup --older-than DAYS   Clean up old preserved tests\nmigrate-tests SOURCE DEST   Migrate test files\nverify-integrity            Verify test file integrity\nreport                      Generate preservation report\n</code></pre></p> <p>Examples: <pre><code># Preserve tests for completed story\npython scripts/test_preservation.py preserve AUTH-001\n\n# Integrate tests into main suite\npython scripts/test_preservation.py integrate AUTH-001\n\n# Clean up old test files\npython scripts/test_preservation.py cleanup --older-than 30\n</code></pre></p>"},{"location":"user-guide/cli-reference/#devops-and-operations","title":"DevOps and Operations","text":""},{"location":"user-guide/cli-reference/#deployment-scripts","title":"Deployment Scripts","text":""},{"location":"user-guide/cli-reference/#scriptsdeploypy","title":"<code>scripts/deploy.py</code>","text":"<p>Deployment automation and management.</p> <pre><code>python scripts/deploy.py [ENVIRONMENT] [OPTIONS]\n</code></pre> <p>Environments: - <code>development</code> - Local development deployment - <code>staging</code> - Staging environment deployment - <code>production</code> - Production deployment</p> <p>Options: <pre><code>--config FILE               Deployment configuration\n--version VERSION           Specific version to deploy\n--rollback                  Rollback to previous version\n--health-check              Run health check after deployment\n--skip-tests                Skip test execution\n--force                     Force deployment (bypass checks)\n--dry-run                   Show what would be deployed\n--notify WEBHOOK            Notification webhook URL\n</code></pre></p> <p>Examples: <pre><code># Deploy to staging\npython scripts/deploy.py staging --health-check\n\n# Production deployment with version\npython scripts/deploy.py production --version v1.2.3 --notify $SLACK_WEBHOOK\n\n# Rollback production\npython scripts/deploy.py production --rollback\n\n# Dry run for production\npython scripts/deploy.py production --dry-run\n</code></pre></p>"},{"location":"user-guide/cli-reference/#monitoring-scripts","title":"Monitoring Scripts","text":""},{"location":"user-guide/cli-reference/#scriptsmonitorpy","title":"<code>scripts/monitor.py</code>","text":"<p>System monitoring and alerting.</p> <pre><code>python scripts/monitor.py [COMMAND] [OPTIONS]\n</code></pre> <p>Commands: <pre><code>start                       Start monitoring daemon\nstop                        Stop monitoring daemon\nstatus                      Show monitoring status\ncheck-health                Run health checks\nalert-test                  Test alerting configuration\nmetrics                     Display current metrics\ndashboard                   Launch monitoring dashboard\n</code></pre></p> <p>Options: <pre><code>--interval SECONDS          Monitoring interval [default: 60]\n--alert-threshold VALUE     Alert threshold configuration\n--webhook URL               Webhook for notifications\n--dashboard-port PORT       Dashboard port [default: 8080]\n--config FILE               Monitoring configuration\n</code></pre></p> <p>Examples: <pre><code># Start monitoring with 30-second intervals\npython scripts/monitor.py start --interval 30\n\n# Test alert system\npython scripts/monitor.py alert-test --webhook $ALERT_WEBHOOK\n\n# Launch dashboard\npython scripts/monitor.py dashboard --dashboard-port 9090\n</code></pre></p>"},{"location":"user-guide/cli-reference/#utility-commands","title":"Utility Commands","text":""},{"location":"user-guide/cli-reference/#data-management","title":"Data Management","text":""},{"location":"user-guide/cli-reference/#scriptsdata_utilspy","title":"<code>scripts/data_utils.py</code>","text":"<p>Data manipulation and analysis utilities.</p> <pre><code>python scripts/data_utils.py [COMMAND] [OPTIONS]\n</code></pre> <p>Commands: <pre><code>export --format FORMAT     Export system data\nimport --file FILE          Import data from file\nmigrate --from VERSION     Migrate data format\nvalidate                    Validate data integrity\ncompress                    Compress data files\ndecompress FILE             Decompress data files\nanalyze                     Analyze data patterns\nreport                      Generate data report\n</code></pre></p>"},{"location":"user-guide/cli-reference/#system-maintenance","title":"System Maintenance","text":""},{"location":"user-guide/cli-reference/#scriptsmaintenancepy","title":"<code>scripts/maintenance.py</code>","text":"<p>System maintenance and cleanup operations.</p> <pre><code>python scripts/maintenance.py [COMMAND] [OPTIONS]\n</code></pre> <p>Commands: <pre><code>cleanup                     General system cleanup\nvacuum                      Database vacuum and optimization\nrotate-logs                 Rotate log files\ncompress-backups            Compress old backups\nupdate-dependencies         Update system dependencies\nhealth-check                Comprehensive health check\nrepair                      Repair system issues\noptimize                    Optimize system performance\n</code></pre></p> <p>Examples: <pre><code># Daily maintenance\npython scripts/maintenance.py cleanup\npython scripts/maintenance.py rotate-logs\npython scripts/maintenance.py vacuum\n\n# Weekly maintenance\npython scripts/maintenance.py compress-backups\npython scripts/maintenance.py optimize\n\n# Health check\npython scripts/maintenance.py health-check --verbose\n</code></pre></p>"},{"location":"user-guide/cli-reference/#environment-variables","title":"Environment Variables","text":""},{"location":"user-guide/cli-reference/#core-configuration","title":"Core Configuration","text":"<pre><code># Required\nexport DISCORD_BOT_TOKEN=\"your_discord_bot_token\"\n\n# Optional but recommended\nexport ANTHROPIC_API_KEY=\"your_anthropic_api_key\"\nexport GITHUB_TOKEN=\"your_github_token\"\n\n# System configuration\nexport HOSTNAME=\"your_hostname\"\nexport LOG_LEVEL=\"INFO\"                    # DEBUG|INFO|WARNING|ERROR\nexport ORCHESTRATOR_MODE=\"blocking\"       # blocking|partial|autonomous\nexport NO_AGENT_MODE=\"false\"             # true for testing with mock agents\n\n# Performance tuning\nexport MAX_CONCURRENT_PROJECTS=\"5\"\nexport AGENT_TIMEOUT_MINUTES=\"30\"\nexport STATE_SAVE_INTERVAL=\"60\"\n\n# Storage configuration\nexport DATA_DIRECTORY=\"/opt/agent-workflow/data\"\nexport LOG_DIRECTORY=\"/opt/agent-workflow/logs\"\nexport BACKUP_DIRECTORY=\"/opt/agent-workflow/backups\"\n\n# Monitoring\nexport METRICS_ENABLED=\"true\"\nexport METRICS_PORT=\"8000\"\nexport HEALTH_CHECK_INTERVAL=\"300\"\n\n# Security\nexport ENCRYPTION_KEY=\"your_encryption_key\"\nexport API_RATE_LIMIT=\"100\"\nexport ALLOWED_HOSTS=\"localhost,your-domain.com\"\n</code></pre>"},{"location":"user-guide/cli-reference/#tdd-specific-variables","title":"TDD-Specific Variables","text":"<pre><code># TDD configuration\nexport TDD_ENABLED=\"true\"\nexport TDD_AUTO_START=\"true\"\nexport TDD_PRESERVE_TESTS=\"true\"\nexport TDD_PARALLEL_EXECUTION=\"true\"\n\n# Test execution\nexport TEST_RUNNER=\"pytest\"\nexport TEST_PARALLEL_JOBS=\"4\"\nexport TEST_TIMEOUT_SECONDS=\"300\"\nexport COVERAGE_THRESHOLD=\"90\"\n\n# Test preservation\nexport TEST_PRESERVATION_DIR=\"tests/tdd\"\nexport TEST_INTEGRATION_DIR=\"tests/unit\"\nexport TEST_BACKUP_ENABLED=\"true\"\n</code></pre>"},{"location":"user-guide/cli-reference/#configuration-file-locations","title":"Configuration File Locations","text":""},{"location":"user-guide/cli-reference/#standard-locations","title":"Standard Locations","text":"<pre><code># Main configuration\n./config.yml                          # Default configuration\n./config/production.yml               # Production configuration\n./config/development.yml              # Development configuration\n\n# Project-specific\n./.orch-state/config.json             # Project runtime configuration\n./.orch-state/status.json             # Project state\n\n# User configuration\n~/.agent-workflow/config.yml          # User global configuration\n~/.agent-workflow/preferences.yml     # User preferences\n\n# Environment-specific\n/etc/agent-workflow/config.yml        # System-wide configuration\n/opt/agent-workflow/config.yml        # Installation configuration\n</code></pre>"},{"location":"user-guide/cli-reference/#exit-codes","title":"Exit Codes","text":"<p>The CLI tools use standard exit codes:</p> <pre><code>0   Success\n1   General error\n2   Configuration error\n3   Permission error\n4   Network error\n5   API error\n10  Validation error\n20  Agent execution error\n30  TDD cycle error\n50  System resource error\n99  Unknown error\n</code></pre>"},{"location":"user-guide/cli-reference/#troubleshooting-cli-issues","title":"Troubleshooting CLI Issues","text":""},{"location":"user-guide/cli-reference/#common-problems","title":"Common Problems","text":""},{"location":"user-guide/cli-reference/#command-not-found","title":"Command Not Found","text":"<pre><code># Check Python path\npython -c \"import sys; print(sys.path)\"\n\n# Verify script permissions\nls -la scripts/orchestrator.py\n\n# Check virtual environment\nwhich python\necho $VIRTUAL_ENV\n</code></pre>"},{"location":"user-guide/cli-reference/#permission-errors","title":"Permission Errors","text":"<pre><code># Fix script permissions\nchmod +x scripts/*.py\n\n# Check file ownership\nls -la config/\nsudo chown -R $USER:$USER .\n</code></pre>"},{"location":"user-guide/cli-reference/#configuration-errors","title":"Configuration Errors","text":"<pre><code># Validate configuration\npython scripts/config_manager.py validate config.yml\n\n# Check environment variables\nenv | grep -E \"(DISCORD|ANTHROPIC|GITHUB)\"\n\n# Test basic imports\npython -c \"import lib.discord_bot; print('OK')\"\n</code></pre>"},{"location":"user-guide/cli-reference/#performance-issues","title":"Performance Issues","text":"<pre><code># Check system resources\ntop -p $(pgrep -f orchestrator)\ndf -h\nfree -m\n\n# Enable debug logging\nexport LOG_LEVEL=DEBUG\npython scripts/orchestrator.py --debug\n</code></pre> <p>This comprehensive CLI reference provides complete documentation for all command-line interfaces and operational tools in the AI Agent TDD-Scrum workflow system.</p>"},{"location":"user-guide/faq/","title":"Frequently Asked Questions","text":"<p>Common questions about the AI Agent TDD-Scrum workflow system.</p>"},{"location":"user-guide/faq/#general-questions","title":"General Questions","text":""},{"location":"user-guide/faq/#what-is-the-ai-agent-tdd-scrum-workflow-system","title":"What is the AI Agent TDD-Scrum workflow system?","text":"<p>It's a Human-In-The-Loop (HITL) orchestration framework that coordinates multiple specialized AI agents through Discord. The system follows a research-mode Scrum methodology optimized for solo engineers working with AI assistance.</p>"},{"location":"user-guide/faq/#do-i-need-ai-integration-to-use-the-system","title":"Do I need AI integration to use the system?","text":"<p>No, the system works without AI integration for testing and learning the workflow. However, you'll need AI capabilities (like Claude Code) for the agents to actually perform development tasks.</p>"},{"location":"user-guide/faq/#can-i-use-this-with-multiple-projects","title":"Can I use this with multiple projects?","text":"<p>Yes, the orchestrator supports multi-project management. Each project gets its own Discord channel and independent state machine.</p>"},{"location":"user-guide/faq/#setup-and-installation","title":"Setup and Installation","text":""},{"location":"user-guide/faq/#what-are-the-minimum-requirements","title":"What are the minimum requirements?","text":"<ul> <li>Python 3.8 or higher</li> <li>Discord bot token</li> <li>Git for cloning the repository</li> <li>Optional: Claude Code or other AI integration for full functionality</li> </ul>"},{"location":"user-guide/faq/#how-do-i-get-a-discord-bot-token","title":"How do I get a Discord bot token?","text":"<ol> <li>Go to the Discord Developer Portal</li> <li>Create a new application</li> <li>Go to the \"Bot\" section</li> <li>Click \"Reset Token\" and copy the token</li> <li>Invite the bot to your server with appropriate permissions</li> </ol>"},{"location":"user-guide/faq/#can-i-run-this-on-windowsmaclinux","title":"Can I run this on Windows/Mac/Linux?","text":"<p>Yes, the system is cross-platform and works on all major operating systems. It's been tested on Windows (including WSL), macOS, and various Linux distributions.</p>"},{"location":"user-guide/faq/#workflow-and-commands","title":"Workflow and Commands","text":""},{"location":"user-guide/faq/#whats-the-difference-between-an-epic-and-a-story","title":"What's the difference between an epic and a story?","text":"<ul> <li>Epic: A high-level initiative or feature area (e.g., \"Build authentication system\")</li> <li>Story: A specific, actionable task within an epic (e.g., \"Create user login form\")</li> </ul>"},{"location":"user-guide/faq/#why-cant-i-run-certain-commands","title":"Why can't I run certain commands?","text":"<p>The system uses a finite state machine that enforces proper workflow sequences. Use the <code>/state</code> command to see which commands are currently available.</p>"},{"location":"user-guide/faq/#how-do-i-know-what-state-im-in","title":"How do I know what state I'm in?","text":"<p>Use the <code>/state</code> command anytime to see: - Current state (e.g., SPRINT_ACTIVE) - Allowed commands for that state - Visual state diagram - Command matrix</p>"},{"location":"user-guide/faq/#can-i-pause-a-sprint-mid-execution","title":"Can I pause a sprint mid-execution?","text":"<p>Yes, use <code>/sprint pause</code> to halt agent work. Resume with <code>/sprint resume</code> when ready to continue.</p>"},{"location":"user-guide/faq/#agents-and-ai-integration","title":"Agents and AI Integration","text":""},{"location":"user-guide/faq/#what-do-the-different-agents-do","title":"What do the different agents do?","text":"<ul> <li>DesignAgent: Creates architecture, designs components, writes specifications</li> <li>CodeAgent: Implements features, fixes bugs, refactors code</li> <li>QAAgent: Creates tests, validates quality, analyzes coverage</li> <li>DataAgent: Analyzes data, creates reports, generates visualizations</li> </ul>"},{"location":"user-guide/faq/#how-do-agents-know-what-to-work-on","title":"How do agents know what to work on?","text":"<p>Agents receive tasks from the orchestrator based on: - Stories in the current sprint - Their specialized capabilities - Human-provided context and requirements</p>"},{"location":"user-guide/faq/#can-i-give-direct-instructions-to-agents","title":"Can I give direct instructions to agents?","text":"<p>Yes, use commands like: - <code>/suggest_fix \"description\"</code> to guide a stuck agent - <code>/request_changes \"description\"</code> to modify agent output - <code>/feedback \"description\"</code> to provide general improvement notes</p>"},{"location":"user-guide/faq/#what-happens-if-an-agent-gets-stuck","title":"What happens if an agent gets stuck?","text":"<p>The system has escalation policies: - After 3 failed attempts, tasks escalate to human review - You can use <code>/suggest_fix</code> to provide guidance - Use <code>/skip_task</code> to abandon problematic tasks</p>"},{"location":"user-guide/faq/#security-and-permissions","title":"Security and Permissions","text":""},{"location":"user-guide/faq/#are-there-security-restrictions-on-agents","title":"Are there security restrictions on agents?","text":"<p>Yes, each agent type has specific tool access controls: - DesignAgent: Read-only access, can create documentation - CodeAgent: Can edit code and commit changes - QAAgent: Can run tests and quality tools only - DataAgent: Can access data files and create visualizations</p>"},{"location":"user-guide/faq/#can-agents-modify-any-file-in-my-project","title":"Can agents modify any file in my project?","text":"<p>Agents respect security boundaries and can only access files within their permitted scope. The system uses principle of least privilege.</p>"},{"location":"user-guide/faq/#is-my-code-sent-to-external-ai-services","title":"Is my code sent to external AI services?","text":"<p>This depends on your AI integration choice. The framework itself doesn't send code externally, but integrated AI services (like Claude Code) may process code according to their terms of service.</p>"},{"location":"user-guide/faq/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/faq/#the-bot-doesnt-respond-to-my-commands","title":"The bot doesn't respond to my commands","text":"<p>Check these common issues: 1. Verify the Discord bot token is set correctly 2. Ensure the bot has proper permissions in your server 3. Make sure you're using slash commands (type <code>/</code> to see available commands)</p>"},{"location":"user-guide/faq/#my-tests-are-failing","title":"My tests are failing","text":"<p>Try these solutions: 1. Run unit tests only: <code>pytest tests/unit/</code> 2. Ensure all dependencies are installed: <code>pip install -r requirements.txt</code> 3. Check that environment variables are set properly</p>"},{"location":"user-guide/faq/#the-system-seems-slow","title":"The system seems slow","text":"<p>Performance can be affected by: - Network connectivity to Discord and AI services - Size and complexity of tasks - System resources (CPU, memory) - Number of concurrent projects</p>"},{"location":"user-guide/faq/#advanced-usage","title":"Advanced Usage","text":""},{"location":"user-guide/faq/#can-i-customize-the-workflow-states","title":"Can I customize the workflow states?","text":"<p>The state machine is designed to be extensible, but modifications require code changes. The current states cover most common development workflows.</p>"},{"location":"user-guide/faq/#how-do-i-integrate-with-other-tools","title":"How do I integrate with other tools?","text":"<p>The system is designed to be modular. You can: - Add new agent types - Integrate additional AI services - Connect to different project management tools - Extend the Discord bot with custom commands</p>"},{"location":"user-guide/faq/#can-i-run-this-in-production","title":"Can I run this in production?","text":"<p>The system is suitable for development workflows. For production use, consider: - Proper error handling and monitoring - Backup and recovery procedures - Security review of AI integrations - Performance optimization for your scale</p>"},{"location":"user-guide/faq/#how-do-i-contribute-to-the-project","title":"How do I contribute to the project?","text":"<ol> <li>Fork the repository</li> <li>Create a feature branch</li> <li>Implement changes with tests</li> <li>Submit a pull request</li> <li>Follow the contributing guidelines in the repository</li> </ol>"},{"location":"user-guide/faq/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/faq/#how-should-i-structure-my-epics-and-stories","title":"How should I structure my epics and stories?","text":"<ul> <li>Keep epics focused on specific feature areas</li> <li>Write stories as user-focused requirements</li> <li>Break large stories into smaller, manageable tasks</li> <li>Prioritize stories based on business value</li> </ul>"},{"location":"user-guide/faq/#whats-the-optimal-sprint-length","title":"What's the optimal sprint length?","text":"<p>For solo development with AI assistance: - Start with 1-2 week sprints - Adjust based on task complexity and AI performance - Consider shorter sprints for learning and experimentation</p>"},{"location":"user-guide/faq/#how-do-i-get-the-best-results-from-ai-agents","title":"How do I get the best results from AI agents?","text":"<ul> <li>Provide clear, specific requirements</li> <li>Include context about existing code and patterns</li> <li>Use descriptive names for features and stories</li> <li>Give feedback regularly to improve agent performance</li> </ul>"},{"location":"user-guide/faq/#tdd-workflow-questions","title":"TDD Workflow Questions","text":""},{"location":"user-guide/faq/#what-is-the-tdd-workflow-in-the-ai-agent-system","title":"What is the TDD workflow in the AI Agent system?","text":"<p>The system implements a parallel TDD state machine that runs alongside the main Scrum workflow. Each story in an active sprint follows a strict Test-Driven Development cycle: DESIGN \u2192 TEST_RED \u2192 CODE_GREEN \u2192 REFACTOR \u2192 COMMIT.</p>"},{"location":"user-guide/faq/#how-does-tdd-work-with-multiple-stories","title":"How does TDD work with multiple stories?","text":"<p>Multiple stories can run TDD cycles simultaneously. Each story has its own independent TDD state machine, allowing parallel development while maintaining TDD discipline for each feature.</p>"},{"location":"user-guide/faq/#what-are-the-tdd-states-and-what-happens-in-each","title":"What are the TDD states and what happens in each?","text":"<ul> <li>DESIGN: Design Agent creates technical specifications and acceptance criteria</li> <li>TEST_RED: QA Agent writes comprehensive failing tests based on specifications  </li> <li>CODE_GREEN: Code Agent implements minimal code to make tests pass</li> <li>REFACTOR: Code Agent improves code quality while keeping tests green</li> <li>COMMIT: Final commit with complete feature and clean code</li> </ul>"},{"location":"user-guide/faq/#how-do-i-monitor-tdd-progress","title":"How do I monitor TDD progress?","text":"<p>Use these commands: - <code>/tdd overview</code> - See status of all active TDD cycles - <code>/tdd status &lt;STORY_ID&gt;</code> - Get detailed information for a specific story - <code>/tdd metrics</code> - View cycle times, success rates, and quality metrics</p>"},{"location":"user-guide/faq/#can-i-control-the-tdd-cycle-manually","title":"Can I control the TDD cycle manually?","text":"<p>Yes, you have several control options: - <code>/tdd pause &lt;STORY_ID&gt;</code> - Temporarily halt a TDD cycle - <code>/tdd resume &lt;STORY_ID&gt;</code> - Resume a paused cycle - <code>/tdd skip_phase &lt;STORY_ID&gt;</code> - Skip current phase (requires approval) - <code>/tdd review_cycle &lt;STORY_ID&gt;</code> - Request human review at any phase</p>"},{"location":"user-guide/faq/#what-happens-if-a-tdd-cycle-gets-stuck","title":"What happens if a TDD cycle gets stuck?","text":"<p>The system has several recovery mechanisms: - After failed attempts, tasks escalate to human review - Use <code>/suggest_fix \"description\"</code> to provide guidance to agents - Use <code>/tdd skip_phase</code> to move past problematic phases - Human approval gates allow intervention at any point</p>"},{"location":"user-guide/faq/#how-do-i-ensure-test-quality-in-tdd-cycles","title":"How do I ensure test quality in TDD cycles?","text":"<p>The system enforces several quality gates: - Tests must fail initially (RED state) before implementation - All tests must pass before refactoring (GREEN requirement) - Code coverage thresholds are maintained - CI integration validates all changes</p>"},{"location":"user-guide/faq/#can-i-run-traditional-sprints-without-tdd","title":"Can I run traditional sprints without TDD?","text":"<p>Yes, TDD is optional. Stories without TDD requirements follow the traditional agent workflow. You can mix TDD and non-TDD stories within the same sprint.</p>"},{"location":"user-guide/faq/#how-does-tdd-integrate-with-cicd","title":"How does TDD integrate with CI/CD?","text":"<p>TDD cycles integrate with CI/CD pipelines: - Tests are committed in RED state for continuous validation - Implementation commits trigger CI builds - Quality gates can include external tools (SonarQube, security scans) - Failed CI runs pause TDD cycles for human intervention</p>"},{"location":"user-guide/faq/#what-metrics-does-the-tdd-system-track","title":"What metrics does the TDD system track?","text":"<p>Key metrics include: - Cycle time per TDD phase - Success rates for each state transition - Test coverage percentages - Refactor frequency and impact - CI success rates and failure patterns</p>"},{"location":"user-guide/faq/#how-do-i-troubleshoot-stuck-tdd-cycles","title":"How do I troubleshoot stuck TDD cycles?","text":"<p>Common issues and solutions:</p> <p>Cycle stuck in CODE_GREEN: - Check test failures in CI logs - Provide guidance with <code>/suggest_fix</code> - Consider <code>/tdd skip_phase</code> if persistently blocked</p> <p>Tests failing after refactor: - System automatically rolls back to last green state - Use <code>/tdd review_cycle</code> for manual intervention - Adjust refactor scope and retry</p> <p>Design phase taking too long: - Check story complexity and requirements clarity - Use <code>/tdd design_complete</code> to manually advance - Consider splitting complex stories</p>"},{"location":"user-guide/faq/#are-there-different-tdd-profiles-for-different-story-types","title":"Are there different TDD profiles for different story types?","text":"<p>Yes, you can configure TDD parameters: - Coverage thresholds per story type - Complexity limits for different components - Custom phase timeouts for API vs UI development - Different quality gates for critical vs non-critical features</p>"},{"location":"user-guide/faq/#how-do-tdd-cycles-handle-dependencies-between-stories","title":"How do TDD cycles handle dependencies between stories?","text":"<p>TDD supports story dependencies: - Stories can wait for other stories to complete specific phases - Use <code>/tdd depends &lt;STORY_A&gt; &lt;STORY_B&gt;</code> to define dependencies - Dependency chains are visualized in <code>/tdd overview</code> - Circular dependencies are detected and prevented</p>"},{"location":"user-guide/faq/#can-i-integrate-external-quality-tools-with-tdd","title":"Can I integrate external quality tools with TDD?","text":"<p>Yes, TDD cycles support external tool integration: - Security scanning during CODE_GREEN phase - Performance benchmarking during REFACTOR - Custom quality gates with <code>/tdd gate</code> commands - Manual overrides with justification tracking</p>"},{"location":"user-guide/faq/#whats-the-difference-between-tdd-commit-types","title":"What's the difference between TDD commit types?","text":"<p>TDD uses incremental commits to preserve test development: - <code>/tdd commit-tests</code> - Commits failing tests (TEST_RED \u2192 CODE_GREEN) - <code>/tdd commit-code</code> - Commits working implementation (CODE_GREEN \u2192 REFACTOR) - <code>/tdd commit-refactor</code> - Commits refactored code (REFACTOR \u2192 COMMIT) - <code>/tdd commit</code> - Final commit when satisfied with quality</p> <p>This approach ensures tests are preserved in the repository even if implementation fails, maintaining TDD audit trail.</p>"},{"location":"user-guide/hitl-commands/","title":"HITL Commands","text":"<p>Command reference for the AI Agent TDD-Scrum workflow system. These commands provide Human-In-The-Loop control over the dual state machine orchestration process with integrated TDD workflows.</p>"},{"location":"user-guide/hitl-commands/#command-quick-reference","title":"Command Quick-Reference","text":""},{"location":"user-guide/hitl-commands/#core-workflow-commands","title":"Core Workflow Commands","text":""},{"location":"user-guide/hitl-commands/#project-management","title":"Project Management","text":"<p><code>/epic \"&lt;description&gt;\"</code> Define a new high-level initiative.</p> <p><code>/approve [ID ...]</code> Approve proposed stories or epics so they can enter a sprint.</p>"},{"location":"user-guide/hitl-commands/#sprint-management","title":"Sprint Management","text":"<p><code>/sprint plan [ID ...]</code> Plan next sprint with specified story IDs.</p> <p><code>/sprint start</code> Kick off the planned sprint.</p> <p><code>/sprint status</code> Get a progress snapshot of the current sprint.</p> <p><code>/sprint pause</code> Halt agent work temporarily.</p> <p><code>/sprint resume</code> Continue paused sprint work.</p>"},{"location":"user-guide/hitl-commands/#backlog-operations","title":"Backlog Operations","text":"<p><code>/backlog view product</code> List all product backlog items.</p> <p><code>/backlog view sprint</code> List current sprint backlog items.</p> <p><code>/backlog view &lt;ITEM_ID&gt;</code> Show full details for a specific item.</p> <p><code>/backlog add_story \"&lt;description&gt;\" --feature &lt;FEATURE_ID&gt;</code> Create a new story under a feature.</p> <p><code>/backlog remove &lt;ITEM_ID&gt;</code> Delete an item from the backlog.</p> <p><code>/backlog prioritize &lt;STORY_ID&gt; &lt;top|high|med|low&gt;</code> Set priority level for a story.</p>"},{"location":"user-guide/hitl-commands/#development-control","title":"Development Control","text":"<p><code>/request_changes \"&lt;description&gt;\"</code> Request modifications on a pull request.</p> <p><code>/suggest_fix \"&lt;description&gt;\"</code> Provide hints to the Code Agent when stuck.</p> <p><code>/skip_task</code> Abandon the currently blocked task and move on.</p> <p><code>/feedback \"&lt;description&gt;\"</code> Provide improvement notes after a sprint.</p> <p><code>/state</code> Inspect current orchestrator state with interactive controls.</p>"},{"location":"user-guide/hitl-commands/#tdd-workflow-commands","title":"TDD Workflow Commands","text":"<p><code>/tdd start &lt;STORY_ID&gt;</code> Manually start TDD cycle for a specific story.</p> <p><code>/tdd status [STORY_ID]</code> Get current TDD phase and progress for one or all active stories.</p> <p><code>/tdd overview</code> Show status of all active TDD cycles with visual progress.</p> <p><code>/tdd pause &lt;STORY_ID&gt;</code> Temporarily halt TDD cycle for a story.</p> <p><code>/tdd resume &lt;STORY_ID&gt;</code> Resume paused TDD cycle.</p> <p><code>/tdd design_complete &lt;STORY_ID&gt;</code> Mark design phase complete and advance to TEST_RED.</p> <p><code>/tdd tests_ready &lt;STORY_ID&gt;</code> Confirm tests are written and failing properly.</p> <p><code>/tdd code_green &lt;STORY_ID&gt;</code> Confirm all tests are now passing.</p> <p><code>/tdd refactor_done &lt;STORY_ID&gt;</code> Complete refactoring and proceed to commit.</p> <p><code>/tdd review_cycle &lt;STORY_ID&gt;</code> Request human review of current TDD cycle.</p> <p><code>/tdd skip_phase &lt;STORY_ID&gt;</code> Skip current TDD phase (requires approval).</p> <p><code>/tdd metrics</code> Display TDD metrics: cycle time, test coverage, refactor frequency.</p> <p><code>/tdd halt_all</code> Emergency stop all TDD cycles (requires confirmation).</p>"},{"location":"user-guide/hitl-commands/#multi-project-commands","title":"Multi-Project Commands","text":"<p><code>/global_status</code> Show status of all projects in multi-project orchestration.</p> <p><code>/project_list</code> List all registered projects with their current state.</p> <p><code>/project_start &lt;PROJECT_NAME&gt;</code> Start orchestration for a specific project.</p> <p><code>/project_stop &lt;PROJECT_NAME&gt;</code> Stop orchestration for a specific project.</p> <p><code>/project_register &lt;NAME&gt; &lt;PATH&gt;</code> Register a new project for orchestration.</p> <p><code>/resource_status</code> Display resource allocation across all projects.</p> <p><code>/resource_optimize</code> Trigger resource optimization across projects.</p>"},{"location":"user-guide/hitl-commands/#context-management-commands","title":"Context Management Commands","text":"<p><code>/context status</code> Show context management system status.</p> <p><code>/context optimize</code> Trigger context optimization across all agents.</p> <p><code>/context memory [AGENT_ID]</code> Display agent memory usage and cache statistics.</p> <p><code>/context clear_cache</code> Clear context cache (use when memory issues occur).</p>"},{"location":"user-guide/hitl-commands/#cross-project-intelligence-commands","title":"Cross-Project Intelligence Commands","text":"<p><code>/insights global</code> Show cross-project insights and pattern analysis.</p> <p><code>/patterns list</code> Display detected patterns across projects.</p> <p><code>/knowledge_transfer</code> Show recommended knowledge transfers between projects.</p>"},{"location":"user-guide/hitl-commands/#examples","title":"Examples","text":""},{"location":"user-guide/hitl-commands/#1-strategic-planning","title":"1. Strategic Planning","text":"<pre><code>/epic \"Build a modular authentication system\"\n</code></pre> <p>Orchestrator returns proposed stories <code>AUTH-1</code>, <code>AUTH-2</code>.</p> <pre><code>/approve AUTH-1 AUTH-2\n</code></pre>"},{"location":"user-guide/hitl-commands/#2-sprint-lifecycle","title":"2. Sprint Lifecycle","text":"<pre><code>/sprint plan AUTH-1 AUTH-2\n/sprint start\n</code></pre> <p>At any time: <pre><code>/sprint status\n/sprint pause   # emergency halt\n/sprint resume  # continue work\n</code></pre></p>"},{"location":"user-guide/hitl-commands/#3-backlog-grooming","title":"3. Backlog Grooming","text":"<pre><code>/backlog view product\n/backlog add_story \"As a user I can reset my password\" --feature AUTH\n/backlog prioritize AUTH-3 high\n</code></pre>"},{"location":"user-guide/hitl-commands/#4-review-debug","title":"4. Review &amp; Debug","text":"<pre><code>/request_changes \"Add duplicate-email guard in registration API\"\n/suggest_fix \"Database URL is wrong in config.py\"\n</code></pre>"},{"location":"user-guide/hitl-commands/#5-multi-project-management","title":"5. Multi-Project Management","text":"<pre><code># Register and start multiple projects\n/project_register frontend-app /path/to/frontend\n/project_register backend-api /path/to/backend\n\n# Check global status\n/global_status\n# Shows: 2 projects registered, 1 active, 3 total agents\n\n# Start specific projects\n/project_start frontend-app\n/project_start backend-api\n\n# Monitor resource allocation\n/resource_status\n# Shows: CPU: 65%, Memory: 4.2GB/8GB, Agents: 5/10\n</code></pre>"},{"location":"user-guide/hitl-commands/#6-context-management","title":"6. Context Management","text":"<pre><code># Check context system status\n/context status\n# Shows: Cache hit rate: 87%, Memory usage: 1.2GB\n\n# Optimize context when performance degrades\n/context optimize\n\n# Check specific agent memory\n/context memory DesignAgent-AUTH-1\n# Shows: Context size: 12K tokens, Cache: 3 items\n\n# Clear cache if needed\n/context clear_cache\n</code></pre>"},{"location":"user-guide/hitl-commands/#7-cross-project-intelligence","title":"7. Cross-Project Intelligence","text":"<pre><code># View insights across projects\n/insights global\n# Shows: 5 patterns detected, 3 transfer opportunities\n\n# List detected patterns\n/patterns list\n# Shows: API design patterns, testing strategies, etc.\n\n# Get knowledge transfer recommendations\n/knowledge_transfer\n# Shows: Transfer logging strategy from backend-api to frontend-app\n/skip_task   # after three failed CI attempts\n</code></pre>"},{"location":"user-guide/hitl-commands/#5-tdd-workflow-management","title":"5. TDD Workflow Management","text":"<pre><code># Monitor TDD progress during active sprint\n/tdd overview\n\n# Check specific story TDD status\n/tdd status AUTH-1\n\n# Manually advance TDD phases when needed\n/tdd design_complete AUTH-1\n/tdd tests_ready AUTH-1\n/tdd code_green AUTH-1\n/tdd refactor_done AUTH-1\n\n# Review TDD cycle before proceeding\n/tdd review_cycle AUTH-1\n\n# Handle stuck TDD cycles\n/tdd pause AUTH-1\n/suggest_fix \"Need to handle async authentication flow\"\n/tdd resume AUTH-1\n\n# Skip problematic phase with justification\n/tdd skip_phase AUTH-1   # Requires approval\n</code></pre>"},{"location":"user-guide/hitl-commands/#6-parallel-tdd-monitoring","title":"6. Parallel TDD Monitoring","text":"<pre><code># Start sprint with multiple stories\n/sprint start\n# Automatically creates TDD cycles for all stories\n\n# Monitor all TDD cycles\n/tdd overview\n</code></pre> <p>Output shows parallel progress: <pre><code>AUTH-1: CODE_GREEN (14/15 tests passing)\nAUTH-2: REFACTOR (applying clean patterns)  \nAUTH-3: TEST_RED (8 failing tests written)\n</code></pre></p> <pre><code># Get TDD performance metrics\n/tdd metrics\n\n# Emergency halt all TDD cycles\n/tdd halt_all\n</code></pre>"},{"location":"user-guide/hitl-commands/#escalation-policy-research-mode","title":"Escalation Policy (Research Mode)","text":"<ol> <li>The Orchestrator escalates after three consecutive CI failures.</li> <li>Security-critical code requires explicit human approval.</li> <li>Agents time-box tasks to 30 min; longer tasks trigger a status ping.</li> </ol> <p>This lightweight command set keeps you focused on big-picture direction while agents handle the details.</p>"},{"location":"user-guide/hitl-commands/#state-awareness-invalid-commands","title":"State Awareness &amp; Invalid Commands","text":"<p>The orchestrator enforces a finite-state machine (see <code>command_state_machine.md</code>).</p> <ul> <li>Use <code>/state</code> at any time to:</li> <li>View the current state (e.g., <code>SPRINT_ACTIVE</code>).</li> <li>Click Allowed Commands \u2013 shows only the verbs valid right now.</li> <li>Click Diagram \u2013 in-chat SVG of the full state chart.</li> <li>Click Matrix \u2013 raw command\u2192state table.</li> </ul> <p>If you issue a command that is not legal for the current state, the bot replies with an error message:</p> <p>Warning: Command <code>/sprint plan</code> is not allowed now (state: SPRINT_ACTIVE). Try <code>/sprint status</code>.</p> <p>No action is taken until a valid command is sent. </p>"},{"location":"user-guide/integration-examples/","title":"Integration Examples &amp; Cookbook","text":"<p>Practical examples and recipes for integrating the AI Agent TDD-Scrum workflow system with various tools, services, and development environments.</p>"},{"location":"user-guide/integration-examples/#quick-start-integration-examples","title":"Quick Start Integration Examples","text":""},{"location":"user-guide/integration-examples/#basic-project-integration","title":"Basic Project Integration","text":""},{"location":"user-guide/integration-examples/#expressjs-api-project","title":"Express.js API Project","text":"<p>Complete setup for a Node.js Express API with TDD workflow.</p> <pre><code># config/express-api.yml\norchestrator:\n  mode: partial\n  project_path: \"/workspace/express-api\"\n\ntdd:\n  enabled: true\n  test_execution:\n    runner: \"npm test\"\n    coverage_threshold: 85\n    parallel_jobs: 2\n\nagents:\n  design_agent:\n    context: \"Express.js REST API with PostgreSQL\"\n  code_agent:\n    implementation_style: \"minimal\"\n  qa_agent:\n    test_types: [\"unit\", \"integration\", \"api\"]\n</code></pre> <p>Discord Workflow: <pre><code># Initialize project\n/project register /workspace/express-api \"Express API\"\n/epic \"User Management API\"\n\n# Add stories\n/backlog add_story \"POST /users endpoint with validation\"\n/backlog add_story \"GET /users/:id endpoint with error handling\"\n/backlog add_story \"PUT /users/:id endpoint with authorization\"\n\n# Plan and execute TDD sprint\n/sprint plan\n/sprint start\n\n# TDD workflow for each story\n/tdd start USER-001 \"User creation endpoint\"\n/tdd design    # Creates API specification\n/tdd test      # Generates Jest tests\n/tdd code      # Implements endpoint\n/tdd refactor  # Optimizes code\n/tdd commit    # Final integration\n</code></pre></p>"},{"location":"user-guide/integration-examples/#python-django-project","title":"Python Django Project","text":"<p>Django web application with comprehensive TDD coverage.</p> <pre><code># config/django-web.yml\norchestrator:\n  mode: blocking\n  project_path: \"/workspace/django-app\"\n\ntdd:\n  enabled: true\n  test_execution:\n    runner: \"python manage.py test\"\n    coverage_threshold: 90\n    parallel_jobs: 4\n\n  quality_gates:\n    code_green_phase:\n      require_migrations: true\n      validate_models: true\n\nintegrations:\n  ci:\n    provider: \"github_actions\"\n    config_file: \".github/workflows/django.yml\"\n</code></pre> <p>TDD Integration: <pre><code># Generated test structure\n# tests/tdd/USER-001/test_user_views.py\nfrom django.test import TestCase, Client\nfrom django.contrib.auth.models import User\nimport json\n\nclass UserViewTestCase(TestCase):\n    def setUp(self):\n        self.client = Client()\n\n    def test_user_registration_valid_data(self):\n        \"\"\"Test user registration with valid data\"\"\"\n        response = self.client.post('/api/users/', {\n            'username': 'testuser',\n            'email': 'test@example.com',\n            'password': 'securepass123'\n        })\n        self.assertEqual(response.status_code, 201)\n        self.assertTrue(User.objects.filter(username='testuser').exists())\n\n    def test_user_registration_invalid_email(self):\n        \"\"\"Test user registration with invalid email\"\"\"\n        response = self.client.post('/api/users/', {\n            'username': 'testuser',\n            'email': 'invalid-email',\n            'password': 'securepass123'\n        })\n        self.assertEqual(response.status_code, 400)\n</code></pre></p>"},{"location":"user-guide/integration-examples/#react-frontend-project","title":"React Frontend Project","text":"<p>React application with component-based TDD.</p> <pre><code># config/react-frontend.yml\norchestrator:\n  mode: partial\n  project_path: \"/workspace/react-app\"\n\ntdd:\n  enabled: true\n  test_execution:\n    runner: \"npm test -- --coverage\"\n    coverage_threshold: 80\n\n  agents:\n    design_agent:\n      detail_level: \"comprehensive\"\n      include_diagrams: true\n    qa_agent:\n      test_types: [\"unit\", \"integration\", \"e2e\"]\n      generate_test_data: true\n</code></pre> <p>Component TDD Example: <pre><code>// tests/tdd/USER-PROFILE-001/UserProfile.test.js\nimport React from 'react';\nimport { render, screen, fireEvent, waitFor } from '@testing-library/react';\nimport { UserProfile } from '../../../src/components/UserProfile';\n\ndescribe('UserProfile Component', () =&gt; {\n  const mockUser = {\n    id: 1,\n    name: 'John Doe',\n    email: 'john@example.com',\n    avatar: 'https://example.com/avatar.jpg'\n  };\n\n  test('renders user information correctly', () =&gt; {\n    render(&lt;UserProfile user={mockUser} /&gt;);\n\n    expect(screen.getByText('John Doe')).toBeInTheDocument();\n    expect(screen.getByText('john@example.com')).toBeInTheDocument();\n    expect(screen.getByRole('img')).toHaveAttribute('src', mockUser.avatar);\n  });\n\n  test('handles edit mode toggle', async () =&gt; {\n    render(&lt;UserProfile user={mockUser} /&gt;);\n\n    const editButton = screen.getByText('Edit Profile');\n    fireEvent.click(editButton);\n\n    await waitFor(() =&gt; {\n      expect(screen.getByDisplayValue('John Doe')).toBeInTheDocument();\n      expect(screen.getByText('Save Changes')).toBeInTheDocument();\n    });\n  });\n});\n</code></pre></p>"},{"location":"user-guide/integration-examples/#cicd-integration","title":"CI/CD Integration","text":""},{"location":"user-guide/integration-examples/#github-actions-integration","title":"GitHub Actions Integration","text":""},{"location":"user-guide/integration-examples/#complete-github-actions-workflow","title":"Complete GitHub Actions Workflow","text":"<pre><code># .github/workflows/agent-workflow.yml\nname: AI Agent TDD Workflow\n\non:\n  push:\n    branches: [ main, develop ]\n  pull_request:\n    branches: [ main ]\n\nenv:\n  DISCORD_WEBHOOK: ${{ secrets.DISCORD_WEBHOOK }}\n  ORCHESTRATOR_MODE: autonomous\n\njobs:\n  tdd-validation:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v3\n\n    - name: Setup Python\n      uses: actions/setup-python@v4\n      with:\n        python-version: '3.9'\n\n    - name: Install AI Agent Workflow\n      run: |\n        pip install -r requirements.txt\n        python scripts/orchestrator.py --setup\n\n    - name: Validate TDD Cycles\n      run: |\n        python scripts/tdd_manager.py validate-all\n        python scripts/test_preservation.py verify-integrity\n\n    - name: Run Preserved Tests\n      run: |\n        pytest tests/tdd/ --cov=src --cov-report=xml\n\n    - name: Upload Coverage\n      uses: codecov/codecov-action@v3\n      with:\n        file: ./coverage.xml\n\n    - name: Notify Discord\n      if: always()\n      run: |\n        python scripts/notify_discord.py \\\n          --webhook $DISCORD_WEBHOOK \\\n          --status ${{ job.status }} \\\n          --commit ${{ github.sha }}\n\n  agent-integration:\n    runs-on: ubuntu-latest\n    needs: tdd-validation\n\n    steps:\n    - uses: actions/checkout@v3\n\n    - name: Start Test Orchestrator\n      run: |\n        export NO_AGENT_MODE=true\n        python scripts/orchestrator.py --health-check\n\n    - name: Run Integration Tests\n      run: |\n        pytest tests/integration/ --tb=short\n\n    - name: Performance Benchmarks\n      run: |\n        python scripts/test_runner.py performance --output-file perf_results.json\n\n    - name: Upload Artifacts\n      uses: actions/upload-artifact@v3\n      with:\n        name: test-results\n        path: |\n          perf_results.json\n          logs/\n</code></pre>"},{"location":"user-guide/integration-examples/#tdd-specific-github-integration","title":"TDD-Specific GitHub Integration","text":"<pre><code># scripts/github_tdd_integration.py\nimport os\nimport requests\nfrom github import Github\nfrom lib.tdd_models import TDDCycle\n\nclass GitHubTDDIntegration:\n    def __init__(self, repo_name, token):\n        self.github = Github(token)\n        self.repo = self.github.get_repo(repo_name)\n\n    async def create_tdd_branch(self, story_id):\n        \"\"\"Create dedicated branch for TDD cycle\"\"\"\n        main_branch = self.repo.get_branch(\"main\")\n        branch_name = f\"tdd/{story_id.lower()}\"\n\n        self.repo.create_git_ref(\n            ref=f\"refs/heads/{branch_name}\",\n            sha=main_branch.commit.sha\n        )\n\n        return branch_name\n\n    async def create_tdd_pr(self, cycle: TDDCycle):\n        \"\"\"Create PR for completed TDD cycle\"\"\"\n        branch_name = f\"tdd/{cycle.story_id.lower()}\"\n\n        # Generate PR description\n        description = self.generate_pr_description(cycle)\n\n        pr = self.repo.create_pull(\n            title=f\"TDD: {cycle.story_id} - {cycle.description}\",\n            body=description,\n            head=branch_name,\n            base=\"main\"\n        )\n\n        # Add TDD-specific labels\n        pr.add_to_labels(\"tdd-cycle\", \"needs-review\")\n\n        return pr\n\n    def generate_pr_description(self, cycle: TDDCycle):\n        \"\"\"Generate comprehensive PR description from TDD cycle\"\"\"\n        return f\"\"\"\n## TDD Cycle Summary\n\n**Story ID:** {cycle.story_id}\n**Description:** {cycle.description}\n**Cycle Duration:** {cycle.get_duration_summary()}\n\n## TDD Phases Completed\n\n- \u2705 **Design Phase**: Technical specifications created\n- \u2705 **Test Red Phase**: {len(cycle.get_test_files())} failing tests written\n- \u2705 **Code Green Phase**: Implementation completed, all tests passing\n- \u2705 **Refactor Phase**: Code optimized while maintaining green tests\n\n## Test Coverage\n\n- **Test Files Created:** {len(cycle.get_test_files())}\n- **Test Coverage:** {cycle.overall_test_coverage:.1f}%\n- **Tests Passing:** {cycle.get_passing_test_count()}\n\n## Files Changed\n\n{self.get_files_changed_summary(cycle)}\n\n## Quality Metrics\n\n- **Code Complexity:** {cycle.get_complexity_score()}\n- **Technical Debt:** {cycle.get_technical_debt_score()}\n- **Performance Impact:** {cycle.get_performance_impact()}\n\n---\n*Generated by AI Agent TDD-Scrum Workflow*\n\"\"\"\n</code></pre>"},{"location":"user-guide/integration-examples/#gitlab-ci-integration","title":"GitLab CI Integration","text":""},{"location":"user-guide/integration-examples/#gitlab-ci-pipeline","title":"GitLab CI Pipeline","text":"<pre><code># .gitlab-ci.yml\nstages:\n  - validate\n  - test\n  - deploy\n  - notify\n\nvariables:\n  ORCHESTRATOR_MODE: partial\n  TDD_ENABLED: \"true\"\n\nvalidate-tdd:\n  stage: validate\n  script:\n    - python scripts/tdd_manager.py validate-all\n    - python scripts/config_manager.py validate config/gitlab.yml\n  artifacts:\n    reports:\n      junit: tdd-validation-report.xml\n\nrun-preserved-tests:\n  stage: test\n  script:\n    - pytest tests/tdd/ --junitxml=tdd-tests.xml --cov=src\n  coverage: '/TOTAL.+ ([0-9]{1,3}%)/'\n  artifacts:\n    reports:\n      junit: tdd-tests.xml\n      coverage_report:\n        coverage_format: cobertura\n        path: coverage.xml\n\nintegration-tests:\n  stage: test\n  services:\n    - postgres:13\n    - redis:6\n  variables:\n    NO_AGENT_MODE: \"true\"\n  script:\n    - python scripts/orchestrator.py --health-check\n    - pytest tests/integration/ --tb=short\n  parallel: 3\n\ndeploy-review:\n  stage: deploy\n  environment:\n    name: review/$CI_COMMIT_REF_SLUG\n    url: https://$CI_COMMIT_REF_SLUG.review.example.com\n  script:\n    - python scripts/deploy.py review --version $CI_COMMIT_SHA\n  only:\n    - merge_requests\n\nnotify-discord:\n  stage: notify\n  script:\n    - |\n      python scripts/notify_discord.py \\\n        --webhook $DISCORD_WEBHOOK \\\n        --pipeline-status $CI_PIPELINE_STATUS \\\n        --commit $CI_COMMIT_SHA \\\n        --branch $CI_COMMIT_REF_NAME\n  when: always\n</code></pre>"},{"location":"user-guide/integration-examples/#jenkins-integration","title":"Jenkins Integration","text":""},{"location":"user-guide/integration-examples/#jenkins-pipeline","title":"Jenkins Pipeline","text":"<pre><code>// Jenkinsfile\npipeline {\n    agent any\n\n    environment {\n        DISCORD_WEBHOOK = credentials('discord-webhook')\n        ORCHESTRATOR_MODE = 'autonomous'\n        NO_AGENT_MODE = 'false'\n    }\n\n    stages {\n        stage('Setup') {\n            steps {\n                script {\n                    sh 'python -m venv .venv'\n                    sh '. .venv/bin/activate &amp;&amp; pip install -r requirements.txt'\n                }\n            }\n        }\n\n        stage('TDD Validation') {\n            parallel {\n                stage('Validate Cycles') {\n                    steps {\n                        sh '''\n                            . .venv/bin/activate\n                            python scripts/tdd_manager.py validate-all\n                        '''\n                    }\n                }\n\n                stage('Test Preservation') {\n                    steps {\n                        sh '''\n                            . .venv/bin/activate\n                            python scripts/test_preservation.py verify-integrity\n                        '''\n                    }\n                }\n            }\n        }\n\n        stage('Execute Tests') {\n            steps {\n                sh '''\n                    . .venv/bin/activate\n                    pytest tests/tdd/ --junitxml=results.xml --cov=src\n                '''\n            }\n            post {\n                always {\n                    junit 'results.xml'\n                    publishHTML([\n                        allowMissing: false,\n                        alwaysLinkToLastBuild: false,\n                        keepAll: true,\n                        reportDir: 'htmlcov',\n                        reportFiles: 'index.html',\n                        reportName: 'Coverage Report'\n                    ])\n                }\n            }\n        }\n\n        stage('Integration Tests') {\n            environment {\n                NO_AGENT_MODE = 'true'\n            }\n            steps {\n                sh '''\n                    . .venv/bin/activate\n                    python scripts/orchestrator.py --health-check\n                    pytest tests/integration/\n                '''\n            }\n        }\n\n        stage('Deploy') {\n            when {\n                branch 'main'\n            }\n            steps {\n                script {\n                    sh '''\n                        . .venv/bin/activate\n                        python scripts/deploy.py production --version ${BUILD_NUMBER}\n                    '''\n                }\n            }\n        }\n    }\n\n    post {\n        always {\n            script {\n                sh '''\n                    . .venv/bin/activate\n                    python scripts/notify_discord.py \\\n                        --webhook ${DISCORD_WEBHOOK} \\\n                        --build-status ${currentBuild.result} \\\n                        --build-number ${BUILD_NUMBER}\n                '''\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"user-guide/integration-examples/#database-integration","title":"Database Integration","text":""},{"location":"user-guide/integration-examples/#postgresql-integration","title":"PostgreSQL Integration","text":""},{"location":"user-guide/integration-examples/#database-configuration","title":"Database Configuration","text":"<pre><code># config/postgresql.yml\nstorage:\n  type: \"postgresql\"\n  connection:\n    host: \"localhost\"\n    port: 5432\n    database: \"agent_workflow\"\n    username: \"workflow_user\"\n    password: \"${DATABASE_PASSWORD}\"\n\n  pool:\n    min_connections: 5\n    max_connections: 20\n\ntdd:\n  test_execution:\n    test_database: \"agent_workflow_test\"\n    isolation_level: \"transaction\"\n</code></pre>"},{"location":"user-guide/integration-examples/#database-schema-migration","title":"Database Schema Migration","text":"<pre><code># scripts/setup_postgresql.py\nimport asyncpg\nimport asyncio\nfrom lib.storage.postgresql_adapter import PostgreSQLAdapter\n\nasync def setup_database():\n    \"\"\"Setup PostgreSQL database for agent workflow\"\"\"\n\n    # Create database schema\n    adapter = PostgreSQLAdapter()\n    await adapter.create_schema()\n\n    # Create TDD-specific tables\n    await adapter.execute_sql(\"\"\"\n        CREATE TABLE IF NOT EXISTS tdd_cycles (\n            id VARCHAR(50) PRIMARY KEY,\n            story_id VARCHAR(50) NOT NULL,\n            current_state VARCHAR(20) NOT NULL,\n            started_at TIMESTAMP DEFAULT NOW(),\n            completed_at TIMESTAMP,\n            metadata JSONB\n        );\n\n        CREATE TABLE IF NOT EXISTS tdd_tasks (\n            id VARCHAR(50) PRIMARY KEY,\n            cycle_id VARCHAR(50) REFERENCES tdd_cycles(id),\n            description TEXT NOT NULL,\n            current_state VARCHAR(20) NOT NULL,\n            test_files JSONB,\n            source_files JSONB,\n            created_at TIMESTAMP DEFAULT NOW()\n        );\n\n        CREATE TABLE IF NOT EXISTS test_results (\n            id SERIAL PRIMARY KEY,\n            task_id VARCHAR(50) REFERENCES tdd_tasks(id),\n            test_name VARCHAR(200) NOT NULL,\n            status VARCHAR(20) NOT NULL,\n            execution_time FLOAT,\n            output TEXT,\n            timestamp TIMESTAMP DEFAULT NOW()\n        );\n\n        CREATE INDEX idx_tdd_cycles_story_id ON tdd_cycles(story_id);\n        CREATE INDEX idx_test_results_task_id ON test_results(task_id);\n    \"\"\")\n\n    print(\"\u2705 PostgreSQL database setup complete\")\n\nif __name__ == \"__main__\":\n    asyncio.run(setup_database())\n</code></pre>"},{"location":"user-guide/integration-examples/#mongodb-integration","title":"MongoDB Integration","text":""},{"location":"user-guide/integration-examples/#mongodb-configuration","title":"MongoDB Configuration","text":"<pre><code># config/mongodb.yml\nstorage:\n  type: \"mongodb\"\n  connection:\n    uri: \"mongodb://localhost:27017/agent_workflow\"\n    options:\n      maxPoolSize: 20\n      retryWrites: true\n\n  collections:\n    tdd_cycles: \"tdd_cycles\"\n    test_results: \"test_results\"\n    agent_logs: \"agent_logs\"\n</code></pre>"},{"location":"user-guide/integration-examples/#mongodb-document-models","title":"MongoDB Document Models","text":"<pre><code># lib/storage/mongodb_models.py\nfrom motor.motor_asyncio import AsyncIOMotorClient\nfrom datetime import datetime\nimport uuid\n\nclass MongoDBTDDStorage:\n    def __init__(self, connection_uri):\n        self.client = AsyncIOMotorClient(connection_uri)\n        self.db = self.client.agent_workflow\n\n    async def save_tdd_cycle(self, cycle):\n        \"\"\"Save TDD cycle to MongoDB\"\"\"\n        document = {\n            \"_id\": cycle.id,\n            \"story_id\": cycle.story_id,\n            \"current_state\": cycle.current_state.value,\n            \"tasks\": [task.to_dict() for task in cycle.tasks],\n            \"started_at\": cycle.started_at,\n            \"completed_at\": cycle.completed_at,\n            \"metadata\": {\n                \"total_test_runs\": cycle.total_test_runs,\n                \"total_refactors\": cycle.total_refactors,\n                \"overall_test_coverage\": cycle.overall_test_coverage\n            },\n            \"updated_at\": datetime.utcnow()\n        }\n\n        await self.db.tdd_cycles.replace_one(\n            {\"_id\": cycle.id},\n            document,\n            upsert=True\n        )\n\n    async def get_active_cycles(self):\n        \"\"\"Get all active TDD cycles\"\"\"\n        cursor = self.db.tdd_cycles.find({\n            \"current_state\": {\"$ne\": \"COMMIT\"},\n            \"completed_at\": None\n        })\n\n        cycles = []\n        async for document in cursor:\n            cycle = self.document_to_cycle(document)\n            cycles.append(cycle)\n\n        return cycles\n</code></pre>"},{"location":"user-guide/integration-examples/#cloud-platform-integration","title":"Cloud Platform Integration","text":""},{"location":"user-guide/integration-examples/#aws-integration","title":"AWS Integration","text":""},{"location":"user-guide/integration-examples/#aws-ecs-deployment","title":"AWS ECS Deployment","text":"<pre><code># aws/ecs-task-definition.json\n{\n  \"family\": \"agent-workflow\",\n  \"networkMode\": \"awsvpc\",\n  \"requiresCompatibilities\": [\"FARGATE\"],\n  \"cpu\": \"1024\",\n  \"memory\": \"2048\",\n  \"executionRoleArn\": \"arn:aws:iam::ACCOUNT:role/ecsTaskExecutionRole\",\n  \"taskRoleArn\": \"arn:aws:iam::ACCOUNT:role/agent-workflow-task-role\",\n  \"containerDefinitions\": [\n    {\n      \"name\": \"orchestrator\",\n      \"image\": \"your-registry/agent-workflow:latest\",\n      \"essential\": true,\n      \"portMappings\": [\n        {\n          \"containerPort\": 8080,\n          \"protocol\": \"tcp\"\n        }\n      ],\n      \"environment\": [\n        {\"name\": \"ORCHESTRATOR_MODE\", \"value\": \"autonomous\"},\n        {\"name\": \"AWS_REGION\", \"value\": \"us-east-1\"}\n      ],\n      \"secrets\": [\n        {\n          \"name\": \"DISCORD_BOT_TOKEN\",\n          \"valueFrom\": \"arn:aws:secretsmanager:us-east-1:ACCOUNT:secret:discord-token\"\n        }\n      ],\n      \"logConfiguration\": {\n        \"logDriver\": \"awslogs\",\n        \"options\": {\n          \"awslogs-group\": \"/ecs/agent-workflow\",\n          \"awslogs-region\": \"us-east-1\",\n          \"awslogs-stream-prefix\": \"ecs\"\n        }\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"user-guide/integration-examples/#aws-lambda-integration","title":"AWS Lambda Integration","text":"<pre><code># aws/lambda_tdd_processor.py\nimport json\nimport boto3\nfrom lib.tdd_models import TDDCycle\nfrom lib.storage.s3_adapter import S3TDDStorage\n\ndef lambda_handler(event, context):\n    \"\"\"AWS Lambda function for processing TDD events\"\"\"\n\n    # Parse SQS message\n    for record in event['Records']:\n        message = json.loads(record['body'])\n        event_type = message['event_type']\n\n        if event_type == 'tdd_cycle_completed':\n            await process_completed_cycle(message['cycle_id'])\n        elif event_type == 'test_results_available':\n            await process_test_results(message['task_id'])\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('TDD events processed successfully')\n    }\n\nasync def process_completed_cycle(cycle_id):\n    \"\"\"Process completed TDD cycle\"\"\"\n    storage = S3TDDStorage()\n    cycle = await storage.load_cycle(cycle_id)\n\n    # Generate completion report\n    report = generate_cycle_report(cycle)\n\n    # Store in S3\n    s3 = boto3.client('s3')\n    s3.put_object(\n        Bucket='agent-workflow-reports',\n        Key=f'tdd-reports/{cycle_id}/completion-report.json',\n        Body=json.dumps(report),\n        ContentType='application/json'\n    )\n\n    # Send SNS notification\n    sns = boto3.client('sns')\n    sns.publish(\n        TopicArn='arn:aws:sns:us-east-1:ACCOUNT:tdd-notifications',\n        Message=f'TDD Cycle {cycle_id} completed successfully',\n        Subject='TDD Cycle Completion'\n    )\n</code></pre>"},{"location":"user-guide/integration-examples/#google-cloud-platform","title":"Google Cloud Platform","text":""},{"location":"user-guide/integration-examples/#gcp-cloud-run-deployment","title":"GCP Cloud Run Deployment","text":"<pre><code># gcp/cloudbuild.yaml\nsteps:\n  # Build the container image\n  - name: 'gcr.io/cloud-builders/docker'\n    args: ['build', '-t', 'gcr.io/$PROJECT_ID/agent-workflow:$COMMIT_SHA', '.']\n\n  # Push the container image to Container Registry\n  - name: 'gcr.io/cloud-builders/docker'\n    args: ['push', 'gcr.io/$PROJECT_ID/agent-workflow:$COMMIT_SHA']\n\n  # Deploy container image to Cloud Run\n  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'\n    entrypoint: 'gcloud'\n    args:\n      - 'run'\n      - 'deploy'\n      - 'agent-workflow'\n      - '--image=gcr.io/$PROJECT_ID/agent-workflow:$COMMIT_SHA'\n      - '--region=us-central1'\n      - '--platform=managed'\n      - '--memory=2Gi'\n      - '--cpu=2'\n      - '--max-instances=10'\n      - '--set-env-vars=ORCHESTRATOR_MODE=autonomous'\n      - '--set-secrets=DISCORD_BOT_TOKEN=discord-token:latest'\n\noptions:\n  logging: CLOUD_LOGGING_ONLY\n</code></pre>"},{"location":"user-guide/integration-examples/#gcp-pubsub-integration","title":"GCP Pub/Sub Integration","text":"<pre><code># gcp/pubsub_tdd_handler.py\nfrom google.cloud import pubsub_v1\nimport json\nimport asyncio\n\nclass PubSubTDDHandler:\n    def __init__(self, project_id, subscription_name):\n        self.subscriber = pubsub_v1.SubscriberClient()\n        self.subscription_path = self.subscriber.subscription_path(\n            project_id, subscription_name\n        )\n\n    def start_listening(self):\n        \"\"\"Start listening for TDD events\"\"\"\n        flow_control = pubsub_v1.types.FlowControl(max_messages=100)\n\n        self.subscriber.subscribe(\n            self.subscription_path,\n            callback=self.handle_message,\n            flow_control=flow_control\n        )\n\n    def handle_message(self, message):\n        \"\"\"Handle incoming TDD event message\"\"\"\n        try:\n            event = json.loads(message.data.decode('utf-8'))\n\n            if event['type'] == 'tdd_state_change':\n                asyncio.run(self.process_state_change(event))\n            elif event['type'] == 'test_execution_complete':\n                asyncio.run(self.process_test_results(event))\n\n            message.ack()\n\n        except Exception as e:\n            print(f\"Error processing message: {e}\")\n            message.nack()\n\n    async def process_state_change(self, event):\n        \"\"\"Process TDD state change event\"\"\"\n        print(f\"TDD State Change: {event['cycle_id']} -&gt; {event['new_state']}\")\n\n        # Update monitoring dashboards\n        await self.update_monitoring_metrics(event)\n\n        # Send notifications if needed\n        if event['new_state'] == 'BLOCKED':\n            await self.send_alert(event)\n</code></pre>"},{"location":"user-guide/integration-examples/#monitoring-observability-integration","title":"Monitoring &amp; Observability Integration","text":""},{"location":"user-guide/integration-examples/#prometheus-grafana","title":"Prometheus &amp; Grafana","text":""},{"location":"user-guide/integration-examples/#prometheus-configuration","title":"Prometheus Configuration","text":"<pre><code># prometheus/prometheus.yml\nglobal:\n  scrape_interval: 15s\n\nscrape_configs:\n  - job_name: 'agent-workflow'\n    static_configs:\n      - targets: ['localhost:8000']\n    metrics_path: '/metrics'\n    scrape_interval: 10s\n\n  - job_name: 'tdd-metrics'\n    static_configs:\n      - targets: ['localhost:8001']\n    metrics_path: '/tdd/metrics'\n    scrape_interval: 30s\n\nrule_files:\n  - \"alert_rules.yml\"\n\nalerting:\n  alertmanagers:\n    - static_configs:\n        - targets:\n          - alertmanager:9093\n</code></pre>"},{"location":"user-guide/integration-examples/#custom-metrics-export","title":"Custom Metrics Export","text":"<pre><code># monitoring/prometheus_exporter.py\nfrom prometheus_client import Counter, Histogram, Gauge, start_http_server\nimport asyncio\nimport time\n\nclass TDDPrometheusExporter:\n    def __init__(self):\n        # Define TDD-specific metrics\n        self.tdd_cycles_total = Counter(\n            'tdd_cycles_total',\n            'Total number of TDD cycles',\n            ['status', 'project']\n        )\n\n        self.tdd_phase_duration = Histogram(\n            'tdd_phase_duration_seconds',\n            'Duration of TDD phases',\n            ['phase', 'project']\n        )\n\n        self.active_tdd_cycles = Gauge(\n            'active_tdd_cycles',\n            'Number of active TDD cycles',\n            ['project']\n        )\n\n        self.test_coverage = Gauge(\n            'test_coverage_percentage',\n            'Test coverage percentage',\n            ['project', 'story_id']\n        )\n\n    async def export_metrics(self):\n        \"\"\"Export TDD metrics to Prometheus\"\"\"\n        while True:\n            # Update active cycles count\n            active_cycles = await self.get_active_cycles()\n            for project, count in active_cycles.items():\n                self.active_tdd_cycles.labels(project=project).set(count)\n\n            # Update coverage metrics\n            coverage_data = await self.get_coverage_metrics()\n            for project, stories in coverage_data.items():\n                for story_id, coverage in stories.items():\n                    self.test_coverage.labels(\n                        project=project,\n                        story_id=story_id\n                    ).set(coverage)\n\n            await asyncio.sleep(30)  # Export every 30 seconds\n\n    def record_cycle_completion(self, project, status):\n        \"\"\"Record TDD cycle completion\"\"\"\n        self.tdd_cycles_total.labels(\n            status=status,\n            project=project\n        ).inc()\n\n    def record_phase_duration(self, phase, project, duration):\n        \"\"\"Record TDD phase duration\"\"\"\n        self.tdd_phase_duration.labels(\n            phase=phase,\n            project=project\n        ).observe(duration)\n\n# Start Prometheus metrics server\nif __name__ == \"__main__\":\n    exporter = TDDPrometheusExporter()\n    start_http_server(8001)\n    asyncio.run(exporter.export_metrics())\n</code></pre>"},{"location":"user-guide/integration-examples/#grafana-dashboard-configuration","title":"Grafana Dashboard Configuration","text":"<pre><code>{\n  \"dashboard\": {\n    \"title\": \"AI Agent TDD Workflow\",\n    \"panels\": [\n      {\n        \"title\": \"Active TDD Cycles\",\n        \"type\": \"stat\",\n        \"targets\": [\n          {\n            \"expr\": \"sum(active_tdd_cycles)\",\n            \"legendFormat\": \"Active Cycles\"\n          }\n        ]\n      },\n      {\n        \"title\": \"TDD Phase Duration\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"tdd_phase_duration_seconds\",\n            \"legendFormat\": \"{{phase}} - {{project}}\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Test Coverage by Project\",\n        \"type\": \"heatmap\",\n        \"targets\": [\n          {\n            \"expr\": \"test_coverage_percentage\",\n            \"legendFormat\": \"{{project}} - {{story_id}}\"\n          }\n        ]\n      },\n      {\n        \"title\": \"TDD Cycle Success Rate\",\n        \"type\": \"stat\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(tdd_cycles_total{status=\\\"completed\\\"}[1h]) / rate(tdd_cycles_total[1h]) * 100\",\n            \"legendFormat\": \"Success Rate %\"\n          }\n        ]\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"user-guide/integration-examples/#elk-stack-integration","title":"ELK Stack Integration","text":""},{"location":"user-guide/integration-examples/#logstash-configuration","title":"Logstash Configuration","text":"<pre><code># logstash/pipeline/agent-workflow.conf\ninput {\n  file {\n    path =&gt; \"/opt/agent-workflow/logs/*.log\"\n    start_position =&gt; \"beginning\"\n    codec =&gt; \"json\"\n  }\n\n  beats {\n    port =&gt; 5044\n  }\n}\n\nfilter {\n  if [logger_name] == \"tdd_state_machine\" {\n    mutate {\n      add_tag =&gt; [\"tdd\"]\n    }\n\n    if [message] =~ /transition/ {\n      grok {\n        match =&gt; { \n          \"message\" =&gt; \"TDD transition: %{WORD:old_state} \u2192 %{WORD:new_state} for %{WORD:story_id}\"\n        }\n      }\n    }\n  }\n\n  if [logger_name] == \"agent_execution\" {\n    mutate {\n      add_tag =&gt; [\"agent\"]\n    }\n\n    if [duration] {\n      mutate {\n        convert =&gt; { \"duration\" =&gt; \"float\" }\n      }\n    }\n  }\n}\n\noutput {\n  elasticsearch {\n    hosts =&gt; [\"elasticsearch:9200\"]\n    index =&gt; \"agent-workflow-%{+YYYY.MM.dd}\"\n  }\n\n  if \"tdd\" in [tags] {\n    elasticsearch {\n      hosts =&gt; [\"elasticsearch:9200\"]\n      index =&gt; \"tdd-cycles-%{+YYYY.MM.dd}\"\n    }\n  }\n}\n</code></pre>"},{"location":"user-guide/integration-examples/#kibana-dashboard-export","title":"Kibana Dashboard Export","text":"<pre><code>{\n  \"objects\": [\n    {\n      \"type\": \"visualization\",\n      \"id\": \"tdd-state-transitions\",\n      \"attributes\": {\n        \"title\": \"TDD State Transitions\",\n        \"visState\": {\n          \"type\": \"line\",\n          \"params\": {\n            \"grid\": {\"categoryLines\": false, \"style\": {\"color\": \"#eee\"}}\n          }\n        },\n        \"kibanaSavedObjectMeta\": {\n          \"searchSourceJSON\": {\n            \"index\": \"tdd-cycles-*\",\n            \"query\": {\n              \"match\": {\n                \"logger_name\": \"tdd_state_machine\"\n              }\n            }\n          }\n        }\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"user-guide/integration-examples/#notification-integration","title":"Notification Integration","text":""},{"location":"user-guide/integration-examples/#slack-integration","title":"Slack Integration","text":""},{"location":"user-guide/integration-examples/#slack-bot-configuration","title":"Slack Bot Configuration","text":"<pre><code># integrations/slack_bot.py\nfrom slack_bolt import App\nfrom slack_bolt.adapter.socket_mode import SocketModeHandler\nimport asyncio\n\nclass SlackTDDBot:\n    def __init__(self, bot_token, app_token):\n        self.app = App(token=bot_token)\n        self.handler = SocketModeHandler(self.app, app_token)\n        self.setup_commands()\n\n    def setup_commands(self):\n        \"\"\"Setup Slack slash commands\"\"\"\n\n        @self.app.command(\"/tdd-status\")\n        def handle_tdd_status(ack, respond, command):\n            ack()\n\n            project = command.get('text', '').strip()\n            status = asyncio.run(self.get_tdd_status(project))\n\n            respond({\n                \"response_type\": \"in_channel\",\n                \"blocks\": [\n                    {\n                        \"type\": \"section\",\n                        \"text\": {\n                            \"type\": \"mrkdwn\",\n                            \"text\": f\"*TDD Status for {project}*\\n{status}\"\n                        }\n                    }\n                ]\n            })\n\n        @self.app.command(\"/tdd-metrics\")\n        def handle_tdd_metrics(ack, respond, command):\n            ack()\n\n            metrics = asyncio.run(self.get_tdd_metrics())\n\n            respond({\n                \"response_type\": \"ephemeral\",\n                \"attachments\": [\n                    {\n                        \"color\": \"good\",\n                        \"title\": \"TDD Metrics Dashboard\",\n                        \"fields\": [\n                            {\n                                \"title\": \"Active Cycles\",\n                                \"value\": str(metrics['active_cycles']),\n                                \"short\": True\n                            },\n                            {\n                                \"title\": \"Avg Cycle Time\",\n                                \"value\": f\"{metrics['avg_cycle_time']:.1f} min\",\n                                \"short\": True\n                            }\n                        ]\n                    }\n                ]\n            })\n\n    async def send_tdd_notification(self, channel, event):\n        \"\"\"Send TDD event notification to Slack\"\"\"\n        if event['type'] == 'cycle_completed':\n            await self.send_cycle_completion(channel, event)\n        elif event['type'] == 'cycle_blocked':\n            await self.send_cycle_blocked(channel, event)\n\n    async def send_cycle_completion(self, channel, event):\n        \"\"\"Send cycle completion notification\"\"\"\n        cycle = event['cycle']\n\n        self.app.client.chat_postMessage(\n            channel=channel,\n            blocks=[\n                {\n                    \"type\": \"section\",\n                    \"text\": {\n                        \"type\": \"mrkdwn\",\n                        \"text\": f\"\ud83c\udf89 *TDD Cycle Completed*\\n\"\n                               f\"*Story:* {cycle['story_id']}\\n\"\n                               f\"*Duration:* {cycle['duration']}\\n\"\n                               f\"*Coverage:* {cycle['coverage']:.1f}%\"\n                    }\n                },\n                {\n                    \"type\": \"actions\",\n                    \"elements\": [\n                        {\n                            \"type\": \"button\",\n                            \"text\": {\"type\": \"plain_text\", \"text\": \"View Details\"},\n                            \"url\": f\"https://dashboard.example.com/tdd/{cycle['id']}\"\n                        }\n                    ]\n                }\n            ]\n        )\n</code></pre>"},{"location":"user-guide/integration-examples/#microsoft-teams-integration","title":"Microsoft Teams Integration","text":""},{"location":"user-guide/integration-examples/#teams-webhook-integration","title":"Teams Webhook Integration","text":"<pre><code># integrations/teams_webhook.py\nimport aiohttp\nimport json\nfrom datetime import datetime\n\nclass TeamsWebhookNotifier:\n    def __init__(self, webhook_url):\n        self.webhook_url = webhook_url\n\n    async def send_tdd_update(self, event):\n        \"\"\"Send TDD update to Microsoft Teams\"\"\"\n        card = self.create_adaptive_card(event)\n\n        async with aiohttp.ClientSession() as session:\n            async with session.post(\n                self.webhook_url,\n                headers={'Content-Type': 'application/json'},\n                data=json.dumps(card)\n            ) as response:\n                return response.status == 200\n\n    def create_adaptive_card(self, event):\n        \"\"\"Create Adaptive Card for TDD event\"\"\"\n        if event['type'] == 'state_transition':\n            return {\n                \"type\": \"message\",\n                \"attachments\": [\n                    {\n                        \"contentType\": \"application/vnd.microsoft.card.adaptive\",\n                        \"content\": {\n                            \"$schema\": \"http://adaptivecards.io/schemas/adaptive-card.json\",\n                            \"type\": \"AdaptiveCard\",\n                            \"version\": \"1.0\",\n                            \"body\": [\n                                {\n                                    \"type\": \"TextBlock\",\n                                    \"text\": \"TDD State Transition\",\n                                    \"weight\": \"bolder\",\n                                    \"size\": \"medium\"\n                                },\n                                {\n                                    \"type\": \"FactSet\",\n                                    \"facts\": [\n                                        {\n                                            \"title\": \"Story:\",\n                                            \"value\": event['story_id']\n                                        },\n                                        {\n                                            \"title\": \"From:\",\n                                            \"value\": event['old_state']\n                                        },\n                                        {\n                                            \"title\": \"To:\",\n                                            \"value\": event['new_state']\n                                        },\n                                        {\n                                            \"title\": \"Time:\",\n                                            \"value\": datetime.now().strftime('%H:%M:%S')\n                                        }\n                                    ]\n                                }\n                            ],\n                            \"actions\": [\n                                {\n                                    \"type\": \"Action.OpenUrl\",\n                                    \"title\": \"View Cycle\",\n                                    \"url\": f\"https://dashboard.example.com/tdd/{event['cycle_id']}\"\n                                }\n                            ]\n                        }\n                    }\n                ]\n            }\n</code></pre> <p>This comprehensive integration guide provides practical examples for connecting the AI Agent TDD-Scrum workflow system with various tools, platforms, and services commonly used in software development workflows.</p>"},{"location":"user-guide/multi-project-orchestration/","title":"Multi-Project Orchestration","text":"<p>The AI Agent TDD-Scrum workflow system now supports comprehensive multi-project orchestration, allowing you to manage multiple AI-assisted development projects simultaneously with intelligent resource allocation, security isolation, monitoring, and cross-project insights.</p>"},{"location":"user-guide/multi-project-orchestration/#overview","title":"Overview","text":"<p>Multi-project orchestration extends the single-project workflow system to handle multiple projects concurrently, providing:</p> <ul> <li>Global Resource Management: Intelligent allocation of CPU, memory, and agents across projects</li> <li>Project Prioritization: Priority-based scheduling and resource allocation</li> <li>Security Isolation: Project-level security boundaries and access control</li> <li>Cross-Project Intelligence: Pattern recognition and knowledge sharing between projects</li> <li>Real-time Monitoring: Comprehensive observability across all projects</li> <li>Unified Management Interface: Single command interface for all projects</li> </ul>"},{"location":"user-guide/multi-project-orchestration/#architecture","title":"Architecture","text":"<p>The multi-project system consists of several integrated components:</p> <pre><code>graph TB\n    A[Multi-Project Orchestrator] --&gt; B[Configuration Manager]\n    A --&gt; C[Global Orchestrator]\n    A --&gt; D[Resource Scheduler]\n    A --&gt; E[Security System]\n    A --&gt; F[Monitoring System]\n    A --&gt; G[Intelligence System]\n    A --&gt; H[Discord Bot]\n\n    C --&gt; I[Project Orchestrator 1]\n    C --&gt; J[Project Orchestrator 2]\n    C --&gt; K[Project Orchestrator N]\n\n    I --&gt; L[TDD State Machine 1]\n    J --&gt; M[TDD State Machine 2]\n    K --&gt; N[TDD State Machine N]</code></pre>"},{"location":"user-guide/multi-project-orchestration/#core-components","title":"Core Components","text":"<ol> <li>Multi-Project Orchestrator (<code>scripts/multi_project_orchestrator.py</code>)</li> <li>Unified entry point for the entire system</li> <li> <p>Coordinates all components and manages system lifecycle</p> </li> <li> <p>Configuration Manager (<code>lib/multi_project_config.py</code>)</p> </li> <li>Manages global and project-specific configurations</li> <li> <p>Handles project discovery and registration</p> </li> <li> <p>Global Orchestrator (<code>lib/global_orchestrator.py</code>)</p> </li> <li>Manages multiple project orchestrator subprocesses</li> <li> <p>Coordinates cross-project activities</p> </li> <li> <p>Resource Scheduler (<code>lib/resource_scheduler.py</code>)</p> </li> <li>Intelligent resource allocation across projects</li> <li> <p>Supports multiple scheduling strategies</p> </li> <li> <p>Security System (<code>lib/multi_project_security.py</code>)</p> </li> <li>User management and access control</li> <li> <p>Project isolation and security boundaries</p> </li> <li> <p>Monitoring System (<code>lib/multi_project_monitoring.py</code>)</p> </li> <li>Real-time metrics collection and alerting</li> <li> <p>WebSocket-based live updates</p> </li> <li> <p>Intelligence System (<code>lib/cross_project_intelligence.py</code>)</p> </li> <li>Pattern recognition across projects</li> <li>Knowledge transfer recommendations</li> </ol>"},{"location":"user-guide/multi-project-orchestration/#getting-started","title":"Getting Started","text":""},{"location":"user-guide/multi-project-orchestration/#installation","title":"Installation","text":"<p>The multi-project system uses the same dependencies as the single-project system, with optional additions for enhanced functionality:</p> <pre><code># Core dependencies (required)\npip install discord.py pygithub pyyaml pytest pytest-asyncio mkdocs-material\n\n# Optional monitoring dependencies\npip install psutil websockets\n\n# Optional visualization dependencies  \npip install prometheus_client grafana_api aiohttp\n</code></pre>"},{"location":"user-guide/multi-project-orchestration/#basic-setup","title":"Basic Setup","text":"<ol> <li> <p>Initialize Configuration <pre><code># Start the multi-project orchestrator\npython scripts/multi_project_orchestrator.py --discover .\n</code></pre></p> </li> <li> <p>Register Projects <pre><code># Register specific projects\npython scripts/multi_project_orchestrator.py --register myproject /path/to/project\n</code></pre></p> </li> <li> <p>Interactive Management <pre><code># Run interactive shell\npython scripts/multi_project_orchestrator.py --interactive\n</code></pre></p> </li> </ol>"},{"location":"user-guide/multi-project-orchestration/#configuration","title":"Configuration","text":""},{"location":"user-guide/multi-project-orchestration/#global-configuration","title":"Global Configuration","text":"<p>The global configuration is stored in <code>orch-config.yaml</code>:</p> <pre><code>global:\n  # Resource limits\n  max_total_agents: 20\n  max_concurrent_projects: 10\n  global_cpu_cores: 4\n  global_memory_limit_gb: 8\n  global_disk_limit_gb: 50\n\n  # Scheduling\n  resource_allocation_strategy: fair_share  # fair_share, priority_based, dynamic\n  scheduling_interval_seconds: 30\n  resource_rebalance_interval_seconds: 300\n\n  # Features\n  enable_cross_project_insights: true\n  enable_knowledge_sharing: true\n  enable_pattern_learning: true\n  enable_project_isolation: true\n\n  # Storage\n  global_state_path: .orch-global\n\n  # Integration\n  global_discord_guild: null\n  monitoring_webhook_url: null\n</code></pre>"},{"location":"user-guide/multi-project-orchestration/#project-configuration","title":"Project Configuration","text":"<p>Each project has its own configuration section:</p> <pre><code>projects:\n  my-project:\n    name: my-project\n    path: /path/to/project\n    priority: normal  # critical, high, normal, low\n    status: active    # active, paused, maintenance, archived, initializing\n\n    # Resource limits\n    resource_limits:\n      max_parallel_agents: 3\n      max_parallel_cycles: 2\n      max_memory_mb: 1024\n      max_disk_mb: 2048\n      cpu_priority: 1.0\n\n    # AI settings\n    ai_settings:\n      auto_approve_low_risk: true\n      require_human_review: false\n      max_auto_retry: 3\n      context_sharing_enabled: true\n\n    # Schedule\n    work_hours:\n      timezone: UTC\n      start: \"09:00\"\n      end: \"17:00\"\n      days: [monday, tuesday, wednesday, thursday, friday]\n\n    # Integration\n    discord_channel: null\n    slack_channel: null\n    team: []\n    dependencies: []\n</code></pre>"},{"location":"user-guide/multi-project-orchestration/#resource-management","title":"Resource Management","text":""},{"location":"user-guide/multi-project-orchestration/#allocation-strategies","title":"Allocation Strategies","text":"<p>The system supports multiple resource allocation strategies:</p>"},{"location":"user-guide/multi-project-orchestration/#fair-share","title":"Fair Share","text":"<p>Distributes resources equally among all active projects: <pre><code>resource_allocation_strategy: fair_share\n</code></pre></p>"},{"location":"user-guide/multi-project-orchestration/#priority-based","title":"Priority-Based","text":"<p>Allocates resources based on project priority: <pre><code>resource_allocation_strategy: priority_based\n</code></pre></p>"},{"location":"user-guide/multi-project-orchestration/#dynamic","title":"Dynamic","text":"<p>Automatically adjusts allocation based on actual usage: <pre><code>resource_allocation_strategy: dynamic\n</code></pre></p>"},{"location":"user-guide/multi-project-orchestration/#resource-quotas","title":"Resource Quotas","text":"<p>Each project receives a resource quota based on: - Global resource limits - Project priority - Current system load - Historical usage patterns</p> <pre><code># Example resource allocation\n{\n    \"project_name\": \"high-priority-project\",\n    \"allocated_agents\": 5,\n    \"allocated_memory_mb\": 2048,\n    \"allocated_cpu_percent\": 40.0,\n    \"priority_weight\": 1.5\n}\n</code></pre>"},{"location":"user-guide/multi-project-orchestration/#project-management","title":"Project Management","text":""},{"location":"user-guide/multi-project-orchestration/#project-discovery","title":"Project Discovery","text":"<p>The system can automatically discover projects in your filesystem:</p> <pre><code># Discover projects in current directory\npython scripts/multi_project_orchestrator.py --discover .\n\n# Discover in multiple paths\npython scripts/multi_project_orchestrator.py --discover /path1 /path2 /path3\n</code></pre> <p>Discovery looks for: - Existing <code>.orch-state</code> directories (orchestrated projects) - Git repositories with development activity - Common project structure patterns</p>"},{"location":"user-guide/multi-project-orchestration/#manual-registration","title":"Manual Registration","text":"<p>Register projects manually with specific configuration:</p> <pre><code># Basic registration\npython scripts/multi_project_orchestrator.py --register myproject /path/to/project\n\n# Interactive registration with full configuration\npython scripts/multi_project_orchestrator.py --interactive\n&gt; register myproject /path/to/project\n</code></pre>"},{"location":"user-guide/multi-project-orchestration/#project-lifecycle","title":"Project Lifecycle","text":"<p>Projects have the following lifecycle states:</p> <ul> <li>Initializing: Project is being set up</li> <li>Active: Project is available for orchestration</li> <li>Paused: Project is temporarily suspended</li> <li>Maintenance: Project is undergoing maintenance</li> <li>Archived: Project is archived but configuration preserved</li> </ul>"},{"location":"user-guide/multi-project-orchestration/#interactive-management","title":"Interactive Management","text":"<p>The interactive shell provides comprehensive project management:</p> <pre><code>python scripts/multi_project_orchestrator.py --interactive\n</code></pre>"},{"location":"user-guide/multi-project-orchestration/#available-commands","title":"Available Commands","text":"<pre><code>multi-orch&gt; help\nAvailable commands:\n  help                    - Show this help message\n  status [component]      - Show system status\n  projects                - List all projects\n  register &lt;name&gt; &lt;path&gt;  - Register a new project\n  discover &lt;paths...&gt;     - Discover and register projects\n  start &lt;project&gt;         - Start a project orchestrator\n  stop &lt;project&gt;          - Stop a project orchestrator\n  optimize                - Run resource optimization\n  insights                - Show cross-project insights\n  exit/quit               - Exit the shell\n</code></pre>"},{"location":"user-guide/multi-project-orchestration/#example-session","title":"Example Session","text":"<pre><code>multi-orch&gt; projects\n\ud83d\udccb Registered Projects:\n  \ud83d\udfe2 frontend-app (\ud83d\udfe0 high)\n    Path: /home/user/projects/frontend-app\n    Status: active\n  \ud83d\udfe2 backend-api (\ud83d\udfe1 normal)\n    Path: /home/user/projects/backend-api\n    Status: active\n\nmulti-orch&gt; status\n\ud83c\udf9b\ufe0f  Multi-Project Orchestrator Status\nRunning: True\nStartup Complete: True\nProjects: 2\nActive: 2\n\nmulti-orch&gt; optimize\n\ud83d\udd27 Resource Optimization Results:\n  Time: 0.15s\n  Changes: 3\n  Strategy: dynamic\n  Changes made:\n    - Increased memory allocation for frontend-app by 512MB\n    - Reduced CPU allocation for backend-api to 25%\n    - Balanced agent distribution across projects\n\nmulti-orch&gt; insights\n\ud83e\udde0 Cross-Project Insights (5 found):\n  \ud83d\udcca Common Testing Patterns\n     Both projects use similar Jest configuration patterns\n     Confidence: 85%\n\n  \ud83d\udcca Shared Dependency Management\n     npm/yarn lock files show similar dependency versions\n     Confidence: 92%\n</code></pre>"},{"location":"user-guide/multi-project-orchestration/#monitoring-and-observability","title":"Monitoring and Observability","text":""},{"location":"user-guide/multi-project-orchestration/#real-time-metrics","title":"Real-time Metrics","text":"<p>The monitoring system collects comprehensive metrics across all projects:</p>"},{"location":"user-guide/multi-project-orchestration/#project-metrics","title":"Project Metrics","text":"<ul> <li>CPU and memory usage</li> <li>Active agents and TDD cycles</li> <li>Story progress and completion rates</li> <li>Error rates and build times</li> </ul>"},{"location":"user-guide/multi-project-orchestration/#system-metrics","title":"System Metrics","text":"<ul> <li>Total resource utilization</li> <li>Cross-project pattern matches</li> <li>Security events and access patterns</li> <li>Performance and efficiency scores</li> </ul>"},{"location":"user-guide/multi-project-orchestration/#websocket-real-time-updates","title":"WebSocket Real-time Updates","text":"<p>Connect to the monitoring WebSocket for live updates:</p> <pre><code>// Connect to monitoring WebSocket\nconst ws = new WebSocket('ws://localhost:8765');\n\nws.onmessage = (event) =&gt; {\n    const data = JSON.parse(event.data);\n\n    if (data.type === 'metric_update') {\n        console.log('Metric update:', data.data);\n    } else if (data.type === 'alert_update') {\n        console.log('Alert:', data.data);\n    }\n};\n</code></pre>"},{"location":"user-guide/multi-project-orchestration/#alerts-and-notifications","title":"Alerts and Notifications","text":"<p>The system generates intelligent alerts based on: - Resource usage thresholds - Project health indicators - Security events - Performance anomalies</p>"},{"location":"user-guide/multi-project-orchestration/#security-and-isolation","title":"Security and Isolation","text":""},{"location":"user-guide/multi-project-orchestration/#user-management","title":"User Management","text":"<p>The security system provides comprehensive user management:</p> <pre><code># Create users with different access levels\nsecurity.create_user(\n    username=\"developer\",\n    email=\"dev@company.com\", \n    password=\"secure_password\",\n    global_access_level=AccessLevel.CONTRIBUTOR\n)\n\n# Grant project-specific access\nsecurity.grant_project_access(\"developer\", \"my-project\", AccessLevel.MAINTAINER)\n</code></pre>"},{"location":"user-guide/multi-project-orchestration/#access-levels","title":"Access Levels","text":"<ul> <li>OWNER: Full system administration</li> <li>ADMIN: Multi-project management</li> <li>MAINTAINER: Project-level administration</li> <li>CONTRIBUTOR: Development access</li> <li>VIEWER: Read-only access</li> </ul>"},{"location":"user-guide/multi-project-orchestration/#project-isolation","title":"Project Isolation","text":"<p>Projects are isolated using multiple mechanisms:</p>"},{"location":"user-guide/multi-project-orchestration/#process-isolation","title":"Process Isolation","text":"<p>Each project runs in its own subprocess with resource limits.</p>"},{"location":"user-guide/multi-project-orchestration/#filesystem-isolation","title":"Filesystem Isolation","text":"<p>Projects have restricted filesystem access to their designated paths.</p>"},{"location":"user-guide/multi-project-orchestration/#network-isolation","title":"Network Isolation","text":"<p>Projects can be assigned to separate network namespaces.</p>"},{"location":"user-guide/multi-project-orchestration/#container-isolation","title":"Container Isolation","text":"<p>Projects can run in Docker containers for maximum isolation.</p>"},{"location":"user-guide/multi-project-orchestration/#cross-project-intelligence","title":"Cross-Project Intelligence","text":""},{"location":"user-guide/multi-project-orchestration/#pattern-recognition","title":"Pattern Recognition","text":"<p>The intelligence system automatically identifies patterns across projects:</p> <pre><code># Patterns detected include:\n- Code architecture similarities\n- Testing strategy patterns\n- Dependency management approaches\n- Development workflow similarities\n- Performance optimization opportunities\n</code></pre>"},{"location":"user-guide/multi-project-orchestration/#knowledge-transfer","title":"Knowledge Transfer","text":"<p>Based on detected patterns, the system recommends knowledge transfers:</p> <pre><code>{\n    \"source_project\": \"backend-api\",\n    \"target_project\": \"frontend-app\", \n    \"transfer_type\": \"optimization\",\n    \"description\": \"API caching strategy from backend-api could improve frontend performance\",\n    \"confidence\": 0.87,\n    \"estimated_impact\": \"medium\"\n}\n</code></pre>"},{"location":"user-guide/multi-project-orchestration/#best-practices-sharing","title":"Best Practices Sharing","text":"<p>The system learns and shares best practices across projects:</p> <ul> <li>Successful testing strategies</li> <li>Effective code organization patterns</li> <li>Performance optimization techniques</li> <li>Security implementation patterns</li> </ul>"},{"location":"user-guide/multi-project-orchestration/#discord-integration","title":"Discord Integration","text":""},{"location":"user-guide/multi-project-orchestration/#multi-project-bot-commands","title":"Multi-Project Bot Commands","text":"<p>The enhanced Discord bot provides multi-project management:</p> <pre><code>/global_status          - Show global orchestration status\n/project_list           - List all registered projects\n/project_start &lt;name&gt;   - Start a specific project\n/project_stop &lt;name&gt;    - Stop a specific project\n/resource_status        - Show resource allocation\n/insights               - Show cross-project insights\n</code></pre>"},{"location":"user-guide/multi-project-orchestration/#project-specific-channels","title":"Project-Specific Channels","text":"<p>Each project can have its own Discord channel for focused communication:</p> <pre><code>projects:\n  my-project:\n    discord_channel: \"#my-project-dev\"\n</code></pre>"},{"location":"user-guide/multi-project-orchestration/#performance-and-scaling","title":"Performance and Scaling","text":""},{"location":"user-guide/multi-project-orchestration/#resource-optimization","title":"Resource Optimization","text":"<p>The system continuously optimizes resource allocation:</p> <ul> <li>Predictive Scaling: Anticipates resource needs based on project patterns</li> <li>Load Balancing: Distributes work across available resources</li> <li>Efficiency Monitoring: Tracks and improves resource utilization</li> </ul>"},{"location":"user-guide/multi-project-orchestration/#scaling-considerations","title":"Scaling Considerations","text":""},{"location":"user-guide/multi-project-orchestration/#horizontal-scaling","title":"Horizontal Scaling","text":"<ul> <li>Add more CPU cores and memory for increased project capacity</li> <li>Distribute projects across multiple machines (future enhancement)</li> </ul>"},{"location":"user-guide/multi-project-orchestration/#vertical-scaling","title":"Vertical Scaling","text":"<ul> <li>Optimize individual project resource usage</li> <li>Improve agent efficiency and cycle times</li> </ul>"},{"location":"user-guide/multi-project-orchestration/#performance-metrics","title":"Performance Metrics","text":"<p>Monitor system performance with key metrics:</p> <pre><code>{\n    \"resource_efficiency\": 0.87,      # How well resources are utilized\n    \"average_cycle_time_hours\": 2.3,  # Average TDD cycle completion time\n    \"cross_project_insights\": 15,     # Number of insights generated\n    \"total_stories_completed\": 42,    # Stories completed across all projects\n    \"system_health_score\": 0.92       # Overall system health (0.0-1.0)\n}\n</code></pre>"},{"location":"user-guide/multi-project-orchestration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/multi-project-orchestration/#common-issues","title":"Common Issues","text":""},{"location":"user-guide/multi-project-orchestration/#resource-allocation-failures","title":"Resource Allocation Failures","text":"<pre><code># Check resource allocation status\npython scripts/multi_project_orchestrator.py --status\n\n# Run optimization\npython scripts/multi_project_orchestrator.py --interactive\n&gt; optimize\n</code></pre>"},{"location":"user-guide/multi-project-orchestration/#project-start-failures","title":"Project Start Failures","text":"<pre><code># Check project configuration\npython scripts/multi_project_orchestrator.py --interactive\n&gt; projects\n\n# Verify project paths and permissions\nls -la /path/to/project/.orch-state/\n</code></pre>"},{"location":"user-guide/multi-project-orchestration/#monitoring-connection-issues","title":"Monitoring Connection Issues","text":"<pre><code># Check if monitoring system is running\ncurl http://localhost:8765/status\n\n# Restart monitoring system\npython scripts/multi_project_orchestrator.py --no-intelligence --no-discord\n</code></pre>"},{"location":"user-guide/multi-project-orchestration/#debug-mode","title":"Debug Mode","text":"<p>Enable debug logging for detailed troubleshooting:</p> <pre><code>python scripts/multi_project_orchestrator.py --debug --interactive\n</code></pre>"},{"location":"user-guide/multi-project-orchestration/#log-analysis","title":"Log Analysis","text":"<p>System logs are organized by component:</p> <pre><code>.orch-global/\n\u251c\u2500\u2500 logs/\n\u2502   \u251c\u2500\u2500 global-orchestrator.log\n\u2502   \u251c\u2500\u2500 resource-scheduler.log\n\u2502   \u251c\u2500\u2500 security.log\n\u2502   \u251c\u2500\u2500 monitoring.log\n\u2502   \u2514\u2500\u2500 intelligence.log\n\u2514\u2500\u2500 status/\n    \u251c\u2500\u2500 system-health.json\n    \u2514\u2500\u2500 performance-metrics.json\n</code></pre>"},{"location":"user-guide/multi-project-orchestration/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/multi-project-orchestration/#project-organization","title":"Project Organization","text":"<ol> <li>Use Consistent Structure: Maintain similar project layouts for better pattern recognition</li> <li>Set Appropriate Priorities: Use priority levels to ensure critical projects get resources</li> <li>Configure Work Hours: Set realistic work schedules to optimize resource allocation</li> <li>Enable Context Sharing: Allow cross-project learning when projects are related</li> </ol>"},{"location":"user-guide/multi-project-orchestration/#resource-management_1","title":"Resource Management","text":"<ol> <li>Monitor Usage Patterns: Review resource utilization regularly</li> <li>Adjust Allocations: Update resource limits based on actual needs</li> <li>Use Dynamic Scaling: Enable dynamic allocation for better efficiency</li> <li>Plan for Peak Loads: Reserve resources for high-priority work periods</li> </ol>"},{"location":"user-guide/multi-project-orchestration/#security","title":"Security","text":"<ol> <li>Regular Access Reviews: Audit user access permissions periodically</li> <li>Project Isolation: Use appropriate isolation levels for sensitive projects</li> <li>Secure Credentials: Use environment variables for sensitive configuration</li> <li>Audit Logging: Enable audit logging for compliance and security monitoring</li> </ol>"},{"location":"user-guide/multi-project-orchestration/#performance","title":"Performance","text":"<ol> <li>Optimize Cycle Times: Focus on reducing TDD cycle completion times</li> <li>Balance Workloads: Distribute work evenly across available resources</li> <li>Monitor Health Scores: Track system health and address issues promptly</li> <li>Leverage Insights: Act on cross-project intelligence recommendations</li> </ol>"},{"location":"user-guide/multi-project-orchestration/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"user-guide/multi-project-orchestration/#custom-scheduling-strategies","title":"Custom Scheduling Strategies","text":"<p>Implement custom resource allocation strategies:</p> <pre><code>class CustomSchedulingStrategy(SchedulingStrategy):\n    def calculate_allocation(self, projects, total_resources):\n        # Custom allocation logic\n        pass\n</code></pre>"},{"location":"user-guide/multi-project-orchestration/#integration-with-external-systems","title":"Integration with External Systems","text":"<p>Connect to external monitoring and management systems:</p> <pre><code>global:\n  monitoring_webhook_url: \"https://your-monitoring-system.com/webhook\"\n  external_metrics_endpoint: \"https://metrics.company.com/api\"\n</code></pre>"},{"location":"user-guide/multi-project-orchestration/#advanced-security-configuration","title":"Advanced Security Configuration","text":"<p>Configure advanced security features:</p> <pre><code>global:\n  security:\n    encryption_at_rest: true\n    audit_log_retention_days: 90\n    require_2fa: true\n    session_timeout_minutes: 480\n</code></pre>"},{"location":"user-guide/multi-project-orchestration/#future-enhancements","title":"Future Enhancements","text":"<p>The multi-project orchestration system is designed for extensibility. Planned enhancements include:</p> <ul> <li>Distributed Orchestration: Multi-machine project distribution</li> <li>Advanced AI Integration: GPT-4 powered project optimization</li> <li>Cloud Integration: AWS/Azure/GCP resource provisioning</li> <li>Advanced Analytics: Machine learning for pattern recognition</li> <li>GitOps Integration: Git-based configuration and deployment</li> </ul>"},{"location":"user-guide/multi-project-orchestration/#support-and-community","title":"Support and Community","text":"<p>For support with multi-project orchestration:</p> <ol> <li>Documentation: Review this guide and the main project documentation</li> <li>Issues: Report bugs and feature requests on GitHub</li> <li>Discussions: Join community discussions for best practices</li> <li>Contributing: Contribute improvements and extensions</li> </ol> <p>The multi-project orchestration system represents a significant advancement in AI-assisted development, providing the tools and intelligence needed to manage complex, multi-project development workflows efficiently and effectively.</p>"},{"location":"user-guide/performance-optimization/","title":"Performance &amp; Optimization Guide","text":"<p>Comprehensive guide to optimizing the AI Agent TDD-Scrum workflow system for production performance, scalability, and resource efficiency.</p>"},{"location":"user-guide/performance-optimization/#performance-overview","title":"Performance Overview","text":""},{"location":"user-guide/performance-optimization/#system-performance-characteristics","title":"System Performance Characteristics","text":"<p>Typical Performance Metrics: - Command Response Time: 100-500ms (Discord commands) - Agent Task Execution: 5-30 seconds (depending on complexity) - State Transitions: &lt;10ms (local operations) - Memory Usage: 100-500MB (base system + active projects) - Concurrent Projects: 1-10 (depending on resources)</p>"},{"location":"user-guide/performance-optimization/#performance-bottlenecks","title":"Performance Bottlenecks","text":"<p>Primary Bottlenecks: 1. AI API Latency - Agent execution limited by AI service response times 2. Git Operations - Large repositories slow commit/push operations 3. Test Execution - Comprehensive test suites impact TDD cycle timing 4. State Persistence - Frequent state saves with large project data 5. Discord Rate Limits - Command throughput limited by Discord API</p>"},{"location":"user-guide/performance-optimization/#system-resource-optimization","title":"System Resource Optimization","text":""},{"location":"user-guide/performance-optimization/#memory-optimization","title":"Memory Optimization","text":""},{"location":"user-guide/performance-optimization/#agent-memory-management","title":"Agent Memory Management","text":"<pre><code># Configure agent memory limits\norchestrator:\n  agents:\n    memory_limit_mb: 256        # Per-agent memory limit\n    cleanup_interval: 300       # Memory cleanup every 5 minutes\n    cache_timeout: 1800         # Agent cache expiration (30 minutes)\n\n  # Global memory settings\n  max_memory_usage_mb: 2048     # Total system memory limit\n  memory_warning_threshold: 0.8 # Warning at 80% usage\n  automatic_gc_enabled: true    # Enable garbage collection\n</code></pre>"},{"location":"user-guide/performance-optimization/#project-data-optimization","title":"Project Data Optimization","text":"<pre><code># Optimize project data handling\nstorage:\n  compression_enabled: true     # Compress stored data\n  max_state_history: 100       # Limit state history retention\n  prune_old_data_days: 30      # Auto-cleanup old data\n\n  # Cache configuration\n  cache:\n    enabled: true\n    max_size_mb: 128           # Cache size limit\n    ttl_seconds: 3600          # Cache TTL (1 hour)\n</code></pre>"},{"location":"user-guide/performance-optimization/#memory-monitoring","title":"Memory Monitoring","text":"<pre><code># Monitor memory usage\nimport psutil\nimport gc\nfrom lib.monitoring import MemoryMonitor\n\nmonitor = MemoryMonitor()\n\n# Set up memory alerts\nmonitor.configure_alerts(\n    warning_threshold=0.75,     # 75% memory usage\n    critical_threshold=0.90,    # 90% memory usage\n    cleanup_threshold=0.85      # Trigger cleanup at 85%\n)\n\n# Automatic cleanup\nasync def memory_cleanup():\n    \"\"\"Automatic memory management\"\"\"\n    memory_percent = psutil.virtual_memory().percent\n\n    if memory_percent &gt; 85:\n        gc.collect()                    # Force garbage collection\n        await cleanup_agent_caches()   # Clear agent caches\n        await compress_state_data()    # Compress stored data\n</code></pre>"},{"location":"user-guide/performance-optimization/#cpu-optimization","title":"CPU Optimization","text":""},{"location":"user-guide/performance-optimization/#concurrent-processing","title":"Concurrent Processing","text":"<pre><code># Optimize concurrent operations\norchestrator:\n  concurrency:\n    max_worker_threads: 8       # CPU cores * 2\n    agent_pool_size: 4          # Concurrent agents\n    async_task_limit: 20        # Max async tasks\n\n  # Task prioritization\n  priority_queues:\n    high_priority: [\"epic\", \"approve\", \"state\"]\n    normal_priority: [\"sprint\", \"backlog\"]\n    low_priority: [\"metrics\", \"cleanup\"]\n</code></pre>"},{"location":"user-guide/performance-optimization/#agent-execution-optimization","title":"Agent Execution Optimization","text":"<pre><code># Optimize agent performance\nclass OptimizedOrchestrator:\n    def __init__(self):\n        self.executor = ThreadPoolExecutor(max_workers=4)\n        self.semaphore = asyncio.Semaphore(4)\n\n    async def execute_agent_task(self, agent, task):\n        \"\"\"Optimized agent execution with resource management\"\"\"\n        async with self.semaphore:\n            # Pre-execution optimization\n            task = await self.optimize_task_context(task)\n\n            # Execute with timeout and resource limits\n            try:\n                result = await asyncio.wait_for(\n                    agent.run(task),\n                    timeout=300  # 5-minute timeout\n                )\n                return result\n\n            except asyncio.TimeoutError:\n                await self.handle_timeout(agent, task)\n\n    async def optimize_task_context(self, task):\n        \"\"\"Optimize task context for better performance\"\"\"\n        # Compress large context data\n        if len(task.context.get('description', '')) &gt; 5000:\n            task.context['description'] = self.compress_text(\n                task.context['description']\n            )\n\n        # Cache frequently used data\n        await self.cache_common_data(task)\n\n        return task\n</code></pre>"},{"location":"user-guide/performance-optimization/#storage-optimization","title":"Storage Optimization","text":""},{"location":"user-guide/performance-optimization/#database-performance","title":"Database Performance","text":"<pre><code># Optimize data storage\nstorage:\n  file_operations:\n    batch_writes: true          # Batch multiple writes\n    async_writes: true          # Non-blocking writes\n    compression: gzip           # Compress stored files\n\n  # State management\n  state_persistence:\n    write_frequency: 60         # Write every 60 seconds\n    incremental_saves: true     # Only save changes\n    background_saves: true      # Non-blocking saves\n</code></pre>"},{"location":"user-guide/performance-optimization/#file-system-optimization","title":"File System Optimization","text":"<pre><code># Optimize file operations\nimport aiofiles\nimport asyncio\nfrom concurrent.futures import ThreadPoolExecutor\n\nclass OptimizedStorage:\n    def __init__(self):\n        self.write_executor = ThreadPoolExecutor(max_workers=2)\n        self.write_queue = asyncio.Queue(maxsize=100)\n\n    async def batch_write_states(self, states):\n        \"\"\"Batch write multiple states for efficiency\"\"\"\n        write_tasks = []\n\n        for project_id, state in states.items():\n            task = self.write_state_async(project_id, state)\n            write_tasks.append(task)\n\n        # Execute all writes concurrently\n        await asyncio.gather(*write_tasks, return_exceptions=True)\n\n    async def write_state_async(self, project_id, state):\n        \"\"\"Non-blocking state write with compression\"\"\"\n        compressed_state = await self.compress_state(state)\n\n        async with aiofiles.open(\n            f\".orch-state/{project_id}/status.json.gz\", \n            'wb'\n        ) as f:\n            await f.write(compressed_state)\n</code></pre>"},{"location":"user-guide/performance-optimization/#network-api-optimization","title":"Network &amp; API Optimization","text":""},{"location":"user-guide/performance-optimization/#discord-api-optimization","title":"Discord API Optimization","text":""},{"location":"user-guide/performance-optimization/#rate-limit-management","title":"Rate Limit Management","text":"<pre><code># Intelligent rate limiting\nimport asyncio\nfrom collections import deque\nimport time\n\nclass DiscordRateLimiter:\n    def __init__(self):\n        self.requests = deque()\n        self.max_requests_per_minute = 50\n\n    async def acquire(self):\n        \"\"\"Smart rate limiting with burst handling\"\"\"\n        now = time.time()\n\n        # Remove old requests (older than 1 minute)\n        while self.requests and now - self.requests[0] &gt; 60:\n            self.requests.popleft()\n\n        # Check if we can make a request\n        if len(self.requests) &gt;= self.max_requests_per_minute:\n            # Calculate wait time\n            wait_time = 60 - (now - self.requests[0])\n            await asyncio.sleep(wait_time)\n\n        self.requests.append(now)\n\n    async def send_message_optimized(self, channel, message):\n        \"\"\"Rate-limited message sending with batching\"\"\"\n        await self.acquire()\n\n        # Batch small messages if possible\n        if len(message) &lt; 500:\n            await self.batch_small_messages(channel, message)\n        else:\n            await channel.send(message)\n</code></pre>"},{"location":"user-guide/performance-optimization/#message-optimization","title":"Message Optimization","text":"<pre><code># Optimize Discord message handling\nclass OptimizedDiscordBot:\n    def __init__(self):\n        self.message_cache = {}\n        self.batch_messages = []\n\n    async def send_optimized_message(self, channel, content):\n        \"\"\"Optimized message sending with caching and compression\"\"\"\n        # Check cache for repeated messages\n        message_hash = hash(content)\n        if message_hash in self.message_cache:\n            cached_msg = self.message_cache[message_hash]\n            await channel.send(f\"\ud83d\udccb (Cached) {cached_msg}\")\n            return\n\n        # Compress long messages\n        if len(content) &gt; 1500:\n            content = await self.compress_message(content)\n\n        # Send with optimizations\n        try:\n            await self.rate_limiter.acquire()\n            message = await channel.send(content)\n\n            # Cache successful messages\n            self.message_cache[message_hash] = content[:100] + \"...\"\n\n        except discord.HTTPException as e:\n            await self.handle_discord_error(e, channel, content)\n</code></pre>"},{"location":"user-guide/performance-optimization/#ai-api-optimization","title":"AI API Optimization","text":""},{"location":"user-guide/performance-optimization/#request-batching","title":"Request Batching","text":"<pre><code># Optimize AI API calls\nclass AIAPIOptimizer:\n    def __init__(self):\n        self.request_queue = asyncio.Queue()\n        self.batch_size = 3\n        self.batch_timeout = 5.0\n\n    async def batch_ai_requests(self):\n        \"\"\"Batch multiple AI requests for efficiency\"\"\"\n        batch = []\n\n        try:\n            # Collect requests for batching\n            while len(batch) &lt; self.batch_size:\n                request = await asyncio.wait_for(\n                    self.request_queue.get(),\n                    timeout=self.batch_timeout\n                )\n                batch.append(request)\n\n        except asyncio.TimeoutError:\n            pass  # Process partial batch\n\n        if batch:\n            await self.process_batch(batch)\n\n    async def process_batch(self, requests):\n        \"\"\"Process batched requests efficiently\"\"\"\n        # Combine contexts for related requests\n        combined_context = self.combine_contexts(requests)\n\n        # Execute with shared context\n        tasks = []\n        for request in requests:\n            task = self.execute_with_shared_context(\n                request, combined_context\n            )\n            tasks.append(task)\n\n        results = await asyncio.gather(*tasks)\n        return results\n</code></pre>"},{"location":"user-guide/performance-optimization/#context-optimization","title":"Context Optimization","text":"<pre><code># Optimize AI context handling\nclass ContextOptimizer:\n    def __init__(self):\n        self.context_cache = {}\n        self.max_context_length = 50000\n\n    async def optimize_context(self, task_context):\n        \"\"\"Optimize context for AI processing\"\"\"\n        # Check cache first\n        context_key = self.generate_context_key(task_context)\n        if context_key in self.context_cache:\n            return self.context_cache[context_key]\n\n        # Compress large contexts\n        optimized_context = await self.compress_context(task_context)\n\n        # Remove redundant information\n        optimized_context = self.deduplicate_context(optimized_context)\n\n        # Cache for future use\n        self.context_cache[context_key] = optimized_context\n\n        return optimized_context\n\n    async def compress_context(self, context):\n        \"\"\"Intelligent context compression\"\"\"\n        if len(str(context)) &lt;= self.max_context_length:\n            return context\n\n        # Prioritize important context elements\n        compressed = {\n            'story_id': context.get('story_id'),\n            'description': context.get('description', '')[:2000],\n            'acceptance_criteria': context.get('acceptance_criteria', [])[:5],\n            'recent_changes': context.get('recent_changes', [])[:3]\n        }\n\n        return compressed\n</code></pre>"},{"location":"user-guide/performance-optimization/#tdd-performance-optimization","title":"TDD Performance Optimization","text":""},{"location":"user-guide/performance-optimization/#test-execution-optimization","title":"Test Execution Optimization","text":""},{"location":"user-guide/performance-optimization/#parallel-test-execution","title":"Parallel Test Execution","text":"<pre><code># Optimize TDD test execution\ntdd:\n  test_execution:\n    parallel_execution: true\n    max_parallel_jobs: 4        # CPU cores\n    test_timeout_seconds: 120   # Individual test timeout\n\n    # Test discovery optimization\n    discovery:\n      cache_test_lists: true\n      incremental_discovery: true\n      fast_fail: true           # Stop on first failure\n\n    # Coverage optimization\n    coverage:\n      parallel_coverage: true\n      incremental_coverage: true\n      cache_coverage_data: true\n</code></pre>"},{"location":"user-guide/performance-optimization/#intelligent-test-sequencing","title":"Intelligent Test Sequencing","text":"<pre><code># Optimize test execution order\nclass TDDTestOptimizer:\n    def __init__(self):\n        self.test_timing_cache = {}\n        self.failure_history = {}\n\n    async def optimize_test_sequence(self, test_files):\n        \"\"\"Optimize test execution order for performance\"\"\"\n        # Sort by historical execution time\n        timed_tests = []\n        for test_file in test_files:\n            avg_time = self.test_timing_cache.get(test_file.path, 1.0)\n            failure_rate = self.failure_history.get(test_file.path, 0.0)\n\n            # Prioritize fast, reliable tests first\n            priority = (1.0 / avg_time) * (1.0 - failure_rate)\n            timed_tests.append((test_file, priority))\n\n        # Sort by priority (highest first)\n        timed_tests.sort(key=lambda x: x[1], reverse=True)\n\n        return [test for test, _ in timed_tests]\n\n    async def execute_optimized_tests(self, test_files):\n        \"\"\"Execute tests with performance optimization\"\"\"\n        optimized_sequence = await self.optimize_test_sequence(test_files)\n\n        # Execute in parallel batches\n        batch_size = 4\n        results = []\n\n        for i in range(0, len(optimized_sequence), batch_size):\n            batch = optimized_sequence[i:i+batch_size]\n\n            batch_tasks = [\n                self.execute_single_test(test_file)\n                for test_file in batch\n            ]\n\n            batch_results = await asyncio.gather(*batch_tasks)\n            results.extend(batch_results)\n\n        return results\n</code></pre>"},{"location":"user-guide/performance-optimization/#tdd-cycle-optimization","title":"TDD Cycle Optimization","text":""},{"location":"user-guide/performance-optimization/#state-transition-optimization","title":"State Transition Optimization","text":"<pre><code># Optimize TDD state transitions\nclass OptimizedTDDStateMachine:\n    def __init__(self):\n        self.transition_cache = {}\n        self.condition_cache = {}\n\n    async def fast_transition(self, command, cycle):\n        \"\"\"Optimized state transition with caching\"\"\"\n        # Check transition cache\n        cache_key = (cycle.current_state, command)\n        if cache_key in self.transition_cache:\n            cached_result = self.transition_cache[cache_key]\n            if cached_result.success:\n                return await self.apply_cached_transition(cycle, cached_result)\n\n        # Check conditions efficiently\n        conditions_met = await self.fast_condition_check(command, cycle)\n\n        if conditions_met:\n            result = await self.execute_transition(command, cycle)\n\n            # Cache successful transitions\n            self.transition_cache[cache_key] = result\n\n            return result\n        else:\n            return self.create_failure_result(command, cycle)\n\n    async def fast_condition_check(self, command, cycle):\n        \"\"\"Optimized condition checking with caching\"\"\"\n        condition_key = (command, cycle.story_id, cycle.current_state)\n\n        if condition_key in self.condition_cache:\n            cached_time, cached_result = self.condition_cache[condition_key]\n\n            # Use cached result if recent (within 30 seconds)\n            if time.time() - cached_time &lt; 30:\n                return cached_result\n\n        # Perform condition check\n        result = await self.check_transition_conditions(command, cycle)\n\n        # Cache result\n        self.condition_cache[condition_key] = (time.time(), result)\n\n        return result\n</code></pre>"},{"location":"user-guide/performance-optimization/#monitoring-performance-metrics","title":"Monitoring &amp; Performance Metrics","text":""},{"location":"user-guide/performance-optimization/#real-time-performance-monitoring","title":"Real-Time Performance Monitoring","text":""},{"location":"user-guide/performance-optimization/#metrics-collection","title":"Metrics Collection","text":"<pre><code># Comprehensive performance monitoring\nfrom prometheus_client import Counter, Histogram, Gauge, start_http_server\nimport time\nimport psutil\n\nclass PerformanceMonitor:\n    def __init__(self):\n        # Define metrics\n        self.command_duration = Histogram(\n            'discord_command_duration_seconds',\n            'Discord command execution time',\n            ['command_type', 'status']\n        )\n\n        self.agent_execution_time = Histogram(\n            'agent_execution_seconds',\n            'Agent task execution time',\n            ['agent_type', 'task_type']\n        )\n\n        self.memory_usage = Gauge(\n            'system_memory_usage_bytes',\n            'System memory usage'\n        )\n\n        self.active_projects = Gauge(\n            'active_projects_total',\n            'Number of active projects'\n        )\n\n        self.tdd_cycle_time = Histogram(\n            'tdd_cycle_duration_seconds',\n            'TDD cycle completion time',\n            ['phase']\n        )\n\n    async def monitor_performance(self):\n        \"\"\"Continuous performance monitoring\"\"\"\n        while True:\n            # Update system metrics\n            self.memory_usage.set(psutil.virtual_memory().used)\n\n            # Update application metrics\n            self.active_projects.set(len(self.get_active_projects()))\n\n            await asyncio.sleep(10)  # Update every 10 seconds\n\n    def record_command_execution(self, command, duration, status):\n        \"\"\"Record Discord command performance\"\"\"\n        self.command_duration.labels(\n            command_type=command,\n            status=status\n        ).observe(duration)\n\n    def record_agent_execution(self, agent_type, task_type, duration):\n        \"\"\"Record agent performance\"\"\"\n        self.agent_execution_time.labels(\n            agent_type=agent_type,\n            task_type=task_type\n        ).observe(duration)\n</code></pre>"},{"location":"user-guide/performance-optimization/#performance-alerts","title":"Performance Alerts","text":"<pre><code># Performance alerting system\nclass PerformanceAlerter:\n    def __init__(self):\n        self.thresholds = {\n            'command_response_time': 5.0,      # 5 seconds\n            'agent_execution_time': 60.0,      # 1 minute\n            'memory_usage_percent': 85.0,      # 85%\n            'error_rate_percent': 10.0         # 10%\n        }\n\n    async def check_performance_alerts(self):\n        \"\"\"Monitor and alert on performance issues\"\"\"\n        # Check command response times\n        avg_response_time = await self.get_avg_response_time()\n        if avg_response_time &gt; self.thresholds['command_response_time']:\n            await self.send_alert(\n                'HIGH_RESPONSE_TIME',\n                f'Average response time: {avg_response_time:.2f}s'\n            )\n\n        # Check memory usage\n        memory_percent = psutil.virtual_memory().percent\n        if memory_percent &gt; self.thresholds['memory_usage_percent']:\n            await self.send_alert(\n                'HIGH_MEMORY_USAGE',\n                f'Memory usage: {memory_percent:.1f}%'\n            )\n\n        # Check error rates\n        error_rate = await self.calculate_error_rate()\n        if error_rate &gt; self.thresholds['error_rate_percent']:\n            await self.send_alert(\n                'HIGH_ERROR_RATE',\n                f'Error rate: {error_rate:.1f}%'\n            )\n</code></pre>"},{"location":"user-guide/performance-optimization/#configuration-optimization","title":"Configuration Optimization","text":""},{"location":"user-guide/performance-optimization/#production-performance-configuration","title":"Production Performance Configuration","text":""},{"location":"user-guide/performance-optimization/#high-performance-configuration","title":"High-Performance Configuration","text":"<pre><code># config/performance.yml - Optimized for performance\norchestrator:\n  mode: autonomous              # Reduce human approval overhead\n  max_concurrent_projects: 6    # Scale based on resources\n\n  # Agent optimization\n  agents:\n    timeout_minutes: 20         # Reduced timeout for faster failure\n    max_retries: 2              # Fewer retries for speed\n    pool_size: 6                # Larger agent pool\n\n  # State management\n  state_management:\n    save_interval_seconds: 120  # Less frequent saves\n    compression_enabled: true   # Compress state data\n    background_saves: true      # Non-blocking saves\n\n  # Memory optimization\n  memory:\n    max_usage_mb: 4096          # 4GB limit\n    cleanup_interval: 300       # 5-minute cleanup\n    cache_size_mb: 512          # 512MB cache\n\ndiscord:\n  # Rate limiting optimization\n  rate_limiting:\n    commands_per_minute: 60     # Higher rate limit\n    burst_size: 10              # Allow bursts\n    backoff_strategy: exponential\n\n  # Message optimization\n  messages:\n    batch_small_messages: true\n    compress_long_messages: true\n    cache_repeated_messages: true\n\ntdd:\n  # Test execution optimization\n  test_execution:\n    parallel_jobs: 8            # More parallel jobs\n    timeout_seconds: 60         # Shorter test timeout\n    fast_fail: true             # Stop on first failure\n\n  # Quality gates optimization\n  quality_gates:\n    reduced_checks: true        # Fewer quality checks\n    coverage_threshold: 80      # Lower threshold for speed\n\nlogging:\n  level: WARNING                # Reduce log volume\n  async_logging: true           # Non-blocking logging\n  buffer_size: 1000            # Larger log buffer\n</code></pre>"},{"location":"user-guide/performance-optimization/#memory-optimized-configuration","title":"Memory-Optimized Configuration","text":"<pre><code># config/memory-optimized.yml - For resource-constrained environments\norchestrator:\n  max_concurrent_projects: 2    # Fewer concurrent projects\n\n  agents:\n    pool_size: 2                # Smaller agent pool\n    memory_limit_mb: 128        # Per-agent memory limit\n\n  memory:\n    max_usage_mb: 1024          # 1GB total limit\n    cleanup_interval: 60        # Frequent cleanup\n    aggressive_gc: true         # Aggressive garbage collection\n\n  # Reduce caching\n  caching:\n    enabled: false              # Disable caching to save memory\n\ntdd:\n  test_execution:\n    parallel_jobs: 2            # Fewer parallel jobs\n    memory_limit_mb: 256        # Test execution memory limit\n\nlogging:\n  level: ERROR                  # Minimal logging\n  max_file_size_mb: 10         # Smaller log files\n</code></pre>"},{"location":"user-guide/performance-optimization/#performance-tuning-checklist","title":"Performance Tuning Checklist","text":""},{"location":"user-guide/performance-optimization/#system-level","title":"System Level","text":"<ul> <li> Memory Usage &lt; 85% of available RAM</li> <li> CPU Usage &lt; 80% sustained load</li> <li> Disk I/O &lt; 80% utilization</li> <li> Network Latency &lt; 100ms to Discord/AI APIs</li> </ul>"},{"location":"user-guide/performance-optimization/#application-level","title":"Application Level","text":"<ul> <li> Command Response &lt; 5 seconds average</li> <li> Agent Execution &lt; 60 seconds average</li> <li> State Transitions &lt; 100ms</li> <li> Error Rate &lt; 5% of operations</li> </ul>"},{"location":"user-guide/performance-optimization/#tdd-performance","title":"TDD Performance","text":"<ul> <li> Test Execution &lt; 2 minutes per phase</li> <li> Cycle Completion &lt; 15 minutes total</li> <li> Parallel Efficiency &gt; 70% CPU utilization</li> <li> Test Coverage gathering &lt; 30 seconds</li> </ul>"},{"location":"user-guide/performance-optimization/#monitoring","title":"Monitoring","text":"<ul> <li> Metrics Collection enabled and functional</li> <li> Performance Alerts configured and tested</li> <li> Log Aggregation working properly</li> <li> Dashboard displaying key metrics</li> </ul>"},{"location":"user-guide/performance-optimization/#troubleshooting-performance-issues","title":"Troubleshooting Performance Issues","text":""},{"location":"user-guide/performance-optimization/#common-performance-problems","title":"Common Performance Problems","text":""},{"location":"user-guide/performance-optimization/#slow-command-response","title":"Slow Command Response","text":"<p>Symptoms: Discord commands take &gt;10 seconds to respond Diagnosis: <pre><code># Check system resources\ntop -p $(pgrep -f orchestrator)\niostat -x 1 5\n\n# Check Discord API latency\ncurl -w \"@curl-format.txt\" -o /dev/null -s \"https://discord.com/api/v10/gateway\"\n\n# Review logs for bottlenecks\ngrep -E \"(took|duration|elapsed)\" logs/orchestrator.log | tail -20\n</code></pre></p> <p>Solutions: - Increase agent pool size - Enable request batching - Optimize message compression - Check network connectivity</p>"},{"location":"user-guide/performance-optimization/#high-memory-usage","title":"High Memory Usage","text":"<p>Symptoms: Memory usage &gt;90%, frequent garbage collection Diagnosis: <pre><code>import psutil\nimport tracemalloc\n\n# Enable memory tracing\ntracemalloc.start()\n\n# Run system for period, then check top consumers\ncurrent, peak = tracemalloc.get_traced_memory()\nsnapshot = tracemalloc.take_snapshot()\ntop_stats = snapshot.statistics('lineno')\n\nfor stat in top_stats[:10]:\n    print(stat)\n</code></pre></p> <p>Solutions: - Enable memory compression - Reduce cache sizes - Implement memory cleanup - Limit concurrent operations</p>"},{"location":"user-guide/performance-optimization/#agent-timeout-issues","title":"Agent Timeout Issues","text":"<p>Symptoms: Frequent agent timeouts, blocked TDD cycles Diagnosis: <pre><code># Check agent execution times\ngrep \"agent_execution_time\" logs/metrics.log | awk '{print $4}' | sort -n | tail -20\n\n# Check for stuck operations\nps aux | grep -E \"(claude|agent)\" | grep -v grep\n</code></pre></p> <p>Solutions: - Reduce task complexity - Implement task splitting - Increase timeout values - Optimize AI API calls</p> <p>This performance optimization guide provides comprehensive strategies for maximizing system efficiency and scalability.</p>"},{"location":"user-guide/project-setup/","title":"Project Setup Guide","text":"<p>This guide explains how to set up and register new project repositories with the AI Agent TDD-Scrum workflow system.</p>"},{"location":"user-guide/project-setup/#prerequisites","title":"Prerequisites","text":"<ol> <li>Git Repository: Your project must be a valid git repository</li> <li>Discord Access: Access to the Discord server with the workflow bot</li> <li>Project Permissions: Write access to the project repository</li> </ol>"},{"location":"user-guide/project-setup/#registration-process","title":"Registration Process","text":""},{"location":"user-guide/project-setup/#step-1-prepare-your-project-repository","title":"Step 1: Prepare Your Project Repository","text":"<p>Ensure your project is a valid git repository:</p> <pre><code># Navigate to your project\ncd /path/to/your/project\n\n# Verify git repository\ngit status\n\n# Ensure you have at least one commit\ngit log --oneline -1\n</code></pre>"},{"location":"user-guide/project-setup/#step-2-register-with-discord-bot","title":"Step 2: Register with Discord Bot","text":"<p>Use the <code>/project register</code> command in Discord:</p> <pre><code>/project register path:/path/to/your/project\n</code></pre> <p>Optional: Specify a custom project name: <pre><code>/project register path:/path/to/your/project name:my-custom-name\n</code></pre></p>"},{"location":"user-guide/project-setup/#step-3-verify-registration","title":"Step 3: Verify Registration","text":"<p>The bot will: 1. \u2705 Validate the path exists and is a git repository 2. \u2705 Check for naming conflicts 3. \u2705 Create a Discord channel <code>{hostname}-{projectname}</code> 4. \u2705 Initialize the <code>.orch-state/</code> directory structure 5. \u2705 Add the project to the orchestration system</p>"},{"location":"user-guide/project-setup/#project-structure-after-registration","title":"Project Structure After Registration","text":"<p>After successful registration, your project will have:</p> <pre><code>your-project/\n\u251c\u2500\u2500 .git/                   # Existing git repository\n\u251c\u2500\u2500 src/                    # Your existing code\n\u251c\u2500\u2500 .orch-state/           # New: AI workflow state\n\u2502   \u251c\u2500\u2500 backlog.json       # Empty project management data\n\u2502   \u251c\u2500\u2500 sprints/           # Directory for sprint history\n\u2502   \u2502   \u2514\u2500\u2500 .gitkeep       # Placeholder file\n\u2502   \u251c\u2500\u2500 architecture.md    # Template architecture decisions\n\u2502   \u251c\u2500\u2500 best-practices.md  # Template project conventions\n\u2502   \u2514\u2500\u2500 status.json        # Current workflow state\n\u2514\u2500\u2500 [your existing files]\n</code></pre>"},{"location":"user-guide/project-setup/#initial-configuration","title":"Initial Configuration","text":""},{"location":"user-guide/project-setup/#architecture-documentation","title":"Architecture Documentation","text":"<p>Edit <code>.orch-state/architecture.md</code> to document your project's architecture:</p> <pre><code># Project Architecture\n\n## Overview\nBrief description of your project's architecture and purpose.\n\n## Components\n- Component 1: Description\n- Component 2: Description\n\n## Design Decisions\n- Decision 1: Rationale\n- Decision 2: Rationale\n\n## Dependencies\n- External APIs and services\n- Key libraries and frameworks\n\n## Future Considerations\n- Planned improvements\n- Technical debt items\n</code></pre>"},{"location":"user-guide/project-setup/#best-practices","title":"Best Practices","text":"<p>Update <code>.orch-state/best-practices.md</code> with project-specific guidelines:</p> <pre><code># Project Best Practices\n\n## Code Standards\n- Coding conventions specific to your project\n- Style guidelines and formatting rules\n\n## Testing Strategy\n- Testing frameworks and approaches\n- Coverage requirements\n\n## Git Workflow\n- Branching strategy\n- Commit message conventions\n\n## AI Agent Guidelines\n- Project-specific instructions for AI agents\n- Patterns and conventions to follow\n\n## Review Process\n- Code review requirements\n- Approval workflows\n</code></pre>"},{"location":"user-guide/project-setup/#discord-channel-usage","title":"Discord Channel Usage","text":""},{"location":"user-guide/project-setup/#channel-naming-convention","title":"Channel Naming Convention","text":"<p>Channels are automatically created with the pattern: <pre><code>{hostname}-{projectname}\n</code></pre></p> <p>For example: - <code>devbox-myproject</code> - <code>laptop-ecommerce-site</code> - <code>server-api-gateway</code></p>"},{"location":"user-guide/project-setup/#available-commands","title":"Available Commands","text":"<p>Once registered, use these commands in your project channel:</p>"},{"location":"user-guide/project-setup/#epic-management","title":"Epic Management","text":"<pre><code>/epic \"Implement user authentication system\"\n</code></pre>"},{"location":"user-guide/project-setup/#backlog-management","title":"Backlog Management","text":"<pre><code>/backlog view\n/backlog add_story title:\"User login\" description:\"Login functionality\"\n/backlog prioritize story_id:story-123 priority:1\n</code></pre>"},{"location":"user-guide/project-setup/#sprint-management","title":"Sprint Management","text":"<pre><code>/sprint plan\n/sprint start\n/sprint status\n/sprint pause\n/sprint resume\n</code></pre>"},{"location":"user-guide/project-setup/#workflow-control","title":"Workflow Control","text":"<pre><code>/approve\n/request_changes \"Need better error handling\"\n/state\n</code></pre>"},{"location":"user-guide/project-setup/#common-setup-scenarios","title":"Common Setup Scenarios","text":""},{"location":"user-guide/project-setup/#new-project-setup","title":"New Project Setup","text":"<p>For a brand new project:</p> <ol> <li> <p>Create and initialize git repository:    <pre><code>mkdir my-new-project\ncd my-new-project\ngit init\ngit commit --allow-empty -m \"Initial commit\"\n</code></pre></p> </li> <li> <p>Register with Discord bot:    <pre><code>/project register path:/path/to/my-new-project\n</code></pre></p> </li> <li> <p>Start with epic definition:    <pre><code>/epic \"Build MVP for user management system\"\n</code></pre></p> </li> </ol>"},{"location":"user-guide/project-setup/#existing-project-integration","title":"Existing Project Integration","text":"<p>For an existing project with code:</p> <ol> <li> <p>Ensure git repository is current:    <pre><code>cd /path/to/existing/project\ngit status\ngit add .\ngit commit -m \"Prepare for AI workflow integration\"\n</code></pre></p> </li> <li> <p>Register project:    <pre><code>/project register path:/path/to/existing/project\n</code></pre></p> </li> <li> <p>Document current architecture:</p> </li> <li>Edit <code>.orch-state/architecture.md</code></li> <li> <p>Update <code>.orch-state/best-practices.md</code></p> </li> <li> <p>Create initial epic for next phase:    <pre><code>/epic \"Modernize authentication system\"\n</code></pre></p> </li> </ol>"},{"location":"user-guide/project-setup/#multiple-environment-setup","title":"Multiple Environment Setup","text":"<p>For projects with different environments:</p> <ol> <li> <p>Register each environment separately:    <pre><code>/project register path:/path/to/project-dev name:myproject-dev\n/project register path:/path/to/project-staging name:myproject-staging\n/project register path:/path/to/project-prod name:myproject-prod\n</code></pre></p> </li> <li> <p>Each gets its own Discord channel:</p> </li> <li><code>#hostname-myproject-dev</code></li> <li><code>#hostname-myproject-staging</code></li> <li><code>#hostname-myproject-prod</code></li> </ol>"},{"location":"user-guide/project-setup/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/project-setup/#registration-failures","title":"Registration Failures","text":"<p>Error: \"Path does not exist\" - Verify the path is correct and accessible - Use absolute paths, not relative paths</p> <p>Error: \"Path is not a git repository\" - Run <code>git init</code> in the directory - Ensure <code>.git</code> directory exists</p> <p>Error: \"Project already registered\" - Use a different project name - Check existing projects with <code>/state</code></p> <p>Error: \"Channel already exists\" - Another project may be using the same name - This could indicate a naming conflict or duplicate registration</p>"},{"location":"user-guide/project-setup/#post-registration-issues","title":"Post-Registration Issues","text":"<p>Cannot find project channel - Check channel naming: <code>{hostname}-{projectname}</code> - Verify you have permission to see the channel - Bot may need time to create the channel</p> <p>Commands not working - Ensure you're in the correct project channel - Check bot permissions - Verify project is in correct state with <code>/state</code></p>"},{"location":"user-guide/project-setup/#best-practices_1","title":"Best Practices","text":""},{"location":"user-guide/project-setup/#project-organization","title":"Project Organization","text":"<ol> <li>Clear Naming: Use descriptive project names</li> <li>Consistent Structure: Follow established patterns</li> <li>Documentation: Keep architecture and practices current</li> <li>Git Hygiene: Regular commits and clean history</li> </ol>"},{"location":"user-guide/project-setup/#workflow-integration","title":"Workflow Integration","text":"<ol> <li>Start Small: Begin with simple epics and stories</li> <li>Iterative Approach: Use short sprints initially</li> <li>Regular Reviews: Conduct sprint retrospectives</li> <li>Continuous Improvement: Update practices based on experience</li> </ol>"},{"location":"user-guide/project-setup/#team-coordination","title":"Team Coordination","text":"<ol> <li>Channel Discipline: Use project-specific channels</li> <li>Clear Communication: Document decisions in architecture.md</li> <li>Approval Process: Establish clear approval workflows</li> <li>Regular Standups: Coordinate with team members</li> </ol>"},{"location":"user-guide/project-setup/#security-considerations","title":"Security Considerations","text":""},{"location":"user-guide/project-setup/#repository-access","title":"Repository Access","text":"<ul> <li>Workflow bot requires read/write access to <code>.orch-state/</code> directory</li> <li>Bot cannot access other project files without explicit permissions</li> <li>Standard git permissions model applies</li> </ul>"},{"location":"user-guide/project-setup/#data-privacy","title":"Data Privacy","text":"<ul> <li>Project management data stored in project repository</li> <li>No external data storage or transmission</li> <li>Audit trail maintained in git history</li> </ul>"},{"location":"user-guide/project-setup/#discord-permissions","title":"Discord Permissions","text":"<ul> <li>Project channels provide access control</li> <li>Bot permissions scoped to workflow operations</li> <li>Team members need appropriate Discord roles</li> </ul>"},{"location":"user-guide/project-setup/#tdd-workflow-setup","title":"TDD Workflow Setup","text":""},{"location":"user-guide/project-setup/#prerequisites-for-tdd-integration","title":"Prerequisites for TDD Integration","text":"<p>Before enabling TDD workflows, ensure your project meets these requirements:</p> <ol> <li>Testing Framework: Your project must have a test framework configured (pytest, unittest, jest, etc.)</li> <li>CI/CD Pipeline: Basic CI integration for automated test execution</li> <li>Project Structure: Clear separation between source and test directories</li> <li>Coverage Tools: Code coverage measurement tools installed</li> </ol>"},{"location":"user-guide/project-setup/#enabling-tdd-mode","title":"Enabling TDD Mode","text":""},{"location":"user-guide/project-setup/#step-1-configure-tdd-settings","title":"Step 1: Configure TDD Settings","text":"<p>Create or update <code>.orch-state/tdd-config.json</code>:</p> <pre><code>{\n  \"tdd_enabled\": true,\n  \"test_framework\": \"pytest\",\n  \"test_directory\": \"tests\",\n  \"tdd_test_directory\": \"tests/tdd\",\n  \"coverage_threshold\": 90.0,\n  \"quality_gates\": {\n    \"complexity_limit\": 10,\n    \"duplication_threshold\": 5.0,\n    \"security_scan\": true\n  },\n  \"ci_integration\": {\n    \"enabled\": true,\n    \"provider\": \"github_actions\",\n    \"trigger_on_commit\": true\n  },\n  \"auto_progression\": {\n    \"enabled\": false,\n    \"require_human_approval\": true,\n    \"stuck_cycle_timeout\": 30\n  }\n}\n</code></pre>"},{"location":"user-guide/project-setup/#step-2-test-framework-setup","title":"Step 2: Test Framework Setup","text":"<p>For Python projects (pytest):</p> <pre><code># Install dependencies\npip install pytest pytest-cov pytest-xdist\n\n# Create pytest.ini\ncat &gt; pytest.ini &lt;&lt; EOF\n[tool:pytest]\ntestpaths = tests\npython_files = test_*.py\npython_classes = Test*\npython_functions = test_*\naddopts = --cov=src --cov-report=html --cov-report=term-missing\nEOF\n</code></pre> <p>For JavaScript projects (jest):</p> <pre><code># Install dependencies\nnpm install --save-dev jest @jest/globals\n\n# Create jest.config.js\ncat &gt; jest.config.js &lt;&lt; EOF\nmodule.exports = {\n  testEnvironment: 'node',\n  coverageDirectory: 'coverage',\n  collectCoverageFrom: [\n    'src/**/*.js',\n    '!src/**/*.test.js'\n  ],\n  testMatch: ['**/tests/**/*.test.js']\n};\nEOF\n</code></pre>"},{"location":"user-guide/project-setup/#step-3-directory-structure-setup","title":"Step 3: Directory Structure Setup","text":"<p>The TDD workflow requires specific directory organization:</p> <pre><code>your-project/\n\u251c\u2500\u2500 src/                      # Source code\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 unit/                # Permanent unit tests\n\u2502   \u251c\u2500\u2500 integration/         # Permanent integration tests\n\u2502   \u2514\u2500\u2500 tdd/                 # TDD workspace (managed by system)\n\u2502       \u251c\u2500\u2500 AUTH-001/        # Story-specific tests\n\u2502       \u2502   \u251c\u2500\u2500 test_login.py\n\u2502       \u2502   \u2514\u2500\u2500 test_auth.py\n\u2502       \u2514\u2500\u2500 USER-002/\n\u2502           \u2514\u2500\u2500 test_profile.py\n\u251c\u2500\u2500 .orch-state/\n\u2502   \u251c\u2500\u2500 tdd-config.json      # TDD configuration\n\u2502   \u251c\u2500\u2500 tdd-cycles/          # Active TDD cycle data\n\u2502   \u2502   \u251c\u2500\u2500 AUTH-001.json    # TDD cycle state\n\u2502   \u2502   \u2514\u2500\u2500 USER-002.json\n\u2502   \u2514\u2500\u2500 tdd-metrics.json     # Performance metrics\n\u2514\u2500\u2500 [existing project files]\n</code></pre>"},{"location":"user-guide/project-setup/#step-4-cicd-integration","title":"Step 4: CI/CD Integration","text":"<p>GitHub Actions (<code>.github/workflows/tdd.yml</code>):</p> <pre><code>name: TDD Workflow\n\non:\n  push:\n    paths:\n      - 'tests/tdd/**'\n      - 'src/**'\n  pull_request:\n    paths:\n      - 'tests/tdd/**'\n      - 'src/**'\n\njobs:\n  tdd-validation:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.9'\n\n      - name: Install dependencies\n        run: |\n          pip install -r requirements.txt\n          pip install pytest pytest-cov\n\n      - name: Run TDD tests\n        run: |\n          pytest tests/tdd/ --cov=src --cov-fail-under=90\n\n      - name: Validate RED state\n        if: contains(github.ref, 'tdd-red')\n        run: |\n          # Expect tests to fail in RED state\n          pytest tests/tdd/ || true\n\n      - name: Validate GREEN state\n        if: contains(github.ref, 'tdd-green')\n        run: |\n          # Expect all tests to pass in GREEN state\n          pytest tests/tdd/ --cov=src --cov-fail-under=90\n\n      - name: Upload coverage\n        uses: codecov/codecov-action@v3\n</code></pre>"},{"location":"user-guide/project-setup/#tdd-workflow-configuration-options","title":"TDD Workflow Configuration Options","text":""},{"location":"user-guide/project-setup/#coverage-requirements","title":"Coverage Requirements","text":"<p>Configure different coverage thresholds for different story types:</p> <pre><code>{\n  \"coverage_profiles\": {\n    \"critical\": {\n      \"threshold\": 95.0,\n      \"branch_coverage\": 90.0,\n      \"exclude_patterns\": []\n    },\n    \"standard\": {\n      \"threshold\": 90.0,\n      \"branch_coverage\": 80.0,\n      \"exclude_patterns\": [\"**/migrations/**\"]\n    },\n    \"experimental\": {\n      \"threshold\": 75.0,\n      \"branch_coverage\": 70.0,\n      \"exclude_patterns\": [\"**/prototypes/**\"]\n    }\n  }\n}\n</code></pre>"},{"location":"user-guide/project-setup/#quality-gates","title":"Quality Gates","text":"<p>Define automated quality checks:</p> <pre><code>{\n  \"quality_gates\": {\n    \"static_analysis\": {\n      \"enabled\": true,\n      \"tools\": [\"pylint\", \"mypy\", \"black\"],\n      \"fail_threshold\": \"error\"\n    },\n    \"security_scan\": {\n      \"enabled\": true,\n      \"tools\": [\"bandit\", \"safety\"],\n      \"fail_on_high\": true\n    },\n    \"performance\": {\n      \"enabled\": true,\n      \"max_execution_time\": 5.0,\n      \"memory_threshold\": \"100MB\"\n    },\n    \"complexity\": {\n      \"enabled\": true,\n      \"cyclomatic_complexity\": 10,\n      \"cognitive_complexity\": 15\n    }\n  }\n}\n</code></pre>"},{"location":"user-guide/project-setup/#agent-behavior-configuration","title":"Agent Behavior Configuration","text":"<p>Customize how TDD agents operate:</p> <pre><code>{\n  \"agent_config\": {\n    \"design_agent\": {\n      \"design_template\": \"api_specification\",\n      \"include_acceptance_criteria\": true,\n      \"generate_test_scenarios\": true\n    },\n    \"qa_agent\": {\n      \"test_types\": [\"unit\", \"integration\", \"edge_cases\"],\n      \"mock_external_dependencies\": true,\n      \"generate_test_data\": true,\n      \"ensure_red_state\": true\n    },\n    \"code_agent\": {\n      \"minimal_implementation\": true,\n      \"avoid_premature_optimization\": true,\n      \"follow_design_patterns\": [\"SOLID\", \"DRY\"]\n    }\n  }\n}\n</code></pre>"},{"location":"user-guide/project-setup/#tdd-specific-project-templates","title":"TDD-Specific Project Templates","text":""},{"location":"user-guide/project-setup/#api-development-template","title":"API Development Template","text":"<pre><code>{\n  \"project_type\": \"api\",\n  \"tdd_config\": {\n    \"test_patterns\": {\n      \"unit\": \"test_unit_*.py\",\n      \"integration\": \"test_api_*.py\",\n      \"contract\": \"test_contract_*.py\"\n    },\n    \"phases\": {\n      \"design\": {\n        \"artifacts\": [\"openapi_spec\", \"data_models\", \"error_schemas\"],\n        \"validation\": \"schema_validation\"\n      },\n      \"test_red\": {\n        \"test_types\": [\"unit\", \"integration\", \"contract\"],\n        \"mock_strategy\": \"external_services\"\n      },\n      \"code_green\": {\n        \"implementation_style\": \"minimal_viable\",\n        \"database_strategy\": \"in_memory\"\n      },\n      \"refactor\": {\n        \"focus_areas\": [\"performance\", \"security\", \"maintainability\"]\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"user-guide/project-setup/#frontend-component-template","title":"Frontend Component Template","text":"<pre><code>{\n  \"project_type\": \"frontend\",\n  \"tdd_config\": {\n    \"test_patterns\": {\n      \"unit\": \"*.test.js\",\n      \"integration\": \"*.integration.test.js\",\n      \"e2e\": \"*.e2e.test.js\"\n    },\n    \"testing_library\": \"react-testing-library\",\n    \"phases\": {\n      \"design\": {\n        \"artifacts\": [\"component_interface\", \"props_schema\", \"state_diagram\"],\n        \"validation\": \"typescript_compilation\"\n      },\n      \"test_red\": {\n        \"test_types\": [\"unit\", \"integration\"],\n        \"mock_strategy\": \"api_calls\"\n      },\n      \"code_green\": {\n        \"implementation_style\": \"component_first\",\n        \"styling_approach\": \"css_modules\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"user-guide/project-setup/#tdd-project-initialization","title":"TDD Project Initialization","text":""},{"location":"user-guide/project-setup/#new-project-with-tdd","title":"New Project with TDD","text":"<p>For new projects starting with TDD:</p> <pre><code># Create project structure\nmkdir my-tdd-project\ncd my-tdd-project\ngit init\n\n# Initialize TDD-ready structure\nmkdir -p src tests/{unit,integration,tdd} .orch-state\n\n# Register with TDD enabled\n/project register path:/path/to/my-tdd-project\n# System detects TDD configuration and enables TDD mode\n\n# Create first epic with TDD\n/epic \"Build user authentication system with TDD\"\n/tdd configure AUTH coverage_profile:critical\n</code></pre>"},{"location":"user-guide/project-setup/#existing-project-tdd-migration","title":"Existing Project TDD Migration","text":"<p>For existing projects adopting TDD:</p> <pre><code># Backup existing tests\ncp -r tests tests_backup\n\n# Create TDD structure\nmkdir -p tests/tdd .orch-state/tdd-cycles\n\n# Move existing tests to permanent locations\nmv tests/test_*.py tests/unit/\nmv tests/integration_*.py tests/integration/\n\n# Enable TDD mode\necho '{\"tdd_enabled\": true}' &gt; .orch-state/tdd-config.json\n\n# Re-register project to detect TDD\n/project register path:/path/to/existing/project\n</code></pre>"},{"location":"user-guide/project-setup/#tdd-troubleshooting-setup","title":"TDD Troubleshooting Setup","text":""},{"location":"user-guide/project-setup/#common-setup-issues","title":"Common Setup Issues","text":"<p>TDD directory not created: - Verify <code>.orch-state/tdd-config.json</code> exists - Check project registration detected TDD configuration - Ensure bot has write permissions to project directory</p> <p>Tests not running in CI: - Verify test framework is properly configured - Check CI workflow includes TDD test paths - Ensure coverage tools are installed in CI environment</p> <p>Agent access errors: - Verify agent security profiles allow TDD operations - Check file permissions in tests/tdd/ directory - Ensure git repository allows automated commits</p>"},{"location":"user-guide/project-setup/#validation-commands","title":"Validation Commands","text":"<p>Verify TDD setup is working:</p> <pre><code># Check TDD configuration\n/tdd status\n\n# Validate test framework\npytest tests/tdd/ --collect-only\n\n# Verify CI integration\ngit add .orch-state/tdd-config.json\ngit commit -m \"Enable TDD workflow\"\ngit push  # Should trigger CI validation\n\n# Test agent permissions\n/tdd start TEST-001  # Should create TDD cycle\n</code></pre>"},{"location":"user-guide/project-setup/#tdd-best-practices-for-setup","title":"TDD Best Practices for Setup","text":""},{"location":"user-guide/project-setup/#project-organization_1","title":"Project Organization","text":"<ol> <li>Separate TDD Workspace: Keep TDD tests separate from permanent test suite</li> <li>Story-Based Organization: Organize TDD tests by story ID for clarity</li> <li>Clear Naming Conventions: Use consistent naming for TDD test files</li> <li>Version Control Integration: Ensure TDD artifacts are properly tracked</li> </ol>"},{"location":"user-guide/project-setup/#cicd-configuration","title":"CI/CD Configuration","text":"<ol> <li>Separate TDD Pipelines: Different CI behavior for RED vs GREEN states</li> <li>Quality Gate Integration: Automated quality checks at each TDD phase</li> <li>Artifact Preservation: Maintain TDD test history for audit trails</li> <li>Performance Monitoring: Track TDD cycle times and success rates</li> </ol>"},{"location":"user-guide/project-setup/#team-coordination_1","title":"Team Coordination","text":"<ol> <li>Shared TDD Standards: Document TDD practices for the team</li> <li>Review Processes: Define review requirements for TDD phases</li> <li>Escalation Procedures: Clear processes when TDD cycles get stuck</li> <li>Metrics Tracking: Regular review of TDD performance metrics</li> </ol> <p>With this setup, your project will be fully configured for TDD workflows with proper tooling, CI integration, and team processes.</p>"},{"location":"user-guide/state-machine/","title":"Dual State Machine Architecture","text":"<p>This document formalizes the dual state machine system: the primary Workflow State Machine for Scrum coordination and the secondary TDD State Machines for individual story implementation.</p>"},{"location":"user-guide/state-machine/#1-primary-workflow-state-machine","title":"1. Primary Workflow State Machine","text":""},{"location":"user-guide/state-machine/#top-level-states","title":"Top-Level States","text":"Key State Name Description IDLE Idle / Awaiting Vision No epic defined; waiting for <code>/epic</code> or backlog grooming. BACKLOG_READY Backlog Ready Stories exist in the product backlog, none selected for sprint. SPRINT_PLANNED Sprint Planned A sprint backlog has been drafted but not started. SPRINT_ACTIVE Sprint Active Agents are working on tasks. SPRINT_PAUSED Sprint Paused Active sprint is temporarily halted. SPRINT_REVIEW Sprint Review Sprint tasks done; PR awaiting user review. BLOCKED Blocked Task Sprint task failed CI 3\u00d7 and awaits user input. (Sub-state of <code>SPRINT_ACTIVE</code>.)"},{"location":"user-guide/state-machine/#workflow-command-state-matrix","title":"Workflow Command \u2192 State Matrix","text":"Command Allowed in States Resulting State <code>/epic</code> IDLE, BACKLOG_READY BACKLOG_READY <code>/approve</code> BACKLOG_READY BACKLOG_READY <code>/backlog *</code> Any (except SPRINT_REVIEW locked) (no change) <code>/sprint plan</code> BACKLOG_READY SPRINT_PLANNED <code>/sprint start</code> SPRINT_PLANNED SPRINT_ACTIVE <code>/sprint status</code> SPRINT_ACTIVE, SPRINT_PAUSED, BLOCKED (no change) <code>/sprint pause</code> SPRINT_ACTIVE SPRINT_PAUSED <code>/sprint resume</code> SPRINT_PAUSED SPRINT_ACTIVE <code>/request_changes</code> SPRINT_REVIEW BACKLOG_READY <code>/suggest_fix</code> BLOCKED SPRINT_ACTIVE <code>/skip_task</code> BLOCKED SPRINT_ACTIVE (next task) <code>/feedback</code> SPRINT_REVIEW IDLE <p>Commands issued outside their Allowed States trigger an error response (see \u00a74). <code>/backlog</code> commands are always safe but may show different context (product vs sprint). <code>BLOCKED</code> is transient: once the user responds the orchestrator returns to <code>SPRINT_ACTIVE</code> or skips forward.</p>"},{"location":"user-guide/state-machine/#primary-workflow-state-diagram","title":"Primary Workflow State Diagram","text":"<pre><code>%%{init: {'theme': 'dark'}}%%\nstateDiagram-v2\n    [*] --&gt; IDLE\n    IDLE --&gt; BACKLOG_READY : /epic\n    BACKLOG_READY --&gt; BACKLOG_READY : /approve\n    BACKLOG_READY --&gt; SPRINT_PLANNED : /sprint plan\n    SPRINT_PLANNED --&gt; SPRINT_ACTIVE : /sprint start\n    SPRINT_ACTIVE --&gt; SPRINT_PAUSED : /sprint pause\n    SPRINT_PAUSED --&gt; SPRINT_ACTIVE : /sprint resume\n    SPRINT_ACTIVE --&gt; BLOCKED : CI fails 3\u00d7\n    BLOCKED --&gt; SPRINT_ACTIVE : /suggest_fix | /skip_task\n    SPRINT_ACTIVE --&gt; SPRINT_REVIEW : all tasks done\n    SPRINT_REVIEW --&gt; BACKLOG_READY : /request_changes\n    SPRINT_REVIEW --&gt; IDLE : /feedback (retrospective complete)</code></pre>"},{"location":"user-guide/state-machine/#2-secondary-tdd-state-machines","title":"2. Secondary TDD State Machines","text":""},{"location":"user-guide/state-machine/#tdd-states-per-story","title":"TDD States per Story","text":"<p>When the primary state machine enters <code>SPRINT_ACTIVE</code>, individual TDD state machines are created for each story in the sprint.</p> Key State Name Description DESIGN Design Phase Design Agent creates technical specifications and architecture. TEST_RED Test Red Phase QA Agent writes failing tests based on design specifications. CODE_GREEN Code Green Phase Code Agent implements minimal code to make all tests pass. REFACTOR Refactor Phase Code Agent improves code quality while maintaining green tests. COMMIT Commit Phase Code Agent commits changes and completes the story."},{"location":"user-guide/state-machine/#tdd-command-state-matrix","title":"TDD Command \u2192 State Matrix","text":"Command Allowed in States Resulting State <code>/tdd start &lt;ID&gt;</code> Any (auto-started from SPRINT_ACTIVE) DESIGN <code>/tdd status [ID]</code> Any TDD state (no change) <code>/tdd design_complete &lt;ID&gt;</code> DESIGN TEST_RED <code>/tdd tests_ready &lt;ID&gt;</code> TEST_RED CODE_GREEN <code>/tdd code_green &lt;ID&gt;</code> CODE_GREEN REFACTOR <code>/tdd refactor_done &lt;ID&gt;</code> REFACTOR COMMIT <code>/tdd review_cycle &lt;ID&gt;</code> Any TDD state (pause for review) <code>/tdd skip_phase &lt;ID&gt;</code> Any TDD state (next phase) <code>/tdd pause &lt;ID&gt;</code> Any active TDD state (paused) <code>/tdd resume &lt;ID&gt;</code> Paused TDD state (previous state)"},{"location":"user-guide/state-machine/#tdd-state-diagram","title":"TDD State Diagram","text":"<pre><code>%%{init: {'theme': 'dark'}}%%\nstateDiagram-v2\n    [*] --&gt; DESIGN\n    DESIGN --&gt; TEST_RED : design complete\n    TEST_RED --&gt; CODE_GREEN : tests failing properly\n    CODE_GREEN --&gt; REFACTOR : all tests passing\n    REFACTOR --&gt; COMMIT : quality gates met\n    COMMIT --&gt; [*] : story complete\n\n    note right of DESIGN\n        Design Agent creates\n        technical specifications\n    end note\n\n    note right of TEST_RED\n        QA Agent writes\n        failing tests\n    end note\n\n    note right of CODE_GREEN\n        Code Agent makes\n        tests pass\n    end note\n\n    note right of REFACTOR\n        Code Agent improves\n        code quality\n    end note\n\n    note right of COMMIT\n        Code Agent commits\n        and closes story\n    end note\n\n    %% Error transitions\n    REFACTOR --&gt; CODE_GREEN : tests broken\n    CODE_GREEN --&gt; TEST_RED : need more tests\n    TEST_RED --&gt; DESIGN : requirements unclear</code></pre>"},{"location":"user-guide/state-machine/#parallel-tdd-execution","title":"Parallel TDD Execution","text":"<p>Multiple TDD state machines run simultaneously during an active sprint:</p> <pre><code>%%{init: {'theme': 'dark'}}%%\nstateDiagram-v2\n    state \"Workflow State Machine\" as WSM\n    state \"Sprint Active\" as ACTIVE\n\n    state \"Story AUTH-1 TDD\" as TDD1 {\n        state \"DESIGN\" as D1\n        state \"TEST_RED\" as T1\n        state \"CODE_GREEN\" as C1\n        state \"REFACTOR\" as R1\n        state \"COMMIT\" as CM1\n\n        [*] --&gt; D1\n        D1 --&gt; T1\n        T1 --&gt; C1\n        C1 --&gt; R1\n        R1 --&gt; CM1\n        CM1 --&gt; [*]\n    }\n\n    state \"Story AUTH-2 TDD\" as TDD2 {\n        state \"DESIGN\" as D2\n        state \"TEST_RED\" as T2\n        state \"CODE_GREEN\" as C2\n        state \"REFACTOR\" as R2\n        state \"COMMIT\" as CM2\n\n        [*] --&gt; D2\n        D2 --&gt; T2\n        T2 --&gt; C2\n        C2 --&gt; R2\n        R2 --&gt; CM2\n        CM2 --&gt; [*]\n    }\n\n    state \"Story AUTH-3 TDD\" as TDD3 {\n        state \"DESIGN\" as D3\n        state \"TEST_RED\" as T3\n        state \"CODE_GREEN\" as C3\n        state \"REFACTOR\" as R3\n        state \"COMMIT\" as CM3\n\n        [*] --&gt; D3\n        D3 --&gt; T3\n        T3 --&gt; C3\n        C3 --&gt; R3\n        R3 --&gt; CM3\n        CM3 --&gt; [*]\n    }\n\n    WSM --&gt; ACTIVE\n    ACTIVE --&gt; TDD1 : spawn\n    ACTIVE --&gt; TDD2 : spawn\n    ACTIVE --&gt; TDD3 : spawn</code></pre>"},{"location":"user-guide/state-machine/#3-state-machine-interactions","title":"3. State Machine Interactions","text":""},{"location":"user-guide/state-machine/#primary-to-secondary-activation","title":"Primary to Secondary Activation","text":"<p>When the primary state machine transitions to <code>SPRINT_ACTIVE</code>, it triggers the creation of TDD state machines:</p> <pre><code>sequenceDiagram\n    participant U as User\n    participant WSM as Workflow State Machine\n    participant Coord as Multi-Task Coordinator\n    participant TDD as TDD State Machine\n\n    U-&gt;&gt;WSM: /sprint start\n    WSM-&gt;&gt;WSM: SPRINT_PLANNED \u2192 SPRINT_ACTIVE\n    WSM-&gt;&gt;Coord: Create TDD cycles\n\n    loop For each story in sprint\n        Coord-&gt;&gt;TDD: Create TDD instance\n        TDD-&gt;&gt;TDD: Initialize DESIGN phase\n        Note over TDD: Story-specific TDD cycle begins\n    end\n\n    TDD-&gt;&gt;Coord: Progress updates\n    Coord-&gt;&gt;WSM: Sprint progress\n    WSM-&gt;&gt;U: Status updates</code></pre>"},{"location":"user-guide/state-machine/#cross-state-machine-commands","title":"Cross-State Machine Commands","text":"<p>Some commands affect both state machines:</p> Command Primary Effect Secondary Effect <code>/sprint pause</code> SPRINT_ACTIVE \u2192 SPRINT_PAUSED Pause all TDD cycles <code>/sprint resume</code> SPRINT_PAUSED \u2192 SPRINT_ACTIVE Resume all TDD cycles <code>/sprint status</code> Show sprint progress Show TDD cycle status <code>/state</code> Show workflow state Show active TDD states"},{"location":"user-guide/state-machine/#4-standardised-error-hint-response","title":"4. Standardised Error &amp; Hint Response","text":"<p>When a user issues an invalid command for the current state, the orchestrator must reply with:</p> <pre><code>{\n  \"type\": \"error\",\n  \"code\": \"INVALID_STATE\",\n  \"current_state\": \"SPRINT_ACTIVE\",\n  \"command\": \"/sprint plan\",\n  \"allowed_in\": [\"BACKLOG_READY\"],\n  \"hint\": \"Sprint already active. Use /sprint status or /sprint pause instead.\"\n}\n</code></pre> <p>In Discord this is rendered as:</p> <p>\u26a0\ufe0f Command <code>/sprint plan</code> is not allowed now (state: SPRINT_ACTIVE). Try <code>/sprint status</code> or <code>/sprint pause</code>.</p>"},{"location":"user-guide/state-machine/#5-implementation-notes","title":"5. Implementation Notes","text":"<ol> <li>Maintain state in orchestrator memory / lightweight DB keyed by guild or workspace.</li> <li>Expose a <code>/state</code> debug command (admin-only) to dump current finite-state and backlog summary.</li> <li>Unit-test the state machine with a table-driven test: <code>(state, command) \u2192 expected</code>.</li> <li>Extend easily: add columns/rows to matrix and diagram.</li> </ol> <p>This state machine keeps user interactions predictable and provides immediate, actionable feedback when mis-ordered commands occur. </p>"},{"location":"user-guide/tdd-workflow/","title":"TDD Workflow Guide","text":"<p>The AI Agent TDD-Scrum system implements a comprehensive Test-Driven Development workflow that runs in parallel with the main Scrum state machine. With advanced context management and multi-project support, the system can coordinate multiple TDD cycles simultaneously across different projects while maintaining proper RED-GREEN-REFACTOR methodology. This guide explains how to use TDD commands and understand the complete TDD ecosystem.</p>"},{"location":"user-guide/tdd-workflow/#multi-project-tdd-architecture","title":"Multi-Project TDD Architecture","text":"<p>The system supports multiple TDD execution modes:</p>"},{"location":"user-guide/tdd-workflow/#single-project-mode","title":"Single-Project Mode","text":"<p>Traditional workflow with one project and multiple parallel TDD cycles: <pre><code># Standard single-project TDD\npython scripts/orchestrator.py\n/sprint start  # Creates TDD cycles for current project\n</code></pre></p>"},{"location":"user-guide/tdd-workflow/#multi-project-mode","title":"Multi-Project Mode","text":"<p>Advanced orchestration across multiple projects with global resource management: <pre><code># Multi-project TDD orchestration\npython scripts/multi_project_orchestrator.py --interactive\n&gt; start backend-api    # Start TDD cycles for backend project\n&gt; start frontend-app   # Start TDD cycles for frontend project\n</code></pre></p>"},{"location":"user-guide/tdd-workflow/#context-managed-tdd","title":"Context-Managed TDD","text":"<p>Intelligent context sharing between TDD cycles for optimal agent performance: - Context Manager: Optimizes agent memory and communication - Token Calculation: Manages context size for efficient agent operation - Cross-Cycle Learning: Agents learn from parallel TDD cycles - Resource Optimization: Smart allocation of agents across TDD cycles</p>"},{"location":"user-guide/tdd-workflow/#tdd-state-machine-overview","title":"TDD State Machine Overview","text":"<p>Each story in an active sprint follows a strict TDD methodology through a dedicated state machine:</p> <pre><code>stateDiagram-v2\n    [*] --&gt; DESIGN\n    DESIGN --&gt; TEST_RED : specs complete\n    TEST_RED --&gt; CODE_GREEN : tests failing\n    CODE_GREEN --&gt; REFACTOR : tests passing\n    REFACTOR --&gt; COMMIT : quality gates met\n    COMMIT --&gt; [*] : story complete\n\n    REFACTOR --&gt; CODE_GREEN : tests broken\n    CODE_GREEN --&gt; TEST_RED : need more tests\n    TEST_RED --&gt; DESIGN : requirements unclear</code></pre>"},{"location":"user-guide/tdd-workflow/#tdd-command-reference","title":"TDD Command Reference","text":""},{"location":"user-guide/tdd-workflow/#story-level-tdd-commands","title":"Story-Level TDD Commands","text":"<p><code>/tdd start &lt;STORY_ID&gt;</code> Manually start TDD cycle for a specific story (normally automatic).</p> <p><code>/tdd status [STORY_ID]</code> Get current TDD phase and progress for one or all active stories.</p> <p><code>/tdd pause &lt;STORY_ID&gt;</code> Temporarily halt TDD cycle for a story.</p> <p><code>/tdd resume &lt;STORY_ID&gt;</code> Resume paused TDD cycle.</p> <p><code>/tdd skip_phase &lt;STORY_ID&gt;</code> Skip current TDD phase (requires approval).</p>"},{"location":"user-guide/tdd-workflow/#phase-specific-commands","title":"Phase-Specific Commands","text":"<p><code>/tdd design_complete &lt;STORY_ID&gt;</code> Mark design phase complete and advance to TEST_RED.</p> <p><code>/tdd tests_ready &lt;STORY_ID&gt;</code> Confirm tests are written and failing properly.</p> <p><code>/tdd code_green &lt;STORY_ID&gt;</code> Confirm all tests are now passing.</p> <p><code>/tdd refactor_done &lt;STORY_ID&gt;</code> Complete refactoring and proceed to commit.</p> <p><code>/tdd review_cycle &lt;STORY_ID&gt;</code> Request human review of current TDD cycle.</p>"},{"location":"user-guide/tdd-workflow/#global-tdd-commands","title":"Global TDD Commands","text":"<p><code>/tdd overview</code> Show status of all active TDD cycles with visual progress.</p> <p><code>/tdd metrics</code> Display TDD metrics: cycle time, test coverage, refactor frequency.</p> <p><code>/tdd halt_all</code> Emergency stop all TDD cycles (requires confirmation).</p>"},{"location":"user-guide/tdd-workflow/#context-management-commands","title":"Context Management Commands","text":"<p><code>/tdd context &lt;STORY_ID&gt;</code> Show context information for TDD cycle agents.</p> <p><code>/tdd context optimize</code> Trigger context optimization across all active TDD cycles.</p> <p><code>/tdd memory &lt;STORY_ID&gt;</code> Display agent memory usage and optimization stats.</p> <p><code>/tdd context_share &lt;STORY_ID&gt; &lt;TARGET_STORY_ID&gt;</code> Enable context sharing between related TDD cycles.</p>"},{"location":"user-guide/tdd-workflow/#multi-project-tdd-commands","title":"Multi-Project TDD Commands","text":"<p><code>/tdd global_overview</code> Show TDD status across all projects in multi-project mode.</p> <p><code>/tdd project_metrics &lt;PROJECT_NAME&gt;</code> Display TDD metrics for a specific project.</p> <p><code>/tdd resource_status</code> Show TDD agent resource allocation across projects.</p>"},{"location":"user-guide/tdd-workflow/#complete-tdd-cycle-walkthrough","title":"Complete TDD Cycle Walkthrough","text":""},{"location":"user-guide/tdd-workflow/#phase-1-design","title":"Phase 1: DESIGN","text":"<p>The Design Agent creates technical specifications for the story.</p> <p>What happens automatically: - Analyzes story requirements and acceptance criteria - Creates technical design document with interfaces and data structures - Defines implementation approach and architecture decisions - Generates design artifacts in <code>.orch-state/designs/</code></p> <p>Human interaction: <pre><code>/tdd status AUTH-1\n# Shows: \"AUTH-1 in DESIGN phase - creating login API specification\"\n\n/tdd review_cycle AUTH-1\n# Request to review design before proceeding\n</code></pre></p> <p>Artifacts created: - Technical specification document - Interface definitions - Data model schemas - Acceptance criteria details</p>"},{"location":"user-guide/tdd-workflow/#phase-2-test_red","title":"Phase 2: TEST_RED","text":"<p>The QA Agent writes comprehensive failing tests.</p> <p>What happens automatically: - Implements unit tests based on design specifications - Creates integration tests for external dependencies - Writes acceptance tests matching story criteria - Ensures all tests fail appropriately (RED state)</p> <p>Human interaction: <pre><code>/tdd status AUTH-1\n# Shows: \"AUTH-1 in TEST_RED phase - 15 tests written, all failing\"\n\n/tdd tests_ready AUTH-1\n# Manually advance if automatic transition doesn't occur\n</code></pre></p> <p>Artifacts created: - Unit test files (<code>test_*.py</code>) - Integration test suite - Test data and fixtures - Coverage baseline reports</p>"},{"location":"user-guide/tdd-workflow/#phase-3-code_green","title":"Phase 3: CODE_GREEN","text":"<p>The Code Agent implements minimal code to make tests pass.</p> <p>What happens automatically: - Writes minimal implementation to pass failing tests - Focuses on making tests green without over-engineering - Implements only what's needed for current test suite - Runs continuous test validation</p> <p>Human interaction: <pre><code>/tdd status AUTH-1\n# Shows: \"AUTH-1 in CODE_GREEN phase - 12/15 tests passing\"\n\n/tdd code_green AUTH-1\n# Confirm when all tests are green and ready for refactor\n</code></pre></p> <p>Artifacts created: - Implementation code - Configuration files - Database migrations - API endpoints</p>"},{"location":"user-guide/tdd-workflow/#phase-4-refactor","title":"Phase 4: REFACTOR","text":"<p>The Code Agent improves code quality while maintaining green tests.</p> <p>What happens automatically: - Applies design patterns and best practices - Removes code duplication and improves readability - Optimizes performance while maintaining functionality - Ensures all tests remain green throughout refactoring</p> <p>Human interaction: <pre><code>/tdd status AUTH-1\n# Shows: \"AUTH-1 in REFACTOR phase - applying clean architecture patterns\"\n\n/tdd refactor_done AUTH-1\n# Mark refactoring complete when satisfied with quality\n</code></pre></p> <p>Quality gates: - Code coverage threshold maintained - Complexity metrics within bounds - Performance benchmarks met - Style and formatting standards applied</p>"},{"location":"user-guide/tdd-workflow/#phase-5-commit","title":"Phase 5: COMMIT","text":"<p>The Code Agent commits changes and completes the story.</p> <p>What happens automatically: - Commits all changes with descriptive message - Updates documentation and changelog - Triggers CI/CD pipeline for validation - Marks story as complete in sprint backlog</p> <p>Human interaction: <pre><code>/tdd status AUTH-1\n# Shows: \"AUTH-1 in COMMIT phase - preparing final commit\"\n\n# Story automatically marked complete when commit succeeds\n</code></pre></p> <p>Artifacts created: - Git commit with complete feature - Updated documentation - Changelog entries - Deployment artifacts</p>"},{"location":"user-guide/tdd-workflow/#parallel-tdd-execution","title":"Parallel TDD Execution","text":"<p>Multiple stories can run TDD cycles simultaneously:</p> <pre><code># Start sprint with multiple stories\n/sprint start\n# Automatically creates TDD cycles for AUTH-1, AUTH-2, AUTH-3\n\n# Check status of all TDD cycles\n/tdd overview\n</code></pre> <p>Example output: <pre><code>TDD Cycle Status - Sprint: Authentication System\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Story   \u2502 Phase       \u2502 Progress     \u2502 Agent       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 AUTH-1  \u2502 CODE_GREEN  \u2502 14/15 tests  \u2502 Code Agent  \u2502\n\u2502 AUTH-2  \u2502 REFACTOR    \u2502 Quality OK   \u2502 Code Agent  \u2502 \n\u2502 AUTH-3  \u2502 TEST_RED    \u2502 8 tests      \u2502 QA Agent    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nUse /tdd status &lt;STORY_ID&gt; for detailed information.\n</code></pre></p>"},{"location":"user-guide/tdd-workflow/#tdd-workflow-integration","title":"TDD Workflow Integration","text":""},{"location":"user-guide/tdd-workflow/#sprint-planning-with-tdd","title":"Sprint Planning with TDD","text":"<pre><code># Epic and story creation\n/epic \"Build authentication system\"\n/approve AUTH-1 AUTH-2 AUTH-3\n\n# Sprint planning includes TDD estimates\n/sprint plan AUTH-1 AUTH-2\n# Orchestrator estimates TDD cycle time for each story\n\n# Start sprint activates TDD cycles\n/sprint start\n# Creates parallel TDD state machines for each story\n</code></pre>"},{"location":"user-guide/tdd-workflow/#tdd-error-handling","title":"TDD Error Handling","text":"<pre><code># If TDD cycle gets stuck\n/tdd status AUTH-1\n# Shows: \"AUTH-1 in CODE_GREEN phase - 3 failed CI attempts\"\n\n# Provide guidance to code agent\n/suggest_fix \"The database connection string is incorrect in config.py\"\n\n# Or skip problematic story\n/tdd skip_phase AUTH-1\n# Moves to next phase with manual intervention flag\n</code></pre>"},{"location":"user-guide/tdd-workflow/#human-approval-gates","title":"Human Approval Gates","text":"<pre><code># Request human review at any phase\n/tdd review_cycle AUTH-1\n\n# Approve or request changes\n/approve AUTH-1\n/request_changes \"Need additional error handling for edge cases\"\n</code></pre>"},{"location":"user-guide/tdd-workflow/#tdd-metrics-and-analytics","title":"TDD Metrics and Analytics","text":""},{"location":"user-guide/tdd-workflow/#cycle-time-metrics","title":"Cycle Time Metrics","text":"<pre><code>/tdd metrics\n</code></pre> <p>Example output: <pre><code>TDD Metrics - Last 30 Days\n\nCycle Times (Average):\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Phase       \u2502 Time     \u2502 Success Rate\u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 DESIGN      \u2502 12 min   \u2502 95%         \u2502\n\u2502 TEST_RED    \u2502 18 min   \u2502 88%         \u2502\n\u2502 CODE_GREEN  \u2502 25 min   \u2502 82%         \u2502\n\u2502 REFACTOR    \u2502 15 min   \u2502 91%         \u2502\n\u2502 COMMIT      \u2502 8 min    \u2502 97%         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nQuality Metrics:\n- Test Coverage: 94% (target: 90%)\n- Code Complexity: 6.2 (target: &lt;10)\n- Refactor Frequency: 1.2x per story\n- CI Success Rate: 89%\n</code></pre></p>"},{"location":"user-guide/tdd-workflow/#story-completion-tracking","title":"Story Completion Tracking","text":"<pre><code>/tdd overview --history\n</code></pre> <p>Shows completed TDD cycles with timing and quality metrics.</p>"},{"location":"user-guide/tdd-workflow/#advanced-tdd-features","title":"Advanced TDD Features","text":""},{"location":"user-guide/tdd-workflow/#custom-tdd-profiles","title":"Custom TDD Profiles","text":"<pre><code># Configure TDD parameters for specific story types\n/tdd configure AUTH-1 --coverage-threshold 95 --complexity-limit 8\n\n# Apply profile to story type\n/tdd profile \"API development\" --design-time 15min --test-coverage 90%\n</code></pre>"},{"location":"user-guide/tdd-workflow/#tdd-dependencies","title":"TDD Dependencies","text":"<pre><code># Define story dependencies in TDD cycles\n/tdd depends AUTH-2 AUTH-1\n# AUTH-2 waits for AUTH-1 to complete COMMIT phase\n\n# Check dependency status\n/tdd dependencies\n</code></pre>"},{"location":"user-guide/tdd-workflow/#integration-with-external-tools","title":"Integration with External Tools","text":"<pre><code># Trigger external quality gates\n/tdd gate AUTH-1 --sonarqube --security-scan\n\n# Manual quality gate override\n/tdd override_gate AUTH-1 --justification \"Security scan false positive\"\n</code></pre>"},{"location":"user-guide/tdd-workflow/#troubleshooting-tdd-workflows","title":"Troubleshooting TDD Workflows","text":""},{"location":"user-guide/tdd-workflow/#common-issues","title":"Common Issues","text":"<p>TDD cycle stuck in CODE_GREEN: - Check test failures in CI logs - Use <code>/suggest_fix</code> to provide guidance - Consider <code>/tdd skip_phase</code> if blocked</p> <p>Tests failing after refactor: - Automatic rollback to last green state - Manual intervention with <code>/tdd review_cycle</code> - Adjust refactor scope and retry</p> <p>Design phase taking too long: - Check story complexity and clarity - Use <code>/tdd design_complete</code> to manually advance - Consider story splitting if too complex</p>"},{"location":"user-guide/tdd-workflow/#best-practices","title":"Best Practices","text":"<ol> <li>Monitor TDD Overview: Regularly check <code>/tdd overview</code> for stuck cycles</li> <li>Human Review Gates: Use <code>/tdd review_cycle</code> for complex stories</li> <li>Metrics Tracking: Monitor cycle times and success rates</li> <li>Early Intervention: Address stuck phases quickly to maintain momentum</li> <li>Quality Gates: Don't skip refactor phase for time pressure</li> </ol> <p>The TDD workflow ensures high-quality code delivery while maintaining development velocity through automated RED-GREEN-REFACTOR cycles and human oversight where needed.</p>"},{"location":"user-guide/testing/","title":"Testing and Validation","text":"<p>This guide covers the testing capabilities of the AI Agent TDD-Scrum workflow system, including the real-time visualizer and NO-AGENT mode for state machine validation.</p>"},{"location":"user-guide/testing/#overview","title":"Overview","text":"<p>The system provides two key testing features:</p> <ol> <li>Real-Time Visualizer: WebSocket-based visualization of workflow and TDD state transitions</li> <li>NO-AGENT Mode: Mock agents for testing state machine logic without AI API calls</li> </ol>"},{"location":"user-guide/testing/#real-time-visualizer","title":"Real-Time Visualizer","text":"<p>The real-time visualizer provides live monitoring of workflow states, TDD cycles, and agent activities through a WebSocket interface.</p>"},{"location":"user-guide/testing/#setup","title":"Setup","text":"<ol> <li> <p>Install Dependencies <pre><code>pip install Flask Flask-SocketIO websockets\n</code></pre></p> </li> <li> <p>Start the Visualizer <pre><code># In the visualizer directory\ncd visualizer\npython app.py\n</code></pre></p> </li> <li> <p>Start the State Broadcaster <pre><code># In your orchestrator or as a separate service\nimport asyncio\nfrom lib.state_broadcaster import start_broadcaster\n\nasync def main():\n    await start_broadcaster(port=8080)\n\nasyncio.run(main())\n</code></pre></p> </li> <li> <p>Access the Interface</p> </li> <li>Open your browser to <code>http://localhost:5000</code></li> <li>The visualizer will connect to the WebSocket server on port 8080</li> </ol>"},{"location":"user-guide/testing/#features","title":"Features","text":""},{"location":"user-guide/testing/#workflow-state-monitoring","title":"Workflow State Monitoring","text":"<ul> <li>Real-time display of main workflow states (IDLE \u2192 BACKLOG_READY \u2192 SPRINT_PLANNED \u2192 SPRINT_ACTIVE \u2192 SPRINT_REVIEW)</li> <li>Visual transitions with timestamps</li> <li>Project-specific state tracking</li> </ul>"},{"location":"user-guide/testing/#tdd-cycle-visualization","title":"TDD Cycle Visualization","text":"<ul> <li>Live TDD state transitions (DESIGN \u2192 TEST_RED \u2192 CODE_GREEN \u2192 REFACTOR \u2192 COMMIT)</li> <li>Story-level TDD cycle monitoring</li> <li>Test execution and commit activity</li> </ul>"},{"location":"user-guide/testing/#agent-activity-tracking","title":"Agent Activity Tracking","text":"<ul> <li>Agent task start/complete/failed events</li> <li>Agent coordination and handoffs</li> <li>Performance metrics and timing</li> </ul>"},{"location":"user-guide/testing/#websocket-events","title":"WebSocket Events","text":"<p>The system emits the following event types:</p> <pre><code>// Workflow transitions\n{\n  \"type\": \"workflow_transition\",\n  \"timestamp\": \"2024-01-01T12:00:00Z\",\n  \"project\": \"my-project\",\n  \"old_state\": \"IDLE\",\n  \"new_state\": \"BACKLOG_READY\"\n}\n\n// TDD transitions\n{\n  \"type\": \"tdd_transition\",\n  \"timestamp\": \"2024-01-01T12:00:00Z\",\n  \"project\": \"my-project\",\n  \"story_id\": \"AUTH-1\",\n  \"old_state\": \"DESIGN\",\n  \"new_state\": \"TEST_RED\"\n}\n\n// Agent activity\n{\n  \"type\": \"agent_activity\",\n  \"timestamp\": \"2024-01-01T12:00:00Z\",\n  \"project\": \"my-project\",\n  \"story_id\": \"AUTH-1\",\n  \"agent_type\": \"QAAgent\",\n  \"action\": \"task_execution\",\n  \"status\": \"completed\"\n}\n</code></pre>"},{"location":"user-guide/testing/#no-agent-mode","title":"NO-AGENT Mode","text":"<p>NO-AGENT mode replaces real AI agents with mock implementations, allowing you to test state machine logic, data flow, and integration points without making actual AI API calls.</p>"},{"location":"user-guide/testing/#setup_1","title":"Setup","text":"<ol> <li> <p>Enable NO-AGENT Mode <pre><code>export NO_AGENT_MODE=true\n</code></pre></p> </li> <li> <p>Run the System <pre><code># All agents will now use mock implementations\npython scripts/orchestrator.py\n</code></pre></p> </li> <li> <p>Or Set in Code <pre><code>import os\nos.environ['NO_AGENT_MODE'] = 'true'\n\n# Now create agents - they will be mock agents\nfrom lib.agents import create_agent\nagent = create_agent(\"DesignAgent\")  # Returns MockDesignAgent\n</code></pre></p> </li> </ol>"},{"location":"user-guide/testing/#mock-agent-behavior","title":"Mock Agent Behavior","text":"<p>Mock agents simulate realistic behavior:</p>"},{"location":"user-guide/testing/#execution-times","title":"Execution Times","text":"<ul> <li>Design tasks: 1.5-3 seconds</li> <li>Test tasks: 2-4 seconds  </li> <li>Code tasks: 3-6 seconds</li> <li>Refactor tasks: 2-4 seconds</li> <li>Analysis tasks: 1-2.5 seconds</li> </ul>"},{"location":"user-guide/testing/#failure-simulation","title":"Failure Simulation","text":"<ul> <li>10% random failure rate for testing error handling</li> <li>Realistic error messages and recovery suggestions</li> <li>Proper logging and state transitions</li> </ul>"},{"location":"user-guide/testing/#response-generation","title":"Response Generation","text":"<p>Mock agents generate context-appropriate responses:</p> <pre><code># Design Agent Mock Response\n\"\"\"\nMockDesignAgent: Design specifications completed for AUTH-1\n\n# Mock Technical Specification\n\n## Overview\nMock implementation specifications generated for testing purposes.\n\n## Acceptance Criteria\n- \u2705 Mock criteria 1: Basic functionality validated\n- \u2705 Mock criteria 2: Error handling specifications\n- \u2705 Mock criteria 3: Integration requirements defined\n\"\"\"\n</code></pre>"},{"location":"user-guide/testing/#agent-types-available","title":"Agent Types Available","text":"<p>All agent types have mock implementations:</p> <ul> <li>MockDesignAgent: TDD specification and design</li> <li>MockQAAgent: Failing test creation and validation</li> <li>MockCodeAgent: Implementation and refactoring</li> <li>MockDataAgent: Analytics and reporting</li> </ul>"},{"location":"user-guide/testing/#validation-workflows","title":"Validation Workflows","text":""},{"location":"user-guide/testing/#complete-state-machine-testing","title":"Complete State Machine Testing","text":"<p>Test the entire workflow with mock agents:</p> <pre><code># 1. Enable NO-AGENT mode\nexport NO_AGENT_MODE=true\n\n# 2. Start real-time visualizer\ncd visualizer &amp;&amp; python app.py &amp;\n\n# 3. Start orchestrator with broadcasting\npython scripts/orchestrator.py &amp;\n\n# 4. Run through complete workflow\n# In Discord or via API:\n/epic \"User Authentication System\"\n/sprint plan\n/sprint start\n/tdd start AUTH-1 \"Login endpoint implementation\"\n/tdd design\n/tdd test\n/tdd code\n/tdd refactor\n/tdd commit\n</code></pre>"},{"location":"user-guide/testing/#tdd-cycle-validation","title":"TDD Cycle Validation","text":"<p>Test TDD state machine transitions:</p> <pre><code># Start a TDD cycle\n/tdd start AUTH-1 \"User login endpoint\"\n\n# Follow TDD workflow\n/tdd design      # DESIGN state\n/tdd test        # \u2192 TEST_RED\n/tdd commit-tests # Commit failing tests  \n/tdd code        # \u2192 CODE_GREEN\n/tdd commit-code # Commit implementation\n/tdd refactor    # \u2192 REFACTOR\n/tdd commit-refactor # \u2192 COMMIT\n\n# Check status and logs\n/tdd status\n/tdd logs AUTH-1\n/tdd overview\n</code></pre>"},{"location":"user-guide/testing/#error-handling-testing","title":"Error Handling Testing","text":"<p>Test error conditions and recovery:</p> <pre><code># Test invalid transitions\n/tdd code  # Should fail in DESIGN state\n/tdd refactor  # Should fail before CODE_GREEN\n\n# Test failure recovery (mock agents will occasionally fail)\n# Retry mechanisms and escalation workflows\n\n# Test resource limits\n# Start multiple TDD cycles to test concurrency limits\n</code></pre>"},{"location":"user-guide/testing/#performance-testing","title":"Performance Testing","text":""},{"location":"user-guide/testing/#load-testing-with-mock-agents","title":"Load Testing with Mock Agents","text":"<pre><code># Generate load with multiple concurrent tasks\nimport asyncio\nfrom lib.agents import create_agent\n\nasync def load_test():\n    agents = [create_agent(\"CodeAgent\") for _ in range(10)]\n    tasks = []\n\n    for i, agent in enumerate(agents):\n        task = Task(\n            id=f\"load-test-{i}\",\n            agent_type=\"CodeAgent\", \n            command=f\"Implement feature {i}\",\n            context={\"story_id\": f\"LOAD-{i}\"}\n        )\n        tasks.append(agent.run(task))\n\n    results = await asyncio.gather(*tasks)\n    # Analyze timing and success rates\n\nasyncio.run(load_test())\n</code></pre>"},{"location":"user-guide/testing/#metrics-collection","title":"Metrics Collection","text":"<p>Monitor performance through the visualizer:</p> <ul> <li>Agent execution times</li> <li>State transition frequencies  </li> <li>Error rates and patterns</li> <li>Resource utilization</li> </ul>"},{"location":"user-guide/testing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/testing/#common-issues","title":"Common Issues","text":""},{"location":"user-guide/testing/#visualizer-not-connecting","title":"Visualizer Not Connecting","text":"<pre><code># Check WebSocket server\nnetstat -an | grep 8080\n\n# Check state broadcaster logs\ntail -f logs/state_broadcaster.log\n</code></pre>"},{"location":"user-guide/testing/#mock-agents-not-loading","title":"Mock Agents Not Loading","text":"<pre><code># Verify environment variable\necho $NO_AGENT_MODE\n\n# Check import paths\npython -c \"from lib.agents.mock_agent import MockAgent; print('OK')\"\n</code></pre>"},{"location":"user-guide/testing/#state-broadcasting-fails","title":"State Broadcasting Fails","text":"<pre><code># Check for missing dependencies\npip install websockets\n\n# Verify graceful fallback\npython -c \"from lib.state_machine import StateMachine; sm = StateMachine(); print('OK')\"\n</code></pre>"},{"location":"user-guide/testing/#debug-mode","title":"Debug Mode","text":"<p>Enable detailed logging:</p> <pre><code>import logging\nlogging.basicConfig(level=logging.DEBUG)\n\n# Run with debug logging\npython scripts/orchestrator.py\n</code></pre>"},{"location":"user-guide/testing/#validation-checklist","title":"Validation Checklist","text":"<ul> <li> Real-time visualizer connects and displays states</li> <li> NO-AGENT mode successfully replaces real agents  </li> <li> Mock agents generate realistic responses and timing</li> <li> State machine transitions broadcast correctly</li> <li> TDD cycles complete successfully with mock agents</li> <li> Error handling and recovery workflows function</li> <li> Performance metrics are collected and displayed</li> <li> All integration points work with mock implementations</li> </ul>"},{"location":"user-guide/testing/#integration-testing","title":"Integration Testing","text":""},{"location":"user-guide/testing/#end-to-end-workflow","title":"End-to-End Workflow","text":"<p>Complete integration test with visualization:</p> <ol> <li> <p>Setup Environment <pre><code>export NO_AGENT_MODE=true\npip install Flask Flask-SocketIO websockets\n</code></pre></p> </li> <li> <p>Start Services <pre><code># Terminal 1: Visualizer\ncd visualizer &amp;&amp; python app.py\n\n# Terminal 2: Orchestrator with broadcasting\npython scripts/orchestrator.py\n</code></pre></p> </li> <li> <p>Execute Test Sequence <pre><code># Create epic and stories\n/epic \"Complete Authentication System\"\n/backlog add_story \"User registration endpoint\" \n/backlog add_story \"User login endpoint\"\n/backlog add_story \"Password reset flow\"\n\n# Plan and start sprint\n/sprint plan\n/sprint start\n\n# Execute TDD cycles for each story\n/tdd start AUTH-1 \"Registration endpoint\"\n# ... complete TDD cycle\n\n/tdd start AUTH-2 \"Login endpoint\"  \n# ... complete TDD cycle\n\n# Complete sprint\n/sprint status\n/feedback \"Sprint completed successfully\"\n</code></pre></p> </li> <li> <p>Validate Results</p> </li> <li>Check visualizer shows all transitions</li> <li>Verify state consistency</li> <li>Confirm mock agents executed correctly</li> <li>Review performance metrics</li> </ol> <p>This comprehensive testing approach ensures the system functions correctly at all levels while providing visibility into the workflow execution process.</p>"},{"location":"user-guide/troubleshooting/","title":"Troubleshooting","text":"<p>Common issues and solutions for the AI Agent TDD-Scrum workflow system.</p>"},{"location":"user-guide/troubleshooting/#discord-bot-issues","title":"Discord Bot Issues","text":""},{"location":"user-guide/troubleshooting/#bot-doesnt-respond-to-commands","title":"Bot doesn't respond to commands","text":"<p>Symptoms: Commands are sent but no response from the bot.</p> <p>Solutions: 1. Verify the Discord bot token is set correctly:    <pre><code>echo $DISCORD_BOT_TOKEN\n</code></pre> 2. Check bot permissions in your Discord server:    - Use Slash Commands    - Send Messages    - Embed Links    - Read Message History 3. Ensure the bot was invited with the correct OAuth2 scopes:    - <code>bot</code>    - <code>applications.commands</code></p>"},{"location":"user-guide/troubleshooting/#commands-return-unknown-interaction","title":"Commands return \"Unknown interaction\"","text":"<p>Symptoms: Discord shows \"This interaction failed\" message.</p> <p>Solutions: 1. Restart the bot to refresh slash command registration 2. Wait up to 1 hour for global commands to sync 3. Use guild-specific commands for faster testing</p>"},{"location":"user-guide/troubleshooting/#installation-issues","title":"Installation Issues","text":""},{"location":"user-guide/troubleshooting/#import-errors-or-missing-dependencies","title":"Import errors or missing dependencies","text":"<p>Symptoms: <code>ModuleNotFoundError</code> when running the system.</p> <p>Solutions: 1. Install all dependencies:    <pre><code>pip install -r requirements.txt\n</code></pre> 2. Verify Python version (3.8+ required):    <pre><code>python --version\n</code></pre> 3. Use a virtual environment to avoid conflicts:    <pre><code>python -m venv venv\nsource venv/bin/activate  # Linux/Mac\n# or\nvenv\\Scripts\\activate     # Windows\n</code></pre></p>"},{"location":"user-guide/troubleshooting/#tests-failing","title":"Tests failing","text":"<p>Symptoms: <code>pytest</code> command shows failures.</p> <p>Solutions: 1. Run unit tests only (skip integration tests):    <pre><code>pytest tests/unit/ -v\n</code></pre> 2. Install test dependencies:    <pre><code>pip install pytest pytest-asyncio\n</code></pre> 3. Set required environment variables for integration tests:    <pre><code>export DISCORD_BOT_TOKEN=\"test_token\"\n</code></pre></p>"},{"location":"user-guide/troubleshooting/#state-machine-issues","title":"State Machine Issues","text":""},{"location":"user-guide/troubleshooting/#invalid-command-errors","title":"Invalid command errors","text":"<p>Symptoms: \"Command not allowed in current state\" messages.</p> <p>Solutions: 1. Check current state:    <pre><code>/state\n</code></pre> 2. Follow the proper command sequence:    - <code>IDLE</code> \u2192 <code>/epic</code> \u2192 <code>BACKLOG_READY</code>    - <code>BACKLOG_READY</code> \u2192 <code>/sprint plan</code> \u2192 <code>SPRINT_PLANNED</code>    - <code>SPRINT_PLANNED</code> \u2192 <code>/sprint start</code> \u2192 <code>SPRINT_ACTIVE</code> 3. Use <code>/state</code> to see allowed commands for your current state</p>"},{"location":"user-guide/troubleshooting/#stuck-in-blocked-state","title":"Stuck in blocked state","text":"<p>Symptoms: System shows <code>BLOCKED</code> state and won't accept commands.</p> <p>Solutions: 1. Use <code>/suggest_fix</code> to provide guidance to agents 2. Use <code>/skip_task</code> to abandon the current task 3. Restart the orchestrator if the state becomes corrupted</p>"},{"location":"user-guide/troubleshooting/#agent-issues","title":"Agent Issues","text":""},{"location":"user-guide/troubleshooting/#agents-not-executing-tasks","title":"Agents not executing tasks","text":"<p>Symptoms: Sprint starts but no progress is made.</p> <p>Solutions: 1. Verify Claude Code integration is working:    <pre><code>claude --version\n</code></pre> 2. Check agent permissions and tool access 3. Review orchestrator logs for error messages 4. Ensure project repository is properly configured</p>"},{"location":"user-guide/troubleshooting/#ai-responses-are-too-verbose-or-incorrect","title":"AI responses are too verbose or incorrect","text":"<p>Symptoms: Agents produce low-quality output.</p> <p>Solutions: 1. Provide more specific task descriptions 2. Use <code>/request_changes</code> to guide agent improvements 3. Check that agents have appropriate context about the project 4. Verify the AI model configuration</p>"},{"location":"user-guide/troubleshooting/#configuration-issues","title":"Configuration Issues","text":""},{"location":"user-guide/troubleshooting/#multi-project-setup-not-working","title":"Multi-project setup not working","text":"<p>Symptoms: Only one project is managed, others are ignored.</p> <p>Solutions: 1. Verify project configuration YAML syntax 2. Ensure each project has a unique identifier 3. Check that project paths are accessible 4. Review orchestrator logs for configuration errors</p>"},{"location":"user-guide/troubleshooting/#environment-variables-not-recognized","title":"Environment variables not recognized","text":"<p>Symptoms: \"Environment variable not set\" errors.</p> <p>Solutions: 1. Set variables in your shell profile:    <pre><code>echo 'export DISCORD_BOT_TOKEN=\"your_token\"' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre> 2. Use a <code>.env</code> file for development:    <pre><code>echo 'DISCORD_BOT_TOKEN=your_token' &gt; .env\n</code></pre> 3. Verify variables are set in the current session:    <pre><code>env | grep DISCORD\n</code></pre></p>"},{"location":"user-guide/troubleshooting/#performance-issues","title":"Performance Issues","text":""},{"location":"user-guide/troubleshooting/#slow-response-times","title":"Slow response times","text":"<p>Symptoms: Commands take longer than 30 seconds to respond.</p> <p>Solutions: 1. Check network connectivity to Discord and AI services 2. Reduce the scope of tasks in sprints 3. Monitor system resources (CPU, memory) 4. Consider running fewer concurrent projects</p>"},{"location":"user-guide/troubleshooting/#memory-usage-growing-over-time","title":"Memory usage growing over time","text":"<p>Symptoms: System memory usage increases during operation.</p> <p>Solutions: 1. Restart the orchestrator periodically 2. Monitor for memory leaks in agent processes 3. Reduce the frequency of state saves 4. Clear old log files and temporary data</p>"},{"location":"user-guide/troubleshooting/#tdd-workflow-issues","title":"TDD Workflow Issues","text":""},{"location":"user-guide/troubleshooting/#tdd-state-machine-problems","title":"TDD State Machine Problems","text":"<p>Symptoms: TDD commands return \"not allowed in current state\" errors.</p> <p>Solutions: 1. Check current TDD state for the story:    <pre><code>/tdd status &lt;STORY_ID&gt;\n</code></pre> 2. Follow the proper TDD sequence:    - <code>DESIGN</code> \u2192 <code>/tdd test</code> \u2192 <code>TEST_RED</code>    - <code>TEST_RED</code> \u2192 <code>/tdd commit-tests</code> \u2192 <code>CODE_GREEN</code>    - <code>CODE_GREEN</code> \u2192 <code>/tdd commit-code</code> \u2192 <code>REFACTOR</code>    - <code>REFACTOR</code> \u2192 <code>/tdd commit-refactor</code> \u2192 <code>COMMIT</code> 3. Use <code>/tdd next</code> to auto-advance to the logical next state 4. Check transition conditions with <code>/tdd status --verbose</code></p>"},{"location":"user-guide/troubleshooting/#tdd-cycle-failures","title":"TDD Cycle Failures","text":"<p>Symptoms: TDD cycles get stuck in specific phases without progressing.</p> <p>Common Scenarios:</p> <p>Stuck in TEST_RED: <pre><code># Check if tests are actually failing\n/tdd run_tests &lt;STORY_ID&gt;\n\n# Provide guidance to QA agent\n/suggest_fix \"Tests need to cover edge case for null input\"\n\n# Manual transition if tests are ready\n/tdd commit-tests &lt;STORY_ID&gt;\n</code></pre></p> <p>Stuck in CODE_GREEN: <pre><code># Check test status\n/tdd run_tests &lt;STORY_ID&gt;\n\n# Review failing tests\n/tdd status &lt;STORY_ID&gt; --show-failures\n\n# Provide implementation guidance\n/suggest_fix \"Use bcrypt for password hashing in auth.py\"\n\n# Manual advance if tests are passing\n/tdd commit-code &lt;STORY_ID&gt;\n</code></pre></p> <p>Stuck in REFACTOR: <pre><code># Check if refactoring broke tests\n/tdd run_tests &lt;STORY_ID&gt;\n\n# If tests are broken, automatic rollback occurs\n# Otherwise provide refactoring guidance\n/suggest_fix \"Extract user validation into separate function\"\n\n# Complete refactoring\n/tdd commit-refactor &lt;STORY_ID&gt;\n</code></pre></p>"},{"location":"user-guide/troubleshooting/#test-preservation-problems","title":"Test Preservation Problems","text":"<p>Symptoms: Test files not being preserved or committed properly.</p> <p>Solutions: 1. Check test file status:    <pre><code>/tdd status &lt;STORY_ID&gt; --show-files\n</code></pre> 2. Verify test directory structure:    <pre><code># Should exist: tests/tdd/&lt;story-id&gt;/\n# Check with: ls -la tests/tdd/\n</code></pre> 3. Manual test file commit:    <pre><code>/tdd commit-tests &lt;STORY_ID&gt; --force\n</code></pre> 4. Check test file permissions and git status 5. Verify CI pipeline has access to test files</p>"},{"location":"user-guide/troubleshooting/#agent-coordination-issues-in-tdd","title":"Agent Coordination Issues in TDD","text":"<p>Symptoms: Multiple agents interfering with each other during TDD cycles.</p> <p>Solutions: 1. Check agent assignments:    <pre><code>/tdd status --show-agents\n</code></pre> 2. Pause conflicting cycles:    <pre><code>/tdd pause &lt;STORY_ID&gt;\n</code></pre> 3. Review agent permissions and tool access:    <pre><code># QA Agent should only create tests in TEST_RED\n# Code Agent should only modify implementation in CODE_GREEN/REFACTOR\n</code></pre> 4. Use agent-specific guidance:    <pre><code>/suggest_fix &lt;STORY_ID&gt; --agent QAAgent \"Focus on integration tests\"\n/suggest_fix &lt;STORY_ID&gt; --agent CodeAgent \"Implement authentication logic\"\n</code></pre></p>"},{"location":"user-guide/troubleshooting/#tdd-recovery-procedures","title":"TDD Recovery Procedures","text":"<p>Emergency Recovery: <pre><code># Stop all TDD cycles\n/tdd halt_all --confirm\n\n# Reset specific TDD cycle\n/tdd reset &lt;STORY_ID&gt; --to-state DESIGN\n\n# Restart with preserved data\n/tdd start &lt;STORY_ID&gt; --resume-from-backup\n</code></pre></p> <p>Data Recovery: <pre><code># Check TDD data integrity\n/tdd validate &lt;STORY_ID&gt;\n\n# Restore from backup\n/tdd restore &lt;STORY_ID&gt; --from-timestamp 2024-01-15T10:30:00\n\n# Manual state reconstruction\n/tdd reconstruct &lt;STORY_ID&gt; --from-git-history\n</code></pre></p> <p>Conflict Resolution: <pre><code># When multiple agents modify same files\n/tdd resolve_conflict &lt;STORY_ID&gt; --strategy merge\n/tdd resolve_conflict &lt;STORY_ID&gt; --strategy agent-priority\n/tdd resolve_conflict &lt;STORY_ID&gt; --strategy manual-review\n</code></pre></p>"},{"location":"user-guide/troubleshooting/#cicd-integration-issues","title":"CI/CD Integration Issues","text":"<p>Symptoms: TDD cycles not triggering CI or CI failures blocking progress.</p> <p>Solutions: 1. Check CI status for TDD workflow:    <pre><code>/tdd ci_status &lt;STORY_ID&gt;\n</code></pre> 2. Retry failed CI runs:    <pre><code>/tdd retry_ci &lt;STORY_ID&gt;\n</code></pre> 3. Override CI failures (with justification):    <pre><code>/tdd override_ci &lt;STORY_ID&gt; --reason \"Flaky test infrastructure\"\n</code></pre> 4. Manual CI trigger:    <pre><code>/tdd trigger_ci &lt;STORY_ID&gt; --tests-only\n</code></pre></p>"},{"location":"user-guide/troubleshooting/#test-coverage-issues","title":"Test Coverage Issues","text":"<p>Symptoms: TDD cycles failing due to insufficient test coverage.</p> <p>Solutions: 1. Check coverage metrics:    <pre><code>/tdd coverage &lt;STORY_ID&gt;\n</code></pre> 2. Adjust coverage thresholds:    <pre><code>/tdd configure &lt;STORY_ID&gt; --coverage-threshold 85\n</code></pre> 3. Generate coverage reports:    <pre><code>/tdd coverage_report &lt;STORY_ID&gt; --detailed\n</code></pre> 4. Guidance for improving coverage:    <pre><code>/suggest_fix &lt;STORY_ID&gt; \"Add tests for error handling paths\"\n</code></pre></p>"},{"location":"user-guide/troubleshooting/#performance-issues-in-tdd","title":"Performance Issues in TDD","text":"<p>Symptoms: TDD cycles taking too long or consuming excessive resources.</p> <p>Solutions: 1. Check TDD cycle timing:    <pre><code>/tdd metrics &lt;STORY_ID&gt; --timing\n</code></pre> 2. Optimize test execution:    <pre><code>/tdd configure &lt;STORY_ID&gt; --parallel-tests --test-timeout 30s\n</code></pre> 3. Reduce scope of TDD cycles:    <pre><code>/tdd split &lt;STORY_ID&gt; --max-tasks 3\n</code></pre> 4. Monitor resource usage:    <pre><code>/tdd resources --show-memory --show-cpu\n</code></pre></p>"},{"location":"user-guide/troubleshooting/#tdd-configuration-issues","title":"TDD Configuration Issues","text":"<p>Symptoms: TDD workflows behaving unexpectedly due to configuration problems.</p> <p>Solutions: 1. Validate TDD configuration:    <pre><code>/tdd config validate\n</code></pre> 2. Reset to defaults:    <pre><code>/tdd config reset --confirm\n</code></pre> 3. Export current configuration:    <pre><code>/tdd config export &gt; tdd_config_backup.yml\n</code></pre> 4. Check story-specific overrides:    <pre><code>/tdd config show &lt;STORY_ID&gt;\n</code></pre></p>"},{"location":"user-guide/troubleshooting/#common-error-messages","title":"Common Error Messages","text":"<p>\"TDD cycle not found for story\" - Story may not be in active sprint - Use <code>/sprint status</code> to verify story inclusion - Manually start TDD cycle: <code>/tdd start &lt;STORY_ID&gt;</code></p> <p>\"Tests already committed for this task\" - TDD cycle has already progressed past TEST_RED - Check current state: <code>/tdd status &lt;STORY_ID&gt;</code> - Use <code>/tdd next</code> to advance to next logical state</p> <p>\"No test files found in TDD directory\" - QA Agent may not have created tests yet - Check agent status and logs - Manual test file creation may be needed</p> <p>\"Test preservation directory not accessible\" - File system permissions issue - Check directory ownership and permissions - Verify tests/tdd/ directory exists and is writable</p>"},{"location":"user-guide/troubleshooting/#tdd-debugging-commands","title":"TDD Debugging Commands","text":"<p>Detailed Status: <pre><code>/tdd debug &lt;STORY_ID&gt;\n# Shows complete state machine status, agent assignments, file locations\n</code></pre></p> <p>Trace TDD History: <pre><code>/tdd trace &lt;STORY_ID&gt;\n# Shows complete history of state transitions and commands\n</code></pre></p> <p>Validate TDD Integrity: <pre><code>/tdd integrity_check &lt;STORY_ID&gt;\n# Validates data consistency and file integrity\n</code></pre></p>"},{"location":"user-guide/troubleshooting/#getting-additional-help","title":"Getting Additional Help","text":"<p>If these solutions don't resolve your issue:</p> <ol> <li>Check the logs: Look for error messages in the console output</li> <li>Use debug mode: Run with increased verbosity for more details</li> <li>Review state: Use <code>/state</code> command to understand system status</li> <li>Check TDD state: Use <code>/tdd status &lt;STORY_ID&gt;</code> for TDD-specific issues</li> <li>Search documentation: Check the User Guide and TDD Workflow for command details</li> <li>Report issues: Create an issue on the project repository with:</li> <li>System information (OS, Python version)</li> <li>Complete error messages</li> <li>Steps to reproduce the problem</li> <li>Expected vs actual behavior</li> <li>TDD state and story information (for TDD issues)</li> </ol>"},{"location":"user-guide/user-profile/","title":"User Profile Context: Solo Engineer \u2192 Technical Orchestrator","text":""},{"location":"user-guide/user-profile/#1-persona-snapshot","title":"1. Persona Snapshot","text":"<ul> <li>Name (alias): Solo-Engineer-Manager (SEM)</li> <li>Current Role: Senior individual contributor owning several products across personal and client repos.</li> <li>Aspired Role: Technical orchestrator who delegates low-level implementation to specialist AI agents while focusing on architecture, product direction, and quality.</li> <li>Daily Time Budget: \u2264 2 hrs deep focus + adhoc reviews.</li> <li>Preferred Communication: Concise, decision-ready summaries; markdown tables over long prose; mermaid diagrams for flows.</li> </ul>"},{"location":"user-guide/user-profile/#2-core-goals","title":"2. Core Goals","text":"<ol> <li>Strategic Alignment \u2013 Spend \u2265 70 % of effort on roadmap definition, architecture, and cross-project coherence.</li> <li>Quality Gateway \u2013 Establish rock-solid automated tests &amp; CI so that merged code is production-ready with minimal manual QA.</li> <li>Throughput, not Tickets \u2013 Keep WIP \u2264 2 concurrent initiatives per project; finish before starting new work.</li> <li>Knowledge Scaling \u2013 Capture design decisions &amp; ADRs once, reuse across projects.</li> </ol>"},{"location":"user-guide/user-profile/#3-decision-boundaries-what-the-agents-decide-vs-what-sem-decides","title":"3. Decision Boundaries (What the Agents Decide vs. What SEM Decides)","text":"Area AI Agents Own SEM Retains Task decomposition Break story \u2192 tasks; propose PR titles Approve sprint scope Implementation Write &amp; refactor code/tests Approve architecture-significant changes Debug loop \u2264 3 autonomous attempts Guide after repeated failure Documentation Tech/User docs generation Final voice &amp; tone check Release Draft releases, changelogs Hit publish button <p>Agents should escalate when: * CI fails 3\u00d7 consecutively * Architectural decision alters public contracts * Security-sensitive code is touched</p>"},{"location":"user-guide/user-profile/#4-workflow-principles","title":"4. Workflow Principles","text":"<ol> <li>Trunk-Based Development with short-lived feature branches.</li> <li>TDD First: tests precede production code.</li> <li>Continuous Deployment gated by green CI.</li> <li>Automated Linters &amp; Formatters enforce style; no manual reviews for cosmetics.</li> <li>Backlog \u2260 Dumping Ground: every item must map to a quarterly objective.</li> </ol>"},{"location":"user-guide/user-profile/#5-key-performance-indicators","title":"5. Key Performance Indicators","text":"<ul> <li>PR cycle time \u2264 1 day.</li> <li>Mean time-to-restore (failing main) &lt; 30 min.</li> <li>Test coverage \u2265 90 % critical paths.</li> <li>Zero P1 bugs escaping to production per quarter.</li> </ul>"},{"location":"user-guide/user-profile/#6-tooling-integrations","title":"6. Tooling &amp; Integrations","text":"<ul> <li>Version Control: GitHub.</li> <li>CI/CD: GitHub Actions.</li> <li>Issue Tracking: GitHub Projects, epics \u2192 features \u2192 stories.</li> <li>Communication: Discord bot (#orchestrator) for agent updates.</li> <li>Observability: Sentry + Prometheus (planned).</li> </ul>"},{"location":"user-guide/user-profile/#tdd-workflow-preferences","title":"TDD Workflow Preferences","text":"<ul> <li>Test Quality Gates: Minimum 90% coverage for story completion</li> <li>TDD Cycle Timeouts: Red phase \u2264 5min, Green phase \u2264 15min, Refactor \u2264 10min</li> <li>Auto-commit Policy: Commit after each successful Green phase</li> <li>TDD Notifications: Alert on prolonged Red states (&gt;20min), cycle completion</li> </ul>"},{"location":"user-guide/user-profile/#7-preferred-output-formats-for-agents","title":"7. Preferred Output Formats for Agents","text":"<ul> <li>Status updates: <code>\ud83d\udcc8 Sprint X \u2013 3/5 tasks done, ETA: 2 days</code>.</li> <li>Decisions needed: <code>\u26a0\ufe0f Decision \u2013 PR #42 alters auth schema. Approve?</code>.</li> <li>Reports: Markdown bullet lists; diagrams in Mermaid.</li> </ul> <p>This profile should be loaded at orchestration start-up so every specialist agent inherits the same context &amp; escalation rules. </p>"},{"location":"user-guide/workflow-sequences/","title":"AI Agent TDD-Scrum Workflows \u2013 Dual State Machine (v4)","text":"<p>This file documents the core interaction patterns between the Product Owner (single user) and the AI-powered dual state machine system with integrated TDD workflows.</p>"},{"location":"user-guide/workflow-sequences/#1-enhanced-tdd-scrum-workflow","title":"1. Enhanced TDD-Scrum Workflow","text":"<pre><code>%%{init: {'theme': 'dark'}}%%\nsequenceDiagram\n    title \"Enhanced TDD-Scrum Workflow with Dual State Machines\"\n\n    participant U as \"User (Product Owner)\"\n    participant WSM as \"Workflow State Machine\"\n    participant Coord as \"Multi-Task Coordinator\"\n    box \"TDD Cycle AUTH-1\"\n        participant TDD1 as \"TDD State Machine\"\n        participant DESIGN1 as \"Design Agent\"\n        participant QA1 as \"QA Agent\"\n        participant DEV1 as \"Code Agent\"\n    end\n    box \"TDD Cycle AUTH-2\"\n        participant TDD2 as \"TDD State Machine\"\n        participant DESIGN2 as \"Design Agent\"\n        participant QA2 as \"QA Agent\"\n        participant DEV2 as \"Code Agent\"\n    end\n    participant GH as \"GitHub Repo\"\n    participant CI as \"CI Runner\"\n\n    %% == 1. Vision &amp; Backlog ==\n    U-&gt;&gt;WSM: /epic \"Build auth system\"\n    WSM-&gt;&gt;WSM: Decompose into candidate stories (AUTH-1, AUTH-2)\n    WSM--&gt;&gt;U: \"Proposed stories ready: [AUTH-1, AUTH-2]\"\n\n    U-&gt;&gt;WSM: /approve AUTH-1 AUTH-2\n    WSM-&gt;&gt;WSM: Add stories to product backlog (BACKLOG_READY)\n\n    %% == 2. Sprint Planning ==\n    U-&gt;&gt;WSM: /sprint plan AUTH-1 AUTH-2\n    WSM--&gt;&gt;U: \"Sprint drafted: Auth System\"\n    U-&gt;&gt;WSM: /sprint start\n    WSM-&gt;&gt;WSM: SPRINT_PLANNED \u2192 SPRINT_ACTIVE\n\n    %% == 3. Parallel TDD Execution ==\n    WSM-&gt;&gt;Coord: Create TDD cycles for AUTH-1, AUTH-2\n    Coord-&gt;&gt;TDD1: Initialize TDD cycle for AUTH-1\n    Coord-&gt;&gt;TDD2: Initialize TDD cycle for AUTH-2\n\n    par AUTH-1 TDD Cycle\n        TDD1-&gt;&gt;TDD1: DESIGN phase\n        TDD1-&gt;&gt;DESIGN1: Create auth API specs\n        DESIGN1--&gt;&gt;TDD1: Technical specifications\n\n        TDD1-&gt;&gt;TDD1: TEST_RED phase\n        TDD1-&gt;&gt;QA1: Write failing tests\n        QA1--&gt;&gt;TDD1: test_auth_api.py (failing)\n\n        TDD1-&gt;&gt;TDD1: CODE_GREEN phase\n        TDD1-&gt;&gt;DEV1: Implement to pass tests\n        DEV1--&gt;&gt;TDD1: auth_api.py\n        DEV1-&gt;&gt;GH: Push AUTH-1 implementation\n        GH-&gt;&gt;CI: Run tests for AUTH-1\n        CI--&gt;&gt;TDD1: \u2714 All tests pass\n\n        TDD1-&gt;&gt;TDD1: REFACTOR phase\n        TDD1-&gt;&gt;DEV1: Improve code quality\n        DEV1--&gt;&gt;TDD1: Refactored auth_api.py\n\n        TDD1-&gt;&gt;TDD1: COMMIT phase\n        TDD1-&gt;&gt;DEV1: Final commit for AUTH-1\n        DEV1-&gt;&gt;GH: Commit AUTH-1 complete\n        TDD1--&gt;&gt;Coord: AUTH-1 complete\n\n    and AUTH-2 TDD Cycle\n        TDD2-&gt;&gt;TDD2: DESIGN phase\n        TDD2-&gt;&gt;DESIGN2: Create user model specs\n        DESIGN2--&gt;&gt;TDD2: User model specifications\n\n        TDD2-&gt;&gt;TDD2: TEST_RED phase\n        TDD2-&gt;&gt;QA2: Write failing tests\n        QA2--&gt;&gt;TDD2: test_user_model.py (failing)\n\n        TDD2-&gt;&gt;TDD2: CODE_GREEN phase\n        TDD2-&gt;&gt;DEV2: Implement user model\n        DEV2--&gt;&gt;TDD2: user_model.py\n        DEV2-&gt;&gt;GH: Push AUTH-2 implementation\n        GH-&gt;&gt;CI: Run tests for AUTH-2\n        CI--&gt;&gt;TDD2: \u2714 All tests pass\n\n        TDD2-&gt;&gt;TDD2: REFACTOR phase\n        TDD2-&gt;&gt;DEV2: Optimize user model\n        DEV2--&gt;&gt;TDD2: Optimized user_model.py\n\n        TDD2-&gt;&gt;TDD2: COMMIT phase\n        TDD2-&gt;&gt;DEV2: Final commit for AUTH-2\n        DEV2-&gt;&gt;GH: Commit AUTH-2 complete\n        TDD2--&gt;&gt;Coord: AUTH-2 complete\n    end\n\n    %% == 4. Sprint Completion ==\n    Coord--&gt;&gt;WSM: All TDD cycles complete\n    WSM-&gt;&gt;WSM: SPRINT_ACTIVE \u2192 SPRINT_REVIEW\n    WSM-&gt;&gt;GH: Create Sprint PR\n    WSM--&gt;&gt;U: \"Sprint complete - Review PR #123\"\n\n    U-&gt;&gt;WSM: /feedback \"Great TDD implementation!\"\n    WSM-&gt;&gt;WSM: SPRINT_REVIEW \u2192 IDLE</code></pre>"},{"location":"user-guide/workflow-sequences/#2-backlog-management-flow","title":"2. Backlog Management Flow","text":"<pre><code>%%{init: {'theme': 'dark'}}%%\nsequenceDiagram\n    title \"Backlog Commands\"\n\n    participant U as \"User\"\n    participant BOT as \"Orchestrator\"\n\n    U-&gt;&gt;BOT: /backlog view product\n    BOT--&gt;&gt;U: List stories [AUTH-1, AUTH-2]\n\n    U-&gt;&gt;BOT: /backlog view AUTH-1\n    BOT--&gt;&gt;U: Full details AUTH-1\n\n    U-&gt;&gt;BOT: /backlog add_story \"As a user I can reset my password\" --feature AUTH\n    BOT--&gt;&gt;U: \"Story AUTH-3 created\"\n\n    U-&gt;&gt;BOT: /backlog prioritize AUTH-3 high\n    BOT--&gt;&gt;U: \"AUTH-3 priority set to high\"</code></pre>"},{"location":"user-guide/workflow-sequences/#3-sprint-control-commands","title":"3. Sprint Control Commands","text":"<pre><code>%%{init: {'theme': 'dark'}}%%\nsequenceDiagram\n    title \"Sprint Control\"\n\n    participant U as \"User\"\n    participant BOT as \"Orchestrator\"\n\n    Note over U,BOT: During an active sprint...\n\n    U-&gt;&gt;BOT: /sprint status\n    BOT--&gt;&gt;U: \"Sprint 'Auth-Basic': 2/4 tasks complete\"\n\n    U-&gt;&gt;BOT: /sprint pause\n    BOT-&gt;&gt;BOT: Freeze agent tasks\n    BOT--&gt;&gt;U: \"Sprint paused\"\n\n    U-&gt;&gt;BOT: /sprint resume\n    BOT-&gt;&gt;BOT: Resume tasks\n    BOT--&gt;&gt;U: \"Sprint resumed\"</code></pre>"},{"location":"user-guide/workflow-sequences/#4-tdd-cycle-management","title":"4. TDD Cycle Management","text":"<pre><code>%%{init: {'theme': 'dark'}}%%\nsequenceDiagram\n    title \"Individual TDD Cycle Control\"\n\n    participant U as \"User\"\n    participant TDD as \"TDD State Machine\"\n    participant DESIGN as \"Design Agent\"\n    participant QA as \"QA Agent\"\n    participant CODE as \"Code Agent\"\n\n    U-&gt;&gt;TDD: /tdd status AUTH-1\n    TDD--&gt;&gt;U: \"AUTH-1 in DESIGN phase\"\n\n    TDD-&gt;&gt;DESIGN: Create specifications\n    DESIGN--&gt;&gt;TDD: Technical specs complete\n    TDD-&gt;&gt;TDD: DESIGN \u2192 TEST_RED\n\n    TDD-&gt;&gt;QA: Write failing tests\n    QA--&gt;&gt;TDD: 12 failing tests written\n\n    U-&gt;&gt;TDD: /tdd review_cycle AUTH-1\n    TDD--&gt;&gt;U: \"Review request: 12 tests ready for implementation\"\n    U-&gt;&gt;TDD: /approve\n\n    TDD-&gt;&gt;TDD: TEST_RED \u2192 CODE_GREEN\n    TDD-&gt;&gt;CODE: Implement to pass tests\n    CODE--&gt;&gt;TDD: Implementation complete\n\n    U-&gt;&gt;TDD: /tdd status AUTH-1\n    TDD--&gt;&gt;U: \"AUTH-1 in REFACTOR phase - quality gates met\"\n\n    TDD-&gt;&gt;TDD: REFACTOR \u2192 COMMIT\n    TDD-&gt;&gt;CODE: Final commit\n    CODE--&gt;&gt;TDD: Story complete</code></pre>"},{"location":"user-guide/workflow-sequences/#5-parallel-tdd-monitoring","title":"5. Parallel TDD Monitoring","text":"<pre><code>%%{init: {'theme': 'dark'}}%%\nsequenceDiagram\n    title \"Multi-Story TDD Coordination\"\n\n    participant U as \"User\"\n    participant Coord as \"Coordinator\"\n    participant TDD_A as \"TDD AUTH-1\"\n    participant TDD_B as \"TDD AUTH-2\"\n    participant TDD_C as \"TDD AUTH-3\"\n\n    U-&gt;&gt;Coord: /tdd overview\n    Coord-&gt;&gt;TDD_A: Get status\n    Coord-&gt;&gt;TDD_B: Get status\n    Coord-&gt;&gt;TDD_C: Get status\n\n    TDD_A--&gt;&gt;Coord: \"CODE_GREEN - 14/15 tests\"\n    TDD_B--&gt;&gt;Coord: \"REFACTOR - applying patterns\"\n    TDD_C--&gt;&gt;Coord: \"DESIGN - creating specs\"\n\n    Coord--&gt;&gt;U: Display parallel progress table\n\n    Note over U,Coord: User sees all TDD cycles at once\n\n    U-&gt;&gt;Coord: /tdd pause AUTH-2\n    Coord-&gt;&gt;TDD_B: Pause cycle\n    TDD_B--&gt;&gt;Coord: \"AUTH-2 paused in REFACTOR\"\n\n    U-&gt;&gt;Coord: /suggest_fix \"AUTH-2 needs error handling for async flows\"\n    Coord-&gt;&gt;TDD_B: Apply suggestion\n\n    U-&gt;&gt;Coord: /tdd resume AUTH-2\n    Coord-&gt;&gt;TDD_B: Resume with guidance\n    TDD_B--&gt;&gt;Coord: \"AUTH-2 resumed in REFACTOR\"</code></pre>"},{"location":"user-guide/workflow-sequences/#6-tdd-error-handling-and-recovery","title":"6. TDD Error Handling and Recovery","text":"<pre><code>%%{init: {'theme': 'dark'}}%%\nsequenceDiagram\n    title \"TDD Cycle Error Recovery\"\n\n    participant U as \"User\"\n    participant TDD as \"TDD State Machine\"\n    participant CODE as \"Code Agent\"\n    participant CI as \"CI System\"\n\n    TDD-&gt;&gt;CODE: Implement feature (attempt 1)\n    CODE-&gt;&gt;CI: Push implementation\n    CI--&gt;&gt;TDD: \u274c Tests fail\n\n    TDD-&gt;&gt;CODE: Fix tests (attempt 2)\n    CODE-&gt;&gt;CI: Push fix\n    CI--&gt;&gt;TDD: \u274c Tests fail\n\n    TDD-&gt;&gt;CODE: Fix tests (attempt 3)\n    CODE-&gt;&gt;CI: Push fix\n    CI--&gt;&gt;TDD: \u274c Tests fail\n\n    TDD--&gt;&gt;U: \"AUTH-1 blocked in CODE_GREEN after 3 attempts\"\n\n    alt User provides guidance\n        U-&gt;&gt;TDD: /suggest_fix \"Database connection timeout in tests\"\n        TDD-&gt;&gt;CODE: Apply suggestion\n        CODE-&gt;&gt;CI: Push with fix\n        CI--&gt;&gt;TDD: \u2705 Tests pass\n        TDD-&gt;&gt;TDD: CODE_GREEN \u2192 REFACTOR\n    else User skips phase\n        U-&gt;&gt;TDD: /tdd skip_phase AUTH-1\n        TDD-&gt;&gt;TDD: CODE_GREEN \u2192 REFACTOR (manual override)\n    else User requests review\n        U-&gt;&gt;TDD: /tdd review_cycle AUTH-1\n        TDD--&gt;&gt;U: \"Manual review requested for AUTH-1\"\n        Note over U,TDD: Human review and intervention\n    end</code></pre>"},{"location":"user-guide/workflow-sequences/#7-debug-rework-loop-condensed","title":"7. Debug &amp; Rework Loop (Condensed)","text":"<pre><code>%%{init: {'theme': 'dark'}}%%\nsequenceDiagram\n    title \"Debug Loop\"\n\n    participant BOT as \"Orchestrator\"\n    participant DEV as \"Code Agent\"\n    participant GH as \"GitHub\"\n    participant CI as \"CI Runner\"\n    participant U as \"User\"\n\n    BOT-&gt;&gt;DEV: \"Fix CI failure (attempt 1)\"\n    loop Up to 3 attempts\n        DEV--&gt;&gt;BOT: patch.diff\n        BOT-&gt;&gt;GH: push\n        GH-&gt;&gt;CI: test\n        CI--&gt;&gt;BOT: \u2716\n        BOT-&gt;&gt;DEV: \"Fix again\"\n    end\n\n    BOT--&gt;&gt;U: \"Task blocked after 3 attempts\"\\nChoose: /suggest_fix or /skip_task</code></pre>"}]}